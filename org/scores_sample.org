#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session sample_decoder :kernel dual_data :output-dir ./figures/scores :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_named_steps["model"]

    norm_w = np.linalg.norm(coef)

    if IF_SIGN:
        # dot_product = (2*y_test -1) * np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)
        dot_product = (2*y_test -1) * clf.decision_function(X_test)
    else:
        dot_product = clf.decision_function(X_test)
        # dot_product = -np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)

    return np.nanmean(dot_product) / coef.shape[0] / norm_w
#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['probas_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

    # lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
    # upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_mat(X, ax, vmin=-1, vmax=1):
  im = ax.imshow(
    X,
    interpolation="lanczos",
    origin="lower",
    cmap="jet",
    extent=[0, 14, 0, 14],
    vmin=vmin,
    vmax=vmax,
  )

  add_vdashed(ax)
  ax.set_xlim([2, 12])
  ax.set_xticks([2, 4, 6, 8, 10, 12])
  ax.set_ylim([2, 12])
  ax.set_yticks([2, 4, 6, 8, 10, 12])

  ax.set_xlabel("Testing Time (s)")
  ax.set_ylabel("Training Time (s)")
  return im
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt

def add_vdashed(ax=None, mouse=""):
    # Define time intervals
    t_STIM = [2, 3]
    t_DIST = [4.5, 5.5]
    t_CUE = [6.5, 7]
    t_TEST = [9, 10]

    # Add vertical dashed lines and text labels for each interval
    if ax is not None:
        # Draw vertical lines
        for t in [t_STIM, t_DIST, t_TEST]:
            ax.axvline(x=t[0], linestyle='--', color='k', lw=2)
            ax.axvline(x=t[1], linestyle='--', color='k', lw=2)

            ax.axhline(y=t[0], linestyle='--', color='k', lw=2)
            ax.axhline(y=t[1], linestyle='--', color='k', lw=2)

        # Add text labels at the middle of each interval
        ax.text((t_STIM[0] + t_STIM[1]) / 2, 12.5, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_DIST[0] + t_DIST[1]) / 2, 12.5, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        # ax.text((t_CUE[0] + t_CUE[1]) / 2, 12.5, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_TEST[0] + t_TEST[1]) / 2, 12.5, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)

        ax.text(12.5, (t_STIM[0] + t_STIM[1]) / 2, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        ax.text(12.5, (t_DIST[0] + t_DIST[1]) / 2, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        # ax.text(12.5, (t_CUE[0] + t_CUE[1]) / 2, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)
        ax.text(12.5, (t_TEST[0] + t_TEST[1]) / 2, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)

#+end_src

#+RESULTS:

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title=''):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12']
  # mice = ['PP09', 'PP17']
  # mice = 'JawsM15'

  kwargs = {
      'mouse': mice[0], 'laser': 0,
      'trials': '', 'reload': 1, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 5, 'n_repeats': 16,
      'class_weight': 0,
      'multilabel':1,
      'mne_estimator':'generalizing', # sliding or generalizing
      'n_jobs': 128,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  safe_f1 = make_scorer(safe_f1_score, needs_proba=True)

  options['hp_scoring'] = lambda estimator, X_test, y_test: np.abs(overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1))
  # options['hp_scoring'] = 'accuracy'
  #   options['scoring'] = options['hp_scoring']

  dum = 'accuracy_loocv'
 #+end_src

#+RESULTS:

* Decoding vs days

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
#+end_src

#+RESULTS:

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', n_jobs=None, tol=0.001, class_weight='balanced')
# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-2, 2, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = 'accuracy'
options['scoring'] = 'accuracy'
# options['scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)

# options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
# options['scoring'] = options['hp_scoring']

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)

options['cv'] = LeaveOneOut()
# options['cv'] = None
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0
options['multilabel']= 0
options['features'] = 'sample'
options['epochs'] = ['ED']

tasks = ['DPA', 'DualGo', 'DualNoGo']
dfs = []

Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']
new_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'ChRM23']
mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
#+end_src

#+RESULTS:

#+begin_src ipython
for mouse in mice:

    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    if mouse in new_mice:
        options['reload'] = 0
        options['NEW_DATA'] = 1
    else:
        options['reload'] = 0
        options['NEW_DATA'] = 0

    options['task'] = 'all'

    for day in days:
        options['day'] = day
        overlaps = get_classification(model, RETURN='df_scores', **options)
        options['reload'] = 0
        df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse

    dfs.append(df_mouse)

df_sample = pd.concat(dfs)
print(df_sample.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (43, 184, 84) X_S2 (29, 184, 84)
X_B (72, 184, 84) y_B (72,) [0. 1.] ['DualGo' 'DPA' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (101, 184, 84) X_S2 (115, 184, 84)
y_labels (216, 13) ['DualNoGo' 'DualGo' 'DPA']
X (216, 184, 84) nans 0.0 y (216,) [0. 1.]
df_A (216, 14) scores (216, 7056) labels (216, 13)
scores_B (72, 84, 84)
df_B (72, 14) scores (72, 7056) labels (72, 13)
df (288, 14)
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (2, 184, 84) X_S2 (3, 184, 84)
X_B (5, 184, 84) y_B (5,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (46, 184, 84) X_S2 (45, 184, 84)
y_labels (91, 13) ['DualNoGo' 'DualGo' 'DPA']
X (91, 184, 84) nans 0.0 y (91,) [0. 1.]
df_A (91, 14) scores (91, 7056) labels (91, 13)
scores_B (5, 84, 84)
df_B (5, 14) scores (5, 7056) labels (5, 13)
df (96, 14)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (59, 201, 84) X_S2 (46, 201, 84)
X_B (105, 201, 84) y_B (105,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (85, 201, 84) X_S2 (98, 201, 84)
y_labels (183, 13) ['DualNoGo' 'DualGo' 'DPA']
X (183, 201, 84) nans 0.0 y (183,) [0. 1.]
df_A (183, 14) scores (183, 7056) labels (183, 13)
scores_B (105, 84, 84)
df_B (105, 14) scores (105, 7056) labels (105, 13)
df (288, 14)
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (27, 201, 84) X_S2 (13, 201, 84)
X_B (40, 201, 84) y_B (40,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (117, 201, 84) X_S2 (131, 201, 84)
y_labels (248, 13) ['DPA' 'DualGo' 'DualNoGo']
X (248, 201, 84) nans 0.0 y (248,) [0. 1.]
df_A (248, 14) scores (248, 7056) labels (248, 13)
scores_B (40, 84, 84)
df_B (40, 14) scores (40, 7056) labels (40, 13)
df (288, 14)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (55, 423, 84) X_S2 (51, 423, 84)
X_B (106, 423, 84) y_B (106,) [0. 1.] ['DualGo' 'DPA' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (89, 423, 84) X_S2 (93, 423, 84)
y_labels (182, 13) ['DPA' 'DualGo' 'DualNoGo']
X (182, 423, 84) nans 0.0 y (182,) [0. 1.]
df_A (182, 14) scores (182, 7056) labels (182, 13)
scores_B (106, 84, 84)
df_B (106, 14) scores (106, 7056) labels (106, 13)
df (288, 14)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (27, 423, 84) X_S2 (24, 423, 84)
X_B (51, 423, 84) y_B (51,) [0. 1.] ['DualNoGo' 'DPA' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (69, 423, 84) X_S2 (72, 423, 84)
y_labels (141, 13) ['DPA' 'DualGo' 'DualNoGo']
X (141, 423, 84) nans 0.0 y (141,) [0. 1.]
df_A (141, 14) scores (141, 7056) labels (141, 13)
scores_B (51, 84, 84)
df_B (51, 14) scores (51, 7056) labels (51, 13)
df (192, 14)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (49, 693, 84) X_S2 (44, 693, 84)
X_B (93, 693, 84) y_B (93,) [0. 1.] ['DPA' 'DualGo' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (95, 693, 84) X_S2 (100, 693, 84)
y_labels (195, 15) ['DualNoGo' 'DualGo' 'DPA']
X (195, 693, 84) nans 0.0 y (195,) [0. 1.]
df_A (195, 16) scores (195, 7056) labels (195, 15)
scores_B (93, 84, 84)
df_B (93, 16) scores (93, 7056) labels (93, 15)
df (288, 16)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (20, 693, 84) X_S2 (19, 693, 84)
X_B (39, 693, 84) y_B (39,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (124, 693, 84) X_S2 (125, 693, 84)
y_labels (249, 15) ['DualGo' 'DualNoGo' 'DPA']
X (249, 693, 84) nans 0.0 y (249,) [0. 1.]
df_A (249, 16) scores (249, 7056) labels (249, 15)
scores_B (39, 84, 84)
df_B (39, 16) scores (39, 7056) labels (39, 15)
df (288, 16)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (27, 444, 84) X_S2 (26, 444, 84)
X_B (53, 444, 84) y_B (53,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (117, 444, 84) X_S2 (118, 444, 84)
y_labels (235, 15) ['DualNoGo' 'DualGo' 'DPA']
X (235, 444, 84) nans 0.0 y (235,) [0. 1.]
df_A (235, 16) scores (235, 7056) labels (235, 15)
scores_B (53, 84, 84)
df_B (53, 16) scores (53, 7056) labels (53, 15)
df (288, 16)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (3, 444, 84) X_S2 (2, 444, 84)
X_B (5, 444, 84) y_B (5,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (141, 444, 84) X_S2 (142, 444, 84)
y_labels (283, 15) ['DualGo' 'DualNoGo' 'DPA']
X (283, 444, 84) nans 0.0 y (283,) [0. 1.]
df_A (283, 16) scores (283, 7056) labels (283, 15)
scores_B (5, 84, 84)
df_B (5, 16) scores (5, 7056) labels (5, 15)
df (288, 16)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (25, 668, 84) X_S2 (29, 668, 84)
X_B (54, 668, 84) y_B (54,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (119, 668, 84) X_S2 (115, 668, 84)
y_labels (234, 15) ['DualNoGo' 'DPA' 'DualGo']
X (234, 668, 84) nans 0.0 y (234,) [0. 1.]
df_A (234, 16) scores (234, 7056) labels (234, 15)
scores_B (54, 84, 84)
df_B (54, 16) scores (54, 7056) labels (54, 15)
df (288, 16)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (12, 668, 84) X_S2 (12, 668, 84)
X_B (24, 668, 84) y_B (24,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (132, 668, 84) X_S2 (132, 668, 84)
y_labels (264, 15) ['DualNoGo' 'DualGo' 'DPA']
X (264, 668, 84) nans 0.0 y (264,) [0. 1.]
df_A (264, 16) scores (264, 7056) labels (264, 15)
scores_B (24, 84, 84)
df_B (24, 16) scores (24, 7056) labels (24, 15)
df (288, 16)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
X_days (960, 232, 84) y_days (960, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (51, 232, 84) X_S2 (39, 232, 84)
X_B (90, 232, 84) y_B (90,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (93, 232, 84) X_S2 (105, 232, 84)
y_labels (198, 13) ['DualGo' 'DPA' 'DualNoGo']
X (198, 232, 84) nans 0.0 y (198,) [0. 1.]
df_A (198, 14) scores (198, 7056) labels (198, 13)
scores_B (90, 84, 84)
df_B (90, 14) scores (90, 7056) labels (90, 13)
df (288, 14)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
X_days (960, 232, 84) y_days (960, 12)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (26, 232, 84) X_S2 (21, 232, 84)
X_B (47, 232, 84) y_B (47,) [0. 1.] ['DualNoGo' 'DPA' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (70, 232, 84) X_S2 (75, 232, 84)
y_labels (145, 13) ['DualNoGo' 'DualGo' 'DPA']
X (145, 232, 84) nans 0.0 y (145,) [0. 1.]
df_A (145, 14) scores (145, 7056) labels (145, 13)
scores_B (47, 84, 84)
df_B (47, 14) scores (47, 7056) labels (47, 13)
df (192, 14)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
X_days (960, 361, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (100, 361, 84) X_S2 (104, 361, 84)
X_B (204, 361, 84) y_B (204,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (188, 361, 84) X_S2 (184, 361, 84)
y_labels (372, 15) ['DPA' 'DualGo' 'DualNoGo']
X (372, 361, 84) nans 0.0 y (372,) [0. 1.]
df_A (372, 16) scores (372, 7056) labels (372, 15)
scores_B (204, 84, 84)
df_B (204, 16) scores (204, 7056) labels (204, 15)
df (576, 16)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
X_days (960, 361, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (16, 361, 84) X_S2 (19, 361, 84)
X_B (35, 361, 84) y_B (35,) [0. 1.] ['DualGo' 'DPA' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (176, 361, 84) X_S2 (173, 361, 84)
y_labels (349, 15) ['DualNoGo' 'DualGo' 'DPA']
X (349, 361, 84) nans 0.0 y (349,) [0. 1.]
df_A (349, 16) scores (349, 7056) labels (349, 15)
scores_B (35, 84, 84)
df_B (35, 16) scores (35, 7056) labels (35, 15)
df (384, 16)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
X_days (960, 113, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (120, 113, 84) X_S2 (124, 113, 84)
X_B (244, 113, 84) y_B (244,) [0. 1.] ['DualNoGo' 'DPA' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (168, 113, 84) X_S2 (164, 113, 84)
y_labels (332, 15) ['DualNoGo' 'DPA' 'DualGo']
X (332, 113, 84) nans 0.0 y (332,) [0. 1.]
df_A (332, 16) scores (332, 7056) labels (332, 15)
scores_B (244, 84, 84)
df_B (244, 16) scores (244, 7056) labels (244, 15)
df (576, 16)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
X_days (960, 113, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (49, 113, 84) X_S2 (52, 113, 84)
X_B (101, 113, 84) y_B (101,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (143, 113, 84) X_S2 (140, 113, 84)
y_labels (283, 15) ['DualGo' 'DPA' 'DualNoGo']
X (283, 113, 84) nans 0.0 y (283,) [0. 1.]
df_A (283, 16) scores (283, 7056) labels (283, 15)
scores_B (101, 84, 84)
df_B (101, 16) scores (101, 7056) labels (101, 15)
df (384, 16)
(5568, 17)
#+end_example

#+begin_src ipython
df_sample['performance'] = df_sample['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_sample['pair'] = df_sample['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
 #+end_src

 #+RESULTS:

 #+begin_src ipython
if len(days)>3:
    name = 'df_sample_%s_days' % dum
elif len(days)==2:
    name = 'df_sample_%s_early_late' % dum
else:
    name = 'df_sample_%s' % dum

if len(mice)==1:
    pkl_save(df_sample, '%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    pkl_save(df_sample, '%s' % name, path="../data/mice/%s_PP" % dum)
else:
    pkl_save(df_sample, '%s' % name, path="../data/mice/%s" % dum)

#+end_src

#+RESULTS:
: saving to ../data/mice/accuracy_loocv/df_sample_accuracy_loocv_early_late.pkl

#+begin_src ipython

#+end_src

#+RESULTS:

* Sample dfs

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_sample_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_sample_%s_early_late' % dum
else:
    name = 'df_sample_%s' % dum

if len(mice)==1:
    df_sample = pkl_load('%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    df_sample = pkl_load('%s' % name, path="../data/mice/%s_ACC" % dum)
else:
    df_sample = pkl_load('%s' % name, path="../data/mice/%s" % dum)
#+end_src

#+RESULTS:
: loading from ../data/mice/accuracy_loocv/df_sample_accuracy_loocv_early_late.pkl

#+begin_src ipython
try:
    size=84
    df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(size, size) ))
except:
    size=115
    df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(size, size) ))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size).T , **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_sample.copy()

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True)

sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['b', 'g', 'r'], ax=ax[0])
df=df[df.performance==1]
# df = df[df.response=='correct_rej']

sns.lineplot(data=df, x='day', y='overlaps_diag_LD', hue='tasks', marker='o', legend=0, palette=['b', 'g', 'r'], ax=ax[1])
sns.lineplot(data=df, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['b', 'g', 'r'], ax=ax[2])

plt.xlabel('Day')
plt.ylabel('Sample Accuracy')
plt.savefig('./figs/sample_accuracy_LD.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/scores/figure_28.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_sample.copy()
df = df[df.performance==1]

plot_overlaps(df, 'first', 'ED', ax[0], size=size, y0=1/2.)
plot_overlaps(df, 'last', 'ED', ax[1],size=size, y0=1/2.)

ax[0].set_ylabel('Sample Accuracy')
ax[0].set_title('Naive')
ax[1].set_title('Expert')

ax[0].set_xlim([0, 12])
ax[0].set_ylim([0.4, 1.0])

plt.savefig('./figs/sample_accuracy.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/scores/figure_29.png]]

#+begin_src ipython
df = df_sample.copy()
# df = df[df.response=='correct_rej']
plot_overlaps_mat(df, 'last', vmin=0.5, vmax=1, title='Sample')
#+end_src

#+RESULTS:
[[./figures/scores/figure_30.png]]

#+begin_src ipython
df = df_sample.copy()
df = df[df.laser==0]
df = df[df.pair==0]
# df = df[df.day=='first']

sns.lineplot(data=df, x='performance', y='overlaps_ED_LD', hue='tasks', marker='o', legend=1, palette=['b', 'g'])

plt.xlabel('Trial')
plt.ylabel('Sample Accuracy')
plt.legend(fontsize=10)
# plt.ylim([.5, 1])
plt.xticks([0, 1], ['Incorrect', 'Correct'])
# plt.title('Middle')
# plt.savefig('figures/icrm/dpa_vs_gng_perf.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/scores/figure_31.png]]

#+begin_src ipython
df_sample.keys()
#+end_src

#+RESULTS:
: Index(['index', 'sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response',
:        'laser', 'day', 'choice', 'odr_perf', 'odr_choice', 'odr_response',
:        'idx', 'overlaps', 'mouse', 'performance', 'pair', 'overlaps_diag',
:        'overlaps_ED', 'overlaps_ED_LD', 'overlaps_diag_LD'],
:       dtype='object')
