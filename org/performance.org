#+TITLE: Performance in the Dual Task
#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session performance :kernel dual_data

* Imports

#+begin_src ipython
  import seaborn as sns
  import sys
  sys.path.insert(0, '../')
  from src.performance.perf_tasks import run_perf_tasks
  from src.common.fig_grid import create_grid
  from src.common.options import set_options
#+end_src

#+RESULTS:

* Notebook Settings

#+begin_src ipython
    %load_ext autoreload
    %autoreload 2
    %reload_ext autoreload

    %run /home/leon/dual_task/dual_data/notebooks/setup.py
    %matplotlib inline
    %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
:RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python
: <Figure size 600x370.82 with 0 Axes>
:END:

#+begin_src ipython
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

* Performance

#+begin_src ipython
# mice = ['JawsM15']
mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
# mice = ['AP02', 'AP12', 'PP09']
# mice = ['PP09','PP17', 'RP13']

tasks = ['DPA', "DualGo", 'DualNoGo']
perf_type = 'correct'

perf_mice = []
for mouse in mice:
    perf_ = []
    for perf_type in ['correct', 'correct_rej', 'correct_hit']:
        print('mouse', mouse, 'perf', perf_type)
        perf, ci = run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='all', tasks=tasks)
        perf_.append(perf)

    while np.array(perf_).shape[-1] !=6:
        perf_ = np.append(perf_, np.nan * np.zeros((3, len(tasks), 1)), axis=-1)

    perf_mice.append(perf_)

perf_mice = np.array(perf_mice)
print(perf_mice.shape)
#+end_src

#+RESULTS:
#+begin_example
mouse JawsM01 perf correct
mouse JawsM01 perf correct_rej
mouse JawsM01 perf correct_hit
mouse JawsM06 perf correct
mouse JawsM06 perf correct_rej
mouse JawsM06 perf correct_hit
mouse JawsM12 perf correct
mouse JawsM12 perf correct_rej
mouse JawsM12 perf correct_hit
mouse JawsM15 perf correct
mouse JawsM15 perf correct_rej
mouse JawsM15 perf correct_hit
mouse JawsM18 perf correct
mouse JawsM18 perf correct_rej
mouse JawsM18 perf correct_hit
mouse ChRM04 perf correct
mouse ChRM04 perf correct_rej
mouse ChRM04 perf correct_hit
mouse ChRM23 perf correct
mouse ChRM23 perf correct_rej
mouse ChRM23 perf correct_hit
mouse ACCM03 perf correct
mouse ACCM03 perf correct_rej
mouse ACCM03 perf correct_hit
mouse ACCM04 perf correct
mouse ACCM04 perf correct_rej
mouse ACCM04 perf correct_hit
(9, 3, 3, 6)
#+end_example

#+begin_src ipython
pkl_save(perf_mice, './data/perf_mice.pkl')
print(perf_mice.shape)
#+end_src

#+RESULTS:
: (9, 3, 3, 6)

#+begin_src ipython
pal = ['r', 'b', 'g']
tasks = ['DPA', 'DualGo', 'DualNoGo']

days = np.arange(1, 7)
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

labels = ['DPA Performance', 'Correct Rej.', 'Hits']

for i in range(3):
   for j in range(3):
      mean_perf = np.nanmean(perf_mice[:, i, j], axis=0)
      sem_perf = np.nanstd(perf_mice[:, i, j], axis=0) / np.sqrt(perf_mice.shape[0])

      ax[i].plot(days, mean_perf, '-o', color=pal[j], label=tasks, ms=10)
      ax[i].fill_between(days, mean_perf - sem_perf, mean_perf + sem_perf, alpha=0.1, color=pal[j])
      ax[i].set_ylabel('DPA Performance')

      ax[i].set_ylabel(labels[i])

   ax[i].plot([1, 6], [.5, .5], '--k')
   ax[i].set_xlabel('Day')
   ax[i].set_xticks([1, 2, 3, 4, 5, 6])

   ax[i].set_ylim([0.45, 1.05])

   ax[i].set_yticks([0.5, 0.75, 1.0])

ax[1].set_ylim([0.25, 1.05])
plt.savefig('./figures/perf/perf_mice.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7cbc78b11289006e18e45d56c02970c32013082a.png]]

#+begin_src ipython
pal = ['r', 'b', 'g']
tasks = ['DPA', 'DualGo', 'DualNoGo']

n_mice = perf_mice.shape[0]
days = np.arange(1, 7)
fig, ax = plt.subplots(n_mice, 3, figsize=[3*width, n_mice*height])

labels = ['DPA Performance', 'Correct Rej.', 'Hits']

for k in range(n_mice):
   for i in range(3):
      for j in range(3):
         mean_perf = perf_mice[k, i, j]
         # sem_perf = np.nanstd(perf_mice[:, i, j], axis=0)

         ax[k][i].plot(days, mean_perf, '-o', color=pal[j], label=tasks, ms=10)
         # ax[k][i].fill_between(days, mean_perf - sem_perf, mean_perf + sem_perf, alpha=0.1, color=pal[j])
         ax[k][i].set_ylabel('DPA Performance')

         ax[k][i].set_ylabel(labels[i])

      ax[k][i].plot([1, 6], [.5, .5], '--k')
      ax[k][i].set_xlabel('Day')
      ax[k][i].set_xticks([1, 2, 3, 4, 5, 6])

      ax[k][i].set_ylim([0.45, 1.05])

      ax[k][i].set_yticks([0.5, 0.75, 1.0])

   ax[k][1].set_ylim([0.0, 1.05])

plt.savefig('./figures/perf/perf_idv.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/4b1d602e1a196779edad8ae633424faf304dc758.png]]

#+begin_src ipython

#+end_src

* GLM

#+begin_src ipython
kwargs = {'mice': mice}
options = set_options(**kwargs)
print(options['mice'])
#+end_src

#+RESULTS:
: ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']

#+begin_src ipython
from src.common.get_data import get_X_y_mice
options['reload'] = 1
X, y = get_X_y_mice(**options)
#+end_src

#+RESULTS:
#+begin_example
/storage/leon/dual_task/data//JawsM01/SamedROI_04Days/Day01/DFF_Data01.mat
mouse JawsM01 n_days 4 day 1 type dF all data: X (192, 184, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM01/SamedROI_04Days/Day02/DFF_Data01.mat
mouse JawsM01 n_days 4 day 2 type dF all data: X (192, 184, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM01/SamedROI_04Days/Day03/DFF_Data01.mat
mouse JawsM01 n_days 4 day 3 type dF all data: X (192, 184, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM01/SamedROI_04Days/Day04/DFF_Data01.mat
mouse JawsM01 n_days 4 day 4 type dF all data: X (192, 184, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM06/SamedROI_06Days/Day01/DFF_Data01.mat
mouse JawsM06 n_days 6 day 1 type dF all data: X (192, 201, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM06/SamedROI_06Days/Day02/DFF_Data01.mat
mouse JawsM06 n_days 6 day 2 type dF all data: X (192, 201, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM06/SamedROI_06Days/Day03/DFF_Data01.mat
mouse JawsM06 n_days 6 day 3 type dF all data: X (192, 201, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM06/SamedROI_06Days/Day04/DFF_Data01.mat
mouse JawsM06 n_days 6 day 4 type dF all data: X (192, 201, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM06/SamedROI_06Days/Day05/DFF_Data01.mat
mouse JawsM06 n_days 6 day 5 type dF all data: X (192, 201, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM06/SamedROI_06Days/Day06/DFF_Data01.mat
mouse JawsM06 n_days 6 day 6 type dF all data: X (192, 201, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM12/SamedROI_05Days/Day01/DFF_Data01.mat
mouse JawsM12 n_days 5 day 1 type dF all data: X (192, 423, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM12/SamedROI_05Days/Day02/DFF_Data01.mat
mouse JawsM12 n_days 5 day 2 type dF all data: X (192, 423, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM12/SamedROI_05Days/Day03/DFF_Data01.mat
mouse JawsM12 n_days 5 day 3 type dF all data: X (192, 423, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM12/SamedROI_05Days/Day04/DFF_Data01.mat
mouse JawsM12 n_days 5 day 4 type dF all data: X (192, 423, 115) y (192, 13)
/storage/leon/dual_task/data//JawsM12/SamedROI_05Days/Day05/DFF_Data01.mat
mouse JawsM12 n_days 5 day 5 type dF all data: X (192, 423, 115) y (192, 13)
mouse JawsM15 n_days 6 day 1 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 2 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 3 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 4 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 5 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 6 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM18 n_days 6 day 1 type dF all data: X (192, 444, 84) y (9, 192)
mouse JawsM18 n_days 6 day 2 type dF all data: X (192, 444, 84) y (9, 192)
mouse JawsM18 n_days 6 day 3 type dF all data: X (192, 444, 84) y (9, 192)
mouse JawsM18 n_days 6 day 4 type dF all data: X (192, 444, 84) y (9, 192)
mouse JawsM18 n_days 6 day 5 type dF all data: X (192, 444, 84) y (9, 192)
mouse JawsM18 n_days 6 day 6 type dF all data: X (192, 444, 84) y (9, 192)
mouse ChRM04 n_days 6 day 1 type dF all data: X (192, 668, 84) y (9, 192)
mouse ChRM04 n_days 6 day 2 type dF all data: X (192, 668, 84) y (9, 192)
mouse ChRM04 n_days 6 day 3 type dF all data: X (192, 668, 84) y (9, 192)
mouse ChRM04 n_days 6 day 4 type dF all data: X (192, 668, 84) y (9, 192)
mouse ChRM04 n_days 6 day 5 type dF all data: X (192, 668, 84) y (9, 192)
mouse ChRM04 n_days 6 day 6 type dF all data: X (192, 668, 84) y (9, 192)
/storage/leon/dual_task/data//ChRM23/SamedROI_05Days/Day01/DFF_Data01.mat
mouse ChRM23 n_days 5 day 1 type dF all data: X (192, 232, 115) y (192, 13)
/storage/leon/dual_task/data//ChRM23/SamedROI_05Days/Day02/DFF_Data01.mat
mouse ChRM23 n_days 5 day 2 type dF all data: X (192, 232, 115) y (192, 13)
/storage/leon/dual_task/data//ChRM23/SamedROI_05Days/Day03/DFF_Data01.mat
mouse ChRM23 n_days 5 day 3 type dF all data: X (192, 232, 115) y (192, 13)
/storage/leon/dual_task/data//ChRM23/SamedROI_05Days/Day04/DFF_Data01.mat
mouse ChRM23 n_days 5 day 4 type dF all data: X (192, 232, 115) y (192, 13)
/storage/leon/dual_task/data//ChRM23/SamedROI_05Days/Day05/DFF_Data01.mat
mouse ChRM23 n_days 5 day 5 type dF all data: X (192, 232, 115) y (192, 13)
mouse ACCM03 n_days 5 day 1 type dF all data: X (192, 361, 84) y (9, 192)
mouse ACCM03 n_days 5 day 2 type dF all data: X (192, 361, 84) y (9, 192)
mouse ACCM03 n_days 5 day 3 type dF all data: X (192, 361, 84) y (9, 192)
mouse ACCM03 n_days 5 day 4 type dF all data: X (192, 361, 84) y (9, 192)
mouse ACCM03 n_days 5 day 5 type dF all data: X (192, 361, 84) y (9, 192)
mouse ACCM04 n_days 5 day 1 type dF all data: X (192, 113, 84) y (9, 192)
mouse ACCM04 n_days 5 day 2 type dF all data: X (192, 113, 84) y (9, 192)
mouse ACCM04 n_days 5 day 3 type dF all data: X (192, 113, 84) y (9, 192)
mouse ACCM04 n_days 5 day 4 type dF all data: X (192, 113, 84) y (9, 192)
mouse ACCM04 n_days 5 day 5 type dF all data: X (192, 113, 84) y (9, 192)
#+end_example

#+begin_src ipython
  print(y.keys())
  print(y['mouse'].unique())
  print(y['response'].unique())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response', 'laser',
:        'day', 'choice', 'pair', 'odr_perf', 'odr_choice', 'odr_response',
:        'odor_pair', 'mouse', 'performance'],
:       dtype='object')
: ['JawsM01' 'JawsM06' 'JawsM12' 'JawsM15' 'JawsM18' 'ChRM04' 'ChRM23'
:  'ACCM03' 'ACCM04']
: ['correct_hit' 'incorrect_fa' 'correct_rej' 'incorrect_miss']

#+begin_src ipython
  df = y[y['laser']==0].copy()
  df['behavior'] = df['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
  df['learning'] = df['day'].apply(lambda x: 0 if x<4 else 1)
  print(df.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response', 'laser',
:        'day', 'choice', 'pair', 'odr_perf', 'odr_choice', 'odr_response',
:        'odor_pair', 'mouse', 'performance', 'behavior', 'learning'],
:       dtype='object')

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:
#+begin_example
During startup - Warning messages:
1: package ‘methods’ was built under R version 4.4.3
2: package ‘datasets’ was built under R version 4.4.3
3: package ‘utils’ was built under R version 4.4.3
4: package ‘grDevices’ was built under R version 4.4.3
5: package ‘graphics’ was built under R version 4.4.3
6: package ‘stats’ was built under R version 4.4.3
R[write to console]: In addition:
R[write to console]: Warning message:
R[write to console]: package ‘tools’ was built under R version 4.4.3
#+end_example

#+begin_src ipython
formula = 'performance ~ tasks * learning  + (1 | mouse)'
df_ = df[df.pair==0]

model = Lmer(formula=formula, data=df_, family='binomial')
results = model.fit();
random_effects = model.ranef

print(results)
#+end_src

#+RESULTS:
#+begin_example
,**NOTE**: Column for 'residuals' not created in model.data, but saved in model.resid only. This is because you have rows with NaNs in your data.

,**NOTE** Column for 'fits' not created in model.data, but saved in model.fits only. This is because you have rows with NaNs in your data.

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*learning+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 2784	 Groups: {'mouse': 5.0}

Log-likelihood: -991.858 	 AIC: 1997.716

Random effects:

              Name    Var   Std
mouse  (Intercept)  0.608  0.78

No random effect correlations specified

Fixed effects:

                        Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)                0.347  -0.376    1.070  0.369  1.415      0.687
tasksDualGo               -0.556  -0.884   -0.227  0.168  0.574      0.413
tasksDualNoGo             -0.014  -0.340    0.312  0.166  0.986      0.712
learning                   1.552   1.144    1.960  0.208  4.722      3.140
tasksDualGo:learning       0.115  -0.441    0.671  0.284  1.122      0.643
tasksDualNoGo:learning    -0.153  -0.718    0.413  0.289  0.858      0.488

                        OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                  2.915  0.586        0.407         0.745   0.941
tasksDualGo                  0.797  0.365        0.292         0.443  -3.314
tasksDualNoGo                1.367  0.497        0.416         0.577  -0.083
learning                     7.100  0.825        0.758         0.877   7.458
tasksDualGo:learning         1.956  0.529        0.392         0.662   0.405
tasksDualNoGo:learning       1.511  0.462        0.328         0.602  -0.529

                        P-val  Sig
(Intercept)             0.347
tasksDualGo             0.001  ***
tasksDualNoGo           0.934
learning                0.000  ***
tasksDualGo:learning    0.685
tasksDualNoGo:learning  0.597
#+end_example

#+begin_src ipython
def generate_colors(N, cmap_name='viridis'):
    cmap = plt.get_cmap(cmap_name)
    return cmap(np.linspace(0, 1, N))
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_betas(results, random_effects, title):

    fig, ax = plt.subplots(figsize=(1.5*width, 1.5*height))

    colors = generate_colors(random_effects.shape[0], 'plasma')
    space = np.random.normal(0, .05, random_effects.shape[0])

    keys = results.Estimate.keys()

    for i, key in enumerate(keys):
        res = results.Estimate[key]

        try:
            res += random_effects[key]
        except:
            res += random_effects['(Intercept)']
            pass

        mean_value = res.mean()
        std_dev = res.std()

        if results['P-val'][key]<0.001:
            plt.text(i,   2, '***', ha='center', va='bottom')
        elif results['P-val'][key]<0.01:
            plt.text(i,   2, '**', ha='center', va='bottom')
        elif results['P-val'][key]<0.05:
            plt.text(i,  2 , '*', ha='center', va='bottom')
        elif results['P-val'][key]<0.1:
            plt.text(i,   2, '.', ha='center', va='bottom')

        plt.scatter(i * np.ones(res.shape[0]) + space, res, color=colors)
        plt.plot(i, mean_value, '_k', ms=20)
        plt.errorbar(i * np.ones(res.shape[0]),
                     [mean_value]*len(res),
                     yerr=[std_dev]*len(res), fmt='-', color='k', capsize=15)

    plt.axhline(y=0, color='black', ls='--')

    plt.xticks(np.arange(len(keys)), keys, fontsize=14, rotation=45)

    plt.ylabel('$\\beta$')
    plt.title(title)
    plt.savefig('beta_response.svg')
    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
plot_betas(results, random_effects, '')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b450b71b486fc8dc91c504e33f9286a157eba2bf.png]]

#+begin_src ipython
import statsmodels.api as sm
import statsmodels.formula.api as smf
import pandas as pd
import matplotlib.pyplot as plt


def plot_glm_coefs(df, formula, family=sm.families.Gaussian()):
    # Fit GLM
    glm = smf.glm(formula=formula, data=df, family=family)
    result = glm.fit()

    # Prepare DataFrame
    coefs = result.params
    conf = result.conf_int()
    pvals = result.pvalues

    coef_df = pd.DataFrame({
        'coef': coefs,
        'ci_lower': conf[0],
        'ci_upper': conf[1],
        'pval': pvals
    })


    coef_df['signif'] = coef_df['pval'].map(
        lambda p: '***' if p < 0.001 else
        '**' if p < 0.01 else
        '*' if p < 0.05 else
        '·' if p < 0.1 else
        ''
    )

    coef_df = coef_df.reset_index().rename(columns={'index': 'term'})

    # Plot
    fig, ax = plt.subplots(figsize=(1.5*width, 1.5*height))
    sns.pointplot(x='term', y='coef', data=coef_df, join=False, ax=ax, scale=0.3)

    ax.errorbar(
        x=range(len(coef_df)),
        y=coef_df['coef'],
        yerr=[coef_df['coef'] - coef_df['ci_lower'], coef_df['ci_upper'] - coef_df['coef']],
        fmt='none', c='gray',
    )

    for i, star in enumerate(coef_df['signif']):
        if star:
            plt.text(i, coef_df['ci_upper'].iloc[i] + 0.02, star, ha='center', color='k', fontsize=15)

    plt.axhline(0, color='black', linewidth=0.7, linestyle='--')
    plt.ylabel('Coefficient')
    plt.xticks(rotation=45, fontsize=10)
    plt.ylim([-.2, 1])
    plt.tight_layout()
    plt.show()

    return result  # Optionally return the model fit for further inspection
#+end_src

#+RESULTS:

#+begin_src ipython
formula = 'performance ~ tasks * learning'
df_ = df[df.pair==0]
result = plot_glm_coefs(df_, formula)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e5d9ebf05407640f2e4f7d5d67cf16e84dcfa4f2.png]]

#+begin_src ipython
print(result.summary())
#+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:            performance   No. Observations:                 1824
Model:                            GLM   Df Residuals:                     1818
Model Family:                Gaussian   Df Model:                            5
Link Function:               Identity   Scale:                         0.20759
Method:                          IRLS   Log-Likelihood:                -1151.3
Date:                Thu, 09 Oct 2025   Deviance:                       377.40
Time:                        13:13:03   Pearson chi2:                     377.
No. Iterations:                     3   Pseudo R-squ. (CS):             0.1210
Covariance Type:            nonrobust
==============================================================================================
                                 coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------------
Intercept                      0.5268      0.025     21.193      0.000       0.478       0.576
tasks[T.DualGo]               -0.1190      0.035     -3.387      0.001      -0.188      -0.050
tasks[T.DualNoGo]             -0.0030      0.035     -0.085      0.933      -0.072       0.066
learning                       0.3041      0.037      8.183      0.000       0.231       0.377
tasks[T.DualGo]:learning       0.0565      0.053      1.076      0.282      -0.046       0.160
tasks[T.DualNoGo]:learning    -0.0191      0.053     -0.363      0.717      -0.122       0.084
==============================================================================================
#+end_example
