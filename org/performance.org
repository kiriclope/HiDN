#+TITLE: Performance in the Dual Task
#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session performance :kernel dual_data

* Notebook Settings
#+begin_src ipython
    %load_ext autoreload
    %autoreload 2
    %reload_ext autoreload

    %run /home/leon/dual_task/dual_data/notebooks/setup.py
    %matplotlib inline
    %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')
  from src.performance.perf_tasks import run_perf_tasks
  from src.common.fig_grid import create_grid
  from src.common.options import set_options
#+end_src

#+RESULTS:

* Performance
** Parameters

#+begin_src ipython
  mouse = 'JawsM01'
  perf_type = 'correct'
  tasks = ["DPA", 'DualGo', 'DualNoGo']
  options = set_options()
  options['reload'] = 0
  options['verbose'] = 1
#+end_src

#+RESULTS:

** Single Mouse

#+begin_src ipython
  tasks = ['DPA', "DualGo", 'DualNoGo']
  run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='AB', tasks=tasks, pal=options['pal'])
  plt.show()
#+end_src

#+RESULTS:
: DPA 768 (768, 11) (128, 11)
: DualGo 768 (768, 11) (128, 11)


[[./.ob-jupyter/c08c81afadcca60d38ba64122761f403595ca94e.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
: ba54c79d-3f5c-4f53-834d-05459f23058e

#+begin_src ipython
  options = set_options()
  tasks = ["DualGo"]
  perf_A = run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='A', tasks=tasks, pal=options['pal'])
  options['pal'][1] = options['pal'][0]
  perf_B = run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='B', tasks=tasks, pal=options['pal'])
  plt.show()
#+end_src

#+RESULTS:
: 9b5462f1-75bb-4d43-9bb7-0c8042d378b4

#+begin_src ipython

#+end_src

#+RESULTS:
: dceb6149-e0ec-4f51-a68a-9e1b768f6822

#+begin_src ipython
  # print(perf_A.shape)
  # print(perf_B.shape)
  # print(np.stack((perf_A, perf_B)).shape)
  Delta_perf = perf_A - perf_B

  plt.plot(np.mean(Delta_perf,0))
  plt.show()
#+end_src

#+RESULTS:
: 5cb4fd6b-6036-40e3-9e97-4b3165b38533


#+begin_example
  loading files from /home/leon/dual_task/src.data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN 0 AVG NOISE True UNIT VAR False
  ##########################################
  DPA 960 (960, 6) (160, 6)
  DualGo 960 (960, 6) (160, 6)
  DualNoGo 960 (960, 6) (160, 6)
  loading files from /home/leon/dual_task/src.data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN 0 AVG NOISE True UNIT VAR False
  ##########################################
  DPA 960 (960, 6) (160, 6)
  DualGo 960 (960, 6) (160, 6)
#+end_example


#+begin_src ipython
  # print(perf_A.shape)
  # print(perf_B.shape)
  # print(np.stack((perf_A, perf_B)).shape)
  Delta_perf = perf_A - perf_B

  plt.plot(np.mean(Delta_perf,0))
  plt.show()
#+end_src

#+RESULTS:
: aaa1f3fc-f199-4a30-a3e3-f58878a9929b

** All Mice

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04', 'JawsM01', 'JawsM06', 'JawsM12', 'ChRM23']
  # mice = ['AP02', 'AP12', 'PP09']
  # mice = ['PP09','PP17', 'RP13']
  # mice = ['ChRM04','JawsM15', 'JawsM18']

  perf_type = 'correct'

  perfs = []

  for mouse in mice:
      print(mouse)
      perf = np.array(run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='all', tasks=tasks, pal=options['pal']))
      plt.close('all')

      while perf.shape[-1] !=6:
          perf = np.append(perf, np.nan * np.zeros((3, 1)), axis=-1)

      print(perf.shape)
      perfs.append(perf)

  perfs = np.array(perfs)
  print(perfs.shape)
#+end_src

#+RESULTS:
#+begin_example
ChRM04
DPA 1152 (1152, 13) (192, 13)
DualGo 1152 (1152, 13) (192, 13)
DualNoGo 1152 (1152, 13) (192, 13)
(3, 6)
JawsM15
DPA 1152 (1152, 13) (192, 13)
DualGo 1152 (1152, 13) (192, 13)
DualNoGo 1152 (1152, 13) (192, 13)
(3, 6)
JawsM18
DPA 1152 (1152, 13) (192, 13)
DualGo 1152 (1152, 13) (192, 13)
DualNoGo 1152 (1152, 13) (192, 13)
(3, 6)
ACCM03
DPA 960 (960, 13) (320, 13)
DualGo 960 (960, 13) (320, 13)
DualNoGo 960 (960, 13) (320, 13)
(3, 6)
ACCM04
DPA 960 (960, 13) (320, 13)
DualGo 960 (960, 13) (320, 13)
DualNoGo 960 (960, 13) (320, 13)
(3, 6)
JawsM01
DPA 768 (768, 11) (128, 11)
DualGo 768 (768, 11) (128, 11)
DualNoGo 768 (768, 11) (128, 11)
(3, 6)
JawsM06
DPA 1152 (1152, 11) (192, 11)
DualGo 1152 (1152, 11) (192, 11)
DualNoGo 1152 (1152, 11) (192, 11)
(3, 6)
JawsM12
DPA 960 (960, 11) (160, 11)
DualGo 960 (960, 11) (160, 11)
DualNoGo 960 (960, 11) (160, 11)
(3, 6)
ChRM23
DPA 960 (960, 11) (160, 11)
DualGo 960 (960, 11) (160, 11)
DualNoGo 960 (960, 11) (160, 11)
(3, 6)
(9, 3, 6)
#+end_example

#+begin_src ipython
print(perfs.shape)
#+end_src

#+RESULTS:
: (9, 3, 6)

#+begin_src ipython
    from scipy import stats

    mean_perf = np.nanmean(perfs, 0)
    sem = stats.sem(perfs, axis=0, nan_policy='omit')
    # Number of comparisons
    num_tests = perfs.shape[1]  # This is the number of confidence intervals you are calculating

    # Family-wise Confidence Level (for all tests)
    family_confidence_level = 0.95

    # Per-comparison Confidence Level for Bonferroni correction
    bonferroni_confidence_level = 1 - (1 - family_confidence_level) / num_tests

    # Calculate the t-statistic for the Bonferroni-adjusted confidence level
    t_stat = stats.t.ppf((1 + bonferroni_confidence_level) / 2., perfs.shape[0] - 1)

    # Calculate the Bonferroni-corrected CI for each time point
    ci_bound = sem * t_stat
    print(mean_perf.shape, ci_bound.shape)
#+end_src

#+RESULTS:
: (3, 6) (3, 6)

#+begin_src ipython
  from src.common.options import set_options
  opts = set_options()
#+end_src

#+RESULTS:

*** perf

#+begin_src ipython
  opts['pal'] = ['r', 'b', 'g']
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = np.arange(1, 7)
  fig, ax = plt.subplots()

  ci_bound[:, -1] = ci_bound[:, -2]
  for i in range(3):
      plt.plot(days, mean_perf[i], '-o', color=opts['pal'][i], label=tasks[i], ms=10)
      plt.fill_between(days,
                       mean_perf[i] - ci_bound[i]/5,
                       mean_perf[i] + ci_bound[i]/5,
                       alpha=0.1, color=opts['pal'][i])

  plt.xlabel('Day')

  plt.ylabel('Performance')
  plt.ylim([0.5, 1])
  plt.yticks([.5, .75, 1])

  plt.xticks([1, 2, 3, 4, 5, 6])
  legend = ax.legend(loc='lower right', fontsize=14, frameon=0)
  bbox = legend.get_window_extent().transformed(ax.transAxes.inverted())
  text_y_coord = bbox.y1 + 0.1  # Add a small offset above the legend
  plt.plot([1, 6], [.5, .5], '--k')
  # Add text above the legend
  ax.text(1.0, text_y_coord, 'n=%d' % perfs.shape[0],
          verticalalignment='bottom',
          horizontalalignment='right',
          transform=ax.transAxes)

  plt.savefig('../figs/perf/performance_all_mice.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/dee7b9f610ed541afff1d10e6d921a38bab57db4.png]]

*** hits

#+begin_src ipython
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = np.arange(1, 7)
  fig, ax = plt.subplots()

  for i in range(3):
      plt.plot(days, mean_perf[i], '-o', color=opts['pal'][i], label=tasks[i])
      plt.fill_between(days,
                       mean_perf[i] - ci_bound[i]/5,
                       mean_perf[i] + ci_bound[i]/5,
                       alpha=0.1, color=opts['pal'][i])

  plt.xlabel('Day')

  plt.ylabel('Hits')
  plt.ylim([0.5, 1])
  plt.yticks([.5, .75, 1])

  plt.xticks([1, 2, 3, 4, 5, 6])
  legend = ax.legend(loc='lower right', fontsize=14, frameon=0)
  bbox = legend.get_window_extent().transformed(ax.transAxes.inverted())
  text_y_coord = bbox.y1 + 0.1  # Add a small offset above the legend
  plt.plot([1, 6], [.5, .5], '--k')
  # Add text above the legend
  ax.text(1.0, text_y_coord, 'n=5     ',
          verticalalignment='bottom',
          horizontalalignment='right',
          transform=ax.transAxes)

  plt.savefig('../figs/perf/hits_all_mice.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/01b2ae215f47bf7d40e6736a0722cba6048b61c3.png]]

*** fa

#+begin_src ipython
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = np.arange(1, 7)
  fig, ax = plt.subplots()
  opts['pal'] = ['r', 'b', 'g']
  for i in range(3):
      plt.plot(days, mean_perf[i], '-o', color=opts['pal'][i], label=tasks[i], ms=10)
      plt.fill_between(days,
                       mean_perf[i] - ci_bound[i]/5,
                       mean_perf[i] + ci_bound[i]/5,
                       alpha=0.1, color=opts['pal'][i])

  plt.xlabel('Day')

  if 'fa' in perf_type:
      plt.ylabel('False Alarms')
      plt.ylim([0., 1])
      plt.yticks([0, .25, .5, .75, 1])

  plt.xticks([1, 2, 3, 4, 5, 6])
  legend = ax.legend(loc='upper right', fontsize=14, frameon=0)
  bbox = legend.get_window_extent().transformed(ax.transAxes.inverted())
  text_y_coord = bbox.y1 + 0.1  # Add a small offset above the legend
  plt.plot([1, 6], [.5, .5], '--k')
  # Add text above the legend
  ax.text(1.0, text_y_coord, 'n=9     ',
          verticalalignment='bottom',
          horizontalalignment='right',
          transform=ax.transAxes)

  if 'fa' in perf_type:
      plt.savefig('../figs/perf/fa_all_mice.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/8d2a1db12e34134932ed6786d8d7d25a3a8c1cc1.png]]

* GLM

#+begin_src ipython
  options = set_options()
#+end_src

#+RESULTS:
: c707d18a-1774-4ce4-b2eb-7d7133d28fc5

#+begin_src ipython
  from src.common.get_data import get_X_y_mice
  options['reload']=0
  X, y = get_X_y_mice(**options)
#+end_src

#+RESULTS:
: ff2ed982-aee6-4ea3-bf76-4e1d39f82f99

#+begin_src ipython
  print(y.keys())
  print(y['mouse'].unique())
  print(y['response'].unique())
#+end_src

#+RESULTS:
: bc5ed88a-5293-40f7-a97c-75f74b7fb1fb

#+begin_src ipython
  df = y[y['laser']==0].copy()
  df['behavior'] = df['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
  df['learning'] = df['day'].apply(lambda x: 0 if x<4 else 1)
  print(df.keys())
#+end_src

#+RESULTS:
: b0a5ada4-6cd1-44e0-8b0c-7304ed6e4d67


#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf
  import pandas as pd
#+end_src

#+RESULTS:
: b1bc2c31-b5a3-424c-ac38-f6bcef9d95a1

#+begin_src ipython
  print(df.keys())
#+end_src

#+RESULTS:
: 129484c8-2fbb-4b0e-8260-5693523b65ee

#+begin_src ipython
  df['response'] = df['response'].astype('category')
  df['mouse'] = df['mouse'].astype('category')
  # df['tasks'] = df['tasks'].astype('category')
#+end_src

#+RESULTS:
: e404bbfb-9808-4487-b5be-2f08fcda05a4

#+begin_src ipython
  print(df['tasks'].unique())
#+end_src

#+RESULTS:
: 8979d2f6-5e24-4df7-afd9-73aa7ab0e25c

#+begin_src ipython
  from statsmodels.stats.anova import anova_lm
  formula = 'behavior ~ tasks * tasks'
  results = []
  anovas = []
  df2 = df[df['tasks']!='DualNoGo'].copy()
  df2['tasks'] = df2['tasks'].astype('category')
  print(df2['tasks'].unique())

  df2 = df2[(df2['response']=='incorrect_fa') | (df2['response'] == 'correct_rej')].copy()
  for i in range(5):
      df3 = df2[df2['day']==i+1].copy()
      model = smf.glm(formula=formula, data=df3, family=sm.families.Gaussian())
      results.append(model.fit())
#+end_src

#+RESULTS:
: 9c8bf9fe-2d41-4141-9345-bf1cf78aa1d0

#+begin_src ipython
  colors = ['r', 'b', 'g']
  fig, ax = plt.subplots(1, 1)
  for j in range(5):

      model = results[j]
      params = model.params
      # print(params)
      conf = model.conf_int()
      # print(conf)
      for i in range(2):
          yerr = np.array([params[i] - conf[0][i], conf[1][i] - params[i]])[:, np.newaxis]
          ax.errorbar(x=j, y=params[i], yerr=yerr, fmt='o', color=colors[i])

  plt.show()
#+end_src

#+RESULTS:
: 2374fae7-1620-4fd5-87de-aed0091fef02

#+begin_src ipython
      model = results[3]
      print(model.summary())
#+end_src

#+RESULTS:
: 3d70c1e3-f25c-4129-b9db-bfb8d3ade389


#+begin_src ipython
  df2 = df[(df['response']=='incorrect_fa') | (df['response'] == 'correct_rej')].copy()
  formula = 'behavior ~ tasks * day'
  glm_gauss = smf.glm(formula=formula, data=df2, family=sm.families.Gaussian())
  result = glm_gauss.fit()
  print(result.summary())
#+end_src

#+RESULTS:
: 44607f4f-a53a-48c4-95be-3521d52cd792

#+begin_src ipython
  params = model.params
  conf = model.conf_int()
  print(conf[1])
#+end_src

#+RESULTS:
: aa191c26-e493-47ff-a490-b978149632a6

#+begin_src ipython
  fig, ax = plt.subplots(1, 1)
  for i in range(3):
      ax.errorbar(x=days, y=params[i], yerr=[params[i] - conf[0][i], conf[1][i] - params[i]], fmt='o')

#+end_src

#+RESULTS:
: 127b0f9e-731a-4f51-8706-9ca1752a5737

#+begin_src ipython
    formula = 'behavior ~ tasks * learning'
    glm_gauss = smf.glm(formula=formula, data=df, family=sm.families.Gaussian())
    result = glm_gauss.fit()
    print(result.summary())
#+end_src

#+RESULTS:
: 739846cd-5f6e-456c-aad6-17677575a2bd

#+begin_src ipython
    formula = 'behavior ~ tasks'
    glm_gauss = smf.glm(formula=formula, data=df, family=sm.families.Gaussian())
    result = glm_gauss.fit()
    print(result.summary())
#+end_src

#+RESULTS:
: 3fd1fee4-9e2b-4c0c-94bc-9a70ed40d6dd

#+begin_src ipython
  import statsmodels.formula.api as smf
  import matplotlib.pyplot as plt
  import pandas as pd
  import numpy as np

  # Assuming you have a DataFrame named df containing your data
  # and the formula you mentioned.
  model = smf.glm(formula='behavior ~ tasks * day', data=df).fit()

  # Extract the parameters (weights) and standard errors
  params = model.params
  conf = model.conf_int()
  conf['mean'] = params
  conf.columns = ['2.5%', '97.5%', 'mean']

  # Create a plot for each task
  tasks = df['tasks'].unique()
  days = df['day'].unique()
  n_tasks = len(tasks)
  n_days = len(days)

  fig, ax = plt.subplots(n_tasks, 1, figsize=(8, n_tasks * 4))

  if n_tasks == 1:
      ax = [ax]  # Ensure ax is iterable when there's only one task

  for i, task in enumerate(tasks):
      task_params = conf.loc[[f'tasks[T.{task}]:day[T.{day}]' for day in days], :]

      # If any main effects exist, add them too
      if f'tasks[T.{task}]' in conf.index:
          task_main = conf.loc[f'tasks[T.{task}]']
          task_params.loc[:, 'mean'] += task_main['mean']
          task_params.loc[:, '2.5%'] += task_main['2.5%']
          task_params.loc[:, '97.5%'] += task_main['97.5%']
      if 'Intercept' in conf.index:
          intercept = conf.loc['Intercept']
          task_params.loc[:, 'mean'] += intercept['mean']
          task_params.loc[:, '2.5%'] += intercept['2.5%']
          task_params.loc[:, '97.5%'] += intercept['97.5%']

      ax[i].errorbar(x=days, y=task_params['mean'], yerr=[task_params['mean'] - task_params['2.5%'], task_params['97.5%'] - task_params['mean']], fmt='o')
      ax[i].set_title(f'Task: {task}')
      ax[i].set_xlabel('Day')
      ax[i].set_ylabel('Weight')

  plt.tight_layout()
  plt.show()
#+end_src

#+RESULTS:
: d9b1366a-7393-4ce7-8bfe-8d4844300d83

* Summary

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04', 'AP02', 'AP12', 'PP09','PP17', 'RP13']

  def figname(mouse):
      return mouse + "_behavior_tasks_correct" + ".svg"

  figlist = ['../figs/' + figname(mouse) for mouse in mice]
  print(figlist)

  golden_ratio = (5**.5 - 1) / 2
  width = 4.3
  height = width * golden_ratio * 1.4
  figsize = [width, height]
  matplotlib.rcParams['lines.markersize'] = 5.5

  create_grid(figlist, "../figs/performance_all_mice.svg", dim=[4,3], fontsize=22)

#+end_src

#+RESULTS:
: fc1d198a-739c-4fc5-9df3-ea02bf11e240

#+NAME: fig:temporal_decoding
#+CAPTION: Temporal Decoding
#+ATTR_ORG: :width 1200
#+ATTR_LATEX: :width 5in
[[file:../figs/performance_all_mice.svg]]
