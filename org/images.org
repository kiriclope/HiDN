#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session overlaps :kernel dual_data :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

** These are horrendous can you improve the visuals

Absolutely! For a modern, visually appealing style in computational neuroscience, let's aim for *clean, minimal, and data-inspired* graphics similar to what is produced in scientific papers and keynote presentations.

Below are *improved, modern code examples* for beautiful, illustrative figures. These use /seaborn/, /matplotlib/, and optionally /plotly/ for interactive aesthetics, but avoid garish colors and clunky shapes.

---

*** Slide 1: Title (Stylized Brain + Task Network)

#+begin_src ipython
import matplotlib.pyplot as plt
import numpy as np

def draw_brain(ax):
    # Outline with spline points for simplicity
    t = np.linspace(0, 2*np.pi, 100)
    x = 0.5 + 0.38 * np.cos(t)
    y = 0.5 + 0.26 * np.sin(t)
    ax.plot(x, y, color='#5a5a5a', lw=3)
    # PFC highlight
    th = np.linspace(0.2*np.pi, 0.5*np.pi, 40)
    ax.fill(
        0.58 + 0.09*np.cos(th),
        0.65 + 0.09*np.sin(th),
        color="#fdcf44", alpha=0.6, lw=0)
    # Task icons as dots
    ax.scatter([0.38,0.70], [0.45, 0.58],
        s=500, color=["#3090fc", "#fa7d09"], alpha=0.7, edgecolor='k', zorder=3)

def make_title_slidesave(filename):
    fig, ax = plt.subplots(figsize=(6,4))
    draw_brain(ax)
    ax.text(0.365, 0.43, "Task 1", fontsize=13, ha='center', va='top', color="#2a3c4e")
    ax.text(0.72, 0.59, "Task 2", fontsize=13, ha='center', va='top', color="#51291e")
    ax.axis("off")
    plt.xlim(0,1)
    plt.ylim(0,1)
    plt.tight_layout()
    plt.savefig(filename, dpi=200, transparent=True)
    # plt.close()
make_title_slidesave("slide1_brain_tasks.png")
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_0.png]]

---

*** Slide 2: Working Memory "Juggling" (Minimal)

#+begin_src ipython
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(6, 4))
draw_brain(ax)
colors = ['#3090fc', '#fdcf44', '#fa7d09']
labels = ['A', '7', '■']
pts = [(0.4,0.8), (0.5,0.87), (0.6,0.8)]
for (x, y), c, l in zip(pts, colors, labels):
    circle = plt.Circle((x, y), 0.045, color=c, ec='k', lw=1, alpha=0.8, zorder=3)
    ax.add_patch(circle)
    ax.text(x, y, l, color='white', fontsize=15, ha='center', va='center', fontweight='bold')
ax.text(0.5, 0.2, "Maintaining multiple items\n(Working Memory)", fontsize=16, ha='center', va='center', color="#2a3c4e")
ax.axis("off")
plt.tight_layout()
plt.savefig("slide2_juggling.png", dpi=200, transparent=True)
# plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_1.png]]

---

*** Slide 3: Dual Task Paradigm (Flowchart Style)

#+begin_src ipython
fig, ax = plt.subplots(figsize=(6, 3))
# Minimal block arrows for tasks
ax.arrow(0.1,0.7,0.28,0, head_width=0.08, head_length=0.05, fc="#3090fc", ec=None, lw=0, alpha=0.8)
ax.text(0.1,0.7,"Task 1:\nMemory", ha="right", va="center", fontsize=14, fontweight='bold', color="#28536b")
ax.arrow(0.1,0.3,0.28,0, head_width=0.08, head_length=0.05, fc="#fa7d09", ec=None, lw=0, alpha=0.8)
ax.text(0.1,0.3,"Task 2:\nAttention", ha="right", va="center", fontsize=14, fontweight='bold', color="#964000")
# Merge arrow
ax.arrow(0.38,0.7,0.23,-0.35, head_width=0.08, head_length=0.05, fc="#9d0191", ec=None, lw=0, alpha=0.7)
# Central "wM resources" box
ax.add_patch(plt.Rectangle((0.63,0.43), 0.23, 0.14, color="#efefef", ec="#333", lw=2, alpha=0.95, zorder=2))
ax.text(0.745,0.5,"Working\nMemory", ha='center', va='center', fontsize=16, fontweight='bold')
ax.axis('off')
plt.xlim(0,1); plt.ylim(0,1)
plt.tight_layout()
plt.savefig("slide3_dual_flow.png", dpi=200, transparent=True)
# plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_2.png]]

---

*** Slide 4: Brain Highlight (Minimalist)

Use the draw_brain function above but emphasize the PFC:

#+begin_src ipython
fig, ax = plt.subplots(figsize=(6,4))
draw_brain(ax)
ax.annotate('Prefrontal Cortex', xy=(0.67,0.7), xytext=(0.80, 0.85),
    arrowprops=dict(facecolor='#fdcf44', edgecolor='#999', arrowstyle='->', lw=2, alpha=0.6),
    fontsize=14, color="#6d5000")
ax.axis('off')
plt.xlim(0,1); plt.ylim(0,1)
plt.tight_layout()
plt.savefig('slide4_brain_region.png', dpi=200, transparent=True)
# plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_3.png]]

---

*** Slide 5: Bottleneck/Venn Diagram (Professional)

#+begin_src ipython
from matplotlib_venn import venn2
fig, ax = plt.subplots(figsize=(2*width, 2*height))
v = venn2(subsets=(1,1,1), set_labels=('Task 1', 'Task 2'),
         set_colors=("#3090fc","#fa7d09"), alpha=0.7, ax=ax)
v.get_label_by_id('10').set_text('Unique\nResources\n')
v.get_label_by_id('01').set_text('\nUnique\nResources')
v.get_label_by_id('11').set_text('Shared\nResources')
plt.title("Competition for Resources", fontsize=24, fontweight='bold')
plt.tight_layout()
plt.savefig('slide5_venn.svg', dpi=300, transparent=True)
# plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_4.png]]

Install venn2:  =pip install matplotlib-venn=

---

*General suggestions for modern visuals:*
- Use minimal color palettes (max 2-3 accent colors + neutral background)
- Use whitespace and avoid clutter
- Consistent style (font, color shades, annotation style)
- Prefer shapes (dots, arrows) over clipart
- Use transparency for overlays
- Keep labels concise and avoid overlabeling in figure

*Use image files with markdown in Quarto:*
#+begin_src markdown
![](slide1_brain_tasks.png)
#+end_src

---

Would you like a downloadable [Jupyter Notebook](https://jupyter.org/) with all of these, or any specific visual refined further (or a new style, e.g., with /plotly/)? Let me know what visual/element you want even more polished!

***

** Can you create visuals for each of these slides? I use quarto for presentation. I want to get the actual image files. Can you generate instructions or code in python to generate modern beautiful visuals?


Absolutely! Below are *Python scripts* (using =matplotlib=, =seaborn=, and =Pillow= for some, and =networkx= for a neural network flavor) to generate modern and clean visuals for your six intro slides. Run each in a Jupyter notebook or as standalone scripts, and they’ll save images PNG files for your Quarto presentation.

---

*** Slide 1: Title Slide (Brain with Tasks)

#+begin_src ipython
import matplotlib.pyplot as plt
import matplotlib.patches as patches

fig, ax = plt.subplots(figsize=(6, 4))
# Brain shape (ellipse)
brain = patches.Ellipse((0.5, 0.5), 0.6, 0.35, facecolor='#c5d4ed', edgecolor='#263a53', linewidth=2)
ax.add_patch(brain)

# Two task icons: rectangle and star
task1 = patches.Rectangle((0.25, 0.58), 0.12, 0.09, color='#faad14', angle=10)
ax.add_patch(task1)
task2 = patches.RegularPolygon((0.68, 0.42), numVertices=5, radius=0.06, orientation=0.8, color='#52c41a')
ax.add_patch(task2)

ax.text(0.33, 0.82, "Working Memory", fontsize=18, fontweight='bold', color='#263a53')
ax.text(0.3, 0.1, "Dual Task", fontsize=16, color='#263a53')
ax.set_axis_off()
plt.tight_layout()
plt.savefig('slide1_title_brain.png', dpi=300)
#plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_0.png]]

---

*** Slide 2: Working Memory “Juggling”

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(6, 4))
# Brain, as before
brain = patches.Ellipse((0.5, 0.5), 0.5, 0.3, facecolor='#d4e6fa', edgecolor='#174e91', linewidth=2)
ax.add_patch(brain)
# Balls being juggled (memory items)
for x, y, label in zip([0.37, 0.5, 0.63], [0.75, 0.82, 0.75], ['A', '3', '●']):
    ax.add_patch(plt.Circle((x, y), 0.035, color='#6f97c5', alpha=0.9))
    ax.text(x, y, label, color='white', fontsize=14, ha='center', va='center', fontweight='bold')
# Simple "arms"
ax.plot([0.42, 0.43], [0.51, 0.59], color='#174e91')
ax.plot([0.58, 0.57], [0.51, 0.59], color='#174e91')

ax.set_axis_off()
plt.tight_layout()
plt.savefig('slide2_juggling_memory.png', dpi=300)
#plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_1.png]]

---

*** Slide 3: Dual Tasks Parallel

#+begin_src ipython
fig, ax = plt.subplots(figsize=(6, 2.5))
task1 = patches.FancyBboxPatch((0.07, 0.45), 0.3, 0.3, boxstyle="round,pad=0.05", fc='#faad14', ec='#874d00', alpha=0.9)
task2 = patches.FancyBboxPatch((0.63, 0.2), 0.3, 0.3, boxstyle="round,pad=0.05", fc='#52c41a', ec='#21581b', alpha=0.9)
ax.add_patch(task1)
ax.add_patch(task2)
ax.annotate("Task 1\n(Memory)", (0.22, 0.6), color='black', ha='center', va='center', fontsize=13, fontweight='bold')
ax.annotate("Task 2\n(Attention)", (0.77, 0.35), color='black', ha='center', va='center', fontsize=13, fontweight='bold')
# Arrows toward center
ax.arrow(0.37, 0.6, 0.23, -0.13, head_width=0.06, head_length=0.045, fc='gray', ec='gray', alpha=0.7)
ax.arrow(0.63, 0.35, -0.23, 0.13, head_width=0.06, head_length=0.045, fc='gray', ec='gray', alpha=0.7)
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_axis_off()
plt.tight_layout()
plt.savefig('slide3_dualtask.png', dpi=300)
# plt.close()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_2.png]]

---

*** Slide 4: Brain Areas (Prefrontal Cortex Highlight)

#+begin_src ipython
from PIL import Image, ImageDraw

img = Image.new('RGBA', (350, 350), (255, 255, 255, 0))
draw = ImageDraw.Draw(img)
# Simple stylized oval brain
draw.ellipse([30, 80, 320, 270], fill='#e0e7f1', outline='#263a53', width=8)
# PFC region highlight (circle)
draw.ellipse([220, 110, 290, 180], fill="#faad14", outline='#874d00', width=7)
draw.text((230, 185), "PFC", fill='#263a53')
img.save('slide4_brain_pfc.png')
#+end_src

#+RESULTS:

/(Optional: For more anatomical accuracy, replace with a downloaded silhouette of the brain and overlay with matplotlib.)/

---

*** Slide 5: Bottleneck / Venn Diagram

#+begin_src python
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(6, 4))
# Venn diagram with overlap
circle1 = plt.Circle((0.4, 0.5), 0.25, color='#faad14', alpha=0.7)
circle2 = plt.Circle((0.6, 0.5), 0.25, color='#52c41a', alpha=0.7)
ax.add_patch(circle1)
ax.add_patch(circle2)
ax.text(0.3, 0.5, "Task 1", fontsize=14, fontweight='bold', color='#874d00', va='center')
ax.text(0.7, 0.5, "Task 2", fontsize=14, fontweight='bold', color='#21581b', va='center')
ax.text(0.5, 0.5, "Shared\nResources", fontsize=13, ha='center', va='center', fontweight='bold')
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_axis_off()
plt.tight_layout()
plt.savefig('slide5_venn.png', dpi=300)
plt.close()
#+end_src

---

*** General notes

- Install necessary libraries: =pip install matplotlib seaborn pillow networkx=
- You can customize color, labels, and annotations to fit your style.
- For /slide 4/ if you want a fancier brain, use [=nilearn=](https://nilearn.github.io/) to plot brain outlines; above is a simplified version.
- Save all images and include in your Quarto slides with Markdown: =![](slide1_title_brain.png)=

Let me know if you want code to tweak any specific style or a certain neuroscientific aspect!

***

#+begin_src ipython
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image

fig, ax = plt.subplots(figsize=(5, 4))
# Load your downloaded brain.png file here
brain_img = Image.open("brain.png")  # Download a transparent brain outline SVG/PNG

ax.imshow(brain_img, extent=[0, 10, 0, 10])

# Overlay modern task icons as colored circles
circleA = patches.Circle((3, 7.5), 0.7, color='#FF6F61', alpha=0.8, zorder=2)
circleB = patches.Circle((7, 7.5), 0.7, color='#49A078', alpha=0.8, zorder=2)
ax.add_patch(circleA)
ax.add_patch(circleB)
ax.text(3, 7.5, "A", color="white", size=22, ha="center", va="center", fontweight="bold")
ax.text(7, 7.5, "B", color="white", size=22, ha="center", va="center", fontweight="bold")

ax.axis('off')
plt.tight_layout()
# plt.savefig("better_brain_dual_tasks.png", dpi=200, transparent=True)
plt.show()
#+end_src


#+RESULTS:
[[./figures/overlaps/figure_5.png]]


#+begin_src ipython
import matplotlib.pyplot as plt
from matplotlib.patches import FancyArrowPatch, Rectangle

fig, ax = plt.subplots(figsize=(6,2.5))
# Task boxes
ax.add_patch(Rectangle((1, 1.5), 1.3, 0.7, color='#F8E16C'))
ax.text(1.65, 1.85, 'Task A', va='center', ha='center', fontsize=15)

ax.add_patch(Rectangle((1, 0), 1.3, 0.7, color='#AEEAF7'))
ax.text(1.65, 0.35, 'Task B', va='center', ha='center', fontsize=15)

# WM box
wm_box = Rectangle((4, 0.6), 2, 1, color='#e7ecef', ec='k', lw=2)
ax.add_patch(wm_box)
ax.text(5, 1.1, 'Working\nMemory', va='center', ha='center', fontsize=15, fontweight='bold')

# Arrows
ax.add_patch(FancyArrowPatch((2.3, 1.85), (4, 1.35), arrowstyle='-|>', mutation_scale=30, color='#7D5BA6', lw=2))
ax.add_patch(FancyArrowPatch((2.3, 0.35), (4, 0.85), arrowstyle='-|>', mutation_scale=30, color='#7D5BA6', lw=2))

ax.axis('off')
ax.set_xlim(0,7)
ax.set_ylim(-0.3,2.5)
plt.savefig('modern_dual_task_schematic.png', dpi=200, transparent=True)
plt.show()
#+end_src



#+RESULTS:
[[./figures/overlaps/figure_6.png]]


#+begin_src ipython
from graphviz import Digraph

dot = Digraph()
dot.attr('node', shape='box')
dot.node('WM', 'Working Memory')
dot.attr('node', shape='ellipse')
dot.node('A', 'Task A')
dot.node('B', 'Task B')
dot.edge('A', 'WM')
dot.edge('B', 'WM')

dot.render('dual_task_schematic', format='png', cleanup=True)
#+end_src

#+RESULTS:





* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
:RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python
: <Figure size 700x432.624 with 0 Axes>
:END:

* Imports

#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd
  import seaborn as sns

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
  from src.decode.bump import circcvl
  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator #.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_.named_steps["model"]

    norm_w = np.linalg.norm(coef) + 1e-6

    # try:
    #     X_test = clf.named_steps["scaler"].transform(X_test)
    # except:
    #     pass

    # try:
    #     X_test = clf.named_steps["pca"].transform(X_test)
    # except:
    #     pass

    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / norm_w # / X_test.shape[1] * 1000
        # dot_product = (2*y_test -1) * clf.named_steps["model"].decision_function(X_test)
        # dot_product = (2*y_test -1) * clf.decision_function(X_test) / norm_w
    else:
        # dot_product = clf.decision_function(X_test) / norm_w
        # dot_product = clf.named_steps["model"].decision_function(X_test)
        dot_product = np.dot(X_test, coef) / norm_w # / X_test.shape[1] * 1000

    return np.nanmean(dot_product)
#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:
#+begin_example
During startup - Warning messages:
1: package ‘methods’ was built under R version 4.4.2
2: package ‘datasets’ was built under R version 4.4.2
3: package ‘utils’ was built under R version 4.4.2
4: package ‘grDevices’ was built under R version 4.4.2
5: package ‘graphics’ was built under R version 4.4.2
6: package ‘stats’ was built under R version 4.4.2
R[write to console]: In addition:
R[write to console]: Warning message:
R[write to console]: package ‘tools’ was built under R version 4.4.2
#+end_example

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0, ls='-', label=None, colors=None, cis=None, **kwargs):
    if day=='all':
        df_ = df.copy()
    else:
        df_ = df[df.day == day].copy()

    if colors is None:
        colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        if label is None:
            ax.plot(time_points, mean_overlaps[task], label=f"{task}", color=colors[i], ls=ls, **kwargs)
            # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)
        else:
            ax.plot(time_points, mean_overlaps[task], label=label, color=colors[i], ls=ls, **kwargs)

        if cis is not None:
            ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')
    ax.legend(fontsize=10)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlaps_traj(df, df2, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0, ls='-', label=None, colors=None, cis=None, **kwargs):
    if day=='all':
        df_ = df.copy()
        df2_ = df2.copy()
    else:
        df_ = df[df.day == day].copy()
        df2_ = df[df.day == day].copy()

    if colors is None:
        colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
        mean_overlaps2 = df2_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
        mean_overlaps2 = df2_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        if label is None:
            ax.plot(time_points, mean_overlaps[task], label=f"{task}", color=colors[i], ls=ls, **kwargs)
            # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)
        else:
            ax.plot(time_points, mean_overlaps[task], label=label, color=colors[i], ls=ls, **kwargs)

        if cis is not None:
            ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')
    ax.legend(fontsize=10)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_mat(X, ax, vmin=-1, vmax=1, palette='bwr'):
  im = ax.imshow(
    X,
    interpolation=None,
    origin="lower",
    cmap=palette,
    extent=[0, 14, 0, 14],
    vmin=vmin,
    vmax=vmax,
  )

  add_vdashed(ax)
  ax.set_xlim([2, 12])
  ax.set_xticks([2, 4, 6, 8, 10, 12])
  ax.set_ylim([2, 12])
  ax.set_yticks([2, 4, 6, 8, 10, 12])

  ax.set_xlabel("Testing Time (s)")
  ax.set_ylabel("Training Time (s)")
  return im
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt

def add_vdashed(ax=None, mouse=""):
    # Define time intervals
    t_STIM = [2, 3]
    t_DIST = [4.5, 5.5]
    t_CUE = [6.5, 7]
    t_TEST = [9, 10]

    # Add vertical dashed lines and text labels for each interval
    if ax is not None:
        # Draw vertical lines
        for t in [t_STIM, t_DIST, t_TEST]:
            ax.axvline(x=t[0], linestyle='--', color='k', lw=2)
            ax.axvline(x=t[1], linestyle='--', color='k', lw=2)

            ax.axhline(y=t[0], linestyle='--', color='k', lw=2)
            ax.axhline(y=t[1], linestyle='--', color='k', lw=2)

        # Add text labels at the middle of each interval
        ax.text((t_STIM[0] + t_STIM[1]) / 2, 12.5, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_DIST[0] + t_DIST[1]) / 2, 12.5, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        # ax.text((t_CUE[0] + t_CUE[1]) / 2, 12.5, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_TEST[0] + t_TEST[1]) / 2, 12.5, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)

        ax.text(12.5, (t_STIM[0] + t_STIM[1]) / 2, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        ax.text(12.5, (t_DIST[0] + t_DIST[1]) / 2, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        # ax.text(12.5, (t_CUE[0] + t_CUE[1]) / 2, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)
        ax.text(12.5, (t_TEST[0] + t_TEST[1]) / 2, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)

#+end_src

#+RESULTS:

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title=''):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  old_mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']

  mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
  # mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
  # mice = Jaws_mice
  # mice = ['JawsM15']

  tasks = ['DPA', 'DualGo', 'DualNoGo']

  kwargs = {
      'mice': mice,
      'mouse': mice[0], 'laser': -1,
      'trials': 'correct', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': 0, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 5, 'n_repeats': 1,
      'class_weight': 0,
      'multilabel': 0,
      'mne_estimator':'generalizing', # sliding or generalizing
      'n_jobs': 64,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  safe_f1 = make_scorer(safe_f1_score, needs_proba=True)

  dum = 'overlaps_loocv_correct'
  # dum = 'overlaps_loocv_laser_only'
  # dum = 'overlaps_loocv_laser_all_l2'
  options['cv_B'] = True
  # dum = 'overlaps_all_loocv'
#+end_src

#+RESULTS:

* Decoding vs days
** utils

#+begin_src ipython
def decode_axis(model, **options):
    new_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'ChRM23']
    options['NEW_DATA'] = 0

    dfs = []
    for mouse in options['mice']:
        df_mouse = []
        options['mouse'] = mouse
        options = set_options(**options)
        days = options['days']

        if mouse in new_mice:
            options['reload'] = 0
            options['NEW_DATA'] = 1
        else:
            options['reload'] = 0
            options['NEW_DATA'] = 0

        for task in ['all']:
            options['task'] = task

            for day in days:
                options['day'] = day

                try:
                # if 0==0:
                    overlaps = get_classification(model, RETURN='df_scores', **options)
                    options['reload'] = 0
                    df_mouse.append(overlaps)
                except:
                    pass

        df_mouse = pd.concat(df_mouse)
        df_mouse['mouse'] = mouse
        dfs.append(df_mouse)

    return pd.concat(dfs)
    #+end_src

#+RESULTS:

#+begin_src ipython
def save_overlaps(df, marg, dum, **options):
    if len(options['days'])>3:
        name = 'df_%s_%s_days' % (marg, dum)
    elif len(options['days'])==2:
        name = 'df_%s_%s_early_late' % (marg, dum)
    else:
        name = 'df_%s_%s' % (marg, dum)

    if len(mice)==1:
        pkl_save(df, '%s' % name, path="/storage/leon/dual_task/data/%s/overlaps" % options['mouse'])
    elif len(mice)==2:
        pkl_save(df, '%s' % name, path="/storage/leon/dual_task/data/mice/overlaps_ACC")
    else:
        pkl_save(df, '%s' % name, path="/storage/leon/dual_task/data/mice/overlaps")
#+end_src

#+RESULTS:

** run

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
#+end_src

#+RESULTS:

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=64, fit_intercept=True)
params = {'model__C': np.logspace(-3, 3, 10)}

# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=64, class_weight='balanced', fit_intercept=True)
# params = {'model__C': np.logspace(-3, 3, 10), 'model__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = lambda estimator, X_test, y_test: np.abs(overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1))
# options['hp_scoring'] = 'accuracy'
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['reload'] = 0

options['T_WINDOW'] = 0.5

options['cv'] = LeaveOneOut()
options['verbose'] = 1
model = ClassificationCV(net, params, **options)
#+end_src

#+RESULTS:
: PCA False 0

#+begin_src ipython
options['features'] = 'sample'
options['epochs'] = ['ED']
df_sample = decode_axis(model, **options)

df_sample['performance'] = df_sample['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_sample['pair'] = df_sample['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
save_overlaps(df_sample, 'sample', dum, **options)
 #+end_src

 #+RESULTS:
 #+begin_example
 Loading files from /storage/leon/dual_task/data/JawsM01
 X_days (768, 184, 84) y_days (768, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (437, 14) ['DPA' 'DualNoGo' 'DualGo']
 X (437, 184, 84) nans 0.0 y (437,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 29s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...Elapsed (with compilation) = 0h 1m 37s
 scores (437, 84, 84) 0.026294421963797842
 df_A (437, 15) scores (437, 7056) labels (437, 14)
 df (437, 15)
 Loading files from /storage/leon/dual_task/data/JawsM01
 X_days (768, 184, 84) y_days (768, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (182, 14) ['DualNoGo' 'DPA' 'DualGo']
 X (182, 184, 84) nans 0.0 y (182,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 33s
 {'model__C': 2.154434690031882}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 0m 44s
 scores (182, 84, 84) 0.028009198760138215
 df_A (182, 15) scores (182, 7056) labels (182, 14)
 df (182, 15)
 Loading files from /storage/leon/dual_task/data/JawsM06
 X_days (1152, 201, 84) y_days (1152, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (374, 14) ['DualNoGo' 'DPA' 'DualGo']
 X (374, 201, 84) nans 0.0 y (374,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 38s
 {'model__C': 2.154434690031882}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 1m 29s
 scores (374, 84, 84) -0.009054221919315507
 df_A (374, 15) scores (374, 7056) labels (374, 14)
 df (374, 15)
 Loading files from /storage/leon/dual_task/data/JawsM06
 X_days (1152, 201, 84) y_days (1152, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (491, 14) ['DualNoGo' 'DualGo' 'DPA']
 X (491, 201, 84) nans 0.0 y (491,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 38s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 2m 6s
 scores (491, 84, 84) -0.05018000500273245
 df_A (491, 15) scores (491, 7056) labels (491, 14)
 df (491, 15)
 Loading files from /storage/leon/dual_task/data/JawsM12
 X_days (960, 423, 84) y_days (960, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (379, 14) ['DPA' 'DualGo' 'DualNoGo']
 X (379, 423, 84) nans 0.0 y (379,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 38s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 2m 29s
 scores (379, 84, 84) -0.10057729231077578
 df_A (379, 15) scores (379, 7056) labels (379, 14)
 df (379, 15)
 Loading files from /storage/leon/dual_task/data/JawsM12
 X_days (960, 423, 84) y_days (960, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (292, 14) ['DualNoGo' 'DPA' 'DualGo']
 X (292, 423, 84) nans 0.0 y (292,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 38s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 1m 42s
 scores (292, 84, 84) -0.052153294490065595
 df_A (292, 15) scores (292, 7056) labels (292, 14)
 df (292, 15)
 Loading files from /storage/leon/dual_task/data/JawsM15
 X_days (1152, 693, 84) y_days (1152, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (385, 16) ['DualGo' 'DPA' 'DualNoGo']
 X (385, 693, 84) nans 0.0 y (385,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 39s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 3m 49s
 scores (385, 84, 84) -0.07300351625051979
 df_A (385, 17) scores (385, 7056) labels (385, 16)
 df (385, 17)
 Loading files from /storage/leon/dual_task/data/JawsM15
 X_days (1152, 693, 84) y_days (1152, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (479, 16) ['DualGo' 'DualNoGo' 'DPA']
 X (479, 693, 84) nans 0.0 y (479,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 39s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 5m 37s
 scores (479, 84, 84) -0.16686570243199977
 df_A (479, 17) scores (479, 7056) labels (479, 16)
 df (479, 17)
 Loading files from /storage/leon/dual_task/data/JawsM18
 X_days (1152, 444, 84) y_days (1152, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (473, 16) ['DualNoGo' 'DualGo' 'DPA']
 X (473, 444, 84) nans 0.0 y (473,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 50s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 3m 52s
 scores (473, 84, 84) -0.08842576762043515
 df_A (473, 17) scores (473, 7056) labels (473, 16)
 df (473, 17)
 Loading files from /storage/leon/dual_task/data/JawsM18
 X_days (1152, 444, 84) y_days (1152, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (566, 16) ['DualNoGo' 'DPA' 'DualGo']
 X (566, 444, 84) nans 0.0 y (566,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 50s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 5m 13s
 scores (566, 84, 84) -0.04104056483413188
 df_A (566, 17) scores (566, 7056) labels (566, 16)
 df (566, 17)
 Loading files from /storage/leon/dual_task/data/ChRM04
 X_days (1152, 668, 84) y_days (1152, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (467, 16) ['DualNoGo' 'DPA' 'DualGo']
 X (467, 668, 84) nans 0.0 y (467,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 42s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 5m 7s
 scores (467, 84, 84) -0.09509014660351846
 df_A (467, 17) scores (467, 7056) labels (467, 16)
 df (467, 17)
 Loading files from /storage/leon/dual_task/data/ChRM04
 X_days (1152, 668, 84) y_days (1152, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (534, 16) ['DualNoGo' 'DualGo' 'DPA']
 X (534, 668, 84) nans 0.0 y (534,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 42s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 6m 36s
 scores (534, 84, 84) -0.17347289814723105
 df_A (534, 17) scores (534, 7056) labels (534, 16)
 df (534, 17)
 Loading files from /storage/leon/dual_task/data/ChRM23
 X_days (960, 232, 84) y_days (960, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (382, 14) ['DualNoGo' 'DualGo' 'DPA']
 X (382, 232, 84) nans 0.0 y (382,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 41s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 1m 43s
 scores (382, 84, 84) -0.12725816831050268
 df_A (382, 15) scores (382, 7056) labels (382, 14)
 df (382, 15)
 Loading files from /storage/leon/dual_task/data/ChRM23
 X_days (960, 232, 84) y_days (960, 13)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (298, 14) ['DualNoGo' 'DualGo' 'DPA']
 X (298, 232, 84) nans 0.0 y (298,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 42s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 1m 20s
 scores (298, 84, 84) -0.1689433057556775
 df_A (298, 15) scores (298, 7056) labels (298, 14)
 df (298, 15)
 Loading files from /storage/leon/dual_task/data/ACCM03
 X_days (960, 361, 84) y_days (960, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (372, 16) ['DPA' 'DualGo' 'DualNoGo']
 X (372, 361, 84) nans 0.0 y (372,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 42s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 2m 16s
 scores (372, 84, 84) 0.0818497411946451
 df_A (372, 17) scores (372, 7056) labels (372, 16)
 df (372, 17)
 Loading files from /storage/leon/dual_task/data/ACCM03
 X_days (960, 361, 84) y_days (960, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (349, 16) ['DualGo' 'DualNoGo' 'DPA']
 X (349, 361, 84) nans 0.0 y (349,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 40s
 {'model__C': 0.09999999999999999}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 2m 3s
 scores (349, 84, 84) 0.14301062463107855
 df_A (349, 17) scores (349, 7056) labels (349, 16)
 df (349, 17)
 Loading files from /storage/leon/dual_task/data/ACCM04
 X_days (960, 113, 84) y_days (960, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER -1
 y_labels (332, 16) ['DualNoGo' 'DPA' 'DualGo']
 X (332, 113, 84) nans 0.0 y (332,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 41s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 1m 1s
 scores (332, 84, 84) -0.02993602972370439
 df_A (332, 17) scores (332, 7056) labels (332, 16)
 df (332, 17)
 Loading files from /storage/leon/dual_task/data/ACCM04
 X_days (960, 113, 84) y_days (960, 15)
 DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER -1
 y_labels (283, 16) ['DualGo' 'DPA' 'DualNoGo']
 X (283, 113, 84) nans 0.0 y (283,) [0. 1.]
 Fitting hyperparameters on single epoch ...
 Elapsed (with compilation) = 0h 0m 41s
 {'model__C': 0.4641588833612777}
 LeaveOneOut()
 Computing cv scores ...
 Elapsed (with compilation) = 0h 0m 55s
 scores (283, 84, 84) -0.0325572886491832
 df_A (283, 17) scores (283, 7056) labels (283, 16)
 df (283, 17)
 saving to /storage/leon/dual_task/data/mice/overlaps/df_sample_overlaps_loocv_all_early_late.pkl
 #+end_example

#+begin_src ipython
# options['features'] = 'distractor'
# options['epochs'] = ['MD']
# df_dist = decode_axis(model, **options)

# df_dist['performance'] = df_dist['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
# df_dist['pair'] = df_dist['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
# save_overlaps(df_dist, 'dist', dum, **options)
#+end_src

#+RESULTS:

#+begin_src ipython
options['features'] = 'choice'
options['epochs'] = ['CHOICE']
df_choice = decode_axis(model, **options)

df_choice['performance'] = df_choice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_choice['pair'] = df_choice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
save_overlaps(df_choice, 'choice', dum, **options)
#+end_src

#+RESULTS:
#+begin_example
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 14) ['DualGo' 'DualNoGo' 'DPA']
X (576, 184, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 38s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 35s
scores (576, 84, 84) -0.03514217822159516
df_A (576, 15) scores (576, 7056) labels (576, 14)
df (576, 15)
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (192, 14) ['DPA' 'DualNoGo' 'DualGo']
X (192, 184, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 39s
{'model__C': 2.154434690031882}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 48s
scores (192, 84, 84) -0.02091939262688265
df_A (192, 15) scores (192, 7056) labels (192, 14)
df (192, 15)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 14) ['DualGo' 'DPA' 'DualNoGo']
X (576, 201, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 39s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 45s
scores (576, 84, 84) 0.03080253396297194
df_A (576, 15) scores (576, 7056) labels (576, 14)
df (576, 15)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (576, 14) ['DualGo' 'DualNoGo' 'DPA']
X (576, 201, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 57s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 45s
scores (576, 84, 84) 0.015116014234666637
df_A (576, 15) scores (576, 7056) labels (576, 14)
df (576, 15)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 14) ['DPA' 'DualGo' 'DualNoGo']
X (576, 423, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 38s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 4m 59s
scores (576, 84, 84) 0.03707753348816945
df_A (576, 15) scores (576, 7056) labels (576, 14)
df (576, 15)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (384, 14) ['DualNoGo' 'DualGo' 'DPA']
X (384, 423, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 39s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 35s
scores (384, 84, 84) 0.012524116444831217
df_A (384, 15) scores (384, 7056) labels (384, 14)
df (384, 15)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 16) ['DualNoGo' 'DualGo' 'DPA']
X (576, 693, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 49s
{'model__C': 0.021544346900318832}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 7m 59s
scores (576, 84, 84) 0.16425369526010491
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (576, 16) ['DualGo' 'DualNoGo' 'DPA']
X (576, 693, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 51s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 8m 0s
scores (576, 84, 84) 0.06522981573848784
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 16) ['DPA' 'DualNoGo' 'DualGo']
X (576, 444, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 50s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 5m 29s
scores (576, 84, 84) 0.11385414466507435
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (576, 16) ['DualNoGo' 'DualGo' 'DPA']
X (576, 444, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 48s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 5m 28s
scores (576, 84, 84) 0.04097490541519714
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 16) ['DualNoGo' 'DualGo' 'DPA']
X (576, 668, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 53s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 7m 45s
scores (576, 84, 84) 0.06950965643014684
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (576, 16) ['DualGo' 'DualNoGo' 'DPA']
X (576, 668, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 54s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 7m 49s
scores (576, 84, 84) 0.05182953679119478
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 14) ['DualNoGo' 'DualGo' 'DPA']
X (576, 232, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 51s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 14s
scores (576, 84, 84) 0.04709331797370931
df_A (576, 15) scores (576, 7056) labels (576, 14)
df (576, 15)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 13)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (384, 14) ['DualNoGo' 'DualGo' 'DPA']
X (384, 232, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 49s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 53s
scores (384, 84, 84) 0.06526215813772414
df_A (384, 15) scores (384, 7056) labels (384, 14)
df (384, 15)
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 16) ['DualNoGo' 'DualGo' 'DPA']
X (576, 361, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 52s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 4m 32s
scores (576, 84, 84) 0.02727684349003779
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (384, 16) ['DPA' 'DualGo' 'DualNoGo']
X (384, 361, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 53s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 30s
scores (384, 84, 84) -0.0734667776825399
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS first LASER -1
y_labels (576, 16) ['DualNoGo' 'DualGo' 'DPA']
X (576, 113, 84) nans 0.0 y (576,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 52s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 3s
scores (576, 84, 84) 0.07310738751883916
df_A (576, 17) scores (576, 7056) labels (576, 16)
df (576, 17)
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS correct DAYS last LASER -1
y_labels (384, 16) ['DualGo' 'DPA' 'DualNoGo']
X (384, 113, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 52s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 15s
scores (384, 84, 84) 0.05170200873719192
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
saving to /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_all_early_late.pkl
#+end_example

#+begin_src ipython

#+end_src

#+RESULTS:

* Data
** utils

#+begin_src ipython
def load_data(marg, dum, **options):
    if len(options['days'])>3:
        name = 'df_%s_%s_days' % (marg, dum)
    elif len(options['days'])==2:
        name = 'df_%s_%s_early_late' % (marg, dum)
    else:
        name = 'df_%s_%s' % (marg, dum)

    if len(options['mice'])==1:
        df = pkl_load('%s' % name, path="/storage/leon/dual_task/data/%s/overlaps" % options['mouse'])
    elif len(options['mice'])==2:
        df = pkl_load('%s' % name, path="/storage/leon/dual_task/data/mice/overlaps_ACC")
    else:
        df = pkl_load('%s' % name, path="/storage/leon/dual_task/data/mice/overlaps")#.reset_index()

    return df
#+end_src

#+RESULTS:

#+begin_src ipython
def get_avg_overlaps(df, epoch_list, **options):

        df['overlaps_diag'] = df['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))

        for epoch2 in epoch_list:
                options['epochs'] = [epoch2]
                df['overlaps_diag_%s' % epoch2] = df['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))

        for epoch in epoch_list:
                options['epochs'] = [epoch]
                df['overlaps_%s' % epoch] = df['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))

                for epoch2 in epoch_list:
                        options['epochs'] = [epoch2]
                        df['overlaps_%s_%s' % (epoch, epoch2)] = df['overlaps_%s' % epoch].apply(lambda x: avg_epochs(np.array(x), **options))


        return df
#+end_src

#+RESULTS:

** run
*** load

#+begin_src ipython
options['T_WINDOW'] = 0.5
options = set_options(**options)
#+end_src

#+RESULTS:

#+begin_src ipython
df_sample = load_data('sample', dum, **options)
df_sample = get_avg_overlaps(df_sample, ['ED', 'MD', 'LD', 'TEST'], **options)
#+end_src

#+RESULTS:
: loading from /storage/leon/dual_task/data/mice/overlaps/df_sample_overlaps_loocv_correct_early_late.pkl

#+begin_src ipython
# df_dist = load_data('dist', dum, **options)
#df_dist = get_avg_overlaps(df_dist, ['MD', 'CUE', 'CHOICE'], **options)
#+end_src

#+RESULTS:

#+begin_src ipython
df_choice = load_data('choice', dum, **options)
df_choice = get_avg_overlaps(df_choice,  ['ED', 'LD', 'TEST', 'CHOICE'], **options)
#+end_src

#+RESULTS:
: loading from /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_correct_early_late.pkl

#+begin_src ipython
df_choice_on = load_data('choice', 'overlaps_loocv_laser_correct', **options)
df_choice_on = get_avg_overlaps(df_choice_on,  ['ED', 'LD', 'TEST', 'CHOICE', 'RWD2'], **options)
#+end_src

#+RESULTS:
: loading from /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_laser_correct_early_late.pkl

*** overlaps

#+begin_src ipython
def plot_overlaps_mean(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0, ls='-', label=None, colors=None, cis=None, **kwargs):
    if day=='all':
        df_ = df.copy()
    else:
        df_ = df[df.day == day].copy()

    if colors is None:
        colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        dum = np.mean(mean_overlaps[task][:14])
        if label is None:
            ax.plot(time_points, mean_overlaps[task]-dum, label=f"{task}", color=colors[i], ls=ls, **kwargs)
            # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)
        else:
            ax.plot(time_points, mean_overlaps[task]-dum, label=label, color=colors[i], ls=ls, **kwargs)

        if cis is not None:
            ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')
    ax.legend(fontsize=10)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
# Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']
# Jaws_mice = ['JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']

df = df_sample.copy()
df1 = df_choice.copy()

df = df[df.mouse.isin(Jaws_mice)]
df1 = df1[df1.mouse.isin(Jaws_mice)]

period = 'last'

epoch= 'LD'
epoch1= 'CHOICE'

df = df[df.laser==0]
df1 = df1[df1.laser==0]

df = df[df.performance==1]
df1 = df1[df1.performance==1]

df = df[df.mouse=='JawsM15']
df1 = df1[df1.mouse=='JawsM15']

ls = ['-', '--', '--', '-']
colors = ['r', 'b', 'g']
labels = ['AC', 'BC', 'AD', 'BD']
tasks = ['DPA', 'DualGo', 'DualNoGo']
#+end_src

#+RESULTS:

 #+begin_src ipython
n_ = len(options['days'])+1
fig, ax = plt.subplots(nrows=3, ncols=n_, figsize=(0.9*n_*width, 0.9*3*height))

for k in range(3):
    df_ = df[df.tasks==tasks[k]]
    df1_ = df1[df1.tasks==tasks[k]]

    for j in range(2):
        for i in range(2):
            df__ = df_[(df_.sample_odor==i) & (df_.test_odor==j)]
            df1__ = df1_[(df1_.sample_odor==i) & (df1_.test_odor==j)]

            plot_overlaps(df__, period, epoch, ax[k][0], y0=0., if_proba=0, label=labels[2*i+j],
                          cis=None, ls=ls[2*i+j], colors=[colors[k]], alpha=(i+1)/2)
            plot_overlaps(df1__, period, epoch1, ax[k][1], y0=0., if_proba=0, label=labels[2*i+j],
                          cis=None, ls=ls[2*i+j], colors=[colors[k]], alpha=(i+1)/2)

            overlaps = df__[df__.day==period].groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
            overlaps1 = df1__[df1__.day==period].groupby('tasks')['overlaps_%s' % epoch1].apply(lambda x: np.nanmean(np.stack(x), axis=0))

            ax[k][2].plot(overlaps[0][:65]-np.mean(overlaps[0][:14]), overlaps1[0][:65]-np.mean(overlaps1[0][:14]), label=labels[2*i+j],
                          ls=ls[2*i+j], color=colors[k], alpha=(i+1)/2)

            # ax[k][2].set_aspect('equal')

        ax[k][0].set_xlabel('Time (s)')
        ax[k][0].set_ylabel('Sample Overlap')

        ax[k][1].set_xlabel('Time (s)')
        ax[k][1].set_ylabel('Choice Overlap')

        ax[k][2].set_xlabel('Sample Overlap')
        ax[k][2].set_ylabel('Choice Overlap')

ax[0][-1].legend(fontsize=10)

plt.savefig('figures/icrm/last_overlaps_%s.svg' % epoch, dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_35.png]]

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
palette = sns.diverging_palette(360, 0, as_cmap=True)
palette = 'bwr'
# palette='jet'

def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title='', palette=palette):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax, palette)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

#+begin_src ipython
plot_overlaps_mat(df1[df1.pair==1], 'last', vmin=-1, vmax=1, title='Choice')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_37.png]]

#+begin_src ipython
plot_overlaps_mat(df[df.sample_odor==1], 'last', vmin=-.5, vmax=.5, title='Sample')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_38.png]]

#+begin_src ipython

#+end_src

*** glm

#+begin_src ipython
import statsmodels.api as sm
import statsmodels.formula.api as smf

df = pd.concat((df_choice, df_choice_on))
df = df[df.day=='last']

formula = 'performance ~ overlaps_CHOICE_LD * laser'

model = smf.glm(formula=formula, data=df, family=sm.families.Binomial())
results = model.fit()

print(results.summary())
#+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:            performance   No. Observations:                 8064
Model:                            GLM   Df Residuals:                     8060
Model Family:                Binomial   Df Model:                            3
Link Function:                  Logit   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -3218.5
Date:                Fri, 06 Jun 2025   Deviance:                       6437.0
Time:                        16:39:00   Pearson chi2:                 8.08e+03
No. Iterations:                     5   Pseudo R-squ. (CS):           0.005820
Covariance Type:            nonrobust
==============================================================================================
                                 coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------------
Intercept                      1.8095      0.043     41.955      0.000       1.725       1.894
overlaps_CHOICE_TEST          -0.1771      0.064     -2.758      0.006      -0.303      -0.051
laser                          0.1727      0.070      2.458      0.014       0.035       0.310
overlaps_CHOICE_TEST:laser     0.6529      0.102      6.426      0.000       0.454       0.852
==============================================================================================
#+end_example

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
# df = df_choice.copy()
df = pd.concat((df_choice, df_choice_on)).reset_index(drop=True)
df = df[df.day=='last']
# formula = 'performance ~ overlaps_CHOICE_LD * day + (1 + overlaps_CHOICE_LD + day | mouse)'
formula = 'performance ~ overlaps_CHOICE_LD * laser * tasks+ (1 + laser | mouse)'

model = Lmer(formula=formula, data=df, family='binomial')
results = model.fit()
random_effects = model.ranef

print(results)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_CHOICE_LD*laser*tasks+(1+laser|mouse)

Family: binomial	 Inference: parametric

Number of observations: 8064	 Groups: {'mouse': 9.0}

Log-likelihood: -3000.679 	 AIC: 6031.358

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.855  0.925
mouse        laser  0.003  0.059

               IV1    IV2  Corr
mouse  (Intercept)  laser  -1.0

Fixed effects:

                                        Estimate  2.5_ci  97.5_ci     SE  \
(Intercept)                                2.218   1.590    2.846  0.320
overlaps_CHOICE_LD                        -0.245  -0.689    0.199  0.226
laser                                     -0.050  -0.339    0.239  0.147
tasksDualGo                               -0.263  -0.485   -0.040  0.114
tasksDualNoGo                             -0.193  -0.401    0.016  0.106
overlaps_CHOICE_LD:laser                   0.332  -0.157    0.821  0.249
overlaps_CHOICE_LD:tasksDualGo             0.111  -0.406    0.629  0.264
overlaps_CHOICE_LD:tasksDualNoGo           0.296  -0.221    0.812  0.264
laser:tasksDualGo                          0.222  -0.144    0.588  0.187
laser:tasksDualNoGo                        0.194  -0.173    0.561  0.187
overlaps_CHOICE_LD:laser:tasksDualGo       0.210  -0.378    0.798  0.300
overlaps_CHOICE_LD:laser:tasksDualNoGo    -0.060  -0.643    0.523  0.297

                                           OR  OR_2.5_ci  OR_97.5_ci   Prob  \
(Intercept)                             9.187      4.902      17.216  0.902
overlaps_CHOICE_LD                      0.782      0.502       1.220  0.439
laser                                   0.951      0.712       1.269  0.487
tasksDualGo                             0.769      0.616       0.961  0.435
tasksDualNoGo                           0.825      0.670       1.016  0.452
overlaps_CHOICE_LD:laser                1.394      0.855       2.273  0.582
overlaps_CHOICE_LD:tasksDualGo          1.118      0.666       1.875  0.528
overlaps_CHOICE_LD:tasksDualNoGo        1.344      0.802       2.253  0.573
laser:tasksDualGo                       1.249      0.866       1.801  0.555
laser:tasksDualNoGo                     1.214      0.841       1.752  0.548
overlaps_CHOICE_LD:laser:tasksDualGo    1.233      0.685       2.220  0.552
overlaps_CHOICE_LD:laser:tasksDualNoGo  0.942      0.526       1.687  0.485

                                        Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                                   0.831         0.945   6.920
overlaps_CHOICE_LD                            0.334         0.549  -1.083
laser                                         0.416         0.559  -0.341
tasksDualGo                                   0.381         0.490  -2.312
tasksDualNoGo                                 0.401         0.504  -1.810
overlaps_CHOICE_LD:laser                      0.461         0.694   1.332
overlaps_CHOICE_LD:tasksDualGo                0.400         0.652   0.421
overlaps_CHOICE_LD:tasksDualNoGo              0.445         0.693   1.122
laser:tasksDualGo                             0.464         0.643   1.190
laser:tasksDualNoGo                           0.457         0.637   1.037
overlaps_CHOICE_LD:laser:tasksDualGo          0.407         0.689   0.699
overlaps_CHOICE_LD:laser:tasksDualNoGo        0.345         0.628  -0.202

                                        P-val  Sig
(Intercept)                             0.000  ***
overlaps_CHOICE_LD                      0.279
laser                                   0.733
tasksDualGo                             0.021    *
tasksDualNoGo                           0.070    .
overlaps_CHOICE_LD:laser                0.183
overlaps_CHOICE_LD:tasksDualGo          0.674
overlaps_CHOICE_LD:tasksDualNoGo        0.262
laser:tasksDualGo                       0.234
laser:tasksDualNoGo                     0.300
overlaps_CHOICE_LD:laser:tasksDualGo    0.484
overlaps_CHOICE_LD:laser:tasksDualNoGo  0.840
#+end_example

#+begin_src ipython
def generate_colors(N, cmap_name='viridis'):
    cmap = plt.get_cmap(cmap_name)
    return cmap(np.linspace(0, 1, N))
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_betas(results, random_effects, title):

    fig, ax = plt.subplots(figsize=(1.5*width, 1.25*height))

    colors = generate_colors(random_effects.shape[0], 'plasma')
    space = np.random.normal(0, .05, random_effects.shape[0])

    keys = results.Estimate.keys()

    for i, key in enumerate(keys):
        res = results.Estimate[key]

        try:
            res += random_effects[key]
        except:
            res += random_effects['(Intercept)']
            pass

        mean_value = res.mean()
        std_dev = res.std()

        if results['P-val'][key]<0.001:
            plt.text(i,   3, '***', ha='center', va='bottom')
        elif results['P-val'][key]<0.01:
            plt.text(i,   3, '**', ha='center', va='bottom')
        elif results['P-val'][key]<0.05:
            plt.text(i,   3, '*', ha='center', va='bottom')
        elif results['P-val'][key]<0.1:
            plt.text(i,   3, '.', ha='center', va='bottom')

        plt.scatter(i * np.ones(res.shape[0]) + space, res, color=colors)
        plt.plot(i, mean_value, '_k', ms=20)
        plt.errorbar(i * np.ones(res.shape[0]),
                     [mean_value]*len(res),
                     yerr=[std_dev]*len(res), fmt='-', color='k', capsize=15)

    plt.axhline(y=0, color='black', ls='--')

    plt.xticks(np.arange(len(keys)), keys, fontsize=14, rotation=45)

    plt.ylabel('$\\beta$')
    plt.title(title)
    plt.savefig('beta_response.svg')
    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
print(results.Estimate.keys())
print(random_effects.keys())
# random_effects['overlaps_CHOICE_LD:daylast'] = random_effects['daylast:overlaps_CHOICE_LD']
#+end_src

#+RESULTS:
: Index(['(Intercept)', 'overlaps_CHOICE_LD', 'laser', 'tasksDualGo',
:        'tasksDualNoGo', 'overlaps_CHOICE_LD:laser',
:        'overlaps_CHOICE_LD:tasksDualGo', 'overlaps_CHOICE_LD:tasksDualNoGo',
:        'laser:tasksDualGo', 'laser:tasksDualNoGo',
:        'overlaps_CHOICE_LD:laser:tasksDualGo',
:        'overlaps_CHOICE_LD:laser:tasksDualNoGo'],
:       dtype='object')
: Index(['(Intercept)', 'laser'], dtype='object')

#+begin_src ipython
plot_betas(results, random_effects, '')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_46.png]]

*** Correlations off on

#+begin_src ipython
from scipy.stats import pearsonr
name = 'overlaps_CHOICE_LD'

df = df_choice[['mouse', 'performance', 'odr_perf', name, 'laser', 'sample_odor']]
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
# laser_mice = ['JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']

df = df[df.mouse.isin(laser_mice)]
# df = df[df.tasks!='DualGo'].drop(columns='tasks')
# df = df[df.tasks==0]

df2 = df_choice_on[['mouse', 'performance', 'odr_perf', name, 'laser', 'sample_odor']]
df2 = df2[df2.mouse.isin(laser_mice)]
# df2 = df2[df2.tasks!='DualGo'].drop(columns='tasks')
#df2 = df2[df2.tasks==0]

df_off = df[df.laser==0].groupby(['mouse', 'sample_odor']).mean().reset_index()
df_on = df2[df2.laser==1].groupby(['mouse', 'sample_odor']).mean().reset_index()

# df_off = df[df.laser==0].groupby(['mouse', 'day']).mean().reset_index()
# df_on = df2[df2.laser==1].groupby(['mouse', 'day']).mean().reset_index()

delta_df = df_off.drop(columns=[name, 'performance', 'odr_perf', 'laser', 'sample_odor'])

delta_df['overlaps_off'] = df_off[name] #  * (2 * df_off['sample_odor'] -1)
delta_df['overlaps_on'] = df_on[name]  # * (2* df_on['sample_odor'] -1)

delta_df['delta_overlaps'] = delta_df['overlaps_off'] - delta_df['overlaps_on']

delta_df['perf_off'] = df_off['performance']
delta_df['perf_on'] = df_on['performance']

delta_df['odr_perf_off'] = df_off['odr_perf']
delta_df['odr_perf_on'] = df_on['odr_perf']

delta_df['delta_perf'] = delta_df['perf_off'] - delta_df['perf_on']
delta_df['delta_odr_perf'] = delta_df['odr_perf_off'] - delta_df['odr_perf_on']

print(delta_df.head())
#+end_src

#+RESULTS:
#+begin_example
     mouse  overlaps_off  overlaps_on  delta_overlaps  perf_off   perf_on  \
0   ChRM04      0.089308     0.026754        0.062554  0.871528  0.868056
1   ChRM04      0.034740    -0.009822        0.044562  0.857639  0.878472
2   ChRM23     -0.014551    -0.023640        0.009088  0.679167  0.687500
3   ChRM23      0.076661    -0.029904        0.106565  0.750000  0.716667
4  JawsM01     -0.003011    -0.185822        0.182811  0.765625  0.796875

   odr_perf_off  odr_perf_on  delta_perf  delta_odr_perf
0      0.890625     0.869792    0.003472        0.020833
1      0.859375     0.885417   -0.020833       -0.026042
2      0.725000     0.706250   -0.008333        0.018750
3      0.768750     0.743750    0.033333        0.025000
4      0.960938     0.984375   -0.031250       -0.023438
#+end_example

#+begin_src ipython
df_day = df_off.copy()
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2 * width, height))

delta_overlaps = df_off[df_off.day=='first'][name].to_numpy() - df_off[df_off.day=='last'][name].to_numpy()
delta_perf = df_off[df_off.day=='first']['performance'].to_numpy() - df_off[df_off.day=='last']['performance'].to_numpy()

# corr, p_value = pearsonr(delta_perf, delta_overlaps)
#ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

ax[0].scatter(delta_perf, delta_overlaps)
ax[0].set_xlabel('$\\Delta$ DPA Perf first-last')
ax[0].set_ylabel('$\\Delta$ Overlaps first-last')

delta_odr_perf = df_off[df_off.day=='first']['odr_perf'].to_numpy() - df_off[df_off.day=='last']['odr_perf'].to_numpy()

corr, p_value = pearsonr(delta_odr_perf, delta_overlaps)
ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

ax[1].scatter(delta_odr_perf, delta_overlaps)
ax[1].set_xlabel('$\\Delta$ GoNoGo Perf first-last')
ax[1].set_ylabel('$\\Delta$ Overlaps first-last')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~/tmp/ipykernel_340330/770745332.py in ?()
      1 df_day = df_off.copy()
      2 fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2 * width, height))
      3
----> 4 delta_overlaps = df_off[df_off.day=='first'][name].to_numpy() - df_off[df_off.day=='last'][name].to_numpy()
      5 delta_perf = df_off[df_off.day=='first']['performance'].to_numpy() - df_off[df_off.day=='last']['performance'].to_numpy()
      6
      7 # corr, p_value = pearsonr(delta_perf, delta_overlaps)

~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/generic.py in ?(self, name)
   6200             and name not in self._accessors
   6201             and self._info_axis._can_hold_identifiers_and_holds_name(name)
   6202         ):
   6203             return self[name]
-> 6204         return object.__getattribute__(self, name)

AttributeError: 'DataFrame' object has no attribute 'day'
#+end_example
[[./figures/overlaps/figure_48.png]]
:END:

 #+begin_src ipython
from scipy.stats import pearsonr
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3 * width, height))

df_= delta_df.copy() # [delta_df.day=='last']
df_ = df_[df_.mouse != 'JawsM15']
# df_ = df_[df_.pair==0]

sns.lineplot(data=df_, x='perf_off', y='perf_on', marker='o', legend=0, ls='', ax=ax[0], ci=None, hue='mouse')

# corr, p_value = pearsonr(df_['perf_off'], df_['perf_on'])
ax[0].plot([.7, 1], [.7, 1], 'k--')
# ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

sns.lineplot(data=df_, x='overlaps_off', y='overlaps_on', marker='o', legend=0, ls='', ax=ax[1], ci=None, hue='mouse')

# corr, p_value = pearsonr(df_['overlaps_off'], df_['overlaps_on'])
# ax[1].plot([-.2, .3], [-.2*corr, .3*corr], 'k--')
# ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

sns.lineplot(data=df_, x='delta_perf', y='delta_overlaps', marker='o', legend=0, ls='', ax=ax[-1], ci=None, hue='mouse')

corr, p_value = pearsonr(df_['delta_perf'], df_['delta_overlaps'])
ax[-1].plot([-.1, .1], [-.1*corr, .1*corr], 'k--')
ax[-1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

plt.xlabel('$\\Delta$ Perf Off-On')
plt.ylabel('$\\Delta$ Overlaps Off-On')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_49.png]]

#+begin_src ipython
from scipy.stats import pearsonr
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3 * width, height))

df_= delta_df.copy()#[delta_df.day=='last']
df_ = df_[df_.mouse != 'JawsM15']
# df_ = df_[df_.tasks=='DualGo']

sns.lineplot(data=df_, x='odr_perf_off', y='odr_perf_on', marker='o', legend=0, ls='', ax=ax[0], ci=None, hue='mouse')

corr, p_value = pearsonr(df_['odr_perf_off'], df_['odr_perf_on'])
ax[0].plot([.7, 1], [.7, 1], 'k--')
ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

sns.lineplot(data=df_, x='overlaps_off', y='overlaps_on', marker='o', legend=0, ls='', ax=ax[1], ci=None, hue='mouse')

corr, p_value = pearsonr(df_['overlaps_off'], df_['overlaps_on'])
ax[1].plot([-.2, .3], [-.2*corr, .3*corr], 'k--')
ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

sns.lineplot(data=df_, x='delta_odr_perf', y='delta_overlaps', marker='o', legend=0, ls='', ax=ax[-1], ci=None, hue='mouse')
corr, p_value = pearsonr(df_['delta_odr_perf'], df_['delta_overlaps'])
ax[-1].plot([-.1, .1], [-.1 * corr, corr * .1], 'k--')
ax[-1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))

plt.xlabel('$\\Delta$ GoNoGo Perf Off-On')
plt.ylabel('$\\Delta$ Overlaps Off-On')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_50.png]]

 #+begin_src ipython

#+end_src

#+RESULTS:
