#+TITLE: Data driven RNN
#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session my_session :kernel torch

#+BEGIN_SRC ipython
  import torch
  import torch.nn as nn
  import torch.nn.functional as F

  class MultivariateRNN(nn.Module):
      def __init__(self, input_size, hidden_size, num_layers, output_size, device='cuda', decay_rate=0.1):
          super(MultivariateRNN, self).__init__()

          self.input_size = input_size
          self.hidden_size = hidden_size
          self.output_size = output_size

          self.num_layers = num_layers

          # Weight matrices
          self.W_ih = nn.Parameter(torch.Tensor(hidden_size, input_size))
          self.W_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))
          # Bias terms
          self.b_ih = nn.Parameter(torch.Tensor(hidden_size))
          self.b_hh = nn.Parameter(torch.Tensor(hidden_size))

          self.fc = nn.Linear(hidden_size, output_size)
          # Decay rate for the hidden state
          self.decay_rate = decay_rate
          self.exp_decay = torch.exp(-torch.tensor(decay_rate))
          # Initialize parameters
          self.reset_parameters()

      def reset_parameters(self):
          # Initialize weight and bias parameters using xavier initialization or another preferred method
          nn.init.xavier_uniform_(self.W_ih)
          nn.init.xavier_uniform_(self.W_hh)
          nn.init.zeros_(self.b_ih)
          nn.init.zeros_(self.b_hh)

      def forward(self, x):
          # x is of shape (batch_size, sequence_length, input_size)
          batch_size, seq_length, _ = x.size()
          # hidden_state = torch.zeros(batch_size, self.W_hh.size(0))
          hidden_state = torch.zeros(batch_size, self.W_hh.size(0), device=x.device)

          outputs = []
          for t in range(seq_length):
              # Compute new hidden state:
              hidden_state = torch.tanh(
                  torch.mm(x[:, t], self.W_ih.t()) + self.b_ih +
                  torch.mm(hidden_state, self.W_hh.t()) + self.b_hh)
              # Apply exponential decay: 
              if t > 0:
                  # Apply decay rate on the hidden state from the previous time step
                  hidden_state = hidden_state * self.exp_decay
              # Collect outputs
              outputs.append(self.fc(hidden_state.unsqueeze(1)))

          # Concatenate outputs along the time dimension
          outputs = torch.cat(outputs, dim=1)

          return outputs
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython
  # Example usage:
  input_size = 10
  hidden_size = 20
  num_layers = 1
  output_size = 10

  decay_rate = 0.1

  seq_length = 5
  batch_size = 3

  model = MultivariateRNN(input_size, hidden_size, num_layers, output_size, decay_rate)
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model.to(device)

  input_tensor = torch.randn(batch_size, seq_length, input_size)
  input_tensor = input_tensor.to(device)

  output = model(input_tensor)
  print(input_tensor.shape, output.shape)
#+END_SRC

#+RESULTS:
: torch.Size([3, 5, 10]) torch.Size([3, 5, 10])

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload
  
  %run /home/leon/dual_task/dual_data/notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

* Torch model
** RNN
*** Model

#+begin_src ipython
  # Define the RNN model
  class MultivariateRNN(nn.Module):
      def __init__(self, input_size, hidden_size, num_layers, output_size, device):
          super(MultivariateRNN, self).__init__()
          self.hidden_size = hidden_size
          self.num_layers = num_layers
          self.device=device
          # You can swap nn.RNN with nn.LSTM or nn.GRU depending on your requirements

          self.rnn = nn.RNN(input_size, hidden_size, num_layers,
                            batch_first=True, nonlinearity='relu', device=self.device)

          self.fc = nn.Linear(hidden_size, output_size, device=self.device)

          DT = 0.1
          TAU = 20

          self.DT_TAU = DT/TAU
          self.EXP_DT_TAU = np.exp(-DT/TAU)

      def forward(self, input):
          # Initial hidden state (can also initialize this outside and pass it as a parameter)
          rates = torch.zeros(self.num_layers, input.size(1), self.hidden_size, device=self.device)
          h = torch.zeros(self.num_layers, input.size(1), self.hidden_size, device=self.device)
          
          # Forward propagate the RNN
          h, _ = self.rnn(input, rates)
          rates = self.EXP_DT_TAU * rates + self.DT_TAU * h
          output = self.fc(rates)

          return output
#+end_src

#+RESULTS:

#+begin_src ipython
  model = MultivariateRNN(100, 100, 1, 100, 'cuda')
  h = torch.zeros((1, 1, 100)).to('cuda')
  model(h)
#+end_src

#+RESULTS:
#+begin_example
  tensor([[[ 0.0743,  0.0349, -0.0281,  0.0244,  0.0638, -0.0326, -0.0098,
            -0.0893, -0.0864,  0.0060, -0.0675,  0.0550, -0.0947, -0.0688,
             0.0893,  0.0037, -0.0952, -0.0735, -0.0637,  0.0374, -0.0392,
            -0.0892, -0.0861,  0.0955, -0.0957, -0.0601,  0.0050, -0.0573,
            -0.0101, -0.0468, -0.0750,  0.0093, -0.0496,  0.0580,  0.0404,
            -0.0109, -0.0046,  0.0811,  0.0832, -0.0034, -0.0890, -0.0895,
            -0.0485, -0.0620, -0.0397, -0.0410,  0.0560,  0.0687,  0.0319,
             0.0292,  0.0970,  0.0766,  0.0810,  0.0926,  0.0071, -0.0206,
            -0.0410, -0.0890, -0.0930, -0.0726, -0.0713, -0.0730,  0.0188,
             0.0178,  0.0304, -0.0033, -0.0768,  0.0896,  0.0487, -0.0550,
            -0.0873, -0.0742, -0.0879,  0.0261,  0.0960,  0.0327, -0.0123,
            -0.0355,  0.0805, -0.0619, -0.0210,  0.0105,  0.0337,  0.0168,
            -0.0204,  0.0357,  0.0311, -0.0377, -0.0324, -0.0346,  0.0420,
             0.0939, -0.0045, -0.0886, -0.0213, -0.0426,  0.0186,  0.0023,
            -0.0154, -0.0235]]], device='cuda:0', grad_fn=<ViewBackward0>)
#+end_example

*** Sliding Window

#+begin_src ipython
  class SlidingWindowDataset(Dataset):
      def __init__(self, data, sequence_length=100, stride=1):
          self.data = data
          self.sequence_length = sequence_length
          self.stride = stride
          # Calculate number of samples once to optimize __len__
          self.num_sessions, self.num_time_points, _ = self.data.size()
          self.num_samples_per_session = (self.num_time_points - self.sequence_length) // self.stride
          self.total_samples = self.num_samples_per_session * self.num_sessions

      def __len__(self):
          return self.total_samples

      def __getitem__(self, idx):
          # Determine which session this idx belongs to
          session_idx = idx // self.num_samples_per_session
          # Determine the start of the slice for this idx
          session_start = idx % self.num_samples_per_session
          time_idx = session_start * self.stride

          # Extract sequences using calculated indices
          input_sequence = self.data[session_idx, time_idx:time_idx + self.sequence_length]
          target_sequence = self.data[session_idx, time_idx + self.sequence_length]

          return input_sequence, target_sequence
#+end_src

#+RESULTS:

*** Data Split

#+begin_src ipython
  def split_data(X, train_perc=0.8, batch_size=32):

    # Split the dataset into training and validation sets
    train_size = int(train_perc * len(X))

    X_train = X[:train_size]
    X_test = X[train_size:]

    # X_train, X_mean, X_std = standard_scaler(X_train, IF_RETURN=1)
    # X_test = (X_test - X_mean) / X_std

    Y_train = Y[:train_size]
    Y_test = Y[train_size:]

    # Y_train, Y_mean, Y_std = standard_scaler(Y_train, IF_RETURN=1)
    # Y_test = (Y_test - Y_mean) / Y_std

    # Create data sets
    # train_dataset = TensorDataset(X_train_scaled, Y_train_scaled)
    # val_dataset = TensorDataset(X_test_scaled, Y_test_scaled)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)
    
    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    # sequence_length = 14  # or any other sequence length you want
    # stride = 1  # or any other stride you want

    # sliding_window_dataset = SlidingWindowDataset(X, sequence_length, stride)
    # train_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)
    # val_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)

    return train_loader, val_loader
#+end_src

#+RESULTS:

*** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer):
      size = len(dataloader.dataset)
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):

          X, y = X.to(device), y.to(device)
          
          # Compute prediction error
          pred = model(X)
          loss = loss_fn(pred, y)

          # Backpropagation
          loss.backward()
          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)

              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)
          val_loss /= size

      return val_loss
      # model.eval()
      # test_loss, correct = 0, 0
      # with torch.no_grad():
      #     for X, y in dataloader:
      #         X, y = X.to(device), y.to(device)
      #         pred = model(X)
      #         test_loss += loss_fn(pred, y).item()
      #         correct += (pred.argmax(1) == y).type(torch.float).sum().item()
      # test_loss /= num_batches
      # correct /= size
      # print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100):

    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    # Training loop.
    for epoch in range(num_epochs):
        loss = train(train_loader, model, loss_fn, optimizer)
        val_loss = test(val_loader, model, loss_fn)
        scheduler.step(val_loss)

        if epoch % int(0.1 * num_epochs) == 0:
            print(f'Epoch {epoch}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

#+end_src

#+RESULTS:

*** Prediction

#+begin_src ipython
  def get_predictions(model, future_steps, device='cuda:1'):
      model.eval()  # Set the model to evaluation mode

      # Start with an initial seed sequence 
      input_size = model.input_size
      hidden_size = model.hidden_size

      seed_sequence = torch.randn(1, future_steps, input_size).to(device)  # Replace with your actual seed

      # Collect predictions
      predictions = []

      # Initialize the hidden state (optional, depends on your model architecture)
      hidden = torch.zeros(model.num_layers, 1, hidden_size).to(device)
      # hidden = torch.randn(model.num_layers, 1, hidden_size, device=device) * 0.01
      
      # Generate time series
      for _ in range(future_steps):
          # Forward pass
          with torch.no_grad():  # No need to track gradients
              # out, hidden = model.rnn(seed_sequence, hidden)
              out = model(hidden)
              next_step = out[:, -1, :]  # Output for the last time step

          predictions.append(next_step.cpu().numpy())

          # Use the predicted next step as the input for the next iteration
          next_step = next_step.unsqueeze(1)  # Add the sequence length dimension
          seed_sequence = torch.cat((seed_sequence[:, 1:, :], next_step), 1)  # Move the window

      # # Convert predictions to a numpy array for further analysis
      predicted_time_series = np.concatenate(predictions, axis=0)

      return predicted_time_series

#+end_src

#+RESULTS:

** Pipeline

#+begin_src ipython
  def standard_scaler(data, IF_RETURN=0):
      mean = data.mean(dim=0, keepdim=True)
      std = data.std(dim=0, keepdim=True)
      if IF_RETURN:
          return (data - mean) / std, mean, std
      else:
          return (data - mean) / std

#+end_src

#+RESULTS:

#+begin_src ipython

  from torch.utils.data import DataLoader
  from torchvision import transforms

  # Assuming 'MyDataset' is a Dataset object you've made for your data
  class MyPipeline:
      def __init__(self, model, preprocessing=None):
          self.model = model
          self.preprocessing = preprocessing

      def __call__(self, x):
          if self.preprocessing:
              x = self.preprocessing(x)
          return self.model(x)

  # Define the transformations (preprocessing)
  preprocessing = transforms.Compose([
      transforms.ToTensor(),
      standard_scaler()
  ])

  # Create the pipeline
  model = MyRNNModel()  # Replace with your actual model
  pipeline = MyPipeline(model, preprocessing)

  # Now you can use your pipeline to process and feed data into your model
  dataset = MyDataset()
  dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

  # Use the pipeline in your training loop
  for inputs, targets in dataloader:
      predictions = pipeline(inputs)
      loss = loss_func(predictions, targets)
      # ... rest of your training loop
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  TypeError                                 Traceback (most recent call last)
  Cell In[58], line 18
       13         return self.model(x)
       15 # Define the transformations (preprocessing)
       16 preprocessing = transforms.Compose([
       17     transforms.ToTensor(),
  ---> 18     standard_scaler()
       19 ])
       21 # Create the pipeline
       22 model = MyRNNModel()  # Replace with your actual model

  TypeError: standard_scaler() missing 1 required positional argument: 'data'
#+end_example
:END:

** Synthetic Data

#+begin_src ipython
  def generate_multivariate_time_series(num_series, num_steps, num_features, device='cuda'):
      np.random.seed(42)  # For reproducibility

      # Generate random frequencies and phases for the sine waves
      frequencies = np.random.uniform(low=0.1, high=2.0, size=(num_features))
      phases = np.random.uniform(low=0, high=2*np.pi, size=(num_features))
      noise = np.random.uniform(low=0, high=1, size=(num_series))

      # Generate time steps for the sine waves
      time_steps = np.linspace(0, num_steps, num_steps)

      # Initialize the data array
      data = np.zeros((num_series, num_steps, num_features))

      # Populate the data array with sine waves
      for i in range(num_series):
          for j in range(num_steps):
              for k in range(num_features):
                  data[i, j, k] = np.sin(2 * np.pi * j / num_steps - phases[k]) + np.random.uniform()

      # Return as torch.FloatTensor
      return torch.FloatTensor(data).to(device)

#+end_src

#+RESULTS:

** Test on synthetic data
*** Create synthetic data

#+begin_src ipython
  num_series = 32  # Number of time series samples to generate
  num_steps = 84  # Number of time steps in each time series
  num_features = 100  # Number of features (signals) in each time series
  
  # Generate synthetic data
  synthetic_data = generate_multivariate_time_series(num_series, num_steps, num_features)

  # Split the data into inputs (X) and targets (Y), e.g., use previous timesteps to predict the next timestep
  X = synthetic_data[:, :-1, :]  # Using all but the last timestep as input
  Y = synthetic_data[:, 1:, :]   # Using all but the first timestep as target (shifted by one)

  print("Input shape:", X.shape)
  print("Target shape:", Y.shape)

#+end_src

#+RESULTS:
: Input shape: torch.Size([32, 83, 100])
: Target shape: torch.Size([32, 83, 100])

#+begin_src ipython
  plt.plot(np.arange(0, num_steps, 180), np.sin(num_steps))
  plt.plot(X.cpu().numpy()[0,:,2], alpha=1)
  plt.plot(X.cpu().numpy()[3,:,0], alpha=1, color='r')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3b18165ce9cd91277e97f3d4353d14ebbde9a524.png]]

*** Train model

#+begin_src ipython

  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  hidden_size = 1000
  num_layers = 1
  model = MultivariateRNN(input_size=num_features, hidden_size=hidden_size,
                          num_layers=num_layers, output_size=num_features, device=device)

  batch_size = 8
  train_loader, val_loader = split_data(X, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.001
  criterion = nn.MSELoss()
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)
  
  num_epochs = 100
  run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)  
#+end_src

#+RESULTS:
#+begin_example
  Epoch 0/100, Training Loss: 0.1629, Validation Loss: 0.1796
  Epoch 10/100, Training Loss: 0.0850, Validation Loss: 0.0888
  Epoch 20/100, Training Loss: 0.0840, Validation Loss: 0.0886
  Epoch 00029: reducing learning rate of group 0 to 1.0000e-04.
  Epoch 30/100, Training Loss: 0.0822, Validation Loss: 0.0865
  Epoch 40/100, Training Loss: 0.0808, Validation Loss: 0.0861
  Epoch 50/100, Training Loss: 0.0800, Validation Loss: 0.0864
  Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
  Epoch 60/100, Training Loss: 0.0811, Validation Loss: 0.0860
  Epoch 00069: reducing learning rate of group 0 to 1.0000e-06.
  Epoch 70/100, Training Loss: 0.0819, Validation Loss: 0.0860
  Epoch 80/100, Training Loss: 0.0826, Validation Loss: 0.0860
  Epoch 00089: reducing learning rate of group 0 to 1.0000e-07.
  Epoch 90/100, Training Loss: 0.0800, Validation Loss: 0.0860
#+end_example

#+RESULTS:

*** See data

#+begin_src ipython
  predicted_time_series = get_predictions(model, future_steps=84, device=device)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  RuntimeError                              Traceback (most recent call last)
  Cell In[78], line 1
  ----> 1 predicted_time_series = get_predictions(model, future_steps=84, device=device)

  Cell In[77], line 22, in get_predictions(model, future_steps, device)
       18 for _ in range(future_steps):
       19     # Forward pass
       20     with torch.no_grad():  # No need to track gradients
       21         # out, hidden = model.rnn(seed_sequence, hidden)
  ---> 22         out = model(hidden)
       23         next_step = out[:, -1, :]  # Output for the last time step
       25     predictions.append(next_step.cpu().numpy())

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518, in Module._wrapped_call_impl(self, *args, **kwargs)
     1516     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
     1517 else:
  -> 1518     return self._call_impl(*args, **kwargs)

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527, in Module._call_impl(self, *args, **kwargs)
     1522 # If we don't have any hooks, we want to skip the rest of the logic in
     1523 # this function, and just call forward.
     1524 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
     1525         or _global_backward_pre_hooks or _global_backward_hooks
     1526         or _global_forward_hooks or _global_forward_pre_hooks):
  -> 1527     return forward_call(*args, **kwargs)
     1529 try:
     1530     result = None

  Cell In[65], line 46, in MultivariateRNN.forward(self, x)
       42 outputs = []
       43 for t in range(seq_length):
       44     # Compute new hidden state:
       45     hidden_state = torch.tanh(
  ---> 46         torch.mm(x[:, t], self.W_ih.t()) + self.b_ih +
       47         torch.mm(hidden_state, self.W_hh.t()) + self.b_hh)
       48     # Apply exponential decay: 
       49     if t > 0:
       50         # Apply decay rate on the hidden state from the previous time step

  RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x1000 and 100x1000)
#+end_example
:END:

#+begin_src ipython
  import numpy as np
  import matplotlib.pyplot as plt

  # Assuming 'predicted_time_series' is a numpy array containing your generated data
  # Each column in 'predicted_time_series' corresponds to a different feature in the time series

  # Plot each feature of the time series
  num_features = predicted_time_series.shape[1]
  plt.figure()
  for i in range(2):
      plt.plot(predicted_time_series[:, i], lw=5)
      plt.plot(X.cpu().numpy()[0, :, i], alpha=.2)

  plt.xlabel('Time')
  plt.ylabel('Feature Value')
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  NameError                                 Traceback (most recent call last)
  Cell In[23], line 8
        2 import matplotlib.pyplot as plt
        4 # Assuming 'predicted_time_series' is a numpy array containing your generated data
        5 # Each column in 'predicted_time_series' corresponds to a different feature in the time series
        6 
        7 # Plot each feature of the time series
  ----> 8 num_features = predicted_time_series.shape[1]
        9 plt.figure()
       10 for i in range(2):

  NameError: name 'predicted_time_series' is not defined
#+end_example
:END:

#+begin_src ipython
  from sklearn.metrics import mean_squared_error

  # Assuming you have data loaders or a way to get your dataset (inputs and targets)
  # inputs: Your input multivariate time series data of shape (batch_size, sequence_length, input_size)
  # targets: The ground truth values of shape (batch_size, sequence_length, output_size)

  # Load the model (once again assuming it's already trained)
  # model = MultivariateRNN(input_size, hidden_size, num_layers, output_size)
  # model.to(device)  # Move the model to the appropriate compute device
  model.eval()  # Set the model to evaluation mode

  # This function feeds inputs through the model and computes the predictions
  def get_predictions(data_loader):
      predictions = []
      ground_truth = []
      with torch.no_grad():  # Disable gradient computation for evaluation
          for inputs, targets in data_loader:
              inputs, targets = inputs.to(device), targets.to(device)
              outputs = model(inputs)
              predictions.append(outputs.cpu())  # If using cuda, need to move data to cpu
              ground_truth.append(targets.cpu())

      # Concatenate all batches
      predictions = torch.cat(predictions, dim=0)
      ground_truth = torch.cat(ground_truth, dim=0)

      return predictions, ground_truth

  # Call the function using your data loader
  predictions, ground_truth = get_predictions(val_loader)

  print(ground_truth.numpy().shape, predictions.numpy().shape)
  # Calculate the loss or performance metric
  # For example, we can use the Mean Squared Error
  # error = mean_squared_error(ground_truth.numpy(), predictions.numpy())
  # print(f"Mean Squared Error: {error}")
#+end_src

#+RESULTS:
: (7, 83, 100) (7, 83, 100)

#+begin_src ipython
  import matplotlib.pyplot as plt

  # Assuming predictions and ground_truth are for a single batch or example:
  # predictions: tensor of shape (batch_size, sequence_length, output_size)
  # ground_truth: tensor of shape (batch_size, sequence_length, output_size)

  # Convert tensors to numpy arrays for plotting
  predictions_np = predictions.numpy()
  ground_truth_np = ground_truth.numpy()

  # Plot the predictions on top of the ground truth
  plt.figure()
  pal = sns.color_palette("tab10")

  # Example for plotting the first feature dimension
  for i in range(2):
     plt.plot(ground_truth_np[0, :, i], label='Ground Truth', marker='.', color=pal[i])
     plt.plot(predictions_np[0, :, i], label='Model Prediction', marker='x', color=pal[i])

  # You can loop through more feature dimensions if needed
  # for i in range(output_size):
  #     plt.plot(ground_truth_np[0, :, i], label=f'Ground Truth Feature {i}', marker='.')
  #     plt.plot(predictions_np[0, :, i], label=f'Prediction Feature {i}', marker='x')

  plt.title("Model Prediction vs Ground Truth")
  plt.xlabel("Time steps")
  plt.ylabel("Value")
  # plt.legend(fontsize=12)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0903581ef936a9e5652040fba52e58231c4a1bec.png]]

* Data
** imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')
  
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.common.options import set_options
#+end_src

#+RESULTS:

** parameters

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = ['first', 'last']

  kwargs = dict()
  kwargs = {'prescreen': None, 'pval': 0.05, 'trials': '', 'balance': 'under',
            'method': 'bootstrap', 'bolasso_pval':0.05, 'bolasso_penalty': 'l2',
            'bootstrap': True, 'n_boots': 1000,
            'preprocess': True, 'scaler_BL': None, 'avg_noise':True, 'unit_var_BL':False,
            'clf':'log_loss', 'scaler': None, 'tol':0.001, 'penalty':'l2',
            'out_fold': 'stratified', 'n_out': 5,
            'in_fold': 'stratified', 'n_in': 5,
            'random_state': None, 'n_repeats': 10,
            'n_lambda': 20, 'T_WINDOW': 0.5,
            }
  
#+end_src

#+RESULTS:

** load

#+begin_src ipython
  options = set_options(**kwargs)
  options['reload'] = True
  options['data_type'] = 'raw'
  options['DCVL'] = 1
  X_days, y_days = get_X_y_days(**options)
  X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)
#+end_src

#+RESULTS:
#+begin_example
  reading raw data
  mouse JawsM15 n_days 6 day 1 type raw all data: X (192, 693, 84) y (9, 192)
  X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 2 type raw all data: X (192, 693, 84) y (9, 192)
  X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 3 type raw all data: X (192, 693, 84) y (9, 192)
  X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 4 type raw all data: X (192, 693, 84) y (9, 192)
  X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 5 type raw all data: X (192, 693, 84) y (9, 192)
  X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 6 type raw all data: X (192, 693, 84) y (9, 192)
  X (192, 693, 84) y (9, 192)
  X_days (1152, 693, 84) y_days (1152, 6)
  ##########################################
  PREPROCESSING: SCALER None AVG MEAN False AVG NOISE True UNIT VAR False
  ##########################################
  Deconvolve Fluo
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:2017: UserWarning: nperseg = 256 is greater than input length  = 84, using nperseg = 84
    warnings.warn('nperseg = {0:d} is greater than input length '
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  /home/leon/mambaforge/envs/torch/lib/python3.10/site-packages/oasis/functions.py:166: RuntimeWarning: invalid value encountered in multiply
    return constrained_oasisAR1(y, g[0], sn, optimize_b=True if b is None else False,
  ##########################################
  DATA: FEATURES sample TASK DualGo TRIALS  DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (48, 693, 84) X_S2 (48, 693, 84)
#+end_example

#+begin_src ipython
  import numpy as np
  from scipy.ndimage import convolve1d
  
  def moving_average_multidim(data, window_size, axis=-1):
      """
      Apply a 1D moving average across a specified axis of a multi-dimensional array.

      :param data: multi-dimensional array of data
      :param window_size: size of the moving window 
      :param axis: axis along which to apply the moving average
      :return: smoothed data with the same shape as input data
      """
      # Create a moving average filter window
      window = np.ones(window_size) / window_size
      # Apply 1D convolution along the specified axis
      smoothed_data = convolve1d(data, weights=window, axis=axis, mode='reflect')
      return smoothed_data

#+end_src

#+RESULTS:

#+begin_src ipython
  from src.decode.bump import circcvl
  # smoothed_data = circcvl(X_data, windowSize=2, axis=-1)
  print(X_data.shape)
  window_size = 6
  # from scipy.ndimage import gaussian_filter1d
  # smoothed_data = gaussian_filter1d(X_data, axis=-1, sigma=2)
  # smoothed_data = moving_average_multidim(X_data[..., :52], window_size, axis=-1)
  smoothed_data = moving_average_multidim(X_data, window_size, axis=-1)
#+end_src

#+RESULTS:
: (96, 693, 84)

#+begin_src ipython
  time = np.linspace(0, 14, 84)
  for i in range(10):
      i = np.random.randint(100)
      plt.plot(time, smoothed_data[0, i,:], alpha=.5)

  plt.ylabel('Rate (Hz)')
  plt.xlabel('Time (s)')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7f4539ef4bed2a80edcf910fae40892f08148ad8.png]]

* Training

#+begin_src ipython
  # y = np.roll(X_data, -1)
  # y = y[..., :-1]

  Y = smoothed_data[..., 1:]
  X = smoothed_data[..., :-1]
  
  X = np.swapaxes(X, 1, -1)
  Y = np.swapaxes(Y, 1, -1)

  print(X.shape, Y.shape)
#+end_src

#+RESULTS:
: (96, 83, 693) (96, 83, 693)

#+begin_src ipython
  X = torch.tensor(X, dtype=torch.float32, device=device)
  Y = torch.tensor(Y, dtype=torch.float32, device=device)
  print(X.shape, Y.shape)
#+end_src

#+RESULTS:
: torch.Size([96, 83, 693]) torch.Size([96, 83, 693])

#+RESULTS:

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  hidden_size = 693
  num_layers = 1
  num_features = 693
  
  model = MultivariateRNN(input_size=num_features, hidden_size=hidden_size,
                          num_layers=num_layers, output_size=num_features, device=device)

  batch_size = 8
  train_loader, val_loader = split_data(X, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.001
  criterion = nn.MSELoss()
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.00001)

  num_epochs = 100
  run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)  
#+end_src

#+RESULTS:
#+begin_example
  Epoch 0/100, Training Loss: 0.0024, Validation Loss: 0.0021
  Epoch 10/100, Training Loss: 0.0006, Validation Loss: 0.0009
  Epoch 20/100, Training Loss: 0.0003, Validation Loss: 0.0007
  Epoch 30/100, Training Loss: 0.0003, Validation Loss: 0.0006
  Epoch 40/100, Training Loss: 0.0002, Validation Loss: 0.0005
  Epoch 50/100, Training Loss: 0.0002, Validation Loss: 0.0005
  Epoch 60/100, Training Loss: 0.0002, Validation Loss: 0.0004
  Epoch 70/100, Training Loss: 0.0002, Validation Loss: 0.0004
  Epoch 80/100, Training Loss: 0.0002, Validation Loss: 0.0004
  Epoch 90/100, Training Loss: 0.0002, Validation Loss: 0.0004
#+end_example

* Reverse Engineering
** Generate series

#+begin_src ipython
  from sklearn.metrics import mean_squared_error

  # Assuming you have data loaders or a way to get your dataset (inputs and targets)
  # inputs: Your input multivariate time series data of shape (batch_size, sequence_length, input_size)
  # targets: The ground truth values of shape (batch_size, sequence_length, output_size)

  # Load the model (once again assuming it's already trained)
  # model = MultivariateRNN(input_size, hidden_size, num_layers, output_size)
  # model.to(device)  # Move the model to the appropriate compute device
  model.eval()  # Set the model to evaluation mode

  # This function feeds inputs through the model and computes the predictions
  def get_predictions(data_loader):
      predictions = []
      ground_truth = []
      with torch.no_grad():  # Disable gradient computation for evaluation
          for inputs, targets in data_loader:
              inputs, targets = inputs.to(device), targets.to(device)
              outputs = model(inputs)
              predictions.append(outputs.cpu())  # If using cuda, need to move data to cpu
              ground_truth.append(targets.cpu())

      # Concatenate all batches
      predictions = torch.cat(predictions, dim=0)
      ground_truth = torch.cat(ground_truth, dim=0)

      return predictions, ground_truth

  # Call the function using your data loader
  predictions, ground_truth = get_predictions(val_loader)

  print(ground_truth.numpy().shape, predictions.numpy().shape)
  # Calculate the loss or performance metric
  # For example, we can use the Mean Squared Error
  # error = mean_squared_error(ground_truth.numpy(), predictions.numpy())
  # print(f"Mean Squared Error: {error}")
#+end_src

#+RESULTS:
: (20, 83, 693) (20, 83, 693)

#+begin_src ipython
  import matplotlib.pyplot as plt

  # Assuming predictions and ground_truth are for a single batch or example:
  # predictions: tensor of shape (batch_size, sequence_length, output_size)
  # ground_truth: tensor of shape (batch_size, sequence_length, output_size)

  # Convert tensors to numpy arrays for plotting
  predictions_np = predictions.numpy()
  ground_truth_np = ground_truth.numpy()

  # Plot the predictions on top of the ground truth
  plt.figure()
  pal = sns.color_palette("tab10")
  time = np.linspace(0, 14, 84)[:-1]
  # Example for plotting the first feature dimension
  for i in range(10):
     i = 10 + i
     plt.plot(time, ground_truth_np[0, :, i], '-', label='Ground Truth', color=pal[i-10], alpha=.2)
     plt.plot(time, predictions_np[0, :, i], label='Model Prediction', marker='o', color=pal[], alpha=1, lw=0)

  # You can loop through more feature dimensions if needed
  # for i in range(output_size):
  #     plt.plot(ground_truth_np[0, :, i], label=f'Ground Truth Feature {i}', marker='.')
  #     plt.plot(predictions_np[0, :, i], label=f'Prediction Feature {i}', marker='x')

  plt.title("Model Prediction vs Ground Truth")
  plt.xlabel("Time steps")
  plt.ylabel("Value")
  # plt.legend(fontsize=12)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ad9ce1bc3737f36fb1c1b5f726bc7118778ab80f.png]]

*** old
#+begin_src ipython
  predicted_time_series = get_predictions(model, future_steps=52, device=device)
#+end_src

#+RESULTS:

#+begin_src ipython
  import numpy as np
  import matplotlib.pyplot as plt

  time = np.linspace(0, 14, 84)[:52]
  num_features = predicted_time_series.shape[1]
  plt.figure()
  for i in range(10):
      i = np.random.randint(100)
      plt.plot(time, predicted_time_series[:, i], lw=1)
      plt.plot(time, X.cpu().numpy()[0, :, i], alpha=.2)

  plt.xlabel('Time')
  plt.ylabel('Feature Value')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3f744212fc665c1af03483616877dfbf1ba6efc0.png]]

** Connectivity

#+begin_src ipython
  # weights = model.rnn.weight_hh_l0.data.cpu().numpy()  # Get the recurring weights of the RNN
  weights = model.W_hh.cpu().detach().numpy()
  print(weights.shape)
  # Perform singular value decomposition<
  U, S, Vt = np.linalg.svd(weights, full_matrices=False)

  u1, u2, u3 = U[:, 0], U[:, 1], U[:, 2]  # First two left singular vectors
  v1, v2, v3 = Vt[0, :], Vt[1, :], Vt[2, :]  # First two right singular vectors
#+end_src

#+RESULTS:
: (693, 693)

#+begin_src ipython
  ksi1 = S[0] * u1 * v1
  ksi2 = S[1] * u2 * v2
  ksi3 = S[2] * u3 * v3
  print(ksi1.shape)
#+end_src

#+RESULTS:
: (693,)

#+begin_src ipython
  plt.imshow(weights, cmap='jet')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/d6f4932eb95afd3ff8aa50422b5670462ce9b27f.png]]

#+begin_src ipython
print(S[:10])
#+end_src

#+RESULTS:
: [2.2203255 1.9502777 1.9423882 1.92128   1.9170479 1.9051721 1.8953644
:  1.8862114 1.8783259 1.8719671]

#+begin_src ipython
  theta = np.arctan2(ksi2, ksi1)
  index = theta.argsort()
  print(index.shape)
#+end_src

#+RESULTS:
: (693,)

#+begin_src ipython
  plt.hist(theta*180/np.pi, bins='auto', density=True)
  plt.ylabel('Density')
  plt.xlabel('$\\theta$ ()')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b0ed52e11f31a96f9002ccd9ce5ddec164c83ab4.png]]

#+begin_src ipython
  plt.scatter(ksi1, ksi2)
  plt.xlabel('$\\xi_{1}$')
  plt.ylabel('$\\xi_{2}$')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e62fbc477220894e4bedf0c9aa1106b217141c8b.png]]

#+begin_src ipython
  Jij = weights[index][index]
  print(Jij.shape)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_src ipython
  print(Jij[:5,:5])
#+end_src

#+RESULTS:
: [[-0.01165107 -0.02418897  0.03574118 -0.03905753 -0.00204194]
:  [-0.03716209  0.02849341 -0.00865756  0.03969168  0.0192147 ]
:  [ 0.00862231 -0.05665462 -0.02051322 -0.05261631  0.0372612 ]
:  [ 0.01896639  0.01403332  0.02511325  0.02357699  0.03226864]
:  [ 0.03584021 -0.05170242  0.00827882 -0.02540789  0.01031427]]

: (693, 693)
:END:
#+RESULTS:
: [[-0.02597944 -0.00937634 -0.01982111  0.01863813  0.0037094 ]
:  [ 0.00066194 -0.02193735  0.00506656  0.00574334  0.00689308]
:  [-0.01483703 -0.00148363  0.01205834  0.02673673 -0.00484562]
:  [-0.03468229  0.01836705 -0.0079672  -0.02631866  0.01750046]
:  [-0.02275267  0.01882395  0.02421768 -0.00107763  0.00368118]]

#+begin_src ipython
  plt.imshow(Jij, cmap='jet')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/79c1de3ef880921522ed2210e9966124a544319b.png]]

#+begin_src ipython
  # Plot the singular values
  plt.figure(figsize=(10, 5))
  plt.plot(S)
  plt.yscale('log')  # Log scale can be helpful to see the drop-off more clearly
  plt.title('Singular Values of the RNN Hidden-to-Hidden Weight Matrix')
  plt.ylabel('Singular values (log scale)')
  plt.xlabel('Index')
  plt.grid(True)
  plt.show()

  # To see the cumulative energy, plot the cumulative sum of squares of singular values
  cumulative_energy = np.cumsum(S*2) / np.sum(S*2)
  plt.figure(figsize=(10, 5))
  plt.plot(cumulative_energy)
  plt.title('Cumulative Sum of Squares of Singular Values')
  plt.ylabel('Cumulative energy')
  plt.xlabel('Index')
  plt.grid(True)
  plt.show()

#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/ab3e9a175abf042764d0bd8899917cddedb0193b.png]]
[[file:./.ob-jupyter/8d3ee7d2a41c82c957ea3eb7c9e85fe24f2d0d04.png]]
:END:
