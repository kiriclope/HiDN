#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder2 :kernel dual_data :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_named_steps["model"]

    norm_w = np.linalg.norm(coef)

    if IF_SIGN:
        # dot_product = (2*y_test -1) * np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)
        dot_product = (2*y_test -1) * clf.decision_function(X_test)
    else:
        dot_product = clf.decision_function(X_test)
        # dot_product = -np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)

    return np.nanmean(dot_product) / coef.shape[0] / norm_w
#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['probas_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

    # lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
    # upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_mat(X, ax, vmin=-1, vmax=1):
  im = ax.imshow(
    X,
    interpolation="lanczos",
    origin="lower",
    cmap="jet",
    extent=[0, 14, 0, 14],
    vmin=vmin,
    vmax=vmax,
  )

  add_vdashed(ax)
  ax.set_xlim([2, 12])
  ax.set_xticks([2, 4, 6, 8, 10, 12])
  ax.set_ylim([2, 12])
  ax.set_yticks([2, 4, 6, 8, 10, 12])

  ax.set_xlabel("Testing Time (s)")
  ax.set_ylabel("Training Time (s)")
  return im
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt

def add_vdashed(ax=None, mouse=""):
    # Define time intervals
    t_STIM = [2, 3]
    t_DIST = [4.5, 5.5]
    t_CUE = [6.5, 7]
    t_TEST = [9, 10]

    # Add vertical dashed lines and text labels for each interval
    if ax is not None:
        # Draw vertical lines
        for t in [t_STIM, t_DIST, t_TEST]:
            ax.axvline(x=t[0], linestyle='--', color='k', lw=2)
            ax.axvline(x=t[1], linestyle='--', color='k', lw=2)

            ax.axhline(y=t[0], linestyle='--', color='k', lw=2)
            ax.axhline(y=t[1], linestyle='--', color='k', lw=2)

        # Add text labels at the middle of each interval
        ax.text((t_STIM[0] + t_STIM[1]) / 2, 12.5, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_DIST[0] + t_DIST[1]) / 2, 12.5, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        # ax.text((t_CUE[0] + t_CUE[1]) / 2, 12.5, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_TEST[0] + t_TEST[1]) / 2, 12.5, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)

        ax.text(12.5, (t_STIM[0] + t_STIM[1]) / 2, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        ax.text(12.5, (t_DIST[0] + t_DIST[1]) / 2, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        # ax.text(12.5, (t_CUE[0] + t_CUE[1]) / 2, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)
        ax.text(12.5, (t_TEST[0] + t_TEST[1]) / 2, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)

#+end_src

#+RESULTS:

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title=''):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12']
  # mice = ['PP09', 'PP17']
  # mice = 'JawsM15'

  kwargs = {
      'mouse': mice[0], 'laser': 0,
      'trials': 'correct', 'reload': 1, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 5, 'n_repeats': 16,
      'class_weight': 0,
      'multilabel':0,
      'mne_estimator':'generalizing', # sliding or generalizing
      'n_jobs': 128,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  safe_f1 = make_scorer(safe_f1_score, needs_proba=True)

  options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
  # options['hp_scoring'] = 'accuracy'
  #   options['scoring'] = options['hp_scoring']

  dum = 'accuracy_loocv'
 #+end_src

#+RESULTS:

#+RESULTS:

* Decoding vs days
** Model

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
#+end_src

#+RESULTS:

** Sample Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', n_jobs=None, tol=0.001, class_weight='balanced')
net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-2, 2, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = 'accuracy'
options['scoring'] = 'accuracy'
# options['scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)

# options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
# options['scoring'] = options['hp_scoring']

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)

options['cv'] = LeaveOneOut()
# options['cv'] = None
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0
options['multilabel']= 0
options['features'] = 'sample'
options['epochs'] = ['LD']

tasks = ['DPA', 'DualGo', 'DualNoGo']
dfs = []

# mice = ['JawsM15']
for mouse in mice:

    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    options['task'] = 'all'

    for day in days:
        options['day'] = day
        overlaps = get_classification(model, RETURN='df_scores', **options)
        options['reload'] = 0
        df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse

    dfs.append(df_mouse)

df_sample = pd.concat(dfs)
print(df_sample.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (25, 668, 84) X_S2 (29, 668, 84)
X_B (54, 668, 84) y_B (54,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (119, 668, 84) X_S2 (115, 668, 84)
y_labels (234, 10) ['DualNoGo' 'DPA' 'DualGo']
X (234, 668, 84) y (234,) [0. 1.]
scores (234, 2, 84, 84) 0.5877631723985891
df_A (234, 11) scores (234, 7056) labels (234, 10)
df_B (54, 11) scores (54, 7056) labels (54, 10)
df (288, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (12, 668, 84) X_S2 (12, 668, 84)
X_B (24, 668, 84) y_B (24,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (132, 668, 84) X_S2 (132, 668, 84)
y_labels (264, 10) ['DualNoGo' 'DualGo' 'DPA']
X (264, 668, 84) y (264,) [0. 1.]
scores (264, 2, 84, 84) 0.6149386259133283
df_A (264, 11) scores (264, 7056) labels (264, 10)
df_B (24, 11) scores (24, 7056) labels (24, 10)
df (288, 11)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (49, 693, 84) X_S2 (44, 693, 84)
X_B (93, 693, 84) y_B (93,) [0. 1.] ['DPA' 'DualGo' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (95, 693, 84) X_S2 (100, 693, 84)
y_labels (195, 12) ['DualNoGo' 'DualGo' 'DPA']
X (195, 693, 84) y (195,) [0. 1.]
scores (195, 2, 84, 84) 0.6082623732363316
df_A (195, 13) scores (195, 7056) labels (195, 12)
df_B (93, 13) scores (93, 7056) labels (93, 12)
df (288, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (20, 693, 84) X_S2 (19, 693, 84)
X_B (39, 693, 84) y_B (39,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (124, 693, 84) X_S2 (125, 693, 84)
y_labels (249, 12) ['DualGo' 'DualNoGo' 'DPA']
X (249, 693, 84) y (249,) [0. 1.]
scores (249, 2, 84, 84) 0.6493139211703199
df_A (249, 13) scores (249, 7056) labels (249, 12)
df_B (39, 13) scores (39, 7056) labels (39, 12)
df (288, 13)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (27, 444, 84) X_S2 (26, 444, 84)
X_B (53, 444, 84) y_B (53,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (117, 444, 84) X_S2 (118, 444, 84)
y_labels (235, 10) ['DualNoGo' 'DualGo' 'DPA']
X (235, 444, 84) y (235,) [0. 1.]
scores (235, 2, 84, 84) 0.6100285021415974
df_A (235, 11) scores (235, 7056) labels (235, 10)
df_B (53, 11) scores (53, 7056) labels (53, 10)
df (288, 11)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (3, 444, 84) X_S2 (2, 444, 84)
X_B (5, 444, 84) y_B (5,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (141, 444, 84) X_S2 (142, 444, 84)
y_labels (283, 10) ['DualGo' 'DualNoGo' 'DPA']
X (283, 444, 84) y (283,) [0. 1.]
scores (283, 2, 84, 84) 0.6065390565948602
df_A (283, 11) scores (283, 7056) labels (283, 10)
df_B (5, 11) scores (5, 7056) labels (5, 10)
df (288, 11)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
X_days (960, 361, 84) y_days (960, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (100, 361, 84) X_S2 (104, 361, 84)
X_B (204, 361, 84) y_B (204,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (188, 361, 84) X_S2 (184, 361, 84)
y_labels (372, 10) ['DPA' 'DualGo' 'DualNoGo']
X (372, 361, 84) y (372,) [0. 1.]
scores (372, 2, 84, 84) 0.6788017290249433
df_A (372, 11) scores (372, 7056) labels (372, 10)
df_B (204, 11) scores (204, 7056) labels (204, 10)
df (576, 11)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
X_days (960, 361, 84) y_days (960, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (16, 361, 84) X_S2 (19, 361, 84)
X_B (35, 361, 84) y_B (35,) [0. 1.] ['DualGo' 'DPA' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (176, 361, 84) X_S2 (173, 361, 84)
y_labels (349, 10) ['DualNoGo' 'DualGo' 'DPA']
X (349, 361, 84) y (349,) [0. 1.]
scores (349, 2, 84, 84) 0.6758705652399849
df_A (349, 11) scores (349, 7056) labels (349, 10)
df_B (35, 11) scores (35, 7056) labels (35, 10)
df (384, 11)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
X_days (960, 113, 84) y_days (960, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (120, 113, 84) X_S2 (124, 113, 84)
X_B (244, 113, 84) y_B (244,) [0. 1.] ['DualNoGo' 'DPA' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (168, 113, 84) X_S2 (164, 113, 84)
y_labels (332, 10) ['DualNoGo' 'DPA' 'DualGo']
X (332, 113, 84) y (332,) [0. 1.]
scores (332, 2, 84, 84) 0.535149114622701
df_A (332, 11) scores (332, 7056) labels (332, 10)
df_B (244, 11) scores (244, 7056) labels (244, 10)
df (576, 11)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
X_days (960, 113, 84) y_days (960, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (49, 113, 84) X_S2 (52, 113, 84)
X_B (101, 113, 84) y_B (101,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (143, 113, 84) X_S2 (140, 113, 84)
y_labels (283, 10) ['DualGo' 'DPA' 'DualNoGo']
X (283, 113, 84) y (283,) [0. 1.]
scores (283, 2, 84, 84) 0.5250326258975813
df_A (283, 11) scores (283, 7056) labels (283, 10)
df_B (101, 11) scores (101, 7056) labels (101, 10)
df (384, 11)
(3648, 14)
#+end_example

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0
options['multilabel']= 0
options['features'] = 'sample'
options['epochs'] = ['LD']

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

mice = ['JawsM15']
tasks = ['DPA', 'DualGo', 'DualNoGo']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_sample = pd.concat(dfs)
print(df_sample.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (35, 693, 84) X_S2 (35, 693, 84)
y_labels (70, 12) ['DPA']
X (70, 693, 84) y (70,) [0. 1.]
scores (70, 84, 84) 0.13545811088896031
df_A (70, 13) scores (70, 7056) labels (70, 12)
df (70, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (45, 693, 84) X_S2 (44, 693, 84)
y_labels (89, 12) ['DPA']
X (89, 693, 84) y (89,) [0. 1.]
scores (89, 84, 84) 0.4288669171861576
df_A (89, 13) scores (89, 7056) labels (89, 12)
df (89, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DualGo TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (27, 693, 84) X_S2 (28, 693, 84)
y_labels (55, 12) ['DualGo']
X (55, 693, 84) y (55,) [0. 1.]
scores (55, 84, 84) 0.12463725356929381
df_A (55, 13) scores (55, 7056) labels (55, 12)
df (55, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DualGo TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (38, 693, 84) X_S2 (40, 693, 84)
y_labels (78, 12) ['DualGo']
X (78, 693, 84) y (78,) [0. 1.]
scores (78, 84, 84) 0.17434821008347376
df_A (78, 13) scores (78, 7056) labels (78, 12)
df (78, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DualNoGo TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (33, 693, 84) X_S2 (37, 693, 84)
y_labels (70, 12) ['DualNoGo']
X (70, 693, 84) y (70,) [0. 1.]
scores (70, 84, 84) 0.16138076194011766
df_A (70, 13) scores (70, 7056) labels (70, 12)
df (70, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DualNoGo TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (41, 693, 84) X_S2 (41, 693, 84)
y_labels (82, 12) ['DualNoGo']
X (82, 693, 84) y (82,) [0. 1.]
scores (82, 84, 84) 0.16810553684289595
df_A (82, 13) scores (82, 7056) labels (82, 12)
df (82, 13)
(444, 14)
#+end_example

#+begin_src ipython
print(df_sample.head())
#+end_src

#+RESULTS:
#+begin_example
   index  sample_odor  test_odor      response     tasks  laser    day  \
0     10          0.0        1.0  incorrect_fa       DPA    0.0  first
1     16          0.0        1.0  incorrect_fa  DualNoGo    0.0  first
2     21          0.0        1.0  incorrect_fa    DualGo    0.0  first
3     29          0.0        1.0  incorrect_fa    DualGo    0.0  first
4     36          0.0        1.0  incorrect_fa  DualNoGo    0.0  first

   dist_odor  choice  idx                                           overlaps  \
0        NaN     1.0   10  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...
1        1.0     1.0   16  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, ...
2        0.0     1.0   21  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...
3        0.0     1.0   29  [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...
4        1.0     1.0   36  [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...

    mouse  performance  pair
0  ChRM04          NaN   NaN
1  ChRM04          NaN   NaN
2  ChRM04          NaN   NaN
3  ChRM04          NaN   NaN
4  ChRM04          NaN   NaN
#+end_example

#+begin_src ipython
df_sample['performance'] = df_sample['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_sample['pair'] = df_sample['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
 #+end_src

 #+RESULTS:

 #+begin_src ipython
if len(days)>3:
    name = 'df_sample_%s_days' % dum
elif len(days)==2:
    name = 'df_sample_%s_early_late' % dum
else:
    name = 'df_sample_%s' % dum

if len(mice)==1:
    pkl_save(df_sample, '%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    pkl_save(df_sample, '%s' % name, path="../data/mice/%s_ACC" % dum)
else:
    pkl_save(df_sample, '%s' % name, path="../data/mice/%s" % dum)

#+end_src

#+RESULTS:
: saving to ../data/mice/accuracy_loocv/df_sample_accuracy_loocv_early_late.pkl

#+begin_src ipython

#+end_src

#+RESULTS:

** Distractor Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-2, 2, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}
# options['hp_scoring'] = safe_f1
options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0

options['features'] = 'distractor'
options['epochs'] = ['MD']

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

# mice = ['JawsM15']
tasks = ['DPA']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_dist = pd.concat(dfs)
print(df_dist.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (41, 668, 84) X_S2 (39, 668, 84)
X_B (80, 668, 84) y_B (80,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (77, 668, 84) X_S2 (77, 668, 84)
y_labels (154, 10) ['DualGo' 'DualNoGo']
X (154, 668, 84) y (154,) [0. 1. 2. 3.]
scores (154, 2, 84, 84) 0.1227189200056329
df_A (154, 11) scores (154, 7056) labels (154, 10)
df_B (80, 11) scores (80, 7056) labels (80, 10)
df (234, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (47, 668, 84) X_S2 (41, 668, 84)
X_B (88, 668, 84) y_B (88,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (89, 668, 84) X_S2 (87, 668, 84)
y_labels (176, 10) ['DualGo' 'DualNoGo']
X (176, 668, 84) y (176,) [0. 1. 2. 3.]
scores (176, 2, 84, 84) -0.033596151438237416
df_A (176, 11) scores (176, 7056) labels (176, 10)
df_B (88, 11) scores (88, 7056) labels (88, 10)
df (264, 11)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (35, 693, 84) X_S2 (35, 693, 84)
X_B (70, 693, 84) y_B (70,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (55, 693, 84) X_S2 (70, 693, 84)
y_labels (125, 12) ['DualGo' 'DualNoGo']
X (125, 693, 84) y (125,) [0. 1. 2. 3.]
scores (125, 2, 84, 84) 0.10221591433984568
df_A (125, 13) scores (125, 7056) labels (125, 12)
df_B (70, 13) scores (70, 7056) labels (70, 12)
df (195, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (45, 693, 84) X_S2 (44, 693, 84)
X_B (89, 693, 84) y_B (89,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (78, 693, 84) X_S2 (82, 693, 84)
y_labels (160, 12) ['DualGo' 'DualNoGo']
X (160, 693, 84) y (160,) [0. 1. 2. 3.]
scores (160, 2, 84, 84) 0.056545209577400356
df_A (160, 13) scores (160, 7056) labels (160, 12)
df_B (89, 13) scores (89, 7056) labels (89, 12)
df (249, 13)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (41, 444, 84) X_S2 (39, 444, 84)
X_B (80, 444, 84) y_B (80,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (78, 444, 84) X_S2 (77, 444, 84)
y_labels (155, 10) ['DualGo' 'DualNoGo']
X (155, 444, 84) y (155,) [0. 1. 2. 3.]
scores (155, 2, 84, 84) 0.28084616894789133
df_A (155, 11) scores (155, 7056) labels (155, 10)
df_B (80, 11) scores (80, 7056) labels (80, 10)
df (235, 11)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 444, 84) X_S2 (47, 444, 84)
X_B (95, 444, 84) y_B (95,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (94, 444, 84) X_S2 (94, 444, 84)
y_labels (188, 10) ['DualGo' 'DualNoGo']
X (188, 444, 84) y (188,) [0. 1. 2. 3.]
scores (188, 2, 84, 84) 0.18982970341237132
df_A (188, 11) scores (188, 7056) labels (188, 10)
df_B (95, 11) scores (95, 7056) labels (95, 10)
df (283, 11)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
X_days (960, 361, 84) y_days (960, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (64, 361, 84) X_S2 (69, 361, 84)
X_B (133, 361, 84) y_B (133,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (104, 361, 84) X_S2 (135, 361, 84)
y_labels (239, 10) ['DualGo' 'DualNoGo']
X (239, 361, 84) y (239,) [0. 1. 2. 3.]
scores (239, 2, 84, 84) 0.1087123336022487
df_A (239, 11) scores (239, 7056) labels (239, 10)
df_B (133, 11) scores (133, 7056) labels (133, 10)
df (372, 11)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
X_days (960, 361, 84) y_days (960, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (60, 361, 84) X_S2 (62, 361, 84)
X_B (122, 361, 84) y_B (122,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (112, 361, 84) X_S2 (115, 361, 84)
y_labels (227, 10) ['DualGo' 'DualNoGo']
X (227, 361, 84) y (227,) [0. 1. 2. 3.]
scores (227, 2, 84, 84) 0.020454845407913827
df_A (227, 11) scores (227, 7056) labels (227, 10)
df_B (122, 11) scores (122, 7056) labels (122, 10)
df (349, 11)
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
X_days (960, 113, 84) y_days (960, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (57, 113, 84) X_S2 (51, 113, 84)
X_B (108, 113, 84) y_B (108,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (113, 113, 84) X_S2 (111, 113, 84)
y_labels (224, 10) ['DualGo' 'DualNoGo']
X (224, 113, 84) y (224,) [0. 1. 2. 3.]
scores (224, 2, 84, 84) -0.08836511490351287
df_A (224, 11) scores (224, 7056) labels (224, 10)
df_B (108, 11) scores (108, 7056) labels (108, 10)
df (332, 11)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
X_days (960, 113, 84) y_days (960, 9)
DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 113, 84) X_S2 (45, 113, 84)
X_B (93, 113, 84) y_B (93,) [0. 1.] ['DPA']
DATA: FEATURES distractor TASK Dual TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (94, 113, 84) X_S2 (96, 113, 84)
y_labels (190, 10) ['DualGo' 'DualNoGo']
X (190, 113, 84) y (190,) [0. 1. 2. 3.]
scores (190, 2, 84, 84) -0.01489087888267717
df_A (190, 11) scores (190, 7056) labels (190, 10)
df_B (93, 11) scores (93, 7056) labels (93, 10)
df (283, 11)
(2796, 14)
#+end_example

#+begin_src ipython
df_dist['performance'] = df_dist['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_dist['pair'] = df_dist['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
if len(days)>3:
    name = 'df_distractor_%s_days' % dum
elif len(days)==2:
    name = 'df_distractor_%s_early_late' % dum
else:
    name = 'df_distractor_%s' % dum

if len(mice)==1:
    pkl_save(df_dist, '%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    pkl_save(df_dist, '%s' % name, path="../data/mice/%s_ACC" % dum)
else:
    pkl_save(df_dist, '%s' % name, path="../data/mice/%s" % dum)

#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps_loocv/df_distractor_overlaps_loocv_early_late.pkl

** Choice Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-3, 3, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0

options['features'] = 'choice'
options['epochs'] = ['CHOICE']

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

# mice = ['JawsM15']
tasks = ['DPA', 'DualGo', 'DualNoGo']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_choice = pd.concat(dfs)
print(df_choice.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (62, 668, 84) X_S2 (34, 668, 84)
y_labels (96, 10) ['DPA']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.06451534673727709
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (54, 668, 84) X_S2 (42, 668, 84)
y_labels (96, 10) ['DPA']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.02259806656637862
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (67, 668, 84) X_S2 (29, 668, 84)
y_labels (96, 10) ['DualGo']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.16822865146160165
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (55, 668, 84) X_S2 (41, 668, 84)
y_labels (96, 10) ['DualGo']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.028269143377907327
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (65, 668, 84) X_S2 (31, 668, 84)
y_labels (96, 10) ['DualNoGo']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.1394245496055107
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (57, 668, 84) X_S2 (39, 668, 84)
y_labels (96, 10) ['DualNoGo']
X (96, 668, 84) y (96,) [0. 1.]
#+end_example

#+begin_src ipython
df_choice['performance'] = df_choice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_choice['pair'] = df_choice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
 #+end_src

 #+RESULTS:
 : 99e59c0c-fce6-44d6-8084-620062ade361

#+begin_src ipython
if len(days)>3:
    name = 'df_choice_%s_days' % dum
elif len(days)==2:
    name = 'df_choice_%s_early_late' % dum
else:
    name = 'df_choice_%s' % dum

if len(mice)==1:
    pkl_save(df_choice, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    pkl_save(df_choice, '%s' % name, path="../data/mice/overlaps_ACC")
else:
    pkl_save(df_choice, '%s' % name, path="../data/mice/overlaps")

#+end_src

#+RESULTS:
: 2b38ef5b-69ce-4f9e-afe5-a16fa72e45c0

#+begin_src ipython

#+end_src

#+RESULTS:
: a91c031d-6c86-4ec4-9241-7897a541193b

** Pair Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-3, 3, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 1

options['features'] = 'pair'
options['epochs'] = ['TEST']

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

mice = ['JawsM15']
tasks = ['DPA', 'DualGo', 'DualNoGo']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_pair = pd.concat(dfs)
print(df_pair.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Reading data from source file
mouse JawsM15 n_days 6 day 1 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 2 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 3 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 4 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 5 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 6 type dF all data: X (192, 693, 84) y (9, 192)
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DPA']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.01846499838597963
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DPA']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.026901399838697843
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.054284115300101216
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) 0.059975103372839095
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualNoGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.06763122860527637
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualNoGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.07311272143880634
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
(576, 14)
#+end_example

#+begin_src ipython
if len(days)>3:
    name = 'df_pair_%s_days' % dum
elif len(days)==2:
    name = 'df_pair_%s_early_late' % dum
else:
    name = 'df_pair_%s' % dum

if len(mice)==1:
    pkl_save(df_pair, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    pkl_save(df_pair, '%s' % name, path="../data/mice/overlaps_ACC")
else:
    pkl_save(df_pair, '%s' % name, path="../data/mice/overlaps")

#+end_src

#+RESULTS:
: saving to ../data/JawsM15/overlaps/df_pair_overlaps_l1_loocv_early_late.pkl

#+begin_src ipython

#+end_src

#+RESULTS:

* All together now

#+begin_src ipython
df.keys()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[41], line 1
: ----> 1 df.keys()
:
: NameError: name 'df' is not defined
:END:

#+begin_src ipython
df_1 = df_sample.reset_index(drop=True)
df_1['sample_overlaps'] = df_1['overlaps']

df_2 = df_dist.reset_index(drop=True)
df_2['dist_overlaps'] = df_2['overlaps']

df_all = pd.merge(df_1['sample_overlaps', 'idx', 'mouse'], df_2[['dist_overlaps', 'idx', 'mouse']], on=['mouse', 'idx'])
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790, in Index.get_loc(self, key)
   3789 try:
-> 3790     return self._engine.get_loc(casted_key)
   3791 except KeyError as err:

File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc()

File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc()

File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: ('sample_overlaps', 'idx', 'mouse')

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[54], line 7
      4 df_2 = df_dist.reset_index(drop=True)
      5 df_2['dist_overlaps'] = df_2['overlaps']
----> 7 df_all = pd.merge(df_1['sample_overlaps', 'idx', 'mouse'], df_2[['dist_overlaps', 'idx', 'mouse']], on=['mouse', 'idx'])

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/frame.py:3893, in DataFrame.__getitem__(self, key)
   3891 if self.columns.nlevels > 1:
   3892     return self._getitem_multilevel(key)
-> 3893 indexer = self.columns.get_loc(key)
   3894 if is_integer(indexer):
   3895     indexer = [indexer]

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797, in Index.get_loc(self, key)
   3792     if isinstance(casted_key, slice) or (
   3793         isinstance(casted_key, abc.Iterable)
   3794         and any(isinstance(x, slice) for x in casted_key)
   3795     ):
   3796         raise InvalidIndexError(key)
-> 3797     raise KeyError(key) from err
   3798 except TypeError:
   3799     # If we have a listlike key, _check_indexing_error will raise
   3800     #  InvalidIndexError. Otherwise we fall through and re-raise
   3801     #  the TypeError.
   3802     self._check_indexing_error(key)

KeyError: ('sample_overlaps', 'idx', 'mouse')
#+end_example
:END:

#+begin_src ipython
options['epochs'] = ['ED']
df_all['overlaps_ED'] = df_all['sample_overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
options['epochs'] = ['LD']
df_all['overlaps_ED_LD'] = df_all['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_all['overlaps_MD'] = df_all['dist_overlaps'].apply(lambda x: -avg_epochs(np.array(x).reshape(84, 84).T, **options))
options['epochs'] = ['ED']
df_all['overlaps_MD_ED'] = df_all['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_overlaps_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_overlaps_%s_early_late' % dum
else:
    name = 'df_overlaps_%s' % dum

if len(mice)==1:
    pkl_save(df_all, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    pkl_save(df_all, '%s' % name, path="../data/mice/overlaps_ACC")
else:
    pkl_save(df_all, '%s' % name, path="../data/mice/overlaps")

#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_overlaps_overlaps_l1_loocv_early_late.pkl

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

df = df_all.copy()
plot_overlaps(df, 'first', 'ED', ax[0], y0=0)
plot_overlaps(df, 'last', 'ED', ax[1], y0=0)
# sns.lineplot(data=df, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_43.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

df = df_all.copy()
# df = df[df.mouse=='JawsM15']
plot_overlaps(df, 'first', 'MD', ax[0], y0=0)
plot_overlaps(df, 'last', 'MD', ax[1], y0=0)
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_44.png]]

#+begin_src ipython
  formula = 'performance ~ overlaps_MD_ED + overlaps_ED_LD + (1 | mouse)'

  data = df_all.copy()
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_MD_ED+overlaps_ED_LD+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1899.898 	 AIC: 3807.795

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.299  0.547

No random effect correlations specified

Fixed effects:

                Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)        1.388   0.900    1.877  0.249  4.008      2.460
overlaps_MD_ED    -0.129  -0.222   -0.036  0.047  0.879      0.801
overlaps_ED_LD     0.004  -0.042    0.049  0.023  1.004      0.959

                OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  P-val  \
(Intercept)          6.532  0.800        0.711         0.867   5.572  0.000
overlaps_MD_ED       0.965  0.468        0.445         0.491  -2.716  0.007
overlaps_ED_LD       1.051  0.501        0.489         0.512   0.151  0.880

                Sig
(Intercept)     ***
overlaps_MD_ED   **
overlaps_ED_LD
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_43.png]]

* Data
** Sample dfs
*** data
:PROPERTIES:
:ID:       14c3fa52-5e87-45c2-af51-3b08aae4360e
:END:

#+begin_src ipython
size = 84
if len(options['days'])>3:
    name = 'df_sample_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_sample_%s_early_late' % dum
else:
    name = 'df_sample_%s' % dum

if len(mice)==1:
    size = size
    df_sample = pkl_load('%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    df_sample = pkl_load('%s' % name, path="../data/mice/%s_ACC" % dum)
    size = 115
else:
    size = 84
    df_sample = pkl_load('%s' % name, path="../data/mice/%s" % dum)
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps_l1_loocv/df_sample_overlaps_l1_loocv_early_late.pkl

#+begin_src ipython
size=84
df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(size, size) ))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size).T , **options))
# df_sample['overlaps_ED'] = -df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size).T , **options)) / (2.0 * df_sample.sample_odor -1.0)
# df_sample['overlaps_ED'] += df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size) , **options)) /2
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['CHOICE']
df_sample['overlaps_ED_CHOICE'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_CHOICE'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_sample.copy()

# df = df[df.mouse!='ChRM04']
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True)

sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[0])
df=df[df.performance==0]
# df = df[df.response=='correct_rej']

sns.lineplot(data=df, x='day', y='overlaps_diag_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[1])
sns.lineplot(data=df, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])

plt.xlabel('Day')
plt.ylabel('Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_52.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_sample.copy()
# df = df[df.mouse!='ChRM04']
# df = df[df.performance==0]
df = df[df.response=='incorrect_fa']
# df = df[df.sample_odor==0]

plot_overlaps(df, 'first', 'ED', ax[0], size=size, y0=0.5)
plot_overlaps(df, 'last', 'ED', ax[1],size=size, y0=0.5)

# plot_overlaps(df, 'first', 'diag', ax[0], size=size, y0=0.5)
# plot_overlaps(df, 'last', 'diag', ax[1],size=size, y0=0.5)

ax[0].set_ylabel('Sample Overlap')
ax[0].set_title('Naive')
ax[1].set_title('Expert')

ax[1].set_xlim([0, 10])
ax[1].set_xlim([0, 12])

plt.savefig('./cosyne/sample_overlap.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_53.png]]

*** Performance
**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~overlaps_ED_LD * tasks +  (1 | mouse)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_ED_LD*tasks+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 2400	 Groups: {'mouse': 5.0}

Log-likelihood: -1222.611 	 AIC: 2459.221

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.304  0.552

No random effect correlations specified

Fixed effects:

                              Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                      1.440   0.841    2.040  0.306  4.221
overlaps_ED_LD                   0.065  -0.498    0.628  0.287  1.067
tasksDualGo                     -0.228  -0.623    0.167  0.201  0.796
tasksDualNoGo                   -0.099  -0.515    0.316  0.212  0.906
overlaps_ED_LD:tasksDualGo      -0.235  -0.924    0.455  0.352  0.791
overlaps_ED_LD:tasksDualNoGo    -0.062  -0.834    0.709  0.394  0.939

                              OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                       2.318       7.688  0.808        0.699
overlaps_ED_LD                    0.608       1.873  0.516        0.378
tasksDualGo                       0.537       1.182  0.443        0.349
tasksDualNoGo                     0.598       1.372  0.475        0.374
overlaps_ED_LD:tasksDualGo        0.397       1.576  0.442        0.284
overlaps_ED_LD:tasksDualNoGo      0.434       2.032  0.484        0.303

                              Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                          0.885   4.708  0.000  ***
overlaps_ED_LD                       0.652   0.226  0.821
tasksDualGo                          0.542  -1.131  0.258
tasksDualNoGo                        0.578  -0.468  0.640
overlaps_ED_LD:tasksDualGo           0.612  -0.667  0.505
overlaps_ED_LD:tasksDualNoGo         0.670  -0.159  0.874
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_50.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ overlaps_ED_LD * tasks + (1 | day)'

  data = df_sample.copy()

  # data = data[data.mouse!='JawsM18']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_ED_LD*tasks+(1|day)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'day': 2.0}

Log-likelihood: -1880.247 	 AIC: 3774.494

Random effects:

            Name    Var    Std
day  (Intercept)  0.358  0.598

No random effect correlations specified

Fixed effects:

                              Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                      1.476   0.632    2.320  0.431  4.377
overlaps_ED_LD                  -0.001  -0.114    0.111  0.058  0.999
tasksDualGo                     -0.304  -0.508   -0.099  0.104  0.738
tasksDualNoGo                   -0.083  -0.292    0.126  0.107  0.920
overlaps_ED_LD:tasksDualGo      -0.012  -0.143    0.119  0.067  0.988
overlaps_ED_LD:tasksDualNoGo     0.063  -0.090    0.217  0.078  1.065

                              OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                       1.882      10.179  0.814        0.653
overlaps_ED_LD                    0.892       1.118  0.500        0.472
tasksDualGo                       0.601       0.906  0.425        0.376
tasksDualNoGo                     0.747       1.134  0.479        0.427
overlaps_ED_LD:tasksDualGo        0.867       1.127  0.497        0.464
overlaps_ED_LD:tasksDualNoGo      0.914       1.242  0.516        0.477

                              Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                          0.911   3.429  0.001  ***
overlaps_ED_LD                       0.528  -0.023  0.982
tasksDualGo                          0.475  -2.910  0.004   **
tasksDualNoGo                        0.531  -0.782  0.434
overlaps_ED_LD:tasksDualGo           0.530  -0.175  0.861
overlaps_ED_LD:tasksDualNoGo         0.554   0.808  0.419
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_60.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_diag_LD + (1 | day)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_diag_LD+(1|day)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'day': 3.0}

Log-likelihood: -1859.806 	 AIC: 3733.611

Random effects:

            Name    Var    Std
day  (Intercept)  0.403  0.635

No random effect correlations specified

Fixed effects:

                                Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                        1.035   0.253    1.816  0.399  2.815
tasksDualGo                        0.136  -0.282    0.554  0.213  1.146
tasksDualNoGo                      0.191  -0.225    0.607  0.212  1.210
overlaps_diag_LD                   0.682   0.270    1.094  0.210  1.978
tasksDualGo:overlaps_diag_LD      -0.661  -1.228   -0.095  0.289  0.516
tasksDualNoGo:overlaps_diag_LD    -0.361  -0.938    0.216  0.294  0.697

                                OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                         1.289       6.149  0.738        0.563
tasksDualGo                         0.754       1.740  0.534        0.430
tasksDualNoGo                       0.798       1.835  0.548        0.444
overlaps_diag_LD                    1.309       2.987  0.664        0.567
tasksDualGo:overlaps_diag_LD        0.293       0.910  0.340        0.227
tasksDualNoGo:overlaps_diag_LD      0.391       1.241  0.411        0.281

                                Prob_97.5_ci  Z-stat  P-val Sig
(Intercept)                            0.860   2.596  0.009  **
tasksDualGo                            0.635   0.638  0.523
tasksDualNoGo                          0.647   0.899  0.369
overlaps_diag_LD                       0.749   3.241  0.001  **
tasksDualGo:overlaps_diag_LD           0.476  -2.288  0.022   *
tasksDualNoGo:overlaps_diag_LD         0.554  -1.227  0.220
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_63.png]]

#+begin_src ipython
df_sample.keys()
#+end_src

#+RESULTS:
#+begin_example
Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
       'dist_odor', 'choice', 'overlaps', 'probas', 'coefs', 'mouse',
       'performance', 'pair', 'overlaps_diag', 'probas_diag', 'overlaps_ED',
       'probas_ED', 'overlaps_LD', 'probas_LD', 'overlaps_MD',
       'overlaps_ED_ED', 'overlaps_LD_ED', 'overlaps_diag_ED', 'probas_ED_ED',
       'probas_diag_ED', 'probas_LD_ED', 'overlaps_ED_LD', 'overlaps_LD_LD',
       'overlaps_diag_LD', 'probas_ED_LD', 'probas_diag_LD', 'overlaps_ED_MD',
       'overlaps_diag_MD', 'overlaps_ED_CHOICE', 'overlaps_diag_CHOICE',
       'probas_ED_CHOICE', 'probas_diag_CHOICE', 'overlaps_ED_POST_DIST',
       'overlaps_diag_POST_DIST', 'probas_ED_POST_DIST',
       'probas_diag_POST_DIST'],
      dtype='object')
#+end_example

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_diag_LD ~ tasks * performance + (1 | mouse)'

  data = df_sample.copy()

  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [lmerMod]
Formula: overlaps_diag_LD~tasks*performance+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -5972.954 	 AIC: 11961.909

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.126  0.355
Residual               1.533  1.238

No random effect correlations specified

Fixed effects:

                           Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  \
(Intercept)                   0.530   0.183    0.877  0.177     6.016   2.992
tasksDualGo                  -0.033  -0.236    0.170  0.104  3638.379  -0.320
tasksDualNoGo                -0.272  -0.483   -0.061  0.108  3638.077  -2.531
performance                   0.144  -0.028    0.316  0.088  3640.105   1.636
tasksDualGo:performance      -0.230  -0.462    0.003  0.119  3638.464  -1.936
tasksDualNoGo:performance     0.017  -0.222    0.255  0.122  3638.084   0.137

                           P-val Sig
(Intercept)                0.024   *
tasksDualGo                0.749
tasksDualNoGo              0.011   *
performance                0.102
tasksDualGo:performance    0.053   .
tasksDualNoGo:performance  0.891
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_66.png]]

** distractor dfs
*** data

#+begin_src ipython
print(options['days'])
if len(options['days'])>3:
    name = 'df_distractor_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_distractor_%s_early_late' % dum
else:
    name = 'df_distractor_%s' % dum

if len(mice)==1:
    df_dist = pkl_load('%s' % name, path="../data/%s/%s" % (options['mouse'], dum)).reset_index(drop=True)
elif len(mice)==2:
    df_dist = pkl_load('%s' % name, path="../data/mice/%s_ACC" % dum).reset_index(drop=True)
else:
    df_dist = pkl_load('%s' % name, path="../data/mice/%s" %dum).reset_index(drop=True)

#+end_src

#+RESULTS:
: ['first', 'last']
: loading from ../data/mice/overlaps_l1_loocv/df_distractor_overlaps_l1_loocv_early_late.pkl

#+begin_src ipython
df_dist['overlaps_diag'] = df_dist['overlaps'].apply(lambda x: -np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD'] = df_dist['overlaps'].apply(lambda x: -avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_dist['overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_ED'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_dist.copy()
# df = df[df.performance==0]
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.xlabel('Day')
plt.ylabel('Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_67.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True)

df = df_dist.copy()
df = df[df.mouse!='JawsM18']
# df = df[df.performance==1]
# df = df[df.response=='correct_rej']

# for i in range(1, 7):
#    plot_overlaps(df, i, 'MD', ax[0])

plot_overlaps(df, 'first', 'MD', ax[0], y0=0)
plot_overlaps(df, 'last', 'MD', ax[1], y0=0)

ax[0].set_ylabel('Go/NoGo Overlap')
ax[0].set_title('Naive')
ax[1].set_title('Expert')
ax[0].set_xlim([0, 12])
ax[1].set_xlim([0, 12])

plt.savefig('./cosyne/dist_overlap.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_68.png]]

*** Performance
**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~ overlaps_MD_ED * tasks + (1 | mouse) '

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_MD_ED*tasks+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1893.033 	 AIC: 3800.066

Random effects:

              Name    Var   Std
mouse  (Intercept)  0.303  0.55

No random effect correlations specified

Fixed effects:

                              Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                      1.537   1.032    2.042  0.258  4.651
overlaps_MD_ED                  -0.252  -0.416   -0.088  0.084  0.777
tasksDualGo                     -0.333  -0.527   -0.139  0.099  0.717
tasksDualNoGo                   -0.091  -0.292    0.109  0.102  0.913
overlaps_MD_ED:tasksDualGo       0.195  -0.031    0.421  0.115  1.215
overlaps_MD_ED:tasksDualNoGo     0.177  -0.043    0.397  0.112  1.193

                              OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                       2.806       7.709  0.823        0.737
overlaps_MD_ED                    0.660       0.916  0.437        0.398
tasksDualGo                       0.590       0.870  0.417        0.371
tasksDualNoGo                     0.747       1.115  0.477        0.428
overlaps_MD_ED:tasksDualGo        0.969       1.523  0.549        0.492
overlaps_MD_ED:tasksDualNoGo      0.958       1.487  0.544        0.489

                              Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                          0.885   5.963  0.000  ***
overlaps_MD_ED                       0.478  -3.014  0.003   **
tasksDualGo                          0.465  -3.359  0.001  ***
tasksDualNoGo                        0.527  -0.894  0.372
overlaps_MD_ED:tasksDualGo           0.604   1.690  0.091    .
overlaps_MD_ED:tasksDualNoGo         0.598   1.575  0.115
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    # elif p < 0.1:
    #     return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * days + (1|mouse)')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.xticks(df_coefs.index, ['Intercept', 'Early \n GoNoGo Overlap', 'DualGo', 'DualNoGo', 'Overlap*DualGo', 'Overlap*DualNoGo'])
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')
plt.savefig('./figures/glm.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_65.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_MD_ED * day + (1 | mouse)'

  data = df_dist.copy()
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_MD_ED*day+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1802.305 	 AIC: 3630.610

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.294  0.542

No random effect correlations specified

Fixed effects:

                                      Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                              1.097   0.587    1.606  0.260  2.994
tasksDualGo                             -0.363  -0.605   -0.121  0.123  0.696
tasksDualNoGo                           -0.061  -0.310    0.189  0.127  0.941
overlaps_MD_ED                          -0.208  -0.414   -0.002  0.105  0.812
daylast                                  1.216   0.885    1.547  0.169  3.374
tasksDualGo:overlaps_MD_ED               0.218  -0.069    0.506  0.147  1.244
tasksDualNoGo:overlaps_MD_ED             0.228  -0.051    0.506  0.142  1.256
tasksDualGo:daylast                      0.030  -0.415    0.475  0.227  1.030
tasksDualNoGo:daylast                   -0.177  -0.630    0.275  0.231  0.838
overlaps_MD_ED:daylast                   0.202  -0.163    0.566  0.186  1.224
tasksDualGo:overlaps_MD_ED:daylast      -0.064  -0.573    0.445  0.260  0.938
tasksDualNoGo:overlaps_MD_ED:daylast    -0.215  -0.709    0.280  0.252  0.807

                                      OR_2.5_ci  OR_97.5_ci   Prob  \
(Intercept)                               1.799       4.985  0.750
tasksDualGo                               0.546       0.886  0.410
tasksDualNoGo                             0.733       1.208  0.485
overlaps_MD_ED                            0.661       0.998  0.448
daylast                                   2.423       4.697  0.771
tasksDualGo:overlaps_MD_ED                0.933       1.658  0.554
tasksDualNoGo:overlaps_MD_ED              0.950       1.659  0.557
tasksDualGo:daylast                       0.660       1.608  0.507
tasksDualNoGo:daylast                     0.533       1.317  0.456
overlaps_MD_ED:daylast                    0.850       1.762  0.550
tasksDualGo:overlaps_MD_ED:daylast        0.564       1.561  0.484
tasksDualNoGo:overlaps_MD_ED:daylast      0.492       1.323  0.446

                                      Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                                 0.643         0.833   4.218
tasksDualGo                                 0.353         0.470  -2.937
tasksDualNoGo                               0.423         0.547  -0.477
overlaps_MD_ED                              0.398         0.500  -1.975
daylast                                     0.708         0.824   7.202
tasksDualGo:overlaps_MD_ED                  0.483         0.624   1.489
tasksDualNoGo:overlaps_MD_ED                0.487         0.624   1.601
tasksDualGo:daylast                         0.398         0.617   0.131
tasksDualNoGo:daylast                       0.348         0.568  -0.767
overlaps_MD_ED:daylast                      0.459         0.638   1.085
tasksDualGo:overlaps_MD_ED:daylast          0.361         0.610  -0.245
tasksDualNoGo:overlaps_MD_ED:daylast        0.330         0.569  -0.852

                                      P-val  Sig
(Intercept)                           0.000  ***
tasksDualGo                           0.003   **
tasksDualNoGo                         0.633
overlaps_MD_ED                        0.048    *
daylast                               0.000  ***
tasksDualGo:overlaps_MD_ED            0.137
tasksDualNoGo:overlaps_MD_ED          0.109
tasksDualGo:daylast                   0.895
tasksDualNoGo:daylast                 0.443
overlaps_MD_ED:daylast                0.278
tasksDualGo:overlaps_MD_ED:daylast    0.806
tasksDualNoGo:overlaps_MD_ED:daylast  0.394
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * tasks')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_67.png]]

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ tasks + (1 | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [lmerMod]
Formula: overlaps_MD_ED~tasks+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -4227.022 	 AIC: 8464.044

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.101  0.317
Residual               0.589  0.767

No random effect correlations specified

Fixed effects:

               Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  P-val Sig
(Intercept)       0.047  -0.235    0.329  0.144     4.121   0.327  0.759
tasksDualGo      -0.041  -0.102    0.020  0.031  3640.993  -1.317  0.188
tasksDualNoGo     0.028  -0.033    0.089  0.031  3640.993   0.907  0.364
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_69.png]]

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ day * tasks + (1 | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [lmerMod]
Formula: overlaps_MD_ED~day*tasks+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -4265.847 	 AIC: 8553.693

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.066  0.258
Residual               0.599  0.774

No random effect correlations specified

Fixed effects:

                         Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  \
(Intercept)                 0.104  -0.133    0.341  0.121     4.714   0.856
daylast                    -0.271  -0.382   -0.160  0.057  3635.506  -4.769
daymiddle                  -0.004  -0.106    0.097  0.052  3634.984  -0.087
tasksDualGo                -0.070  -0.171    0.031  0.052  3634.984  -1.354
tasksDualNoGo               0.017  -0.084    0.118  0.052  3634.984   0.328
daylast:tasksDualGo         0.136  -0.021    0.293  0.080  3634.984   1.698
daymiddle:tasksDualGo       0.079  -0.064    0.223  0.073  3634.984   1.084
daylast:tasksDualNoGo      -0.024  -0.181    0.133  0.080  3634.984  -0.297
daymiddle:tasksDualNoGo     0.048  -0.096    0.191  0.073  3634.984   0.652

                         P-val  Sig
(Intercept)              0.433
daylast                  0.000  ***
daymiddle                0.931
tasksDualGo              0.176
tasksDualNoGo            0.743
daylast:tasksDualGo      0.090    .
daymiddle:tasksDualGo    0.278
daylast:tasksDualNoGo    0.766
daymiddle:tasksDualNoGo  0.514
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_78.png]]

** choice dfs
*** data

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_choice_overlaps_days'
else:
    name = 'df_choice_overlaps'

if len(mice)==1:
    df_choice = pkl_load('%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    df_choice = pkl_load('%s' % name, path="../data/mice/overlaps_ACC")
else:
    df_choice = pkl_load('%s' % name, path="../data/mice/overlaps").reset_index()
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_choice_overlaps.pkl

#+begin_src ipython
df_choice['overlaps_diag'] = df_choice['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#df_choice['overlaps_diag'] = (2.0 * df_choice['choice'] -1 )  * df_choice['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_choice['overlaps_LD'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_LD'] = (2.0 * df_choice['choice'] -1 )  * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['TEST']
df_choice['overlaps_TEST'] = (2.0 * df_choice['pair'] -1 )  * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['TEST']
df_choice['overlaps_TEST'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_TEST'] = (2.0 * df_choice['choice'] -1 ) * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['RWD']
df_choice['overlaps_RWD'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_RWD'] = (2.0 * df_choice['choice'] -1 ) * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['RWD2']
df_choice['overlaps_RWD2'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_RWD'] = (2.0 * df_choice['choice'] -1 ) * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']

df_choice['overlaps_LD_LD'] = df_choice['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_diag_LD'] = df_choice['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_TEST_LD'] = df_choice['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_choice['overlaps_LD_ED'] = df_choice['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_diag_ED'] = df_choice['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_TEST_ED'] = df_choice['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_choice.copy()
sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0.5, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Performance')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_95.png]]

#+begin_src ipython
import seaborn as sns
df = df_choice.copy()
# df = df_choice[df_choice.mouse=='ACCM03']
# df = df[df.performance == 1]
sns.lineplot(data=df, x='day', y='overlaps_CHOICE_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Choice Overlap \n Late Delay')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_96.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_choice.copy()

plot_overlaps(df, 'first', 'TEST', ax[0], title='Choice', y0=0)
plot_overlaps(df, 'last', 'TEST', ax[1], title='Choice', y0=0)

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_90.png]]

#+begin_src ipython
plot_overlaps_mat(df_choice, 'first', vmin=0, vmax=2, title='Choice')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_91.png]]


#+begin_src ipython
plot_overlaps_mat(df_choice, 'last', vmin=0, vmax=2, title='Choice')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_92.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

*** Performance
**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~ day * overlaps_diag_LD + (1 | mouse)'

  data = df_choice.copy()
  # data = data[data.mouse!='JawsM18']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*overlaps_diag_LD+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1773.823 	 AIC: 3561.645

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.268  0.518

No random effect correlations specified

Fixed effects:

                            Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                    0.790   0.317    1.262  0.241  2.203
daylast                        1.421   1.176    1.666  0.125  4.142
daymiddle                      0.995   0.797    1.192  0.101  2.704
overlaps_diag_LD              -0.099  -0.152   -0.045  0.027  0.906
daylast:overlaps_diag_LD      -0.059  -0.182    0.064  0.063  0.942
daymiddle:overlaps_diag_LD    -0.080  -0.173    0.014  0.048  0.923

                            OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                     1.373       3.533  0.688        0.579
daylast                         3.242       5.292  0.806        0.764
daymiddle                       2.218       3.295  0.730        0.689
overlaps_diag_LD                0.859       0.956  0.475        0.462
daylast:overlaps_diag_LD        0.833       1.066  0.485        0.455
daymiddle:overlaps_diag_LD      0.841       1.014  0.480        0.457

                            Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                        0.779   3.277  0.001   **
daylast                            0.841  11.368  0.000  ***
daymiddle                          0.767   9.853  0.000  ***
overlaps_diag_LD                   0.489  -3.624  0.000  ***
daylast:overlaps_diag_LD           0.516  -0.943  0.346
daymiddle:overlaps_diag_LD         0.503  -1.668  0.095    .
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * days')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_88.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_diag_LD + (1 | mouse)'

  data = df_choice.copy()
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_diag_LD+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1862.552 	 AIC: 3739.105

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.272  0.521

No random effect correlations specified

Fixed effects:

                                Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                        1.532   1.050    2.014  0.246  4.626
tasksDualGo                       -0.181  -0.389    0.027  0.106  0.835
tasksDualNoGo                     -0.011  -0.221    0.199  0.107  0.989
overlaps_diag_LD                  -0.119  -0.204   -0.034  0.043  0.888
tasksDualGo:overlaps_diag_LD      -0.075  -0.179    0.029  0.053  0.927
tasksDualNoGo:overlaps_diag_LD    -0.052  -0.162    0.059  0.056  0.950

                                OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                         2.857       7.491  0.822        0.741
tasksDualGo                         0.678       1.027  0.455        0.404
tasksDualNoGo                       0.802       1.220  0.497        0.445
overlaps_diag_LD                    0.815       0.967  0.470        0.449
tasksDualGo:overlaps_diag_LD        0.836       1.029  0.481        0.455
tasksDualNoGo:overlaps_diag_LD      0.850       1.060  0.487        0.460

                                Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                            0.882   6.230  0.000  ***
tasksDualGo                            0.507  -1.704  0.088    .
tasksDualNoGo                          0.550  -0.102  0.919
overlaps_diag_LD                       0.491  -2.745  0.006   **
tasksDualGo:overlaps_diag_LD           0.507  -1.419  0.156
tasksDualNoGo:overlaps_diag_LD         0.515  -0.919  0.358
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * tasks')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_90.png]]

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_diag_LD ~ tasks + (1 | mouse)'

  data = df_choice.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [lmerMod]
Formula: overlaps_diag_LD~tasks+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -7506.789 	 AIC: 15023.579

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.129  0.359
Residual               3.567  1.889

No random effect correlations specified

Fixed effects:

               Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  P-val  Sig
(Intercept)       0.187  -0.146    0.520  0.170     4.641   1.101  0.325
tasksDualGo       0.386   0.236    0.536  0.077  3641.033   5.042  0.000  ***
tasksDualNoGo     0.145  -0.005    0.295  0.077  3641.033   1.896  0.058    .
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_92.png]]

** Pairs dfs
*** data

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_pair_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_pair_%s_early_late' % dum
else:
    name = 'df_pair_%s' % dum

if len(mice)==1:
    df_pairs = pkl_load('%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps_ACC")
else:
    df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps").reset_index()
#+end_src

#+RESULTS:
:RESULTS:
: loading from ../data/mice/overlaps/df_pair_overlaps_l1_loocv_early_late.pkl
# [goto error]
#+begin_example
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
Cell In[48], line 13
     11     df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps_ACC")
     12 else:
---> 13     df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps").reset_index()

Cell In[8], line 13, in pkl_load(name, path)
     11 source = path + "/" + name + '.pkl'
     12 print('loading from', source)
---> 13 return pkl.load(open( source, "rb"))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284, in _modified_open(file, *args, **kwargs)
    277 if file in {0, 1, 2}:
    278     raise ValueError(
    279         f"IPython won't let you open fd={file} by default "
    280         "as it is likely to crash IPython. If you know what you are doing, "
    281         "you can use builtins' open."
    282     )
--> 284 return io_open(file, *args, **kwargs)

FileNotFoundError: [Errno 2] No such file or directory: '../data/mice/overlaps/df_pair_overlaps_l1_loocv_early_late.pkl'
#+end_example
:END:

#+begin_src ipython
df_pairs['overlaps_diag'] = df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#df_pairs['overlaps_diag'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[34], line 1
: ----> 1 df_pairs['overlaps_diag'] = df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
:       2 #df_pairs['overlaps_diag'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['LD']
df_pairs['overlaps_LD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_LD'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[35], line 2
:       1 options['epochs'] = ['LD']
: ----> 2 df_pairs['overlaps_LD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_LD'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['TEST']
df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pair'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[36], line 2
:       1 options['epochs'] = ['TEST']
: ----> 2 df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pair'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['TEST']
df_pairs['overlaps_TEST'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[37], line 2
:       1 options['epochs'] = ['TEST']
: ----> 2 df_pairs['overlaps_TEST'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['RWD']
df_pairs['overlaps_RWD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[38], line 2
:       1 options['epochs'] = ['RWD']
: ----> 2 df_pairs['overlaps_RWD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['RWD2']
df_pairs['overlaps_RWD2'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[39], line 2
:       1 options['epochs'] = ['RWD2']
: ----> 2 df_pairs['overlaps_RWD2'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['LD']

df_pairs['overlaps_LD_LD'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_diag_LD'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_TEST_LD'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[40], line 3
:       1 options['epochs'] = ['LD']
: ----> 3 df_pairs['overlaps_LD_LD'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
:       4 df_pairs['overlaps_diag_LD'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
:       5 df_pairs['overlaps_TEST_LD'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['ED']
df_pairs['overlaps_LD_ED'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_diag_ED'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_TEST_ED'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[41], line 2
:       1 options['epochs'] = ['ED']
: ----> 2 df_pairs['overlaps_LD_ED'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
:       3 df_pairs['overlaps_diag_ED'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
:       4 df_pairs['overlaps_TEST_ED'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
import seaborn as sns
df = df_pairs.copy()
sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0.5, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Performance')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[42], line 2
:       1 import seaborn as sns
: ----> 2 df = df_pairs.copy()
:       3 sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
:       4 plt.axhline(0.5, ls='--', color='k')
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
import seaborn as sns
df = df_pairs.copy()
# df = df_pairs[df_pairs.mouse=='ACCM03']
# df = df[df.performance == 1]
sns.lineplot(data=df, x='day', y='overlaps_PAIRS_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Pairs Overlap \n Late Delay')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[43], line 2
:       1 import seaborn as sns
: ----> 2 df = df_pairs.copy()
:       3 # df = df_pairs[df_pairs.mouse=='ACCM03']
:       4 # df = df[df.performance == 1]
:       5 sns.lineplot(data=df, x='day', y='overlaps_PAIRS_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_pairs.copy()

plot_overlaps(df, 'first', 'TEST', ax[0], title='Pairs', y0=0)
plot_overlaps(df, 'last', 'TEST', ax[1], title='Pairs', y0=0)

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[44], line 3
:       1 fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)
: ----> 3 df = df_pairs.copy()
:       5 plot_overlaps(df, 'first', 'TEST', ax[0], title='Pairs', y0=0)
:       6 plot_overlaps(df, 'last', 'TEST', ax[1], title='Pairs', y0=0)
:
: NameError: name 'df_pairs' is not defined
[[./figures/overlaps/figure_111.png]]
:END:

#+begin_src ipython
plot_overlaps_mat(df_pairs, 'first', vmin=0, vmax=2, title='Pairs')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[45], line 1
: ----> 1 plot_overlaps_mat(df_pairs, 'first', vmin=0, vmax=2, title='Pairs')
:
: NameError: name 'df_pairs' is not defined
:END:


#+begin_src ipython
plot_overlaps_mat(df_pairs, 'last', vmin=0, vmax=2, title='Pairs')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[46], line 1
: ----> 1 plot_overlaps_mat(df_pairs, 'last', vmin=0, vmax=2, title='Pairs')
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython

#+end_src

#+RESULTS:
