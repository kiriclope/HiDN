#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder2 :kernel dual_data :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_named_steps["model"]

    norm_w = np.linalg.norm(coef)

    if IF_SIGN:
        # dot_product = (2*y_test -1) * np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)
        dot_product = (2*y_test -1) * clf.decision_function(X_test)
    else:
        dot_product = clf.decision_function(X_test)
        # dot_product = -np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)

    return np.nanmean(dot_product) / coef.shape[0] / norm_w
#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['probas_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

    # lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
    # upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_mat(X, ax, vmin=-1, vmax=1):
  im = ax.imshow(
    X,
    interpolation="lanczos",
    origin="lower",
    cmap="jet",
    extent=[0, 14, 0, 14],
    vmin=vmin,
    vmax=vmax,
  )

  add_vdashed(ax)
  ax.set_xlim([2, 12])
  ax.set_xticks([2, 4, 6, 8, 10, 12])
  ax.set_ylim([2, 12])
  ax.set_yticks([2, 4, 6, 8, 10, 12])

  ax.set_xlabel("Testing Time (s)")
  ax.set_ylabel("Training Time (s)")
  return im
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt

def add_vdashed(ax=None, mouse=""):
    # Define time intervals
    t_STIM = [2, 3]
    t_DIST = [4.5, 5.5]
    t_CUE = [6.5, 7]
    t_TEST = [9, 10]

    # Add vertical dashed lines and text labels for each interval
    if ax is not None:
        # Draw vertical lines
        for t in [t_STIM, t_DIST, t_TEST]:
            ax.axvline(x=t[0], linestyle='--', color='k', lw=2)
            ax.axvline(x=t[1], linestyle='--', color='k', lw=2)

            ax.axhline(y=t[0], linestyle='--', color='k', lw=2)
            ax.axhline(y=t[1], linestyle='--', color='k', lw=2)

        # Add text labels at the middle of each interval
        ax.text((t_STIM[0] + t_STIM[1]) / 2, 12.5, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_DIST[0] + t_DIST[1]) / 2, 12.5, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        # ax.text((t_CUE[0] + t_CUE[1]) / 2, 12.5, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_TEST[0] + t_TEST[1]) / 2, 12.5, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)

        ax.text(12.5, (t_STIM[0] + t_STIM[1]) / 2, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        ax.text(12.5, (t_DIST[0] + t_DIST[1]) / 2, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        # ax.text(12.5, (t_CUE[0] + t_CUE[1]) / 2, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)
        ax.text(12.5, (t_TEST[0] + t_TEST[1]) / 2, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)

#+end_src

#+RESULTS:

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title=''):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12']
  # mice = ['PP09', 'PP17']
  # mice = 'JawsM15'

  kwargs = {
      'mouse': mice[0], 'laser': 0,
      'trials': '', 'reload': 1, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 5, 'n_repeats': 16,
      'class_weight': 0,
      'multilabel':1,
      'mne_estimator':'generalizing', # sliding or generalizing
      'n_jobs': 128,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  safe_f1 = make_scorer(safe_f1_score, needs_proba=True)

  options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
  # options['hp_scoring'] = 'accuracy'
  #   options['scoring'] = options['hp_scoring']

  dum = 'accuracy_loocv'
 #+end_src

#+RESULTS:

* Decoding vs days
** Model

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
#+end_src

#+RESULTS:

** Sample Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', n_jobs=None, tol=0.001, class_weight='balanced')
# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-2, 2, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = 'accuracy'
options['scoring'] = 'accuracy'
# options['scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)

# options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
# options['scoring'] = options['hp_scoring']

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)

options['cv'] = LeaveOneOut()
# options['cv'] = None
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0
options['multilabel']= 1
options['features'] = 'sample'
options['epochs'] = ['ED']

tasks = ['DPA', 'DualGo', 'DualNoGo']
dfs = []

mice = ['JawsM06']
for mouse in mice:

    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    options['task'] = 'all'

    for day in days:
        options['day'] = day
        overlaps = get_classification(model, RETURN='df_scores', **options)
        options['reload'] = 0
        df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse

    dfs.append(df_mouse)

df_sample = pd.concat(dfs)
print(df_sample.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 115) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (59, 201, 115) X_S2 (46, 201, 115)
X_B (105, 201, 115) y_B (105,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (85, 201, 115) X_S2 (98, 201, 115)
y_labels (183, 10) ['DualNoGo' 'DualGo' 'DPA']
X (183, 201, 115) y (183,) [0. 1.]
scores (183, 2, 115, 115) 0.5181038647342995
df_A (183, 11) scores (183, 13225) labels (183, 10)
df_B (105, 11) scores (105, 13225) labels (105, 10)
df (288, 11)
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 115) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS incorrect DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (27, 201, 115) X_S2 (13, 201, 115)
X_B (40, 201, 115) y_B (40,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (117, 201, 115) X_S2 (131, 201, 115)
y_labels (248, 10) ['DPA' 'DualGo' 'DualNoGo']
X (248, 201, 115) y (248,) [0. 1.]
scores (248, 2, 115, 115) 0.5416018168452006
df_A (248, 11) scores (248, 13225) labels (248, 10)
df_B (40, 11) scores (40, 13225) labels (40, 10)
df (288, 11)
(576, 12)
#+end_example

#+begin_src ipython
# options['verbose'] = 1
# options['reload'] = 0
# options['multilabel']= 0
# options['features'] = 'sample'
# options['epochs'] = ['LD']

# tasks = ['DPA', 'DualGo', 'DualNoGo']

# dfs = []

# mice = ['JawsM15']
# tasks = ['DPA', 'DualGo', 'DualNoGo']

# for mouse in mice:
#     df_mouse = []
#     options['mouse'] = mouse
#     options = set_options(**options)
#     days = options['days']
#     print(days)

#     for task in tasks:
#         options['task'] = task

#         for day in days:
#             options['day'] = day
#             overlaps = get_classification(model, RETURN='df_scores', **options)
#             options['reload'] = 0
#             df_mouse.append(overlaps)

#     df_mouse = pd.concat(df_mouse)
#     df_mouse['mouse'] = mouse
#     dfs.append(df_mouse)

# df_sample = pd.concat(dfs)
# print(df_sample.shape)
    #+end_src

    #+RESULTS:

#+begin_src ipython
print(df_sample.head())
#+end_src

#+RESULTS:
#+begin_example
   index  sample_odor  test_odor        response     tasks  laser    day  \
0      8          0.0        0.0  incorrect_miss       DPA    0.0  first
1     26          0.0        1.0    incorrect_fa       DPA    0.0  first
2     29          0.0        0.0  incorrect_miss    DualGo    0.0  first
3     33          0.0        1.0    incorrect_fa  DualNoGo    0.0  first
4     40          0.0        1.0    incorrect_fa    DualGo    0.0  first

   dist_odor  choice  performance  pair  idx  \
0        NaN     0.0            0     1    8
1        NaN     1.0            0     0   26
2        0.0     0.0            0     1   29
3        1.0     1.0            0     0   33
4        0.0     1.0            0     0   40

                                            overlaps    mouse
0  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...  JawsM15
1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...  JawsM15
2  [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...  JawsM15
3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...  JawsM15
4  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...  JawsM15
#+end_example

#+begin_src ipython
df_sample['performance'] = df_sample['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_sample['pair'] = df_sample['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
 #+end_src

 #+RESULTS:

 #+begin_src ipython
if len(days)>3:
    name = 'df_sample_%s_days' % dum
elif len(days)==2:
    name = 'df_sample_%s_early_late' % dum
else:
    name = 'df_sample_%s' % dum

if len(mice)==1:
    pkl_save(df_sample, '%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    pkl_save(df_sample, '%s' % name, path="../data/mice/%s_PP" % dum)
else:
    pkl_save(df_sample, '%s' % name, path="../data/mice/%s" % dum)

#+end_src

#+RESULTS:
: saving to ../data/JawsM15/accuracy_loocv/df_sample_accuracy_loocv_early_late.pkl

#+begin_src ipython

#+end_src

#+RESULTS:

** Distractor Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-2, 2, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}
# options['hp_scoring'] = safe_f1
options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0

options['features'] = 'distractor'
options['epochs'] = ['MD']
options['NEW_DATA'] = 0
tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

mice = ['ChRM04']
tasks = ['DPA']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_dist = pd.concat(dfs)
print(df_dist.shape)
    #+end_src

#+RESULTS:


#+begin_src ipython
df_dist['performance'] = df_dist['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_dist['pair'] = df_dist['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
if len(days)>3:
    name = 'df_distractor_%s_days' % dum
elif len(days)==2:
    name = 'df_distractor_%s_early_late' % dum
else:
    name = 'df_distractor_%s' % dum

if len(mice)==1:
    pkl_save(df_dist, '%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    pkl_save(df_dist, '%s' % name, path="../data/mice/%s_ACC" % dum)
else:
    pkl_save(df_dist, '%s' % name, path="../data/mice/%s" % dum)

#+end_src

#+RESULTS:
: saving to ../data/JawsM06/accuracy_loocv/df_distractor_accuracy_loocv_early_late.pkl

** Choice Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-3, 3, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 0

options['features'] = 'choice'
options['epochs'] = ['CHOICE']

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

# mice = ['JawsM15']
tasks = ['DPA', 'DualGo', 'DualNoGo']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_choice = pd.concat(dfs)
print(df_choice.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (62, 668, 84) X_S2 (34, 668, 84)
y_labels (96, 10) ['DPA']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.06451534673727709
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (54, 668, 84) X_S2 (42, 668, 84)
y_labels (96, 10) ['DPA']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.02259806656637862
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (67, 668, 84) X_S2 (29, 668, 84)
y_labels (96, 10) ['DualGo']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.16822865146160165
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (55, 668, 84) X_S2 (41, 668, 84)
y_labels (96, 10) ['DualGo']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.028269143377907327
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (65, 668, 84) X_S2 (31, 668, 84)
y_labels (96, 10) ['DualNoGo']
X (96, 668, 84) y (96,) [0. 1.]
scores (96, 84, 84) 0.1394245496055107
df_A (96, 11) scores (96, 7056) labels (96, 10)
df (96, 11)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 9)
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (57, 668, 84) X_S2 (39, 668, 84)
y_labels (96, 10) ['DualNoGo']
X (96, 668, 84) y (96,) [0. 1.]
#+end_example

#+begin_src ipython
df_choice['performance'] = df_choice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_choice['pair'] = df_choice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
 #+end_src

 #+RESULTS:
 : 99e59c0c-fce6-44d6-8084-620062ade361

#+begin_src ipython
if len(days)>3:
    name = 'df_choice_%s_days' % dum
elif len(days)==2:
    name = 'df_choice_%s_early_late' % dum
else:
    name = 'df_choice_%s' % dum

if len(mice)==1:
    pkl_save(df_choice, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    pkl_save(df_choice, '%s' % name, path="../data/mice/overlaps_ACC")
else:
    pkl_save(df_choice, '%s' % name, path="../data/mice/overlaps")

#+end_src

#+RESULTS:
: 2b38ef5b-69ce-4f9e-afe5-a16fa72e45c0

#+begin_src ipython

#+end_src

#+RESULTS:
: a91c031d-6c86-4ec4-9241-7897a541193b

** Pair Overlaps

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=None, l1_ratio=0.95,  tol=0.001, class_weight='balanced')

params = {'model__C': np.logspace(-3, 3, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src ipython
options['verbose'] = 1
options['reload'] = 1

options['features'] = 'pair'
options['epochs'] = ['TEST']

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []

mice = ['JawsM15']
tasks = ['DPA', 'DualGo', 'DualNoGo']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']
    print(days)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_pair = pd.concat(dfs)
print(df_pair.shape)
    #+end_src

#+RESULTS:
#+begin_example
['first', 'last']
Reading data from source file
mouse JawsM15 n_days 6 day 1 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 2 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 3 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 4 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 5 type dF all data: X (192, 693, 84) y (9, 192)
mouse JawsM15 n_days 6 day 6 type dF all data: X (192, 693, 84) y (9, 192)
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DPA']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.01846499838597963
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DPA']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.026901399838697843
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.054284115300101216
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) 0.059975103372839095
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualNoGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.06763122860527637
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES pair TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 3 middle 0
X_S1 (48, 693, 84) X_S2 (48, 693, 84)
y_labels (96, 12) ['DualNoGo']
X (96, 693, 84) y (96,) [0 1]
scores (96, 84, 84) -0.07311272143880634
df_A (96, 13) scores (96, 7056) labels (96, 12)
df (96, 13)
(576, 14)
#+end_example

#+begin_src ipython
if len(days)>3:
    name = 'df_pair_%s_days' % dum
elif len(days)==2:
    name = 'df_pair_%s_early_late' % dum
else:
    name = 'df_pair_%s' % dum

if len(mice)==1:
    pkl_save(df_pair, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    pkl_save(df_pair, '%s' % name, path="../data/mice/overlaps_ACC")
else:
    pkl_save(df_pair, '%s' % name, path="../data/mice/overlaps")

#+end_src

#+RESULTS:
: saving to ../data/JawsM15/overlaps/df_pair_overlaps_l1_loocv_early_late.pkl

#+begin_src ipython

#+end_src

#+RESULTS:

* All together now

#+begin_src ipython
df.keys()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[41], line 1
: ----> 1 df.keys()
:
: NameError: name 'df' is not defined
:END:

#+begin_src ipython
df_1 = df_sample.reset_index(drop=True)
df_1['sample_overlaps'] = df_1['overlaps']

df_2 = df_dist.reset_index(drop=True)
df_2['dist_overlaps'] = df_2['overlaps']

df_all = pd.merge(df_1['sample_overlaps', 'idx', 'mouse'], df_2[['dist_overlaps', 'idx', 'mouse']], on=['mouse', 'idx'])
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790, in Index.get_loc(self, key)
   3789 try:
-> 3790     return self._engine.get_loc(casted_key)
   3791 except KeyError as err:

File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc()

File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc()

File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()

File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: ('sample_overlaps', 'idx', 'mouse')

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[54], line 7
      4 df_2 = df_dist.reset_index(drop=True)
      5 df_2['dist_overlaps'] = df_2['overlaps']
----> 7 df_all = pd.merge(df_1['sample_overlaps', 'idx', 'mouse'], df_2[['dist_overlaps', 'idx', 'mouse']], on=['mouse', 'idx'])

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/frame.py:3893, in DataFrame.__getitem__(self, key)
   3891 if self.columns.nlevels > 1:
   3892     return self._getitem_multilevel(key)
-> 3893 indexer = self.columns.get_loc(key)
   3894 if is_integer(indexer):
   3895     indexer = [indexer]

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797, in Index.get_loc(self, key)
   3792     if isinstance(casted_key, slice) or (
   3793         isinstance(casted_key, abc.Iterable)
   3794         and any(isinstance(x, slice) for x in casted_key)
   3795     ):
   3796         raise InvalidIndexError(key)
-> 3797     raise KeyError(key) from err
   3798 except TypeError:
   3799     # If we have a listlike key, _check_indexing_error will raise
   3800     #  InvalidIndexError. Otherwise we fall through and re-raise
   3801     #  the TypeError.
   3802     self._check_indexing_error(key)

KeyError: ('sample_overlaps', 'idx', 'mouse')
#+end_example
:END:

#+begin_src ipython
options['epochs'] = ['ED']
df_all['overlaps_ED'] = df_all['sample_overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
options['epochs'] = ['LD']
df_all['overlaps_ED_LD'] = df_all['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_all['overlaps_MD'] = df_all['dist_overlaps'].apply(lambda x: -avg_epochs(np.array(x).reshape(84, 84).T, **options))
options['epochs'] = ['ED']
df_all['overlaps_MD_ED'] = df_all['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_overlaps_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_overlaps_%s_early_late' % dum
else:
    name = 'df_overlaps_%s' % dum

if len(mice)==1:
    pkl_save(df_all, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    pkl_save(df_all, '%s' % name, path="../data/mice/overlaps_ACC")
else:
    pkl_save(df_all, '%s' % name, path="../data/mice/overlaps")

#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_overlaps_overlaps_l1_loocv_early_late.pkl

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

df = df_all.copy()
plot_overlaps(df, 'first', 'ED', ax[0], y0=0)
plot_overlaps(df, 'last', 'ED', ax[1], y0=0)
# sns.lineplot(data=df, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_43.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

df = df_all.copy()
# df = df[df.mouse=='JawsM15']
plot_overlaps(df, 'first', 'MD', ax[0], y0=0)
plot_overlaps(df, 'last', 'MD', ax[1], y0=0)
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_44.png]]

#+begin_src ipython
  formula = 'performance ~ overlaps_MD_ED + overlaps_ED_LD + (1 | mouse)'

  data = df_all.copy()
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_MD_ED+overlaps_ED_LD+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1899.898 	 AIC: 3807.795

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.299  0.547

No random effect correlations specified

Fixed effects:

                Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)        1.388   0.900    1.877  0.249  4.008      2.460
overlaps_MD_ED    -0.129  -0.222   -0.036  0.047  0.879      0.801
overlaps_ED_LD     0.004  -0.042    0.049  0.023  1.004      0.959

                OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  P-val  \
(Intercept)          6.532  0.800        0.711         0.867   5.572  0.000
overlaps_MD_ED       0.965  0.468        0.445         0.491  -2.716  0.007
overlaps_ED_LD       1.051  0.501        0.489         0.512   0.151  0.880

                Sig
(Intercept)     ***
overlaps_MD_ED   **
overlaps_ED_LD
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_43.png]]

* Data
** Sample dfs
*** data
:PROPERTIES:
:ID:       14c3fa52-5e87-45c2-af51-3b08aae4360e
:END:

#+begin_src ipython
size = 115
if len(options['days'])>3:
    name = 'df_sample_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_sample_%s_early_late' % dum
else:
    name = 'df_sample_%s' % dum

if len(mice)==1:
    size = size
    df_sample = pkl_load('%s' % name, path="../data/%s/%s" % (options['mouse'], dum))
elif len(mice)==2:
    df_sample = pkl_load('%s' % name, path="../data/mice/%s_ACC" % dum)
    size = 115
else:
    size = 84
    df_sample = pkl_load('%s' % name, path="../data/mice/%s" % dum)
#+end_src

#+RESULTS:
: loading from ../data/JawsM06/accuracy_loocv/df_sample_accuracy_loocv_early_late.pkl

#+begin_src ipython
size=84
df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(size, size) ))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size).T , **options))
# df_sample['overlaps_ED'] = -df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size).T , **options)) / (2.0 * df_sample.sample_odor -1.0)
# df_sample['overlaps_ED'] += df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(size, size) , **options)) /2
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['CHOICE']
df_sample['overlaps_ED_CHOICE'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_CHOICE'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_sample.copy()

# df = df[df.mouse!='ChRM04']
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True)

sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[0])
df=df[df.performance==0]
# df = df[df.response=='correct_rej']

sns.lineplot(data=df, x='day', y='overlaps_diag_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[1])
sns.lineplot(data=df, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])

plt.xlabel('Day')
plt.ylabel('Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_52.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_sample.copy()
# df = df[df.mouse!='ChRM04']
df = df[df.performance==1]
# df = df[df.response=='incorrect_fa']
# df = df[df.sample_odor==0]

# plot_overlaps(df, 'first', 'ED', ax[0], size=size, y0=1/4.)
# plot_overlaps(df, 'last', 'ED', ax[1],size=size, y0=1/4.)

plot_overlaps(df, 'first', 'diag', ax[0], size=size, y0=0.5)
plot_overlaps(df, 'last', 'diag', ax[1],size=size, y0=0.5)

ax[0].set_ylabel('Sample Overlap')
ax[0].set_title('Naive')
ax[1].set_title('Expert')

ax[1].set_xlim([0, 10])
ax[1].set_xlim([0, 12])

plt.savefig('./cosyne/sample_overlap.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_53.png]]

*** Performance
**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~overlaps_ED_LD * tasks +  (1 | mouse)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_ED_LD*tasks+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 2400	 Groups: {'mouse': 5.0}

Log-likelihood: -1222.611 	 AIC: 2459.221

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.304  0.552

No random effect correlations specified

Fixed effects:

                              Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                      1.440   0.841    2.040  0.306  4.221
overlaps_ED_LD                   0.065  -0.498    0.628  0.287  1.067
tasksDualGo                     -0.228  -0.623    0.167  0.201  0.796
tasksDualNoGo                   -0.099  -0.515    0.316  0.212  0.906
overlaps_ED_LD:tasksDualGo      -0.235  -0.924    0.455  0.352  0.791
overlaps_ED_LD:tasksDualNoGo    -0.062  -0.834    0.709  0.394  0.939

                              OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                       2.318       7.688  0.808        0.699
overlaps_ED_LD                    0.608       1.873  0.516        0.378
tasksDualGo                       0.537       1.182  0.443        0.349
tasksDualNoGo                     0.598       1.372  0.475        0.374
overlaps_ED_LD:tasksDualGo        0.397       1.576  0.442        0.284
overlaps_ED_LD:tasksDualNoGo      0.434       2.032  0.484        0.303

                              Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                          0.885   4.708  0.000  ***
overlaps_ED_LD                       0.652   0.226  0.821
tasksDualGo                          0.542  -1.131  0.258
tasksDualNoGo                        0.578  -0.468  0.640
overlaps_ED_LD:tasksDualGo           0.612  -0.667  0.505
overlaps_ED_LD:tasksDualNoGo         0.670  -0.159  0.874
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_50.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ overlaps_ED_LD * tasks + (1 | day)'

  data = df_sample.copy()

  # data = data[data.mouse!='JawsM18']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_ED_LD*tasks+(1|day)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'day': 2.0}

Log-likelihood: -1880.247 	 AIC: 3774.494

Random effects:

            Name    Var    Std
day  (Intercept)  0.358  0.598

No random effect correlations specified

Fixed effects:

                              Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                      1.476   0.632    2.320  0.431  4.377
overlaps_ED_LD                  -0.001  -0.114    0.111  0.058  0.999
tasksDualGo                     -0.304  -0.508   -0.099  0.104  0.738
tasksDualNoGo                   -0.083  -0.292    0.126  0.107  0.920
overlaps_ED_LD:tasksDualGo      -0.012  -0.143    0.119  0.067  0.988
overlaps_ED_LD:tasksDualNoGo     0.063  -0.090    0.217  0.078  1.065

                              OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                       1.882      10.179  0.814        0.653
overlaps_ED_LD                    0.892       1.118  0.500        0.472
tasksDualGo                       0.601       0.906  0.425        0.376
tasksDualNoGo                     0.747       1.134  0.479        0.427
overlaps_ED_LD:tasksDualGo        0.867       1.127  0.497        0.464
overlaps_ED_LD:tasksDualNoGo      0.914       1.242  0.516        0.477

                              Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                          0.911   3.429  0.001  ***
overlaps_ED_LD                       0.528  -0.023  0.982
tasksDualGo                          0.475  -2.910  0.004   **
tasksDualNoGo                        0.531  -0.782  0.434
overlaps_ED_LD:tasksDualGo           0.530  -0.175  0.861
overlaps_ED_LD:tasksDualNoGo         0.554   0.808  0.419
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_60.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_diag_LD + (1 | day)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_diag_LD+(1|day)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'day': 3.0}

Log-likelihood: -1859.806 	 AIC: 3733.611

Random effects:

            Name    Var    Std
day  (Intercept)  0.403  0.635

No random effect correlations specified

Fixed effects:

                                Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                        1.035   0.253    1.816  0.399  2.815
tasksDualGo                        0.136  -0.282    0.554  0.213  1.146
tasksDualNoGo                      0.191  -0.225    0.607  0.212  1.210
overlaps_diag_LD                   0.682   0.270    1.094  0.210  1.978
tasksDualGo:overlaps_diag_LD      -0.661  -1.228   -0.095  0.289  0.516
tasksDualNoGo:overlaps_diag_LD    -0.361  -0.938    0.216  0.294  0.697

                                OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                         1.289       6.149  0.738        0.563
tasksDualGo                         0.754       1.740  0.534        0.430
tasksDualNoGo                       0.798       1.835  0.548        0.444
overlaps_diag_LD                    1.309       2.987  0.664        0.567
tasksDualGo:overlaps_diag_LD        0.293       0.910  0.340        0.227
tasksDualNoGo:overlaps_diag_LD      0.391       1.241  0.411        0.281

                                Prob_97.5_ci  Z-stat  P-val Sig
(Intercept)                            0.860   2.596  0.009  **
tasksDualGo                            0.635   0.638  0.523
tasksDualNoGo                          0.647   0.899  0.369
overlaps_diag_LD                       0.749   3.241  0.001  **
tasksDualGo:overlaps_diag_LD           0.476  -2.288  0.022   *
tasksDualNoGo:overlaps_diag_LD         0.554  -1.227  0.220
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_63.png]]

#+begin_src ipython
df_sample.keys()
#+end_src

#+RESULTS:
#+begin_example
Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
       'dist_odor', 'choice', 'overlaps', 'probas', 'coefs', 'mouse',
       'performance', 'pair', 'overlaps_diag', 'probas_diag', 'overlaps_ED',
       'probas_ED', 'overlaps_LD', 'probas_LD', 'overlaps_MD',
       'overlaps_ED_ED', 'overlaps_LD_ED', 'overlaps_diag_ED', 'probas_ED_ED',
       'probas_diag_ED', 'probas_LD_ED', 'overlaps_ED_LD', 'overlaps_LD_LD',
       'overlaps_diag_LD', 'probas_ED_LD', 'probas_diag_LD', 'overlaps_ED_MD',
       'overlaps_diag_MD', 'overlaps_ED_CHOICE', 'overlaps_diag_CHOICE',
       'probas_ED_CHOICE', 'probas_diag_CHOICE', 'overlaps_ED_POST_DIST',
       'overlaps_diag_POST_DIST', 'probas_ED_POST_DIST',
       'probas_diag_POST_DIST'],
      dtype='object')
#+end_example

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_diag_LD ~ tasks * performance + (1 | mouse)'

  data = df_sample.copy()

  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [lmerMod]
Formula: overlaps_diag_LD~tasks*performance+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -5972.954 	 AIC: 11961.909

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.126  0.355
Residual               1.533  1.238

No random effect correlations specified

Fixed effects:

                           Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  \
(Intercept)                   0.530   0.183    0.877  0.177     6.016   2.992
tasksDualGo                  -0.033  -0.236    0.170  0.104  3638.379  -0.320
tasksDualNoGo                -0.272  -0.483   -0.061  0.108  3638.077  -2.531
performance                   0.144  -0.028    0.316  0.088  3640.105   1.636
tasksDualGo:performance      -0.230  -0.462    0.003  0.119  3638.464  -1.936
tasksDualNoGo:performance     0.017  -0.222    0.255  0.122  3638.084   0.137

                           P-val Sig
(Intercept)                0.024   *
tasksDualGo                0.749
tasksDualNoGo              0.011   *
performance                0.102
tasksDualGo:performance    0.053   .
tasksDualNoGo:performance  0.891
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_66.png]]

** distractor dfs
*** data

#+begin_src ipython
print(options['days'])
if len(options['days'])>3:
    name = 'df_distractor_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_distractor_%s_early_late' % dum
else:
    name = 'df_distractor_%s' % dum

if len(mice)==1:
    df_dist = pkl_load('%s' % name, path="../data/%s/%s" % (options['mouse'], dum)).reset_index(drop=True)
elif len(mice)==2:
    df_dist = pkl_load('%s' % name, path="../data/mice/%s_ACC" % dum).reset_index(drop=True)
else:
    df_dist = pkl_load('%s' % name, path="../data/mice/%s" %dum).reset_index(drop=True)

#+end_src

#+RESULTS:
: ['first', 'last']
: loading from ../data/JawsM06/accuracy_loocv/df_distractor_accuracy_loocv_early_late.pkl

#+begin_src ipython
size = 115
df_dist['overlaps_diag'] = df_dist['overlaps'].apply(lambda x: -np.diag(np.array(x).reshape(size, size)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD'] = df_dist['overlaps'].apply(lambda x: -avg_epochs(np.array(x).reshape(size, size).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_dist['overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_ED'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_dist.copy()
# df = df[df.performance==0]
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.xlabel('Day')
plt.ylabel('Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_67.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True)

df = df_dist.copy()
# df = df[df.mouse!='JawsM18']
# df = df[df.performance==1]
# df = df[df.response=='correct_rej']

# for i in range(1, 7):
#    plot_overlaps(df, i, 'MD', ax[0])

plot_overlaps(df, 'first', 'MD', ax[0], y0=0, size=size)
plot_overlaps(df, 'last', 'MD', ax[1], y0=0, size=size)

ax[0].set_ylabel('Go/NoGo Overlap')
ax[0].set_title('Naive')
ax[1].set_title('Expert')
ax[0].set_xlim([0, 12])
ax[1].set_xlim([0, 12])

plt.savefig('./cosyne/dist_overlap.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_68.png]]

*** Performance
**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~ overlaps_MD_ED * tasks + (1 | mouse) '

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[49], line 6
      4 # data = data[data.mouse!='JawsM18']
      5 glm = Lmer(formula=formula, data=data, family='binomial')
----> 6 result = glm.fit()
      7 print(result)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:440, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    438         _fam = self.family
    439     lmc = robjects.r(f"glmerControl({control})")
--> 440     self.model_obj = lmer.glmer(
    441         self.formula,
    442         data=data,
    443         family=_fam,
    444         control=lmc,
    445         contrasts=contrasts,
    446     )
    448 # Store design matrix and get number of IVs for inference
    449 design_matrix = stats.model_matrix(self.model_obj)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:869, in SexpClosure.__call__(self, *args, **kwargs)
    862     res = rmemory.protect(
    863         openrlib.rlib.R_tryEval(
    864             call_r,
    865             call_context.__sexp__._cdata,
    866             error_occured)
    867     )
    868     if error_occured[0]:
--> 869         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    870 return res

RRuntimeError: Error: grouping factors must have > 1 sampled level
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    # elif p < 0.1:
    #     return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * days + (1|mouse)')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.xticks(df_coefs.index, ['Intercept', 'Early \n GoNoGo Overlap', 'DualGo', 'DualNoGo', 'Overlap*DualGo', 'Overlap*DualNoGo'])
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')
plt.savefig('./figures/glm.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[50], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

TypeError: 'NoneType' object is not subscriptable
#+end_example
:END:

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_MD_ED * day + (1 | mouse)'

  data = df_dist.copy()
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[51], line 5
      3 data = df_dist.copy()
      4 glm = Lmer(formula=formula, data=data, family='binomial')
----> 5 result = glm.fit()
      6 print(result)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:440, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    438         _fam = self.family
    439     lmc = robjects.r(f"glmerControl({control})")
--> 440     self.model_obj = lmer.glmer(
    441         self.formula,
    442         data=data,
    443         family=_fam,
    444         control=lmc,
    445         contrasts=contrasts,
    446     )
    448 # Store design matrix and get number of IVs for inference
    449 design_matrix = stats.model_matrix(self.model_obj)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:869, in SexpClosure.__call__(self, *args, **kwargs)
    862     res = rmemory.protect(
    863         openrlib.rlib.R_tryEval(
    864             call_r,
    865             call_context.__sexp__._cdata,
    866             error_occured)
    867     )
    868     if error_occured[0]:
--> 869         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    870 return res

RRuntimeError: Error: grouping factors must have > 1 sampled level
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * tasks')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[52], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

TypeError: 'NoneType' object is not subscriptable
#+end_example
:END:

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ tasks + (1 | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[53], line 7
      4 # data = data[data.mouse!='JawsM18']
      6 glm = Lmer(formula=formula, data=data, family='gaussian')
----> 7 result = glm.fit()
      8 print(result)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:424, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    422     lmer = importr("lmerTest")
    423     lmc = robjects.r(f"lmerControl({control})")
--> 424     self.model_obj = lmer.lmer(
    425         self.formula, data=data, REML=REML, control=lmc, contrasts=contrasts
    426     )
    427 else:
    428     if verbose:

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:869, in SexpClosure.__call__(self, *args, **kwargs)
    862     res = rmemory.protect(
    863         openrlib.rlib.R_tryEval(
    864             call_r,
    865             call_context.__sexp__._cdata,
    866             error_occured)
    867     )
    868     if error_occured[0]:
--> 869         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    870 return res

RRuntimeError: Error: grouping factors must have > 1 sampled level
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[54], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

TypeError: 'NoneType' object is not subscriptable
#+end_example
:END:

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ day * tasks + (1 | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[55], line 7
      4 # data = data[data.mouse!='JawsM18']
      6 glm = Lmer(formula=formula, data=data, family='gaussian')
----> 7 result = glm.fit()
      8 print(result)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:424, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    422     lmer = importr("lmerTest")
    423     lmc = robjects.r(f"lmerControl({control})")
--> 424     self.model_obj = lmer.lmer(
    425         self.formula, data=data, REML=REML, control=lmc, contrasts=contrasts
    426     )
    427 else:
    428     if verbose:

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:869, in SexpClosure.__call__(self, *args, **kwargs)
    862     res = rmemory.protect(
    863         openrlib.rlib.R_tryEval(
    864             call_r,
    865             call_context.__sexp__._cdata,
    866             error_occured)
    867     )
    868     if error_occured[0]:
--> 869         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    870 return res

RRuntimeError: Error: grouping factors must have > 1 sampled level
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[56], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

TypeError: 'NoneType' object is not subscriptable
#+end_example
:END:

** choice dfs
*** data

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_choice_overlaps_days'
else:
    name = 'df_choice_overlaps'

if len(mice)==1:
    df_choice = pkl_load('%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    df_choice = pkl_load('%s' % name, path="../data/mice/overlaps_ACC")
else:
    df_choice = pkl_load('%s' % name, path="../data/mice/overlaps").reset_index()
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_choice_overlaps.pkl

#+begin_src ipython
df_choice['overlaps_diag'] = df_choice['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#df_choice['overlaps_diag'] = (2.0 * df_choice['choice'] -1 )  * df_choice['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_choice['overlaps_LD'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_LD'] = (2.0 * df_choice['choice'] -1 )  * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['TEST']
df_choice['overlaps_TEST'] = (2.0 * df_choice['pair'] -1 )  * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['TEST']
df_choice['overlaps_TEST'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_TEST'] = (2.0 * df_choice['choice'] -1 ) * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['RWD']
df_choice['overlaps_RWD'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_RWD'] = (2.0 * df_choice['choice'] -1 ) * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['RWD2']
df_choice['overlaps_RWD2'] = df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_choice['overlaps_RWD'] = (2.0 * df_choice['choice'] -1 ) * df_choice['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']

df_choice['overlaps_LD_LD'] = df_choice['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_diag_LD'] = df_choice['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_TEST_LD'] = df_choice['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_choice['overlaps_LD_ED'] = df_choice['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_diag_ED'] = df_choice['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_choice['overlaps_TEST_ED'] = df_choice['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_choice.copy()
sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0.5, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Performance')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_95.png]]

#+begin_src ipython
import seaborn as sns
df = df_choice.copy()
# df = df_choice[df_choice.mouse=='ACCM03']
# df = df[df.performance == 1]
sns.lineplot(data=df, x='day', y='overlaps_CHOICE_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Choice Overlap \n Late Delay')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_96.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_choice.copy()

plot_overlaps(df, 'first', 'TEST', ax[0], title='Choice', y0=0)
plot_overlaps(df, 'last', 'TEST', ax[1], title='Choice', y0=0)

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_90.png]]

#+begin_src ipython
plot_overlaps_mat(df_choice, 'first', vmin=0, vmax=2, title='Choice')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_91.png]]


#+begin_src ipython
plot_overlaps_mat(df_choice, 'last', vmin=0, vmax=2, title='Choice')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_92.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

*** Performance
**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~ day * overlaps_diag_LD + (1 | mouse)'

  data = df_choice.copy()
  # data = data[data.mouse!='JawsM18']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*overlaps_diag_LD+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1773.823 	 AIC: 3561.645

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.268  0.518

No random effect correlations specified

Fixed effects:

                            Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                    0.790   0.317    1.262  0.241  2.203
daylast                        1.421   1.176    1.666  0.125  4.142
daymiddle                      0.995   0.797    1.192  0.101  2.704
overlaps_diag_LD              -0.099  -0.152   -0.045  0.027  0.906
daylast:overlaps_diag_LD      -0.059  -0.182    0.064  0.063  0.942
daymiddle:overlaps_diag_LD    -0.080  -0.173    0.014  0.048  0.923

                            OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                     1.373       3.533  0.688        0.579
daylast                         3.242       5.292  0.806        0.764
daymiddle                       2.218       3.295  0.730        0.689
overlaps_diag_LD                0.859       0.956  0.475        0.462
daylast:overlaps_diag_LD        0.833       1.066  0.485        0.455
daymiddle:overlaps_diag_LD      0.841       1.014  0.480        0.457

                            Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                        0.779   3.277  0.001   **
daylast                            0.841  11.368  0.000  ***
daymiddle                          0.767   9.853  0.000  ***
overlaps_diag_LD                   0.489  -3.624  0.000  ***
daylast:overlaps_diag_LD           0.516  -0.943  0.346
daymiddle:overlaps_diag_LD         0.503  -1.668  0.095    .
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * days')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_88.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_diag_LD + (1 | mouse)'

  data = df_choice.copy()
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_diag_LD+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1862.552 	 AIC: 3739.105

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.272  0.521

No random effect correlations specified

Fixed effects:

                                Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                        1.532   1.050    2.014  0.246  4.626
tasksDualGo                       -0.181  -0.389    0.027  0.106  0.835
tasksDualNoGo                     -0.011  -0.221    0.199  0.107  0.989
overlaps_diag_LD                  -0.119  -0.204   -0.034  0.043  0.888
tasksDualGo:overlaps_diag_LD      -0.075  -0.179    0.029  0.053  0.927
tasksDualNoGo:overlaps_diag_LD    -0.052  -0.162    0.059  0.056  0.950

                                OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                         2.857       7.491  0.822        0.741
tasksDualGo                         0.678       1.027  0.455        0.404
tasksDualNoGo                       0.802       1.220  0.497        0.445
overlaps_diag_LD                    0.815       0.967  0.470        0.449
tasksDualGo:overlaps_diag_LD        0.836       1.029  0.481        0.455
tasksDualNoGo:overlaps_diag_LD      0.850       1.060  0.487        0.460

                                Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                            0.882   6.230  0.000  ***
tasksDualGo                            0.507  -1.704  0.088    .
tasksDualNoGo                          0.550  -0.102  0.919
overlaps_diag_LD                       0.491  -2.745  0.006   **
tasksDualGo:overlaps_diag_LD           0.507  -1.419  0.156
tasksDualNoGo:overlaps_diag_LD         0.515  -0.919  0.358
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')

plt.title('Performance ~ overlaps * tasks')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_90.png]]

**** Overlaps ~ tasks

#+begin_src ipython
  formula = 'overlaps_diag_LD ~ tasks + (1 | mouse)'

  data = df_choice.copy()
  # data = data[data.mouse!='JawsM18']

  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [lmerMod]
Formula: overlaps_diag_LD~tasks+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -7506.789 	 AIC: 15023.579

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.129  0.359
Residual               3.567  1.889

No random effect correlations specified

Fixed effects:

               Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  P-val  Sig
(Intercept)       0.187  -0.146    0.520  0.170     4.641   1.101  0.325
tasksDualGo       0.386   0.236    0.536  0.077  3641.033   5.042  0.000  ***
tasksDualNoGo     0.145  -0.005    0.295  0.077  3641.033   1.896  0.058    .
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_92.png]]

** Pairs dfs
*** data

#+begin_src ipython
if len(options['days'])>3:
    name = 'df_pair_%s_days' % dum
elif len(options['days'])==2:
    name = 'df_pair_%s_early_late' % dum
else:
    name = 'df_pair_%s' % dum

if len(mice)==1:
    df_pairs = pkl_load('%s' % name, path="../data/%s/overlaps" % options['mouse'])
elif len(mice)==2:
    df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps_ACC")
else:
    df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps").reset_index()
#+end_src

#+RESULTS:
:RESULTS:
: loading from ../data/mice/overlaps/df_pair_overlaps_l1_loocv_early_late.pkl
# [goto error]
#+begin_example
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
Cell In[48], line 13
     11     df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps_ACC")
     12 else:
---> 13     df_pairs = pkl_load('%s' % name, path="../data/mice/overlaps").reset_index()

Cell In[8], line 13, in pkl_load(name, path)
     11 source = path + "/" + name + '.pkl'
     12 print('loading from', source)
---> 13 return pkl.load(open( source, "rb"))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284, in _modified_open(file, *args, **kwargs)
    277 if file in {0, 1, 2}:
    278     raise ValueError(
    279         f"IPython won't let you open fd={file} by default "
    280         "as it is likely to crash IPython. If you know what you are doing, "
    281         "you can use builtins' open."
    282     )
--> 284 return io_open(file, *args, **kwargs)

FileNotFoundError: [Errno 2] No such file or directory: '../data/mice/overlaps/df_pair_overlaps_l1_loocv_early_late.pkl'
#+end_example
:END:

#+begin_src ipython
df_pairs['overlaps_diag'] = df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#df_pairs['overlaps_diag'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[34], line 1
: ----> 1 df_pairs['overlaps_diag'] = df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
:       2 #df_pairs['overlaps_diag'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['LD']
df_pairs['overlaps_LD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_LD'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[35], line 2
:       1 options['epochs'] = ['LD']
: ----> 2 df_pairs['overlaps_LD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_LD'] = (2.0 * df_pairs['pairs'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['TEST']
df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pair'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[36], line 2
:       1 options['epochs'] = ['TEST']
: ----> 2 df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pair'] -1 )  * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['TEST']
df_pairs['overlaps_TEST'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[37], line 2
:       1 options['epochs'] = ['TEST']
: ----> 2 df_pairs['overlaps_TEST'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_TEST'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['RWD']
df_pairs['overlaps_RWD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[38], line 2
:       1 options['epochs'] = ['RWD']
: ----> 2 df_pairs['overlaps_RWD'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['RWD2']
df_pairs['overlaps_RWD2'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
# df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[39], line 2
:       1 options['epochs'] = ['RWD2']
: ----> 2 df_pairs['overlaps_RWD2'] = df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:       3 # df_pairs['overlaps_RWD'] = (2.0 * df_pairs['pairs'] -1 ) * df_pairs['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['LD']

df_pairs['overlaps_LD_LD'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_diag_LD'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_TEST_LD'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[40], line 3
:       1 options['epochs'] = ['LD']
: ----> 3 df_pairs['overlaps_LD_LD'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
:       4 df_pairs['overlaps_diag_LD'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
:       5 df_pairs['overlaps_TEST_LD'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
options['epochs'] = ['ED']
df_pairs['overlaps_LD_ED'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_diag_ED'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_pairs['overlaps_TEST_ED'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[41], line 2
:       1 options['epochs'] = ['ED']
: ----> 2 df_pairs['overlaps_LD_ED'] = df_pairs['overlaps_LD'].apply(lambda x: avg_epochs(np.array(x), **options))
:       3 df_pairs['overlaps_diag_ED'] = df_pairs['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
:       4 df_pairs['overlaps_TEST_ED'] = df_pairs['overlaps_TEST'].apply(lambda x: avg_epochs(np.array(x), **options))
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
import seaborn as sns
df = df_pairs.copy()
sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0.5, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Performance')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[42], line 2
:       1 import seaborn as sns
: ----> 2 df = df_pairs.copy()
:       3 sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
:       4 plt.axhline(0.5, ls='--', color='k')
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
import seaborn as sns
df = df_pairs.copy()
# df = df_pairs[df_pairs.mouse=='ACCM03']
# df = df[df.performance == 1]
sns.lineplot(data=df, x='day', y='overlaps_PAIRS_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
plt.axhline(0, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Pairs Overlap \n Late Delay')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[43], line 2
:       1 import seaborn as sns
: ----> 2 df = df_pairs.copy()
:       3 # df = df_pairs[df_pairs.mouse=='ACCM03']
:       4 # df = df[df.performance == 1]
:       5 sns.lineplot(data=df, x='day', y='overlaps_PAIRS_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)

df = df_pairs.copy()

plot_overlaps(df, 'first', 'TEST', ax[0], title='Pairs', y0=0)
plot_overlaps(df, 'last', 'TEST', ax[1], title='Pairs', y0=0)

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[44], line 3
:       1 fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharex=True, sharey=True)
: ----> 3 df = df_pairs.copy()
:       5 plot_overlaps(df, 'first', 'TEST', ax[0], title='Pairs', y0=0)
:       6 plot_overlaps(df, 'last', 'TEST', ax[1], title='Pairs', y0=0)
:
: NameError: name 'df_pairs' is not defined
[[./figures/overlaps/figure_111.png]]
:END:

#+begin_src ipython
plot_overlaps_mat(df_pairs, 'first', vmin=0, vmax=2, title='Pairs')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[45], line 1
: ----> 1 plot_overlaps_mat(df_pairs, 'first', vmin=0, vmax=2, title='Pairs')
:
: NameError: name 'df_pairs' is not defined
:END:


#+begin_src ipython
plot_overlaps_mat(df_pairs, 'last', vmin=0, vmax=2, title='Pairs')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[46], line 1
: ----> 1 plot_overlaps_mat(df_pairs, 'last', vmin=0, vmax=2, title='Pairs')
:
: NameError: name 'df_pairs' is not defined
:END:

#+begin_src ipython

#+end_src

#+RESULTS:
