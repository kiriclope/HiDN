#+TITLE: Data driven RNN
#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session my_session :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run /home/leon/dual_task/dual_data/notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  DEVICE = 'cuda'
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

* Utils

#+begin_src ipython
def add_vlines(ax=None, mouse=""):
    t_BL = [0, 2]
    t_STIM = [2 , 3]
    t_ED = [3 , 4.5]
    t_DIST = [4.5 , 5.5]
    t_MD = [5.5 , 6.5]
    t_CUE = [6.5 , 7]
    t_RWD = [7 , 7.5]
    t_LD = [7.5 , 9]
    t_TEST = [9 , 10]
    t_RWD2 = [11 , 12]

    if "P" in mouse:
        t_BL = [0 , 2]
        t_STIM = [2 , 3]
        t_ED = [3 , 4]
        t_DIST = [4 , 5]
        t_MD = [5 , 6]
        t_CUE = [6 , 7]
        t_RWD = [7 , 8]
        t_LD = [8 , 9]
        t_TEST = [9 , 10]
        t_RWD2 = [10.5 , 11]

    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE, t_RWD2, t_RWD]
    colors = ["b", "b", "b", "g", "y", "y"]

    if ax is None:
        for period, color in zip(time_periods, colors):
            plt.axvspan(period[0], period[1], alpha=0.05, color=color)
    else:
        for period, color in zip(time_periods, colors):
            ax.axvspan(period[0], period[1], alpha=0.05, color=color)
#+end_src

#+RESULTS:

** Sliding Window

#+begin_src ipython
import numpy as np

def rescale_to_minus_one_to_one(data):
    """
    Rescale a 3D NumPy array to be between -1 and 1.

    Parameters:
    data (np.ndarray): Input data of shape (N_trials, N_neurons, N_time).

    Returns:
    np.ndarray: Rescaled data with the same shape as input.
    """
    data_min = np.min(data)
    data_max = np.max(data)

    # Avoid division by zero if min and max are equal
    if data_min == data_max:
        return np.zeros_like(data)

    # Rescale data
    normalized_data = 2 * ((data - data_min) / (data_max - data_min)) - 1
    return normalized_data
#+end_src

#+RESULTS:

#+begin_src ipython
  class SlidingWindowDataset(Dataset):
      def __init__(self, data, sequence_length=100, stride=1):
          self.data = data
          self.sequence_length = sequence_length
          self.stride = stride
          # Calculate number of samples once to optimize __len__
          self.num_sessions, self.num_time_points, _ = self.data.size()
          self.num_samples_per_session = (self.num_time_points - self.sequence_length) // self.stride
          self.total_samples = self.num_samples_per_session * self.num_sessions

      def __len__(self):
          return self.total_samples

      def __getitem__(self, idx):
          # Determine which session this idx belongs to
          session_idx = idx // self.num_samples_per_session
          # Determine the start of the slice for this idx
          session_start = idx % self.num_samples_per_session
          time_idx = session_start * self.stride

          # Extract sequences using calculated indices
          input_sequence = self.data[session_idx, time_idx:time_idx + self.sequence_length]
          target_sequence = self.data[session_idx, time_idx + self.sequence_length]

          return input_sequence, target_sequence
#+end_src

#+RESULTS:

#+begin_src ipython
  import numpy as np
  from scipy.ndimage import convolve1d

  def moving_average_multidim(data, window_size, axis=-1):
      """
      Apply a 1D moving average across a specified axis of a multi-dimensional array.

      :param data: multi-dimensional array of data
      :param window_size: size of the moving window
      :param axis: axis along which to apply the moving average
      :return: smoothed data with the same shape as input data
      """
      # Create a moving average filter window
      window = np.ones(window_size) / window_size
      # Apply 1D convolution along the specified axis
      smoothed_data = convolve1d(data, weights=window, axis=axis, mode='reflect')
      return smoothed_data

#+end_src

#+RESULTS:

** Data Split


#+RESULTS:

#+begin_src ipython
    def split_data(X, Y, train_perc=0.8, batch_size=8, n_labels=2):

       sample_size = int(train_perc * (X.shape[0] // n_labels))
       all_indices = np.arange(X.shape[0] // n_labels)

       train_indices = []
       test_indices = []
       for i in range(n_labels):
          all_indices = np.arange(i * X.shape[0] // n_labels, (i+1) * X.shape[0] // n_labels)
          idx = np.random.choice(all_indices, size=sample_size, replace=False)

          train_indices.append(idx)
          test_indices.append(np.setdiff1d(all_indices, idx))

       X_train = X[train_indices]
       X_test = X[test_indices]

       Y_train = Y[train_indices]
       Y_test = Y[test_indices]

       print(X_train.shape, Y_train.shape)
       train_dataset = TensorDataset(X_train, Y_train)

       print(X_test.shape, Y_test.shape)
       val_dataset = TensorDataset(X_test, Y_test)

       # Create data loaders
       train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
       val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

       # sequence_length = 14  # or any other sequence length you want
       # stride = 1  # or any other stride you want

       # sliding_window_dataset = SlidingWindowDataset(X, sequence_length, stride)
       # train_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)
       # val_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)

       return train_loader, val_loader
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
from torch.utils.data import TensorDataset, DataLoader
import torch

def split_data(X, Y, train_perc=0.8, batch_size=8, n_labels=2):

    sample_size = int(train_perc * (X.shape[0] // n_labels))
    train_indices = []
    test_indices = []

    for i in range(n_labels):
        start_idx = i * (X.shape[0] // n_labels)
        end_idx = (i + 1) * (X.shape[0] // n_labels)
        all_indices = np.arange(start_idx, end_idx)
        idx = np.random.choice(all_indices, size=sample_size, replace=False)
        train_indices.extend(idx)
        test_indices.extend(np.setdiff1d(all_indices, idx))

    train_indices = np.array(train_indices)
    test_indices = np.array(test_indices)

    X_train, X_test = X[train_indices], X[test_indices]
    Y_train, Y_test = Y[train_indices], Y[test_indices]

    print("X_train shape:", X_train.shape, "Y_train shape:", Y_train.shape)
    train_dataset = TensorDataset(X_train, Y_train)

    print("X_test shape:", X_test.shape, "Y_test shape:", Y_test.shape)
    val_dataset = TensorDataset(X_test, Y_test)

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0, l1_ratio=0.95):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          y_pred = model(X)
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  elif penalty=='l2':
                      reg_loss += torch.sum(torch.square(param))
                  else:
                      reg_loss += l1_ratio * torch.sum(torch.abs(param)) + (1.0-l1_ratio) * torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              y_pred = model(X)
              loss = loss_fn(y_pred, y)

              val_loss += loss.item() * X.size(0)

          val_loss /= size
          # acc = metric.compute()
          # print(f"Accuracy: {acc}")
          # metric.reset()
      return val_loss
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
    def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=0, thresh=0.005, l1_ratio=0.95):

      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
      model.to(device)

      # Training loop.
      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, l1_ratio=l1_ratio)
          val_loss = validation_step(val_loader, model, loss_fn)

          scheduler.step()

          if epoch % int(num_epochs  / 10) == 0:
              print(f'Epoch {epoch}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break
#+end_src

#+RESULTS:

** Prediction


#+begin_src ipython
  def get_predictions(model, future_steps, device='cuda:1'):
      model.eval()  # Set the model to evaluation mode

      # Start with an initial seed sequence
      input_size = model.input_size
      hidden_size = model.hidden_size

      seed_sequence = torch.randn(1, future_steps, input_size).to(device)  # Replace with your actual seed

      # Collect predictions
      predictions = []

      # Initialize the hidden state (optional, depends on your model architecture)
      hidden = torch.zeros(model.num_layers, 1, hidden_size).to(device)
      # hidden = torch.randn(model.num_layers, 1, hidden_size, device=device) * 0.01

      # Generate time series
      for _ in range(future_steps):
          # Forward pass
          with torch.no_grad():  # No need to track gradients
              # out, hidden = model.rnn(seed_sequence, hidden)
              out = model(hidden)
              next_step = out[:, -1, :]  # Output for the last time step

          predictions.append(next_step.cpu().numpy())

          # Use the predicted next step as the input for the next iteration
          next_step = next_step.unsqueeze(1)  # Add the sequence length dimension
          seed_sequence = torch.cat((seed_sequence[:, 1:, :], next_step), 1)  # Move the window

      # # Convert predictions to a numpy array for further analysis
      predicted_time_series = np.concatenate(predictions, axis=0)

      return predicted_time_series

#+end_src

#+RESULTS:

** Pipeline

#+begin_src ipython
  def standard_scaler(data, IF_RETURN=0):
      mean = data.mean(dim=0, keepdim=True)
      std = data.std(dim=0, keepdim=True)
      if IF_RETURN:
          return (data - mean) / std, mean, std
      else:
          return (data - mean) / std

#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  class CustomBCELoss(nn.Module):
      def __init__(self):
          super(CustomBCELoss, self).__init__()

      def forward(self, inputs, targets):
          inputs = torch.cat(inputs, dim=1)
          y_pred = self.linear(inputs[:, -1, :])

          proba = torch.sigmoid(y_pred).squeeze(-1)

          loss = F.binary_cross_entropy(proba, targets, reduction='none')

          return loss.mean()  # Or .sum(), or custom reduction as needed.
#+end_src

#+RESULTS:

* RNN models

#+begin_src ipython
  class FullRNN(nn.Module):
      def __init__(self, N_NEURON, N_BATCH, DT=0.05, TAU=1, SIGMA=1, NONLINEAR='sig', DEVICE='cuda', DROP=0.5):
          super(FullRNN, self).__init__()

          self.N_BATCH = N_BATCH
          self.DEVICE = DEVICE

          self.N_NEURON = N_NEURON

          self.DT = DT
          self.TAU = TAU
          # self.GAIN = nn.Parameter(torch.tensor(1.0).to(DEVICE))
          self.GAIN = nn.Parameter(torch.ones((1, 1, self.N_NEURON)).to(DEVICE))

          self.SIGMA = nn.Parameter(torch.tensor(SIGMA).to(torch.float).to(DEVICE))
          # self.SIGMA = SIGMA

          self.EXP_DT_TAU = torch.exp(-torch.tensor(self.DT / self.TAU).to(DEVICE))
          self.DT_TAU = torch.tensor(self.DT / self.TAU).to(DEVICE)

          self.dropout = nn.Dropout(DROP)

          if NONLINEAR == 'relu':
              self.Activation = nn.ReLU()
          else:
              self.Activation = nn.Tanh()

          self.Wab = nn.Parameter(torch.randn((self.N_NEURON, self.N_NEURON), device=DEVICE) * 0.0)

      def update_dynamics(self, rates, ff_input, rec_input, lr):
          noise = torch.randn_like(rates)

          # update hidden state
          hidden = rates @ lr

          rec_input = rec_input * self.EXP_DT_TAU + hidden * self.DT_TAU # + noise * torch.sqrt(self.SIGMA * self.DT_TAU)

          # compute net input
          net_input = ff_input + rec_input + noise * self.SIGMA**2

          # update rates
          # non_linear = self.Activation(net_input)
          # rates = rates * self.EXP_DT_TAU + non_linear * self.DT_TAU + noise

          rates = self.GAIN * self.Activation(net_input)
          # rates = net_input

          return rates, rec_input

      def forward(self, ff_input):

          # initialize state
          rates = torch.zeros(ff_input.size(0), self.N_NEURON, device=self.DEVICE)
          rec_input = torch.zeros(ff_input.size(0), self.N_NEURON, device=self.DEVICE)
          lr = self.Wab / self.N_NEURON


          rates_sequence = []
          for step in range(ff_input.size(1)):
              rates, rec_input = self.update_dynamics(rates, ff_input[:, step], rec_input, lr)
              rates_sequence.append(rates.unsqueeze(1))

          rates_sequence = torch.cat(rates_sequence, dim=1)

          return rates_sequence
#+end_src

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

* Train on Experimental Data
** Parameters

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.common.options import set_options
#+end_src

#+RESULTS:

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = ['first', 'last']

  kwargs = dict()
  kwargs = {'trials': '', 'preprocess': None, 'scaler_BL': 'standard', 'avg_noise':True, 'unit_var_BL':False}

  kwargs['mouse'] = 'JawsM15'
#+end_src

#+RESULTS:

** Load Data

#+begin_src ipython
options = set_options(**kwargs)
options['reload'] = False
options['data_type'] = 'dF'
options['DCVL'] = 0
#+end_src

#+RESULTS:

#+begin_src ipython
X_days, y_days = get_X_y_days(**options)
options['trials'] = 'correct'
options['day'] = 'last'
options['task'] = 'all'
X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

print(X_data.shape, y_data.shape)
#+end_src

#+RESULTS:
: (249, 693, 84) (249, 13)

#+begin_src ipython
from  mne.decoding import Scaler
std_scaler = Scaler(scalings='mean')
X_data = std_scaler.fit_transform(X_data)
print(X_data.shape)
#+end_src

#+RESULTS:
: (249, 693, 84)

#+begin_src ipython
from src.decode.bump import circcvl
# smoothed_data = circcvl(X_data, windowSize=2, axis=-1)
print(X_data.shape)
window_size = 6
# from scipy.ndimage import gaussian_filter1d
# smoothed_data = gaussian_filter1d(X_data, axis=-1, sigma=2)
# smoothed_data = moving_average_multidim(X_data[..., :52], window_size, axis=-1)
smoothed_data = moving_average_multidim(X_data, window_size, axis=-1)
#+end_src

#+RESULTS:
: (249, 693, 84)

#+RESULTS:

#+begin_src ipython
  time = np.linspace(0, 14, 84)
  for i in range(10):
      i = np.random.randint(100)
      plt.plot(time, smoothed_data[-1, i,:], alpha=.5)

  plt.ylabel('Rate (Hz)')
  plt.xlabel('Time (s)')
  plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/4fc2a49d0ccaaea3552d6b3459df4ea9ce4ccce1.png]]

** Training

#+begin_src ipython
  # y = np.roll(X_data, -1)
  # y = y[..., :-1]

  X = smoothed_data[..., :-1]
  Y = smoothed_data[..., 1:]

  # X = rescale_to_minus_one_to_one(X)
  # Y = rescale_to_minus_one_to_one(Y)

  X = np.swapaxes(X, 1, -1)
  Y = np.swapaxes(Y, 1, -1)

  print(X.shape, Y.shape)
#+end_src

#+RESULTS:
: (249, 83, 693) (249, 83, 693)

#+begin_src ipython
X = torch.tensor(X, dtype=torch.float32, device=device)
Y = torch.tensor(Y, dtype=torch.float32, device=device)
print(X.shape, Y.shape)
#+end_src

#+RESULTS:
: torch.Size([249, 83, 693]) torch.Size([249, 83, 693])

#+RESULTS:

#+begin_src ipython
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

num_features = X.shape[-1]
batch_size = 16
train_loader, val_loader = split_data(X, Y, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: X_train shape: torch.Size([198, 83, 693]) Y_train shape: torch.Size([198, 83, 693])
: X_test shape: torch.Size([50, 83, 693]) Y_test shape: torch.Size([50, 83, 693])

#+begin_src ipython
model = FullRNN(N_NEURON=num_features, N_BATCH=batch_size, DEVICE=device)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In[1312], line 1
----> 1 model = FullRNN(N_NEURON=num_features, N_BATCH=batch_size, DEVICE=device)

Cell In[1301], line 15, in FullRNN.__init__(self, N_NEURON, N_BATCH, DT, TAU, SIGMA, NONLINEAR, DEVICE, DROP)
     12 # self.GAIN = nn.Parameter(torch.tensor(1.0).to(DEVICE))
     13 self.GAIN = nn.Parameter(torch.ones((1, 1, self.N_NEURON)).to(DEVICE))
---> 15 self.SIGMA = nn.Parameter(torch.tensor(SIGMA).to(DEVICE))
     16 # self.SIGMA = SIGMA
     18 self.EXP_DT_TAU = torch.exp(-torch.tensor(self.DT / self.TAU).to(DEVICE))

File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/parameter.py:40, in Parameter.__new__(cls, data, requires_grad)
     36     data = torch.empty(0)
     37 if type(data) is torch.Tensor or type(data) is Parameter:
     38     # For ease of BC maintenance, keep this path for standard Tensor.
     39     # Eventually (tm), we should change the behavior for standard Tensor to match.
---> 40     return torch.Tensor._make_subclass(cls, data, requires_grad)
     42 # Path for custom tensors: set a flag on the instance to indicate parameter-ness.
     43 t = data.detach().requires_grad_(requires_grad)

RuntimeError: Only Tensors of floating point and complex dtype can require gradients
#+end_example
:END:

#+begin_src ipython
learning_rate = 0.1
num_epochs = 100

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs, thresh=.001, penalty=None, lbd=1)
#+end_src

#+RESULTS:
: Epoch 0/100, Training Loss: 0.1678, Validation Loss: 0.1757
: Epoch 10/100, Training Loss: 0.1120, Validation Loss: 0.1769
: Epoch 20/100, Training Loss: 0.1898, Validation Loss: 0.1779
: Epoch 30/100, Training Loss: 0.1344, Validation Loss: 0.1785
: Epoch 40/100, Training Loss: 0.1098, Validation Loss: 0.1790
: Epoch 50/100, Training Loss: 0.1635, Validation Loss: 0.1792
: Epoch 60/100, Training Loss: 0.1413, Validation Loss: 0.1794
: Epoch 70/100, Training Loss: 0.1767, Validation Loss: 0.1795

#+begin_src ipython
print(model.GAIN, model.SIGMA)
#+end_src

#+RESULTS:
: f7a90a85-43ae-432e-a08a-49e89f449175

** Testing

#+begin_src ipython
  from sklearn.metrics import mean_squared_error

  model.eval()  # Set the model to evaluation mode

  # This function feeds inputs through the model and computes the predictions
  def get_predictions(data_loader):
      predictions = []
      ground_truth = []
      with torch.no_grad():  # Disable gradient computation for evaluation
          for inputs, targets in data_loader:
              inputs, targets = inputs.to(device), targets.to(device)
              outputs = model(inputs)
              predictions.append(outputs.cpu())  # If using cuda, need to move data to cpu
              ground_truth.append(targets.cpu())

      # Concatenate all batches
      predictions = torch.cat(predictions, dim=0)
      ground_truth = torch.cat(ground_truth, dim=0)

      return predictions, ground_truth

  # Call the function using your data loader
  predictions, ground_truth = get_predictions(val_loader)

  print(ground_truth.numpy().shape, predictions.numpy().shape)
#+end_src

#+RESULTS:
: b022a11c-ed57-4a05-a289-63eb98f606f5

#+begin_src ipython
  import matplotlib.pyplot as plt

  # Convert tensors to numpy arrays for plotting
  predictions_np = predictions.numpy()
  ground_truth_np = ground_truth.numpy()

  # Plot the predictions on top of the ground truth
  plt.figure()
  pal = sns.color_palette("tab10")
  time = np.linspace(0, 14, 84)[:-1]
  # Example for plotting the first feature dimension
  for i in range(3):
     j = np.random.randint(model.N_NEURON)
     plt.plot(time, ground_truth_np[0, :, j], 'x', label='Ground Truth', color=pal[i], alpha=.2)
     plt.plot(time, predictions_np[0, :, j], '-', label='Model Prediction', color=pal[i], alpha=1)

  plt.title("Model Prediction vs Ground Truth")
  plt.xlabel("Time steps")
  plt.ylabel("Value")
  # plt.legend(fontsize=12)
  plt.show()
#+end_src

#+RESULTS:
: cd12a5a0-71ba-476b-9246-0656c7264090

#+begin_src ipython
  # weights = (model.U @ model.V.T).cpu().detach().numpy()
  weights = model.Wab.cpu().detach().numpy()
  U, S, Vt = np.linalg.svd(weights, full_matrices=False)
#+end_src

#+RESULTS:
: 0419a231-d784-41b4-b483-49fc666e8367

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])
ax[0].scatter(U[0], U[1])
ax[1].scatter(V[0], V[1])
plt.show()
#+end_src

#+RESULTS:
: b34608be-2ef6-4175-8196-09d1e9f959fe

#+begin_src ipython
  X_days, y_days = get_X_y_days(**options)
  options['day'] = 6
  options['task'] = 'DPA'
  X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

  print(X_data.shape)
  # X_data = std_scaler.transform(X_data)
  X_data = np.swapaxes(X_data, 1, -1)
  # y_data = y_data[:, np.newaxis]
  print(X_data.shape, y_data.shape)
#+end_src

#+RESULTS:
: 1ddd93a6-67c9-4838-b44b-2d62afb29036

#+begin_src ipython
plt.plot(S, 'o')
plt.xlabel('#')
plt.ylabel('Singular Value')
plt.show()
#+end_src

#+RESULTS:
: 9a198326-e587-4148-bbed-6e47ae6bc352

#+begin_src ipython
lbd, U = np.linalg.eig(weights.T)
idx = np.argsort(np.real(lbd))

lbd = np.real(lbd[idx])
U = np.real(U[idx])
#+end_src

#+RESULTS:
: 88006e8c-1c34-476e-8d59-19161887e53a

#+begin_src ipython
plt.plot(lbd[-11:], 'o')
plt.xlabel('#')
plt.ylabel('Eigen Value')
plt.show()
#+end_src

#+RESULTS:
: c6bd18c7-0eef-4d0b-9e23-1c2112ef4399

#+begin_src ipython
print(lbd[-11:])
#+end_src

#+RESULTS:
: 3948482c-6b0e-45d6-abd3-0262fe87b50d

#+begin_src ipython
idx = 0
#+end_src

#+RESULTS:
: c1f965ed-7c33-4ade-bd83-5cb82bda45bd

#+begin_src ipython
overlap = torch.tensor(X_data).to(torch.float).to(device) @ torch.tensor(U).to(torch.float).to(device)

fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])

ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')
ax[0].plot(np.linspace(0, 14, 84), overlap[8:16, :, idx].cpu().detach().mean(0), 'r--')

ax[0].plot(np.linspace(0, 14, 84), overlap[16:24, :, idx].cpu().detach().mean(0), 'b')
ax[0].plot(np.linspace(0, 14, 84), overlap[24:32, :, idx].cpu().detach().mean(0), 'b--')
ax[0].axhline(0, ls='--', color='k')
ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('$U_0$')

ax[1].plot(np.linspace(0, 14, 84), overlap[:8, :, 1].cpu().detach().mean(0), 'r')
ax[1].plot(np.linspace(0, 14, 84), overlap[8:16, :, 1].cpu().detach().mean(0), 'r--')

ax[1].plot(np.linspace(0, 14, 84), overlap[16:24, :, 1].cpu().detach().mean(0), 'b')
ax[1].plot(np.linspace(0, 14, 84), overlap[24:32, :, 1].cpu().detach().mean(0), 'b--')
ax[1].axhline(0, ls='--', color='k')
ax[1].set_xlabel('Time (s)')
ax[1].set_ylabel('$U_1$')

add_vlines(ax[0])
add_vlines(ax[1])
plt.show()
#+end_src

#+RESULTS:
: 48f37fba-0596-4eb7-8097-0d656939063a

#+begin_src ipython
idx = 3
#+end_src

#+RESULTS:
: 1e606e46-01f5-4889-8d6e-41c12a1783ae

#+begin_src ipython
overlap = torch.tensor(X_data).to(torch.float).to(device) @ torch.tensor(Vt.T).to(torch.float).to(device)

fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])

ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')
ax[0].plot(np.linspace(0, 14, 84), overlap[8:16, :, idx].cpu().detach().mean(0), 'r--')

ax[0].plot(np.linspace(0, 14, 84), overlap[16:24, :, idx].cpu().detach().mean(0), 'b')
ax[0].plot(np.linspace(0, 14, 84), overlap[24:32, :, idx].cpu().detach().mean(0), 'b--')
ax[0].axhline(0, ls='--', color='k')

ax[1].plot(np.linspace(0, 14, 84), overlap[:8, :, 1].cpu().detach().mean(0), 'r')
ax[1].plot(np.linspace(0, 14, 84), overlap[8:16, :, 1].cpu().detach().mean(0), 'r--')

ax[1].plot(np.linspace(0, 14, 84), overlap[16:24, :, 1].cpu().detach().mean(0), 'b')
ax[1].plot(np.linspace(0, 14, 84), overlap[24:32, :, 1].cpu().detach().mean(0), 'b--')
ax[1].axhline(0, ls='--', color='k')

ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('$V_0$')

ax[1].set_xlabel('Time (s)')
ax[1].set_ylabel('$V_1$')

add_vlines(ax[0])
add_vlines(ax[1])
plt.show()
#+end_src

#+RESULTS:
: d8748a7d-c030-4e09-ba4c-bf399828bc5c

#+begin_src ipython

#+end_src

#+RESULTS:
: 14834626-1215-4186-b088-5fd3b0f599ac
