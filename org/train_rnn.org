#+TITLE: Data driven RNN
#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session my_session :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run /home/leon/dual_task/dual_data/notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  DEVICE = 'cuda'
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torch.nn.functional as F
  import torch.nn.init as init
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

* Utils

#+begin_src ipython
def add_vlines(ax=None, mouse=""):
    t_BL = [0, 2]
    t_STIM = [2 , 3]
    t_ED = [3 , 4.5]
    t_DIST = [4.5 , 5.5]
    t_MD = [5.5 , 6.5]
    t_CUE = [6.5 , 7]
    t_RWD = [7 , 7.5]
    t_LD = [7.5 , 9]
    t_TEST = [9 , 10]
    t_RWD2 = [11 , 12]

    if "P" in mouse:
        t_BL = [0 , 2]
        t_STIM = [2 , 3]
        t_ED = [3 , 4]
        t_DIST = [4 , 5]
        t_MD = [5 , 6]
        t_CUE = [6 , 7]
        t_RWD = [7 , 8]
        t_LD = [8 , 9]
        t_TEST = [9 , 10]
        t_RWD2 = [10.5 , 11]

    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE, t_RWD2, t_RWD]
    colors = ["b", "b", "b", "g", "y", "y"]

    if ax is None:
        for period, color in zip(time_periods, colors):
            plt.axvspan(period[0], period[1], alpha=0.05, color=color)
    else:
        for period, color in zip(time_periods, colors):
            ax.axvspan(period[0], period[1], alpha=0.05, color=color)
#+end_src

#+RESULTS:

** Sliding Window

#+begin_src ipython
import numpy as np

def rescale_to_minus_one_to_one(data):
    """
    Rescale a 3D NumPy array to be between -1 and 1.

    Parameters:
    data (np.ndarray): Input data of shape (N_trials, N_neurons, N_time).

    Returns:
    np.ndarray: Rescaled data with the same shape as input.
    """
    data_min = np.min(data)
    data_max = np.max(data)

    # Avoid division by zero if min and max are equal
    if data_min == data_max:
        return np.zeros_like(data)

    # Rescale data
    normalized_data = 2 * ((data - data_min) / (data_max - data_min)) - 1
    return normalized_data
#+end_src

#+RESULTS:

#+begin_src ipython
  class SlidingWindowDataset(Dataset):
      def __init__(self, data, sequence_length=100, stride=1):
          self.data = data
          self.sequence_length = sequence_length
          self.stride = stride
          # Calculate number of samples once to optimize __len__
          self.num_sessions, self.num_time_points, _ = self.data.size()
          self.num_samples_per_session = (self.num_time_points - self.sequence_length) // self.stride
          self.total_samples = self.num_samples_per_session * self.num_sessions

      def __len__(self):
          return self.total_samples

      def __getitem__(self, idx):
          # Determine which session this idx belongs to
          session_idx = idx // self.num_samples_per_session
          # Determine the start of the slice for this idx
          session_start = idx % self.num_samples_per_session
          time_idx = session_start * self.stride

          # Extract sequences using calculated indices
          input_sequence = self.data[session_idx, time_idx:time_idx + self.sequence_length]
          target_sequence = self.data[session_idx, time_idx + self.sequence_length]

          return input_sequence, target_sequence
#+end_src

#+RESULTS:

#+begin_src ipython
  import numpy as np
  from scipy.ndimage import convolve1d

  def moving_average_multidim(data, window_size, axis=-1):
      """
      Apply a 1D moving average across a specified axis of a multi-dimensional array.

      :param data: multi-dimensional array of data
      :param window_size: size of the moving window
      :param axis: axis along which to apply the moving average
      :return: smoothed data with the same shape as input data
      """
      # Create a moving average filter window
      window = np.ones(window_size) / window_size
      # Apply 1D convolution along the specified axis
      smoothed_data = convolve1d(data, weights=window, axis=axis, mode='reflect')
      return smoothed_data

#+end_src

#+RESULTS:

** Data Split

#+begin_src ipython
    def split_data(X, Y, train_perc=0.8, batch_size=8, n_labels=2):

       sample_size = int(train_perc * (X.shape[0] // n_labels))
       all_indices = np.arange(X.shape[0] // n_labels)

       train_indices = []
       test_indices = []

       for i in range(n_labels):
          all_indices = np.arange(i * X.shape[0] // n_labels, (i+1) * X.shape[0] // n_labels)
          idx = np.random.choice(all_indices, size=sample_size, replace=False)

          train_indices.append(idx)
          test_indices.append(np.setdiff1d(all_indices, idx))

       X_train = X[train_indices]
       X_test = X[test_indices]

       Y_train = Y[train_indices]
       Y_test = Y[test_indices]

       print(X_train.shape, Y_train.shape)
       train_dataset = TensorDataset(X_train, Y_train)

       print(X_test.shape, Y_test.shape)
       val_dataset = TensorDataset(X_test, Y_test)

       # Create data loaders
       train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
       val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

       # sequence_length = 14  # or any other sequence length you want
       # stride = 1  # or any other stride you want

       # sliding_window_dataset = SlidingWindowDataset(X, sequence_length, stride)
       # train_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)
       # val_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)

       return train_loader, val_loader
#+end_src

#+RESULTS:

 #+begin_src ipython :tangle ../../../src/train/split.py

from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

def strat_split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)

    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
from torch.utils.data import TensorDataset, DataLoader
import torch

def split_data(X, Y, train_perc=0.8, batch_size=8, n_labels=2):

    sample_size = int(train_perc * (X.shape[0] // n_labels))
    train_indices = []
    test_indices = []

    for i in range(n_labels):
        start_idx = i * (X.shape[0] // n_labels)
        end_idx = (i + 1) * (X.shape[0] // n_labels)
        all_indices = np.arange(start_idx, end_idx)
        idx = np.random.choice(all_indices, size=sample_size, replace=False)
        train_indices.extend(idx)
        test_indices.extend(np.setdiff1d(all_indices, idx))

    train_indices = np.array(train_indices)
    test_indices = np.array(test_indices)

    X_train, X_test = X[train_indices], X[test_indices]
    Y_train, Y_test = Y[train_indices], Y[test_indices]

    print("X_train shape:", X_train.shape, "Y_train shape:", Y_train.shape)
    train_dataset = TensorDataset(X_train, Y_train)

    print("X_test shape:", X_test.shape, "Y_test shape:", Y_test.shape)
    val_dataset = TensorDataset(X_test, Y_test)

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

#+RESULTS:

** Optimization

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0, l1_ratio=0.95):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          Y_pred = model(X)
          loss = loss_fn(Y_pred, X)

          # add readout term to fit behavior
          readout = model.linear(Y_pred)[:, 54:]
          sign_readout = torch.sign(2 * y - 1.0) * readout.mean(dim=1)
          loss += F.relu(1.0 - sign_readout).mean()

          loss.backward()

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              # fit next point in time series
              Y_pred = model(X)
              loss = loss_fn(Y_pred, X)

              # # add readout term to fit behavior
              # readout = model.linear(Y_pred)[:, 54:]
              # sign_readout = torch.sign(2 * y - 1.0) * readout.mean(dim=1)
              # loss += F.relu(- sign_readout).mean()

              val_loss += loss.item() * X.size(0)

          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=0, thresh=0.005, l1_ratio=0.95):

      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
      model.to(device)

      # Training loop.
      for epoch in range(num_epochs):
            loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, l1_ratio=l1_ratio)
            val_loss = validation_step(val_loader, model, loss_fn)

            scheduler.step()

            if epoch % int(num_epochs  / 10) == 0:
                  print(f'Epoch {epoch}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

            if val_loss < thresh and loss < thresh:
                  print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
                  break

            if val_loss > 300:
                  print(f'Stopping training as loss is too high: {val_loss}')
                  break

            if torch.isnan(loss):
                  print(f'Stopping training as loss is NaN.')
                  break
#+end_src

#+RESULTS:

** Prediction

#+begin_src ipython
  def get_predictions(model, future_steps, device='cuda:1'):
      model.eval()  # Set the model to evaluation mode

      # Start with an initial seed sequence
      input_size = model.input_size
      hidden_size = model.hidden_size

      seed_sequence = torch.randn(1, future_steps, input_size).to(device)  # Replace with your actual seed

      # Collect predictions
      predictions = []

      # Initialize the hidden state (optional, depends on your model architecture)
      hidden = torch.zeros(model.num_layers, 1, hidden_size).to(device)
      # hidden = torch.randn(model.num_layers, 1, hidden_size, device=device) * 0.01

      # Generate time series
      for _ in range(future_steps):
          # Forward pass
          with torch.no_grad():  # No need to track gradients
              # out, hidden = model.rnn(seed_sequence, hidden)
              out = model(hidden)
              next_step = out[:, -1, :]  # Output for the last time step

          predictions.append(next_step.cpu().numpy())

          # Use the predicted next step as the input for the next iteration
          next_step = next_step.unsqueeze(1)  # Add the sequence length dimension
          seed_sequence = torch.cat((seed_sequence[:, 1:, :], next_step), 1)  # Move the window

      # # Convert predictions to a numpy array for further analysis
      predicted_time_series = np.concatenate(predictions, axis=0)

      return predicted_time_series

#+end_src

#+RESULTS:

** Pipeline

#+begin_src ipython
  def standard_scaler(data, IF_RETURN=0):
      mean = data.mean(dim=0, keepdim=True)
      std = data.std(dim=0, keepdim=True)
      if IF_RETURN:
          return (data - mean) / std, mean, std
      else:
          return (data - mean) / std

#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  class CustomBCELoss(nn.Module):
      def __init__(self):
          super(CustomBCELoss, self).__init__()

      def forward(self, inputs, targets):
          inputs = torch.cat(inputs, dim=1)
          y_pred = self.linear(inputs[:, -1, :])

          proba = torch.sigmoid(y_pred).squeeze(-1)

          loss = F.binary_cross_entropy(proba, targets, reduction='none')

          return loss.mean()  # Or .sum(), or custom reduction as needed.
#+end_src

#+RESULTS:

* RNN models

#+begin_src ipython
  class FullRNN(nn.Module):
      def __init__(self, N_NEURON, N_BATCH, DT=0.05, TAU=1, SIGMA=1, NONLINEAR='sig', DEVICE='cuda', DROP=0.5):
          super(FullRNN, self).__init__()

          self.N_BATCH = N_BATCH
          self.DEVICE = DEVICE

          self.N_NEURON = N_NEURON

          self.DT = DT
          self.TAU = TAU

          self.GAIN = torch.tensor(1.0).to(DEVICE)
          # self.GAIN = nn.Parameter(torch.tensor(1.0).to(DEVICE))
          # self.GAIN = nn.Parameter(torch.ones((1, self.N_NEURON)).to(DEVICE))

          self.SIGMA = nn.Parameter(torch.tensor(SIGMA).to(torch.float).to(DEVICE))
          # self.SIGMA = SIGMA

          self.EXP_DT_TAU = torch.exp(-torch.tensor(self.DT / self.TAU).to(DEVICE))
          self.DT_TAU = torch.tensor(self.DT / self.TAU).to(DEVICE)

          self.dropout = nn.Dropout(DROP)

          if NONLINEAR == 'relu':
              self.Activation = nn.ReLU()
          else:
              self.Activation = nn.Tanh()

          self.Wab = nn.Parameter(torch.randn((self.N_NEURON, self.N_NEURON), device=DEVICE) * 0.0)

          self.linear = nn.Linear(self.N_NEURON, 1, device=DEVICE)
          init.normal_(self.linear.weight, mean=0.0, std=1.0)
          init.normal_(self.linear.bias, mean=0.0, std=1.0)

      def update_dynamics(self, rates, ff_input, rec_input, lr):
          noise = torch.randn_like(rates)

          # update hidden state
          hidden = rates @ lr

          rec_input = rec_input * self.EXP_DT_TAU + hidden * self.DT_TAU # + noise * torch.sqrt(self.SIGMA * self.DT_TAU)

          # compute net input
          net_input = ff_input + rec_input + noise * self.SIGMA**2

          # update rates
          # non_linear = self.Activation(net_input)
          # rates = rates * self.EXP_DT_TAU + non_linear * self.DT_TAU + noise

          # rates = self.GAIN * self.Activation(net_input)

          rates = net_input

          return rates, rec_input

      def forward(self, ff_input):

          # initialize state
          rates = torch.zeros(ff_input.size(0), self.N_NEURON, device=self.DEVICE)
          rec_input = torch.zeros(ff_input.size(0), self.N_NEURON, device=self.DEVICE)

          lr = self.Wab / self.N_NEURON

          rates_sequence = []
          for step in range(ff_input.size(1)):
              rates, rec_input = self.update_dynamics(rates, ff_input[:, step], rec_input, lr)
              rates_sequence.append(rates.unsqueeze(1))

          rates_sequence = torch.cat(rates_sequence, dim=1)

          return rates_sequence
#+end_src

#+RESULTS:

#+begin_src ipython
  class LRRNN(nn.Module):
      def __init__(self, N_NEURON, N_BATCH, RANK=2, DT=0.05, TAU=1, SIGMA=0.001, NONLINEAR='sig', DEVICE='cuda', DROP=0.5):
          super(LRRNN, self).__init__()

          self.N_BATCH = N_BATCH
          self.DEVICE = DEVICE

          self.N_NEURON = N_NEURON
          self.RANK = RANK

          self.DT = DT
          self.TAU = TAU
          self.GAIN = nn.Parameter(torch.tensor(1.0).to(DEVICE))

          self.SIGMA = nn.Parameter(torch.tensor(SIGMA).to(DEVICE))
          self.EXP_DT_TAU = torch.exp(-torch.tensor(self.DT / self.TAU).to(DEVICE))
          self.DT_TAU = torch.tensor(self.DT / self.TAU).to(DEVICE)

          self.dropout = nn.Dropout(DROP)

          if NONLINEAR == 'relu':
              self.Activation = nn.ReLU()
          else:
              self.Activation = nn.Tanh()

          self.U = nn.Parameter(
              torch.randn((self.N_NEURON, int(self.RANK)), device=self.DEVICE)
          )

          self.V = nn.Parameter(
              torch.randn((self.N_NEURON, int(self.RANK)), device=self.DEVICE)
          )

      def linear(self, rates):
          return rates @ self.V / self.N_NEURON

      def update_dynamics(self, rates, ff_input, rec_input, lr):
          noise = torch.randn_like(rates)

          # update hidden state
          hidden = rates @ lr

          rec_input = rec_input * self.EXP_DT_TAU + hidden * self.DT_TAU # + noise * torch.sqrt(self.SIGMA * self.DT_TAU)

          # compute net input
          net_input = ff_input + rec_input + noise * self.SIGMA

          # rates = self.GAIN * self.Activation(net_input)
          rates = net_input

          return rates, rec_input

      def forward(self, ff_input):

          # initialize state
          rates = torch.zeros(ff_input.size(0), self.N_NEURON, device=self.DEVICE)
          rec_input = torch.zeros(ff_input.size(0), self.N_NEURON, device=self.DEVICE)
          lr = self.U @ self.V.T / self.N_NEURON

          rates_sequence = []
          for step in range(ff_input.size(1)):
              rates, rec_input = self.update_dynamics(rates, ff_input[:, step], rec_input, lr)
              rates_sequence.append(rates.unsqueeze(1))

          rates_sequence = torch.cat(rates_sequence, dim=1)

          return rates_sequence

#+end_src

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

* Train on Experimental Data
** Parameters

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.common.options import set_options
#+end_src

#+RESULTS:

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = ['first', 'last']

  kwargs = dict()
  kwargs = {'trials': '', 'preprocess': None, 'scaler_BL': 'standard', 'avg_noise':True, 'unit_var_BL':False}

  kwargs['mouse'] = 'JawsM15'
#+end_src

#+RESULTS:

** Load Data

#+begin_src ipython
options = set_options(**kwargs)
options['reload'] = False
options['data_type'] = 'dF'
options['DCVL'] = 0
#+end_src

#+RESULTS:

#+begin_src ipython
X_days, y_days = get_X_y_days(**options)
options['trials'] = ''
options['day'] = 'last'
options['task'] = 'all'

X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

X_data = X_data[..., :]
print(X_data.shape, y_data.shape, y_data.keys())
#+end_src

#+RESULTS:
: (288, 693, 84) (288, 14) Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'dist_odor', 'choice', 'performance', 'pair', 'odor_pair',
:        'odr_response', 'odr_choice', 'odr_perf'],
:       dtype='object')

#+begin_src ipython
from  mne.decoding import Scaler
std_scaler = Scaler(scalings='mean')
# X_data = std_scaler.fit_transform(X_data)
print(X_data.shape)
#+end_src

#+RESULTS:
: (288, 693, 84)

#+begin_src ipython
from src.decode.bump import circcvl
# smoothed_data = circcvl(X_data, windowSize=2, axis=-1)
print(X_data.shape)
window_size = 12
# from scipy.ndimage import gaussian_filter1d
# smoothed_data = gaussian_filter1d(X_data, axis=-1, sigma=2)
# smoothed_data = moving_average_multidim(X_data[..., :52], window_size, axis=-1)
smoothed_data = moving_average_multidim(X_data, window_size, axis=-1)
#+end_src

#+RESULTS:
: (288, 693, 84)

#+RESULTS:

#+begin_src ipython
  time = np.linspace(0, 14, X_data.shape[-1])
  for i in range(10):
      i = np.random.randint(100)
      plt.plot(time, smoothed_data[-1, i,:], alpha=.5)

  plt.ylabel('Rate (Hz)')
  plt.xlabel('Time (s)')
  plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/8852382b8e3556eb5ee162c2b4ed01ce615ba3c1.png]]

** Training

#+begin_src ipython
  X = smoothed_data
  y = y_data.choice.to_numpy()
  print(X.shape, y.shape)

  # X = rescale_to_minus_one_to_one(X)
  X = np.swapaxes(X, 1, -1)
#+end_src

#+RESULTS:
: (288, 693, 84) (288,)

#+begin_src ipython
X = torch.tensor(X, dtype=torch.float32, device=DEVICE)
y = torch.tensor(y, dtype=torch.float32, device=DEVICE).unsqueeze(-1)
print(X.shape, y.shape)
#+end_src

#+RESULTS:
: torch.Size([288, 84, 693]) torch.Size([288, 1])

#+RESULTS:

#+begin_src ipython
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

num_features = X.shape[-1]
batch_size = 16
train_loader, val_loader = strat_split_data(X, y, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([230, 84, 693]) torch.Size([58, 84, 693])
: torch.Size([230, 1]) torch.Size([58, 1])

#+begin_src ipython
model = FullRNN(N_NEURON=num_features, N_BATCH=batch_size, DEVICE=device)
# model = LRRNN(N_NEURON=num_features, N_BATCH=batch_size, DEVICE=device)
#+end_src

#+RESULTS:

#+begin_src ipython
learning_rate = 0.01
num_epochs = 50

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, thresh=.001, penalty=None, lbd=1)
torch.save(model.state_dict(), './model.pth')
#+end_src

#+RESULTS:
#+begin_example
Epoch 0/50, Training Loss: 7.8253, Validation Loss: 0.5442
Epoch 5/50, Training Loss: 0.6882, Validation Loss: 0.0537
Epoch 10/50, Training Loss: 0.2807, Validation Loss: 0.0199
Epoch 15/50, Training Loss: 0.2418, Validation Loss: 0.0095
Epoch 20/50, Training Loss: 0.1209, Validation Loss: 0.0060
Epoch 25/50, Training Loss: 0.0042, Validation Loss: 0.0042
Epoch 30/50, Training Loss: 0.0033, Validation Loss: 0.0033
Epoch 35/50, Training Loss: 0.0028, Validation Loss: 0.0028
Epoch 40/50, Training Loss: 0.0025, Validation Loss: 0.0025
Epoch 45/50, Training Loss: 0.0023, Validation Loss: 0.0023
#+end_example

** Testing

#+begin_src ipython
  from sklearn.metrics import mean_squared_error

  model.eval()  # Set the model to evaluation mode

  # This function feeds inputs through the model and computes the predictions
  def get_predictions(data_loader):
      predictions = []
      ground_truth = []
      with torch.no_grad():  # Disable gradient computation for evaluation
          for inputs, targets in data_loader:

              inputs, targets = inputs.to(device), targets.to(device)
              targets = inputs

              outputs = model(inputs)
              predictions.append(outputs.cpu())  # If using cuda, need to move data to cpu
              ground_truth.append(targets.cpu())

      # Concatenate all batches
      predictions = torch.cat(predictions, dim=0)
      ground_truth = torch.cat(ground_truth, dim=0)

      return predictions, ground_truth

  # Call the function using your data loader
  predictions, ground_truth = get_predictions(val_loader)
  print(ground_truth.numpy().shape, predictions.numpy().shape)
#+end_src

#+RESULTS:
: (58, 84, 693) (58, 84, 693)

#+begin_src ipython
  import matplotlib.pyplot as plt

  # Convert tensors to numpy arrays for plotting
  predictions_np = predictions.numpy()
  ground_truth_np = ground_truth.numpy()

  # Plot the predictions on top of the ground truth
  plt.figure()
  pal = sns.color_palette("tab10")
  time = np.linspace(0, 14, 84)
  # Example for plotting the first feature dimension
  for i in range(3):
     j = np.random.randint(model.N_NEURON)
     plt.plot(time, ground_truth_np[0, :, j], 'x', label='Ground Truth', color=pal[i], alpha=.5)
     plt.plot(time, predictions_np[0, :, j], '-', label='Model Prediction', color=pal[i], alpha=1)

  plt.title("Model Prediction vs Ground Truth")
  plt.xlabel("Time steps")
  plt.ylabel("Value")
  # plt.legend(fontsize=12)
  plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/3ff51445a03e36fb7df70e2a97a32ac9ee092da6.png]]

#+begin_src ipython
try:
    weights = model.Wab.cpu().detach().numpy()
except:
    weights = (model.U @ model.V.T).cpu().detach().numpy()

U, S, Vt = np.linalg.svd(weights, full_matrices=False)
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])
ax[0].scatter(U[0], U[1])
ax[1].scatter(Vt.T[0], Vt.T[1])
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/81cbde27e733e605c088d8996fb890e518dec1f5.png]]

#+begin_src ipython
  X_days, y_days = get_X_y_days(**options)
  options['day'] = 6
  options['task'] = 'DPA'
  X_test, y_test = get_X_y_S1_S2(X_days, y_days, **options)

  print(X_test.shape)
  # X_test = std_scaler.transform(X_test)
  X_test = np.swapaxes(X_test, 1, -1)

  print(X_test.shape, y_test.shape)
#+end_src

#+RESULTS:
: (32, 693, 84)
: (32, 84, 693) (32, 14)

#+begin_src ipython
plt.plot(S, 'o')
plt.xlabel('#')
plt.ylabel('Singular Value')
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/aa5dd72cba2e29ca693fa39374e6594e1904ee1b.png]]

#+begin_src ipython
lbd, U2 = np.linalg.eig(weights.T)
idx = np.argsort(np.real(lbd))

Relbd = np.real(lbd[idx])
Imlbd = np.imag(lbd[idx])
U2 = np.real(U2[idx])
#+end_src

#+RESULTS:

#+begin_src ipython
plt.scatter(Relbd, Imlbd)
plt.xlabel('Re')
plt.ylabel('Im')
plt.axvline(1, color='k', ls='--')
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/b4ed0894e74ee9e51a960e56d3f200de3b40dbed.png]]

#+begin_src ipython
lbd[:10]
#+end_src

#+RESULTS:
: array([11.8278675  +0.j        ,  0.0820804 +10.441734j  ,
:         0.0820804 -10.441734j  ,  2.1953633  +0.j        ,
:        -1.8370997  +0.j        , -0.5066431  +0.7049943j ,
:        -0.5066431  -0.7049943j , -0.7764151  +0.2512745j ,
:        -0.7764151  -0.2512745j ,  0.43740162 +0.36472526j],
:       dtype=complex64)

#+begin_src ipython
plt.plot(Relbd[-11:], 'o')
plt.xlabel('#')
plt.ylabel('Eigen Value')
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/303fd92bd9a55cd40016415f01c1d6648f7447a0.png]]

#+begin_src ipython
print(lbd[-11:])
#+end_src

#+RESULTS:
: [6.1260878e-05+2.3657472e-05j 6.1260878e-05-2.3657472e-05j
:  6.8771900e-05+6.3865255e-06j 6.8771900e-05-6.3865255e-06j
:  5.1434119e-05+3.9122009e-05j 5.1434119e-05-3.9122009e-05j
:  3.4701297e-05+0.0000000e+00j 9.2235596e-06+3.6033569e-05j
:  9.2235596e-06-3.6033569e-05j 2.4772833e-06+1.0453249e-05j
:  2.4772833e-06-1.0453249e-05j]

#+begin_src ipython
idx = 0
#+end_src

#+RESULTS:

#+begin_src ipython
overlap = torch.tensor(X_test).to(torch.float).to(device) @ torch.tensor(U).to(torch.float).to(device)

fig, ax = plt.subplots(1, 3, figsize= [3 * width, height])

ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')
ax[0].plot(np.linspace(0, 14, 84), overlap[8:16, :, idx].cpu().detach().mean(0), 'r--')

ax[0].plot(np.linspace(0, 14, 84), overlap[16:24, :, idx].cpu().detach().mean(0), 'b')
ax[0].plot(np.linspace(0, 14, 84), overlap[24:32, :, idx].cpu().detach().mean(0), 'b--')
ax[0].axhline(0, ls='--', color='k')
ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('$U_0$')

ax[1].plot(np.linspace(0, 14, 84), overlap[:8, :, 1].cpu().detach().mean(0), 'r')
ax[1].plot(np.linspace(0, 14, 84), overlap[8:16, :, 1].cpu().detach().mean(0), 'r--')

ax[1].plot(np.linspace(0, 14, 84), overlap[16:24, :, 1].cpu().detach().mean(0), 'b')
ax[1].plot(np.linspace(0, 14, 84), overlap[24:32, :, 1].cpu().detach().mean(0), 'b--')
ax[1].axhline(0, ls='--', color='k')
ax[1].set_xlabel('Time (s)')
ax[1].set_ylabel('$U_1$')

ax[2].plot(np.linspace(0, 14, 84), overlap[:8, :, 2].cpu().detach().mean(0), 'r')
ax[2].plot(np.linspace(0, 14, 84), overlap[8:16, :, 2].cpu().detach().mean(0), 'r--')

ax[2].plot(np.linspace(0, 14, 84), overlap[16:24, :, 2].cpu().detach().mean(0), 'b')
ax[2].plot(np.linspace(0, 14, 84), overlap[24:32, :, 2].cpu().detach().mean(0), 'b--')
ax[2].axhline(0, ls='--', color='k')
ax[2].set_xlabel('Time (s)')
ax[2].set_ylabel('$U_2$')

add_vlines(ax[0])
add_vlines(ax[1])
add_vlines(ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/6ab0d58ab5c799c060c4e066898b3493fc841ec4.png]]

#+begin_src ipython
overlap = torch.tensor(X_test).to(torch.float).to(device) @ torch.tensor(Vt.T).to(torch.float).to(device)

fig, ax = plt.subplots(1, 3, figsize= [3 * width, height])

ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')
ax[0].plot(np.linspace(0, 14, 84), overlap[8:16, :, idx].cpu().detach().mean(0), 'r--')

ax[0].plot(np.linspace(0, 14, 84), overlap[16:24, :, idx].cpu().detach().mean(0), 'b')
ax[0].plot(np.linspace(0, 14, 84), overlap[24:32, :, idx].cpu().detach().mean(0), 'b--')
ax[0].axhline(0, ls='--', color='k')
ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('$V_0$')

ax[1].plot(np.linspace(0, 14, 84), overlap[:8, :, 1].cpu().detach().mean(0), 'r')
ax[1].plot(np.linspace(0, 14, 84), overlap[8:16, :, 1].cpu().detach().mean(0), 'r--')

ax[1].plot(np.linspace(0, 14, 84), overlap[16:24, :, 1].cpu().detach().mean(0), 'b')
ax[1].plot(np.linspace(0, 14, 84), overlap[24:32, :, 1].cpu().detach().mean(0), 'b--')
ax[1].axhline(0, ls='--', color='k')
ax[1].set_xlabel('Time (s)')
ax[1].set_ylabel('$V_1$')

ax[2].plot(np.linspace(0, 14, 84), overlap[:8, :, 2].cpu().detach().mean(0), 'r')
ax[2].plot(np.linspace(0, 14, 84), overlap[8:16, :, 2].cpu().detach().mean(0), 'r--')

ax[2].plot(np.linspace(0, 14, 84), overlap[16:24, :, 2].cpu().detach().mean(0), 'b')
ax[2].plot(np.linspace(0, 14, 84), overlap[24:32, :, 2].cpu().detach().mean(0), 'b--')
ax[2].axhline(0, ls='--', color='k')
ax[2].set_xlabel('Time (s)')
ax[2].set_ylabel('$V_2$')

add_vlines(ax[0])
add_vlines(ax[1])
add_vlines(ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/239073f86fc05b5e4aeadabbdd3b4559dea14705.png]]

#+begin_src ipython
overlap = torch.tensor(X_test).to(torch.float).to(device) @ model.U / model.N_NEURON

fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])

ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')
ax[0].plot(np.linspace(0, 14, 84), overlap[8:16, :, idx].cpu().detach().mean(0), 'r--')

ax[0].plot(np.linspace(0, 14, 84), overlap[16:24, :, idx].cpu().detach().mean(0), 'b')
ax[0].plot(np.linspace(0, 14, 84), overlap[24:32, :, idx].cpu().detach().mean(0), 'b--')
ax[0].axhline(0, ls='--', color='k')
ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('$U_0$')

ax[1].plot(np.linspace(0, 14, 84), overlap[:8, :, 1].cpu().detach().mean(0), 'r')
ax[1].plot(np.linspace(0, 14, 84), overlap[8:16, :, 1].cpu().detach().mean(0), 'r--')

ax[1].plot(np.linspace(0, 14, 84), overlap[16:24, :, 1].cpu().detach().mean(0), 'b')
ax[1].plot(np.linspace(0, 14, 84), overlap[24:32, :, 1].cpu().detach().mean(0), 'b--')
ax[1].axhline(0, ls='--', color='k')
ax[1].set_xlabel('Time (s)')
ax[1].set_ylabel('$U_1$')


add_vlines(ax[0])
add_vlines(ax[1])

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In[44], line 1
----> 1 overlap = torch.tensor(X_test).to(torch.float).to(device) @ model.U / model.N_NEURON
      3 fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])
      5 ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')

File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1688, in Module.__getattr__(self, name)
   1686     if name in modules:
   1687         return modules[name]
-> 1688 raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")

AttributeError: 'FullRNN' object has no attribute 'U'
#+end_example
:END:

#+begin_src ipython
overlap = torch.tensor(X_test).to(torch.float).to(device) @ model.V / model.N_NEURON

fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])

ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')
ax[0].plot(np.linspace(0, 14, 84), overlap[8:16, :, idx].cpu().detach().mean(0), 'r--')

ax[0].plot(np.linspace(0, 14, 84), overlap[16:24, :, idx].cpu().detach().mean(0), 'b')
ax[0].plot(np.linspace(0, 14, 84), overlap[24:32, :, idx].cpu().detach().mean(0), 'b--')
ax[0].axhline(0, ls='--', color='k')
ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('$U_0$')

ax[1].plot(np.linspace(0, 14, 84), overlap[:8, :, 1].cpu().detach().mean(0), 'r')
ax[1].plot(np.linspace(0, 14, 84), overlap[8:16, :, 1].cpu().detach().mean(0), 'r--')

ax[1].plot(np.linspace(0, 14, 84), overlap[16:24, :, 1].cpu().detach().mean(0), 'b')
ax[1].plot(np.linspace(0, 14, 84), overlap[24:32, :, 1].cpu().detach().mean(0), 'b--')
ax[1].axhline(0, ls='--', color='k')
ax[1].set_xlabel('Time (s)')
ax[1].set_ylabel('$U_1$')


add_vlines(ax[0])
add_vlines(ax[1])

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In[45], line 1
----> 1 overlap = torch.tensor(X_test).to(torch.float).to(device) @ model.V / model.N_NEURON
      3 fig, ax = plt.subplots(1, 2, figsize= [2 * width, height])
      5 ax[0].plot(np.linspace(0, 14, 84), overlap[:8, :, idx].cpu().detach().mean(0) , 'r')

File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1688, in Module.__getattr__(self, name)
   1686     if name in modules:
   1687         return modules[name]
-> 1688 raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")

AttributeError: 'FullRNN' object has no attribute 'V'
#+end_example
:END:

* reload

#+begin_src ipython

#+end_src

#+RESULTS:

#+begin_src ipython
import gc
gc.collect()

torch.cuda.empty_cache()
torch.cuda.device(DEVICE)   # where X is the GPU index, e.g., 0, 1
torch.cuda.synchronize()
torch.cuda.reset_accumulated_memory_stats(DEVICE)
#+end_src

#+RESULTS:

#+begin_src ipython
model_state_dict = torch.load('./model.pth')
model.load_state_dict(model_state_dict)
model.eval();
#+end_src

#+RESULTS:

#+begin_src ipython
print(X.shape, y.shape)
#+end_src

#+RESULTS:
: torch.Size([288, 84, 693]) torch.Size([288, 1])

#+begin_src ipython
Y_pred = model(X[:8])
readout = model.linear(Y_pred)

Y_pred = model(X[16:24])
readout2 = model.linear(Y_pred)

# readout = torch.sign(2 * y[:32].unsqueeze(-1) - 1.0)  * model.linear(Y_pred)
#+end_src

#+RESULTS:

#+begin_src ipython
print(readout.shape)
#+end_src

#+RESULTS:
: torch.Size([8, 84, 1])

#+begin_src ipython
xtime = np.linspace(0, 14, 84)
cmap = plt.get_cmap('Blues')
colors = [cmap((i+1)/ readout.shape[0]) for i in range(readout.shape[0]+1)]

for i in range(readout.shape[0]):
    plt.plot(xtime, readout[i, :, 0].cpu().detach().numpy(), color=colors[i], alpha=.5);
    plt.plot(xtime, readout2[i, :, 0].cpu().detach().numpy(), color=colors[i], alpha=.5);

add_vlines()
plt.xlabel('Time (s)')
plt.ylabel('readout')
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/7f1a098ac3584abc64b1cc799ae4ef0263ec6f32.png]]
