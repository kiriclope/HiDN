#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dpca :kernel dual_data :exports results :output-dir ./figures/dpca :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports

#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  from time import perf_counter

  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.decode.bump import decode_bump, circcvl
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
#+end_src

#+RESULTS:

#+begin_src ipython
from src.dPCA import dPCA
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.impute import SimpleImputer
import numpy as np

class CustomImputer(BaseEstimator, TransformerMixin):
    """
    A custom imputer for 5D data that flattens the last dimension(s) to apply
    scikit‐learn's SimpleImputer, then reshapes back to the original 5D form.
    """
    def __init__(self, strategy="mean"):
        """
        Parameters
        ----------
        strategy : str, optional (default="mean")
            The imputation strategy to pass to SimpleImputer.
            Could be "mean", "median", "most_frequent", or "constant".
        """
        self.strategy = strategy
        self.imputer_ = None
        self.original_shape_ = None

    def fit_transform(self, X, y=None):
        self.fit(X, y)
        return self.transform(X)

    def fit(self, X, y=None):
        """
        Fit the imputer to X.

        Parameters
        ----------
        X : ndarray of shape (n1, n2, n3, n4, n5)
            The 5D data to fit.

        Returns
        -------
        self : Custom5DImputer
        """
        self.original_shape_ = X.shape

        # (n1, n2, n3, n4, n5) → reshape to 2D for SimpleImputer
        # One common approach is to treat everything as features except the first axis:
        # e.g. (n1, n2*n3*n4*n5). Or flatten sections differently if needed.
        X_2d = X.reshape(X.shape[0], -1)

        # Create and fit an actual SimpleImputer
        self.imputer_ = SimpleImputer(strategy=self.strategy)
        self.imputer_.fit(X_2d)

        return self

    def transform(self, X):
        """
        Transform (impute) X with the fitted imputer.

        Parameters
        ----------
        X : ndarray of shape (n1, n2, n3, n4, n5)
            The 5D data to transform/impute.

        Returns
        -------
        X_imputed : ndarray of shape (n1, n2, n3, n4, n5)
            The imputed 5D data.
        """
        # Check shape consistency
        if X.shape != self.original_shape_:
            raise ValueError(
                f"Shape of X {X.shape} does not match the fitted shape {self.original_shape_}."
            )

        # Reshape to 2D
        X_2d = X.reshape(X.shape[0], -1)

        # Transform
        X_2d_imputed = self.imputer_.transform(X_2d)

        # Reshape back to 5D
        X_imputed = X_2d_imputed.reshape(self.original_shape_)

        return X_imputed
#+end_src

#+RESULTS:

** Other


#+begin_src ipython
class standard_scaler():
      def __init__(self, axis=0):
            self.axis = axis

      def fit(self, X):
            self.mean = np.nanmean(X, axis=axis, keepdims=True)
            self.std = np.nanstd(X, axis=axis, keepdims=True) + 1e-6

            return self

      def transform(self, X):
            return (X - self.mean) / self.std

      def fit_transform(self, X):
            self.fit(X)
            return self.transform(X)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval

#+RESULTS:

#+RESULTS:

      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython
def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      cos_theta = A_norm @ B_norm.T
      angle_radians = np.arccos(np.clip(cos_theta, -1.0, 1.0))

      return np.degrees(angle_radians)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  # mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
  # mice = ['JawsM15']
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12']
  # mice = ['PP09', 'PP17']

  kwargs = {
      'mouse': mice[0], 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05, 'n_comp': 0,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise': True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 1000,
      'n_splits': 5, 'n_repeats': 10,
      'class_weight': 0,
      'multilabel':0,
      'mne_estimator': 'generalizing', # sliding or generalizing
      'n_jobs': 128,
      'bolasso_penalty': 'l2',
      'bolasso_pval': 0.05,
      'laser' : 0,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  # kwargs['days'] = ['first']

  options = set_options(**kwargs)
  print(options['days'])
  options['mice'] = mice
  name = '5folds'
#+end_src

#+RESULTS:
: ['first', 'last']

#+begin_src ipython
import pandas as pd

new_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'ChRM23']

options['reload'] = 0
X_mouse, y_mouse = [], []
y_laser = []
y_choice = []
y_dfs = []

for idx, mouse in enumerate(options['mice']):
    options['mouse'] = mouse
    options['features'] = 'sample'
    options['verbose'] = 0

    options['trials'] = ''
    options['reload'] = 0

    if mouse in new_mice:
        options['NEW_DATA'] = 1
    else:
        options['NEW_DATA'] = 0

    options = set_options(**options)

    X_list = []
    y_df__ = []
    tasks = ["DPA", "DualGo", "DualNoGo"]

    for i, day in enumerate(options['days']):
        X_dum = []
        y_df_ = []

        options['day'] = day

        for task in tasks:
            options['task'] = task
            X_days, y_days = get_X_y_days(**options)
            options['reload'] = 0
            X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

            X_dum.append(X_data)
            y_df_.append(y_data)

        y_df_ = pd.concat(y_df_)
        y_df_['DAY'] = day
        y_df__.append(y_df_)

        X_list.append(X_dum)

    X_mouse.append(X_list)
    y_df__ = pd.concat(y_df__)
    y_df__['mouse'] = mouse
    y_dfs.append(y_df__)

y_dfs = pd.concat(y_dfs)
#+end_src

#+RESULTS:
#+begin_example
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
last [4. 5. 6.] [1. 0.]
last [4. 5. 6.] [1. 0.]
last [4. 5. 6.] [1. 0.]
first [1. 2. 3.] [0. 1.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
last [4. 5. 6.] [1. 0.]
last [4. 5. 6.] [1. 0.]
last [4. 5. 6.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
last [4. 5. 6.] [1. 0.]
last [4. 5. 6.] [1. 0.]
last [4. 5. 6.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
last [4. 5.] [1. 0.]
last [4. 5.] [1. 0.]
last [4. 5.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
first [1. 2. 3.] [1. 0.]
last [4. 5.] [1. 0.]
last [4. 5.] [1. 0.]
last [4. 5.] [1. 0.]
#+end_example

#+begin_src ipython

#+end_src

#+RESULTS:

* Pair * choice * time

#+begin_src ipython
from sklearn.model_selection import KFold, LeaveOneOut, StratifiedKFold, RepeatedKFold
from collections import defaultdict

def dpca_cv(X, dPCA, n_splits=5):
    kf = KFold(n_splits, shuffle=True, random_state=None)

    Z_test = []
    for train_idx, test_idx in kf.split(X):
        X_train, X_test = X[train_idx], X[test_idx]
        print(X_train.shape, X_test.shape)

        X_train_avg = np.nanmean(X_train, axis=0)

        axes = tuple(range(1, X_train_avg.ndim-1))
        X_train_scale = np.nanmean(X_train_avg, axis=axes, keepdims=True)
        X_train_avg -= X_train_scale

        X_test_avg = np.nanmean(X_test, axis=0)
        X_test_avg -= X_train_scale

        dPCA.fit_transform(X_train_avg, X_train)
        Z_test.append(dPCA.transform(X_test_avg))

    result = defaultdict(list)
    for d in Z_test:
        for k, v in d.items():
            result[k].append(v)

    means = {k: np.mean(vs, axis=0) for k, vs in result.items()}

    return means
#+end_src

#+RESULTS:

#+begin_src ipython
# crossvalidate the regularization parameter
from sklearn.model_selection import KFold, LeaveOneOut, StratifiedKFold, RepeatedKFold

def crossval_dpca_reg(X_trials, marginalization='st', lambdas=np.logspace(-3, 3, 10)):
    """ Crossvalidates (5-fold) the lambda for the PCA model. Better than built-in function as built-in does not crossvalidate.
    Inputs:         X_trials:           trial-by-trial input vector (trials, neurons, stimuli, times)
                    marginalization:    marginalization points
                    lambdas:            range of potential lambdas to test for

    Outputs:        best_lambda:    Best crossvalidated lambda parameter
                    all_scores:     dictionary of all lambdas with their respective crossvalidation scores
    """
    kf = KFold(n_splits=3, shuffle=True, random_state=None)

    X = X_trials.copy()
    # axes = tuple(range(1, X_trials.ndim))
    # mask = np.any(np.isnan(X_trials), axis=axes)
    # X = X_trials[~mask]

    print(X.shape)

    best_lambda = None
    best_score = -np.inf
    all_scores = {}
    for lam in lambdas:
        scores = []
        for train_idx, test_idx in kf.split(X):
            # Average over training trials
            X_train_avg = np.nanmean(X[train_idx], axis=0)

            axes = tuple(range(1, X_train_avg.ndim-1)) # avg over marg (1, 2), 0 is neurons and -1 is time
            X_train_scale = np.nanmean(X_train_avg, axis=axes, keepdims=True)
            X_train_avg -= X_train_scale

            # Average over testing trials
            X_test = X[test_idx]  # keep trials separate
            X_test_avg = np.nanmean(X_test, axis=0)
            X_test_avg -= X_train_scale


            # Fit dPCA on training average
            dpca = dPCA.dPCA(labels=marginalization, regularizer=lam)
            dpca.protect = ['t']
            Z = dpca.fit_transform(X_train_avg, X[train_idx])

            # Compute reconstruction trial-averages from components of training data
            X_recons = []
            for marg in Z:
                X_marg = dpca.inverse_transform(Z[marg], marg)
                X_recons.append(X_marg)
            X_reconstructed = np.sum(X_recons, axis=0)

            # Evaluate reconstruction of the test average
            mse = np.mean((X_test_avg - X_reconstructed) ** 2)
            total_var = np.mean(X_test_avg ** 2)
            explained_ratio = 1 - mse / total_var
            scores.append(explained_ratio)

        # average out crossvalidations
        mean_score = np.mean(scores)
        all_scores[lam] = mean_score
        if mean_score > best_score:
            best_score = mean_score
            best_lambda = lam

    return best_lambda
#+end_src

#+RESULTS:

#+begin_src ipython
print(mouse)
X = np.vstack(X_mouse[0][1])
y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == 'last')]
print(X.shape, y.shape)

idx_off = (y.laser==0)

#  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
X_dpca = np.zeros((4, 2, int(X.shape[0]/4), X.shape[-2],  X.shape[-1]))
print('X_dpca', X_dpca.shape)

for i in range(4):
    for j in range(2):
        dum = X[(y.odor_pair==i) & (y.choice==j)]
        mean_dum = np.mean(dum, axis=0)[np.newaxis]

        X_dpca[i, j, :dum.shape[0]] = dum
        X_dpca[i, j, dum.shape[0]:] = mean_dum

X_dpca = np.transpose(X_dpca, (2, 3, 0, 1, 4))
X_dpca_avg = np.nanmean(X_dpca, axis=0)
print(X_dpca.shape, X_dpca_avg.shape)
#+end_src

#+RESULTS:
: JawsM15
: (288, 693, 84) (288, 17)
: X_dpca (4, 2, 72, 693, 84)
: (72, 693, 4, 2, 84) (693, 4, 2, 84)

#+begin_src ipython
reg = crossval_dpca_reg(X_dpca, marginalization='pct', lambdas=np.logspace(-3, 3, 10))
print(reg)
#+end_src

#+RESULTS:
: (72, 693, 4, 2, 84)

#+begin_src ipython
dpca = dPCA.dPCA(labels='pct', n_components=2, regularizer=1.0 / X_dpca.shape[1])
dpca.protect = ['t']

Z = dpca_cv(X_dpca, dpca, n_splits=X_dpca.shape[0])
#+end_src

#+begin_src ipython
print(Z['p'].shape)
#+end_src

#+RESULTS:
: (2, 4, 2, 84)

#+begin_src ipython
dpca = dPCA.dPCA(labels='pct', n_components=2, regularizer=reg)
dpca.protect = ['t']

# axes = (1, 2, 3)
# X_dpca -= np.mean(X_dpca, axis=axes, keepdims=True)

axes = (1, 2)
X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

Z = dpca.fit_transform(X_dpca_avg, X_dpca)
print(Z['p'].shape)
#+end_src

#+RESULTS:
: Start optimizing regularization.
: Starting trial  1 / 3
: Starting trial  2 / 3
: Starting trial  3 / 3
: Optimized regularization, optimal lambda =  0.0017286737396774677
: Regularization will be fixed; to compute the optimal                    parameter again on the next fit, please                    set opt_regularizer_flag to True.
: (2, 4, 2, 84)

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--']
label = ['lick', 'nolick']
pc = ['Pair', 'Choice', 'Choice * Time']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
for i in range(2):
        ax[0].plot(xtime, Z['p'][n_comp][pair][i], ls = ls[i], label=label[i])
        ax[1].plot(xtime, Z['c'][n_comp][pair][i], ls = ls[i], label=label[i])
        ax[2].plot(xtime, Z['ct'][n_comp][pair][i], ls = ls[i], label=label[i])

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_20.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--']
label = ['lick', 'nolick']
pc = ['Pair', 'Choice', 'Choice * Time']

xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

pair = [0, 2]
for i in range(2):
        ax[0].plot(xtime, (Z['p'][0][pair[0]][i] - Z['p'][0][pair[1]][i])/2, ls = ls[i], label=label[i])
        ax[1].plot(xtime, (Z['c'][0][pair[0]][i] + Z['c'][0][pair[1]][i])/2, ls = ls[i], label=label[i])
        ax[2].plot(xtime, (Z['ct'][0][pair[0]][i] + Z['ct'][0][pair[1]][i])/2, ls = ls[i], label=label[i])

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' % pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_21.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--']
label = ['lick', 'nolick']
pc = ['Pair', 'Choice', 'Choice * Time']

xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

pair = [1, 3]
for i in range(2):
        ax[0].plot(xtime, (Z['p'][0][pair[0]][i] - Z['p'][0][pair[1]][i])/2, ls = ls[i], label=label[i])
        ax[1].plot(xtime, (Z['c'][0][pair[0]][i] + Z['c'][0][pair[1]][i])/2, ls = ls[i], label=label[i])
        ax[2].plot(xtime, (Z['ct'][0][pair[0]][i] + Z['ct'][0][pair[1]][i])/2, ls = ls[i], label=label[i])

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' % pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_22.png]]


#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * choice * time

#+begin_src ipython
i_mouse = 5
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
: ChRM04

#+begin_src ipython
from collections import defaultdict

Z_day = []
EV_day = []

for i_day, day in enumerate(['first', 'last']):
    X = np.vstack(X_mouse[i_mouse][i_day])
    mouse = options['mice'][i_mouse]
    y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]

    print(X.shape, y.shape, y.day.unique())

    idx_off = (y.laser==0)

    #  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
    X_dpca = np.zeros((2, 2, int(X.shape[0]/2), X.shape[-2],  X.shape[-1]))
    print('X_dpca', X_dpca.shape)

    for i in range(2):
        for j in range(2):
            dum = X[(y.sample_odor==i) & (y.choice==j)]
            mean_dum = np.mean(dum, axis=0)[np.newaxis]

            X_dpca[i, j, :dum.shape[0]] = dum
            X_dpca[i, j, dum.shape[0]:] = mean_dum

    X_dpca = np.transpose(X_dpca, (2, 3, 0, 1, 4))
    X_dpca_avg = np.nanmean(X_dpca, axis=0)
    print(X_dpca.shape, X_dpca_avg.shape)

    dpca = dPCA.dPCA(labels='pct', n_components=2, regularizer=1/X.shape[0])
    dpca.protect = ['t']

    axes = (1, 2)
    X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

    Z = dpca.fit_transform(X_dpca_avg, X_dpca)
    EV = dpca.explained_variance_ratio_

    print(Z['p'].shape)

    Z_day.append(Z)
    EV_day.append(EV)

#+end_src

#+RESULTS:
: (288, 668, 84) (288, 17) [1. 2. 3.]
: X_dpca (2, 2, 144, 668, 84)
: (144, 668, 2, 2, 84) (668, 2, 2, 84)
: (2, 2, 2, 84)
: (288, 668, 84) (288, 17) [4. 5. 6.]
: X_dpca (2, 2, 144, 668, 84)
: (144, 668, 2, 2, 84) (668, 2, 2, 84)
: (2, 2, 2, 84)

#+begin_src ipython
Z_all = defaultdict(list)
for d in Z_day:
    for k, v in d.items():
        Z_all[k].append(v)

print(np.array(Z_all['p']).shape)
#+end_src

#+RESULTS:
: (2, 2, 2, 2, 84)

#+begin_src ipython
EV_all = defaultdict(list)
for d in EV_day:
    for k, v in d.items():
        print(k, np.round(v[0]*100))
        EV_all[k].append(v)
#+end_src

#+RESULTS:


#+begin_src ipython
from collections import defaultdict
n_shuffles = 0
explained_shuffled = []

Z_shuf = []
for _ in range(n_shuffles):
    # Permute labels independently
    shuffled_sample = np.random.permutation(y.sample_odor.values)
    shuffled_choice = np.random.permutation(y.choice.values)

    # Reconstruct X_dpca with shuffled labels
    X_dpca_shuf = np.zeros((2, 2, int(X.shape[0]/2), X.shape[-2],  X.shape[-1]))
    idxs = np.arange(X.shape[0])

    for i in range(2):
        for j in range(2):
            mask = (shuffled_sample == i) & (shuffled_choice == j)
            dum = X[mask]
            mean_dum = np.mean(dum, axis=0)[np.newaxis]
            X_dpca_shuf[i, j, :dum.shape[0]] = dum
            X_dpca_shuf[i, j, dum.shape[0]:] = mean_dum

    X_dpca_shuf = np.transpose(X_dpca_shuf, (2, 3, 0, 1, 4))
    X_dpca_shuf_avg = np.nanmean(X_dpca_shuf, axis=0)
    X_dpca_shuf_avg -= np.mean(X_dpca_shuf_avg, axis=axes, keepdims=True)

    Z_shuf.append(dpca.fit_transform(X_dpca_shuf_avg, X_dpca_shuf))
    # explained_shuffled.append(dpca.explained_variance_ratio_.copy())

result = defaultdict(list)
for d in Z_shuf:
    for k, v in d.items():
        result[k].append(v)

mean_shuf = {k: np.mean(vs, axis=0) for k, vs in result.items()}
std_shuf = {k: np.std(vs, axis=0) for k, vs in result.items()}
#+end_src

#+RESULTS:

#+begin_src ipython
# Z_scored = {k: (Z[k] - mean_shuf[k])  for k in Z}
#+end_src

#+RESULTS:

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--']
label = ['lick', 'nolick']
pc = ['Sample', 'Choice', 'Choice * Time']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
for i in range(2):
        ax[0].plot(xtime, Z['p'][n_comp][pair][i], ls = ls[i], label=label[i])
        ax[1].plot(xtime, Z['c'][n_comp][pair][i], ls = ls[i], label=label[i])
        ax[2].plot(xtime, Z['ct'][n_comp][pair][i], ls = ls[i], label=label[i])

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_27.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--']
color = ['r', 'b']
label = ['lick', 'nolick']
pc = ['Sample', 'Choice', 'Choice * Time']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i] - Z_day[j]['p'][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i] + Z_day[j]['c'][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['ct'][n_comp][pair][i] + Z_day[j]['p'][j][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_30.png]]


#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * test * time

#+begin_src ipython
i_mouse = 5
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
: ChRM04

#+begin_src ipython
from collections import defaultdict

Z_day = []

for i_day, day in enumerate(['first', 'last']):
    X = np.vstack(X_mouse[i_mouse][i_day])
    mouse = options['mice'][i_mouse]
    y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]
    print(X.shape, y.shape, y.day.unique())

    idx_off = (y.laser==0)

    #  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
    X_dpca = np.zeros((2, 2, int(X.shape[0]/2), X.shape[-2],  X.shape[-1]))
    print('X_dpca', X_dpca.shape)

    for i in range(2):
        for j in range(2):
            dum = X[(y.sample_odor==i) & (y.test_odor==j)]
            mean_dum = np.mean(dum, axis=0)[np.newaxis]

            X_dpca[i, j, :dum.shape[0]] = dum
            X_dpca[i, j, dum.shape[0]:] = mean_dum

    X_dpca = np.transpose(X_dpca, (2, 3, 0, 1, 4))
    X_dpca_avg = np.nanmean(X_dpca, axis=0)
    print(X_dpca.shape, X_dpca_avg.shape)

    dpca = dPCA.dPCA(labels='pct', n_components=2, regularizer=1/X.shape[0])
    dpca.protect = ['t']

    axes = (1, 2)
    X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

    Z = dpca.fit_transform(X_dpca_avg, X_dpca)
    print(Z['p'].shape)

    Z_day.append(Z)
#+end_src

#+RESULTS:
: (288, 668, 84) (288, 17) [1. 2. 3.]
: X_dpca (2, 2, 144, 668, 84)
: (144, 668, 2, 2, 84) (668, 2, 2, 84)
: (2, 2, 2, 84)
: (288, 668, 84) (288, 17) [4. 5. 6.]
: X_dpca (2, 2, 144, 668, 84)
: (144, 668, 2, 2, 84) (668, 2, 2, 84)
: (2, 2, 2, 84)

#+begin_src ipython
Z_all = defaultdict(list)
for d in Z_day:
    for k, v in d.items():
        Z_all[k].append(v)

print(np.array(Z_all['p']).shape)
#+end_src

#+RESULTS:
: (2, 2, 2, 2, 84)

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--']
color = ['r', 'b']
label = ['lick', 'nolick']
pc = ['Sample', 'Test', 'Test * Time']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i] - Z_day[j]['p'][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i] + Z_day[j]['c'][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['ct'][n_comp][pair][i] + Z_day[j]['p'][j][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_34.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * task * time

#+begin_src ipython
i_mouse = 5
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
: ChRM04

#+begin_src ipython
from collections import defaultdict

Z_day = []
tasks = ['DPA', 'DualGo', 'DualNoGo']
for i_day, day in enumerate(['first', 'last']):
    X = np.vstack(X_mouse[i_mouse][i_day])
    mouse = options['mice'][i_mouse]
    y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]

    idx_off = (y.laser==0)

    #  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
    X_dpca = np.zeros((2, 3, int(X.shape[0]/3), X.shape[-2],  X.shape[-1]))

    for i in range(2):
        for j in range(3):
            dum = X[(y.sample_odor==i) & (y.tasks==tasks[j])]
            mean_dum = np.mean(dum, axis=0)[np.newaxis]

            X_dpca[i, j, :dum.shape[0]] = dum
            X_dpca[i, j, dum.shape[0]:] = mean_dum

    X_dpca = np.transpose(X_dpca, (2, 3, 0, 1, 4))
    X_dpca_avg = np.nanmean(X_dpca, axis=0)

    dpca = dPCA.dPCA(labels='pct', n_components=2, regularizer=1/X.shape[0])
    dpca.protect = ['t']

    axes = (1, 2)
    X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

    Z = dpca.fit_transform(X_dpca_avg, X_dpca)
    Z_day.append(Z)
#+end_src

#+RESULTS:
: (288, 668, 84) (288, 17) [1. 2. 3.]
: X_dpca (2, 3, 96, 668, 84)
: (96, 668, 2, 3, 84) (668, 2, 3, 84)
: (2, 2, 3, 84)
: (288, 668, 84) (288, 17) [4. 5. 6.]
: X_dpca (2, 3, 96, 668, 84)
: (96, 668, 2, 3, 84) (668, 2, 3, 84)
: (2, 2, 3, 84)

#+begin_src ipython
Z_all = defaultdict(list)
for d in Z_day:
    for k, v in d.items():
        Z_all[k].append(v)

print(np.array(Z_all['p']).shape)
#+end_src

#+RESULTS:
: (2, 2, 2, 3, 84)

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['DPA', 'Go', 'NoGo']
pc = ['Sample', 'Task', 'Task * Time']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
for i in range(1):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i] - Z_day[j]['p'][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i] + Z_day[j]['c'][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['ct'][n_comp][pair][i] + Z_day[j]['p'][j][n_comp][1][i])/2, ls = ls[i], label=label[i], color=color[i], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_40.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * Test * Choice * Time

#+begin_src ipython
i_mouse = 7
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: IndexError                                Traceback (most recent call last)
: Cell In[171], line 2
:       1 i_mouse = 7
: ----> 2 print(options['mice'][i_mouse])
:
: IndexError: list index out of range
:END:

#+begin_src ipython
from collections import defaultdict

mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
tasks = ['DPA', 'DualGo', 'DualNoGo']

Z_day = []
for i_day, day in enumerate(['first', 'last']):

    Z_mouse = []
    for i_mouse, mouse in enumerate(mice):
        mouse = options['mice'][i_mouse]


        X = np.vstack(X_mouse[i_mouse][i_day])
        y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]

        X_dpca = np.zeros((2, 2, 2, int(X.shape[0]/4), X.shape[-2],  X.shape[-1]))

        for i in range(2):
            for j in range(2):
                for k in range(2):
                    dum = X[(y.sample_odor==i) & (y.test_odor==j) & (y.choice==k)]
                    if dum.shape[0]>0:
                        mean_dum = np.mean(dum, axis=0)[np.newaxis]

                        X_dpca[i, j, k, :dum.shape[0]] = dum
                        X_dpca[i, j, k, dum.shape[0]:] = mean_dum


        X_dpca = np.transpose(X_dpca, (3, 4, 0, 1, 2, 5))
        X_dpca_avg = np.nanmean(X_dpca, axis=0)

        dpca = dPCA.dPCA(labels='pcdt', n_components=2, regularizer=1/X.shape[0])
        dpca.protect = ['t']

        axes = (1, 2, 3)
        X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

        Z = dpca.fit_transform(X_dpca_avg, X_dpca)
        Z_mouse.append(Z)

    Z_all = defaultdict(list)
    for d in Z_mouse:
        for k, v in d.items():
            Z_all[k].append(v)

    Z_day.append({k: np.mean(vs, axis=0) for k, vs in Z_all.items()})
#+end_src

#+RESULTS:

#+begin_src ipython
print(Z_all)
# Z_day = {k: np.mean(vs, axis=0) for k, vs in Z_all.items()}
#+end_src

#+RESULTS:

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Pair', 'Unpair']
pc = ['Sample', 'Test', 'Choice']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_45.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Test', 'Choice']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 0

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_46.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * Test * Task * Time

#+begin_src ipython
i_mouse = 7
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
: ACCM03

#+begin_src ipython
from collections import defaultdict

Z_day = []
tasks = ['DPA', 'DualGo', 'DualNoGo']
for i_day, day in enumerate(['first', 'last']):
    X = np.vstack(X_mouse[i_mouse][i_day])
    mouse = options['mice'][i_mouse]
    y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]

    idx_off = (y.laser==0)

    #  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
    X_dpca = np.zeros((2, 2, 3, int(X.shape[0]/12), X.shape[-2],  X.shape[-1]))

    for i in range(2):
        for j in range(2):
            for k in range(3):
                dum = X[(y.sample_odor==i) & (y.test_odor==j) & (y.tasks==tasks[k])]
                mean_dum = np.mean(dum, axis=0)[np.newaxis]

                X_dpca[i, j, k, :dum.shape[0]] = dum
                X_dpca[i, j, k, dum.shape[0]:] = mean_dum

    X_dpca = np.transpose(X_dpca, (3, 4, 0, 1, 2, 5))
    X_dpca_avg = np.nanmean(X_dpca, axis=0)

    dpca = dPCA.dPCA(labels='pcdt', n_components=2, regularizer=1/X.shape[0])
    dpca.protect = ['t']

    axes = (1, 2, 3)
    X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

    Z = dpca.fit_transform(X_dpca_avg, X_dpca)
    Z_day.append(Z)
#+end_src

#+RESULTS:

#+begin_src ipython
Z_all = defaultdict(list)
for d in Z_day:
    for k, v in d.items():
        Z_all[k].append(v)

print(np.array(Z_all['p']).shape)
#+end_src

#+RESULTS:
: (2, 2, 2, 2, 3, 84)

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Test', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 0

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)


for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_51.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Test', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_52.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Test', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = -1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_53.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * Choice * Task * Time

#+begin_src ipython
i_mouse = 7
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
: ACCM03

#+begin_src ipython
from collections import defaultdict

Z_day = []
tasks = ['DPA', 'DualGo', 'DualNoGo']
for i_day, day in enumerate(['first', 'last']):
    X = np.vstack(X_mouse[i_mouse][i_day])
    mouse = options['mice'][i_mouse]
    y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]

    idx_off = (y.laser==0)

    #  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
    X_dpca = np.zeros((2, 2, 3, int(X.shape[0]/6), X.shape[-2],  X.shape[-1]))

    for i in range(2):
        for j in range(2):
            for k in range(3):
                dum = X[(y.sample_odor==i) & (y.choice==j) & (y.tasks==tasks[k])]
                mean_dum = np.mean(dum, axis=0)[np.newaxis]

                X_dpca[i, j, k, :dum.shape[0]] = dum
                X_dpca[i, j, k, dum.shape[0]:] = mean_dum

    X_dpca = np.transpose(X_dpca, (3, 4, 0, 1, 2, 5))
    X_dpca_avg = np.nanmean(X_dpca, axis=0)

    dpca = dPCA.dPCA(labels='pcdt', n_components=2, regularizer=1/X.shape[0])
    dpca.protect = ['t']

    axes = (1, 2, 3)
    X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

    Z = dpca.fit_transform(X_dpca_avg, X_dpca)
    Z_day.append(Z)
#+end_src

#+RESULTS:

#+begin_src ipython
Z_all = defaultdict(list)
for d in Z_day:
    for k, v in d.items():
        Z_all[k].append(v)

print(np.array(Z_all['p']).shape)
#+end_src

#+RESULTS:
: (2, 2, 2, 2, 3, 84)

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Choice', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 0

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_58.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Choice', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_59.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Choice', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = -1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_60.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Sample * Test * Choice * Task * Time

#+begin_src ipython
i_mouse = 7
print(options['mice'][i_mouse])
#+end_src

#+RESULTS:
: ACCM03

#+begin_src ipython
from collections import defaultdict

Z_day = []
tasks = ['DPA', 'DualGo', 'DualNoGo']
for i_day, day in enumerate(['first', 'last']):
    X = np.vstack(X_mouse[i_mouse][i_day])
    mouse = options['mice'][i_mouse]
    y = y_dfs[(y_dfs.mouse==mouse) & (y_dfs.DAY == day)]

    idx_off = (y.laser==0)

    #  n_trials, n_neurons, Z1, Z2, ..., n_time, lets do odor pair * choice
    X_dpca = np.zeros((2, 2, 2, 3, int(X.shape[0]/3), X.shape[-2],  X.shape[-1]))

    for i in range(2):
        for j in range(2):
            for k in range(2):
                for l in range(3):
                    dum = X[(y.sample_odor==i) & (y.test_odor==j)   & (y.choice==k) & (y.tasks==tasks[l])]

                    if dum.shape[0]>0:
                        mean_dum = np.mean(dum, axis=0)[np.newaxis]

                        X_dpca[i, j, k, l, :dum.shape[0]] = dum
                        X_dpca[i, j, k, l, dum.shape[0]:] = mean_dum

    X_dpca = np.transpose(X_dpca, (4, 5, 0, 1, 2, 3, 6))

    X_dpca_avg = np.nanmean(X_dpca, axis=0)

    dpca = dPCA.dPCA(labels='pcdkt', n_components=2, regularizer=1/X.shape[0])
    dpca.protect = ['t']

    axes = (1, 2, 3, 4)
    X_dpca_avg -= np.mean(X_dpca_avg, axis=axes, keepdims=True)

    Z = dpca.fit_transform(X_dpca_avg, X_dpca)
    Z_day.append(Z)
#+end_src

#+RESULTS:

#+begin_src ipython
Z_all = defaultdict(list)
for d in Z_day:
    for k, v in d.items():
        Z_all[k].append(v)

print(np.array(Z_all['p']).shape)
#+end_src

#+RESULTS:
: (2, 2, 2, 2, 2, 3, 84)

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Test', 'Choice']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 0
l=1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k][l] - Z_day[j]['p'][n_comp][1][i][k][l])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k][l] + Z_day[j]['c'][n_comp][1][i][k][l])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k][l] + Z_day[j]['p'][j][n_comp][1][i][k][l])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_65.png]]

#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Choice', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = 1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src


#+begin_src ipython
from src.common.plot_utils import add_vlines

ls = ['-', '--', ':']
color = ['r', 'b', 'g']
label = ['Lick', 'No Lick']
pc = ['Sample', 'Choice', 'Task']
xtime = np.linspace(0, 14, 84)

fig, ax = plt.subplots(1, 3, figsize=[3* width, height])

n_comp = 0
pair = 0
k = -1

for i in range(2):
        for j in range(2):
                ax[0].plot(xtime, (Z_day[j]['p'][n_comp][pair][i][k] - Z_day[j]['p'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[1].plot(xtime, (Z_day[j]['c'][n_comp][pair][i][k] + Z_day[j]['c'][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)
                ax[2].plot(xtime, (Z_day[j]['d'][n_comp][pair][i][k] + Z_day[j]['p'][j][n_comp][1][i][k])/2, ls = ls[i], label=label[i], color=color[k], alpha=j/2+0.5)

for k in range(3):
        add_vlines(ax[k])
        ax[k].set_xlim([0, 12])
        ax[k].axhline(0, ls=':')
        ax[k].set_xlabel('Time (s)')
        ax[k].set_ylabel('%s' %pc[k])

plt.legend(fontsize=14, frameon=0)
plt.show()
#+end_src



#+begin_src ipython

#+end_src

#+RESULTS:
