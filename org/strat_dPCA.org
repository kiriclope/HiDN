#+STARTUP: fold
#+PROPERTY: header-args:jupyter-python :results both :exports both :session dpca :kernel dual :output-dir ./figures/dpca :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src jupyter-python
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual/bin/python

* Imports

#+begin_src jupyter-python
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd
  import seaborn as sns

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
  from src.decode.bump import circcvl
  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src jupyter-python
import numpy as np

class StandardScaler:
    def __init__(self, axis=0, if_scale=1):
        self.axis = axis
        self.center_ = None
        self.scale_ = None
        self.if_scale_ = if_scale

    def fit(self, X):
        self.center_ = np.nanmean(X, axis=self.axis, keepdims=True)
        self.scale_ = np.nanstd(X, axis=(0, -1), keepdims=True)
        # Prevent division by zero
        self.scale_ = np.where(self.scale_==0, 1, self.scale_)
        # self.scale_ = np.where(np.abs(self.scale_)<1e-3, 1, self.scale_)
        return self

    def transform(self, X):
        if self.if_scale_:
            return (X - self.center_) / self.scale_
        return (X - self.center_)

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

class RobustScaler:
    def __init__(self, axis=0):
        self.axis = axis
        self.center_ = None
        self.scale_ = None

    def fit(self, X):
        self.center_ = np.nanmedian(X, axis=self.axis, keepdims=True)
        q75 = np.nanpercentile(X, 75, axis=self.axis, keepdims=True)
        q25 = np.nanpercentile(X, 25, axis=self.axis, keepdims=True)
        self.scale_ = q75 - q25
        # Prevent division by zero
        self.scale_ = np.where(self.scale_ == 0, 1, self.scale_)
        return self

    def transform(self, X):
        return (X - self.center_) / self.scale_

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def pad_list(arrays, axis=0, max_len=None):
    """
    Pads a list of arrays along the specified axis with NaNs so all have the same size along that axis.
    Returns a list of padded arrays.
    """
    # Find maximum size along specified axis
    if max_len is None:
        max_len = max(arr.shape[axis] for arr in arrays)

    padded = []
    for arr in arrays:
        pad_width = [(0, 0)] * arr.ndim


        n_pad = max_len - arr.shape[axis]

        if n_pad > 0:
            pad_width[axis] = (0, n_pad)
            arr_padded = np.pad(arr, pad_width, mode='constant', constant_values=np.nan)
        else:
            arr_padded = arr
        padded.append(arr_padded)

    return padded
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src jupyter-python
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src jupyter-python
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.linalg import orthogonal_procrustes

def align_fold_to_ref(W_fold, W_ref, X_pca_fold):
    """
    Align W_fold to W_ref using orthogonal Procrustes and
    rotate fold's projected data accordingly.

    W_ref, W_fold: (n_comp, n_neurons)
    X_pca_fold: (n_trials, T, n_comp)

    Returns: X_pca_aligned, W_fold_aligned
    """
    if W_ref is None:
        W_ref = W_fold
    # Procrustes finds R that best maps W_fold -> W_ref:  W_fold @ R ≈ W_ref
    R, _ = orthogonal_procrustes(W_fold.T, W_ref.T)  # shapes (n_neurons, n_comp)

    # R is (n_neurons, n_comp), so mapping in component space is R_comp = R.T
    R_comp = R.T  # (n_comp, n_neurons) is W-aligned space; rotation in PC space is R_comp.T

    # rotate projections: (n_trials * T, n_comp) @ (n_comp, n_comp)
    n_trials, T, n_comp = X_pca_fold.shape
    X_flat = X_pca_fold.reshape(-1, n_comp)
    X_aligned = X_flat @ R_comp.T
    X_aligned = X_aligned.reshape(n_trials, T, n_comp)

    W_aligned = (W_fold.T @ R).T  # still (n_comp, n_neurons)
    return X_aligned, W_aligned
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import itertools
from functools import reduce
import operator

def cv_avg_cond(X, y, condition='odor_pair'):
    # Ensure condition is a list
    if isinstance(condition, str):
        condition = [condition]

    # Find unique values for each condition
    unique_vals = [y[c].unique() for c in condition]

    X_avg = []
    combos = list(itertools.product(*unique_vals))
    for combo in combos:
        # Build boolean mask for all conditions
        idx = reduce(operator.and_, [(y[c]==v) for c,v in zip(condition, combo)])
        if idx.any():
            X_avg.append(np.mean(X[idx], axis=0))

    return np.array(X_avg)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold
from sklearn.decomposition import PCA
from tqdm import tqdm

def cross_val_avg_pca(X, y, n_splits, n_repeats, n_comp, epoch, condition, scaler=None):

    if scaler is not None:
        scaler = StandardScaler(axis=0, if_scale=1)

    pca = PCA(n_components=n_comp, svd_solver='randomized')
    # kf = StratifiedKFold(n_splits=n_splits, shuffle=True)
    kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)

    labels = y['mouse'].astype(str) + '_' + y['odor_pair'].astype(str) + '_' + y['tasks'].astype(str) + '_' + y['laser'].astype(str)

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    w_ref = None
    for train_idx, test_idx in tqdm(kf.split(X, labels), total=kf.get_n_splits(X, labels)):

        X_train, y_train = X[train_idx], y.iloc[train_idx]

        # m_train = (y_train.performance==1) & (y_train.laser==0)
        # m_train = (y_train.performance==1) & ((y_train.tasks=='DPA') | (y_train.odr_perf==1)) & (y_train.laser==0)
        m_train = (y_train.laser==0)

        X_train = X_train[m_train]
        y_train = y_train[m_train]

        if scaler is not None:
            X_train = scaler.fit_transform(X_train)
        X_train_epoch = X_train[..., epoch]

        X_train_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_flat, axis=0, keepdims=True)

        X_avg_epoch = cv_avg_cond(X_train_epoch, y_train, condition)
        X_avg_flat = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
        X_cent = X_avg_flat - X_mean

        pca.fit(X_cent)
        w_fold = pca.components_
        evr_folds.append(pca.explained_variance_ratio_)

        X_test, y_test = X[test_idx], y.iloc[test_idx]
        if scaler is not None:
            X_test = scaler.transform(X_test)

        X_test_flat = X_test.transpose(0, 2, 1).reshape(-1, X_test.shape[1])
        X_cent_test = X_test_flat - X_mean
        X_out = pca.transform(X_cent_test).reshape(X_test.shape[0], X_test.shape[-1], -1)

        X_pca_aligned, w_fold_aligned = align_fold_to_ref(w_fold, w_ref, X_out)

        w_folds.append(w_fold_aligned)

        if w_ref is None:
                w_ref = w_folds[0]

        X_folds.append(X_pca_aligned)
        y_folds.append(y_test)

    X_folds = np.concatenate(X_folds, 0)
    y_folds = pd.concat(y_folds)

    w_folds = np.array(w_folds, dtype=object)
    evr_folds = np.array(evr_folds, dtype=object)

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold
from sklearn.decomposition import PCA
from tqdm import tqdm

def cross_val_avg_dpca(X, y, n_splits, n_repeats, n_comp, epoch, condition, target='sample_odor'):

    pca = PCA(n_components=n_comp, svd_solver='randomized')
    kf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)

    labels = y['mouse'].astype(str) + '_' + y['odor_pair'].astype(str) + '_' + y['tasks'].astype(str) + '_' + y['laser'].astype(str)

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    w_ref = None
    for train_idx, test_idx in tqdm(kf.split(X, labels), total=kf.get_n_splits(X, labels)):

        X_train, y_train = X[train_idx], y.iloc[train_idx]

        # m_train = (y_train.performance==1) & (y_train.laser==0)
        # m_train = (y_train.performance==1) & ((y_train.tasks=='DPA') | (y_train.odr_perf==1)) & (y_train.laser==0)
        m_train = (y_train.laser==0)

        X_train = X_train[m_train]
        y_train = y_train[m_train]

        X_train_epoch = X_train[..., epoch]

        X_train_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_flat, axis=0, keepdims=True)

        X_avg_epoch, keys = cv_avg_cond_with_keys(X_train_epoch, y_train, condition)

        print(keys, condition)

        # isolate sample main effect (demixed)
        X_demix = demix_component(
            X_avg_epoch, keys_df=keys,
            factors=condition,
            target=target,
            add_interactions=True
        )

        X_avg_flat = X_demix.transpose(0, 2, 1).reshape(-1, X_demix.shape[1])
        X_cent = X_avg_flat - X_mean

        pca.fit(X_cent)
        w_fold = pca.components_
        evr_folds.append(pca.explained_variance_ratio_)

        X_test, y_test = X[test_idx], y.iloc[test_idx]

        X_test_flat = X_test.transpose(0, 2, 1).reshape(-1, X_test.shape[1])
        X_cent_test = X_test_flat - X_mean
        X_out = pca.transform(X_cent_test).reshape(X_test.shape[0], X_test.shape[-1], -1)

        X_pca_aligned, w_fold_aligned = align_fold_to_ref(w_fold, w_ref, X_out)

        w_folds.append(w_fold_aligned)

        if w_ref is None:
                w_ref = w_folds[0]

        X_folds.append(X_pca_aligned)
        y_folds.append(y_test)

    X_folds = np.concatenate(X_folds, 0)
    y_folds = pd.concat(y_folds)

    w_folds = np.array(w_folds, dtype=object)
    evr_folds = np.array(evr_folds, dtype=object)

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import griddata
from scipy.ndimage import gaussian_filter

def polar_velocities(x, y, sigma_r=1, sigma_t=1, sigma_time=1):
    """
    x, y: (n_traj, n_points)
    sigma: gaussian smoothing in time (in points)
    Returns:
      dr_s, dtheta_s: (n_traj, n_points): smoothed radial and angular velocities
      r, theta: positions at each point, for later conversion
    """

    r = np.sqrt(x**2 + y**2)
    theta = np.arctan2(y, x)
    theta_u = np.unwrap(theta, axis=1)

    # r_s = gaussian_filter1d(r, sigma=sigma_r)
    # theta_s = gaussian_filter1d(theta_u, sigma=sigma_t)

    r_s = gaussian_filter(r, sigma=(sigma_r, sigma_time))
    theta_s = gaussian_filter(theta_u, sigma=(sigma_t, sigma_time))

    dr_s = np.gradient(r_s, axis=1)
    dtheta_s = np.gradient(theta_s, axis=1)

    return dr_s, dtheta_s, r_s, theta_s
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def pol2cart(dr, dtheta, r, theta):
    """
    Converts smoothed polar velocities to Cartesian velocities.
    All arrays shape: (n_traj, n_points)
    """
    u = dr * np.cos(theta) - r * dtheta * np.sin(theta)
    v = dr * np.sin(theta) + r * dtheta * np.cos(theta)
    return u, v
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def create_field(x, y, u, v, grid_size=100, method='linear', z_lim=5):
    """
    Interpolate velocity field to a regular grid.
    Inputs: x,y,u,v all (n_samples,) or (n_traj, n_points) -- flatten them first.
    Returns: xi, yi, ui, vi: all (grid_size, grid_size) arrays.
    """
    x_flat = x.flatten()
    y_flat = y.flatten()
    u_flat = u.flatten()
    v_flat = v.flatten()

    # xi, yi = np.meshgrid(
    #     np.linspace(np.min(x_flat), np.max(x_flat), grid_size),
    #     np.linspace(np.min(y_flat), np.max(y_flat), grid_size),
    # )

    x_min, x_max = np.min(x_flat)-1, np.max(x_flat)+1
    y_min, y_max = np.min(y_flat)-1, np.max(y_flat)+1

    if z_lim is 0:
        z_min = np.min((x_min, y_min))
        z_max = np.min((x_max, y_max))
    else:
        z_min = -z_lim
        z_max = z_lim

    xi, yi = np.meshgrid(np.linspace(z_min, z_max, grid_size),
                         np.linspace(z_min, z_max, grid_size))


    ui = griddata((x_flat, y_flat), u_flat, (xi, yi), method=method, fill_value=np.nan)
    vi = griddata((x_flat, y_flat), v_flat, (xi, yi), method=method, fill_value=np.nan)

    # Fill nans with nearest
    mask = np.isnan(ui)
    if np.any(mask):
        ui[mask] = griddata((x_flat, y_flat), u_flat, (xi, yi), method='nearest')[mask]
        vi[mask] = griddata((x_flat, y_flat), v_flat, (xi, yi), method='nearest')[mask]

    return xi, yi, ui, vi

#+end_src

#+RESULTS:

#+begin_src jupyter-python
def plot_field(xi, yi, ui, vi, ax=None, density=1.0, show_cbar=0):
    speed = np.sqrt(ui**2 + vi**2)
    if ax is None:
        fig, ax = plt.subplots(figsize=(5,5))
    # Normalize for coloring
    import matplotlib as mpl
    vmin, vmax = np.nanpercentile(speed, [5, 95])
    norm = mpl.colors.Normalize(vmin, vmax)
    # strm = ax.streamplot(xi, yi, ui, vi, density=density, color=speed, cmap='coolwarm', norm=norm)
    heatmap = ax.pcolormesh(xi, yi, speed, cmap='coolwarm', shading='gouraud', norm=norm)

    if show_cbar:
        plt.colorbar(strm.lines, ax=ax, label='Speed')

    ax.set_aspect('equal')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    return ax
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

from scipy.ndimage import gaussian_filter1d, gaussian_filter
from scipy.interpolate import Rbf

def create_field_rbf(
    x, y, u, v,
    grid_size=32,
    z_lim=5,
    method='multiquadric',
    epsilon=None,
    smooth=0.0
):
    """
    Interpolate velocity field to a regular grid using RBFs.

    Inputs:
      x, y, u, v: (n_traj, n_points) or (n_samples,) arrays
      grid_size: number of grid points per dimension
      z_lim: if 0, use bounding box of data; otherwise [-z_lim, z_lim]^2
      function: RBF type ('multiquadric', 'inverse', 'gaussian', 'linear', etc.)
      epsilon: shape parameter; if None, Rbf chooses something heuristic
      smooth: smoothing parameter passed to Rbf (regularization)

    Returns:
      xi, yi, ui, vi: all (grid_size, grid_size) arrays
    """
    x_flat = x.flatten()
    y_flat = y.flatten()
    u_flat = u.flatten()
    v_flat = v.flatten()

    # Domain limits
    if z_lim == 0:
        x_min, x_max = x_flat.min() - 1, x_flat.max() + 1
        y_min, y_max = y_flat.min() - 1, y_flat.max() + 1
        z_min = min(x_min, y_min)
        z_max = max(x_max, y_max)
    else:
        z_min, z_max = -z_lim, z_lim

    xi, yi = np.meshgrid(np.linspace(z_min, z_max, grid_size),
                         np.linspace(z_min, z_max, grid_size))

    # One RBF for u, one for v
    rbfu = Rbf(
        x_flat, y_flat, u_flat,
        function=method,
        epsilon=epsilon,
        smooth=smooth
    )
    rbfv = Rbf(
        x_flat, y_flat, v_flat,
        function=method,
        epsilon=epsilon,
        smooth=smooth
    )

    ui = rbfu(xi, yi)
    vi = rbfv(xi, yi)

    return xi, yi, ui, vi
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

from scipy.ndimage import gaussian_filter1d, gaussian_filter
from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator

def create_field(x, y, u, v, grid_size=100, method='linear', z_lim=5):
    """
    Interpolate velocity field to a regular grid.

    Inputs:
      x, y, u, v: (n_traj, n_points) or (n_samples,) arrays
      grid_size: number of grid points per dimension
      method: 'linear' (via LinearNDInterpolator) or any method supported
              by griddata ('linear', 'nearest', 'cubic') if not 'linear' here.
      z_lim: if 0, use bounding box of data; otherwise domain = [-z_lim, z_lim]^2

    Returns:
      xi, yi, ui, vi: all (grid_size, grid_size) arrays
    """
    x_flat = x.flatten()
    y_flat = y.flatten()
    u_flat = u.flatten()
    v_flat = v.flatten()

    # Domain limits
    if z_lim == 0:
        x_min, x_max = x_flat.min() - 1, x_flat.max() + 1
        y_min, y_max = y_flat.min() - 1, y_flat.max() + 1
        z_min = min(x_min, y_min)
        z_max = max(x_max, y_max)
    else:
        z_min, z_max = -z_lim, z_lim

    xi, yi = np.meshgrid(np.linspace(z_min, z_max, grid_size),
                         np.linspace(z_min, z_max, grid_size))

    # Interpolation
    if method == 'linear':
        # Use LinearNDInterpolator + NearestNDInterpolator fallback
        pts = np.column_stack((x_flat, y_flat))
        lin_u = LinearNDInterpolator(pts, u_flat)
        lin_v = LinearNDInterpolator(pts, v_flat)

        ui = lin_u(xi, yi)
        vi = lin_v(xi, yi)

        mask = np.isnan(ui)
        if np.any(mask):
            near_u = NearestNDInterpolator(pts, u_flat)
            near_v = NearestNDInterpolator(pts, v_flat)
            ui[mask] = near_u(xi[mask], yi[mask])
            vi[mask] = near_v(xi[mask], yi[mask])
    else:
        from scipy.interpolate import griddata
        ui = griddata((x_flat, y_flat), u_flat, (xi, yi),
                      method=method, fill_value=np.nan)
        vi = griddata((x_flat, y_flat), v_flat, (xi, yi),
                      method=method, fill_value=np.nan)

        mask = np.isnan(ui)
        if np.any(mask):
            ui[mask] = griddata((x_flat, y_flat), u_flat, (xi, yi),
                                method='nearest')[mask]
            vi[mask] = griddata((x_flat, y_flat), v_flat, (xi, yi),
                                method='nearest')[mask]

    return xi, yi, ui, vi
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def get_mean_velo(r_s, dr_s, n_bins=32, z_lim=10):

    r_all  = r_s.flatten()
    dr_all = dr_s.flatten()

    bins = np.linspace(np.nanmin(r_all), np.nanmax(r_all), n_bins)

    bin_centers = 0.5*(bins[:-1] + bins[1:])
    digitized = np.digitize(r_all, bins)

    dr_mean = np.array([np.nanmean(dr_all[digitized == i]) for i in range(1, len(bins))])

    return dr_mean, bins, bin_centers, digitized
#+end_src

#+RESULTS:

* Parameters

#+begin_src jupyter-python
old_mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']

mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
# mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
# mice = ['JawsM15', 'JawsM18', 'ChRM04']

tasks = ['Dual'] # all

kwargs = {
   'mice': mice,
   'tasks': tasks,
   'mouse': mice[0], 'laser': 0,
   'trials': '', 'reload': 0, 'data_type': 'dF',
   'prescreen': None, 'pval': 0.05,
   'preprocess': False, 'scaler_BL': 'standard',
   'avg_noise':False, 'unit_var_BL': False,
   'random_state': None, 'T_WINDOW': 0.0,
   'l1_ratio': 0.95,
   'n_comp': 3, 'pca': 'pca',
   'scaler': None,
   'bootstrap': 1, 'n_boots': 128,
   'n_splits': 5, 'n_repeats': 10,
   'class_weight': 0,
   'multilabel': 0,
   'mne_estimator':'generalizing', # sliding or generalizing
   'n_jobs': 64,
}

# kwargs['days'] = ['first', 'middle', 'last']
kwargs['days'] = ['first', 'last']
# kwargs['days'] = 'all'
options = set_options(**kwargs)
options['cv_B'] = False
#+end_src

#+RESULTS:

#+begin_src jupyter-python
options['learning'] = 'Expert'
options['laser'] = 0

options['epochs'] = ['TASK']
epoch = options['bins_' + options['epochs'][0]]

condition = 'odor_pair'
# condition = ['sample_odor', 'choice']
#+end_src

#+RESULTS:

* Load Data

#+begin_src jupyter-python
X_trials, y_trials = [], []

n_neurons = 3319
counter = 0
for mouse in options['mice']:

    options['mouse'] = mouse
    options = set_options(**options)
    X, y = get_X_y_days(**options)

    print(mouse, X.shape, y.shape, options['n_days'])

    X_scale = X.copy()
    for day in range(1, options['n_days']+1):
        idx = (y.day==day) & (y.laser==0) & (y.performance==1)

        mean_ = np.nanmean(X[idx], 0, keepdims=1)
        std_ = np.nanstd(X[idx], (0, -1), keepdims=1)
        std_ = np.where(std_==0, 1, std_)

        X_scale[idx] = (X[idx] - mean_) / std_

        idx = (y.day==day) & ((y.laser==1) | (y.performance==0))
        X_scale[idx] = (X[idx] - mean_) / std_

        # for tasks in ['DPA', 'DualGo', 'DualNoGo']:
        #     idx = (y.day==day) & (y.laser==0) & (y.tasks==tasks)

        #     mean_ = np.nanmean(X[idx], 0, keepdims=1)
        #     std_ = np.nanstd(X[idx], (0, -1), keepdims=1)
        #     std_ = np.where(std_==0, 1, std_)

        #     X_scale[idx] = (X[idx] - mean_) / std_

        #     idx = (y.day==day) & (y.laser==1) & (y.tasks==tasks)
        #     X_scale[idx] = (X[idx] - mean_) / std_

    X_trial = np.zeros((X.shape[0], n_neurons, X.shape[-1])) * np.nan
    X_trial[:, counter:X.shape[1]+counter, :] = X_scale

    counter += X.shape[1]

    X_trials.append(X_trial)

    y['mouse'] = mouse
    y_trials.append(y)

X_trials = np.array(X_trials, dtype=object)
y_trials = np.array(y_trials, dtype=object)
#+end_src

#+RESULTS:
: JawsM01 (768, 184, 84) (768, 15) 4
: JawsM06 (1152, 201, 84) (1152, 15) 6
: JawsM12 (960, 423, 84) (960, 15) 5
: JawsM15 (1152, 693, 84) (1152, 15) 6
: JawsM18 (1152, 444, 84) (1152, 15) 6
: ChRM04 (1152, 668, 84) (1152, 15) 6
: ChRM23 (960, 232, 84) (960, 15) 5
: ACCM03 (960, 361, 84) (960, 15) 5
: ACCM04 (960, 113, 84) (960, 15) 5

#+begin_src jupyter-python
X_all = np.concatenate(X_trials, 0)
y_all = pd.concat(y_trials)
print(X_all.shape, y_all.shape)
#+end_src

#+RESULTS:
: (9216, 3319, 84) (9216, 16)

#+begin_src jupyter-python
pkl_save(X_all, 'X_all', path="../data/pca")
pkl_save(y_all, 'y_all', path="../data/pca")
#+end_src

#+RESULTS:
: saving to ../data/pca/X_all.pkl
: saving to ../data/pca/y_all.pkl

* Meta Mouse
** Load

#+begin_src jupyter-python
X_all = pkl_load('X_all', path="../data/pca")
y_all = pkl_load('y_all', path="../data/pca")
#+end_src

#+RESULTS:
: loading from ../data/pca/X_all.pkl
: loading from ../data/pca/y_all.pkl

#+begin_src jupyter-python
print(y_all.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response', 'laser',
:        'day', 'choice', 'pair', 'odr_perf', 'odr_choice', 'odr_response',
:        'odor_pair', 'learning', 'performance', 'mouse'],
:       dtype='object')

** Model

#+begin_src jupyter-python
idx = (y_all.learning == options['learning']) # & (y_all.tasks=='DPA')  # & (~y_all['mouse'].str.contains('ACC')) # & (y_all.laser==options['laser'])
# idx = (y_all.learning == options['learning']) &( y_all.performance==1) & ((y_all.tasks=='DPA') | (y_all.odr_perf==1)) & (y_all.laser==0)
# idx = (y_all.learning == options['learning']) &( y_all.performance==1)

X_pca = X_all[idx]
y_pca = y_all[idx]

pca_mask = np.isnan(X_pca)
X_pca[pca_mask] = 0

print('laser', options['laser'])
print(X_pca.shape, y_pca.shape)
print(y_pca.mouse.unique())
print(y_pca.odor_pair.unique())
print(y_pca.tasks.unique())
#+end_src

#+RESULTS:
: laser 0
: (4032, 3319, 84) (4032, 16)
: ['JawsM01' 'JawsM06' 'JawsM12' 'JawsM15' 'JawsM18' 'ChRM04' 'ChRM23'
:  'ACCM03' 'ACCM04']
: [1. 2. 3. 0.]
: ['DualNoGo' 'DualGo' 'DPA']

 #+begin_src jupyter-python
# pca = PCA(n_components=3)
# scaler = StandardScaler(axis=0)

# # fit on full data
# X_scaled = scaler.fit_transform(X)
# X_avg = cv_avg_cond(X_scaled, y.copy(), condition)
# X_flat = X_avg[..., epoch].transpose(0, 2, 1).reshape(-1, X_avg.shape[1])
# X_mean = np.nanmean(X_flat, 0, keepdims=1)
# X_cent = (X_flat - X_mean)

# pca.fit(X_cent)
# w_all = pca.components_
# evr_all = pca.explained_variance_ratio_

# X_flat = X_scaled.transpose(0, 2, 1).reshape(-1, X_scaled.shape[1])
# X_mean = np.nanmean(X_flat, 0, keepdims=1)
# X_cent = (X_flat - X_mean)

# X_pca = pca.transform(X_cent).reshape(X_scaled.shape[0], X_scaled.shape[-1], -1)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
n_splits = 5
n_repeats = 1
n_comp = 3

X_cv, y_cv, w_cv, evr_cv = cross_val_avg_pca(X_pca, y_pca, n_splits, n_repeats, n_comp, epoch, condition)
#+end_src

#+RESULTS:
: 100% 5/5 [10:37<00:00, 127.54s/it]

#+begin_src jupyter-python
print(X_cv.shape, y_cv.shape, w_cv.shape, evr_cv.shape)
#+end_src

#+RESULTS:
: (4032, 84, 3) (4032, 16) (5, 3, 3319) (5, 3)

#+begin_src jupyter-python
X_meta = np.array(X_cv, dtype=float)
X_meta = np.swapaxes(X_meta, 1, 2)
y_meta = y_cv
evr_meta = evr_cv
w_meta = np.mean(w_cv, 0, dtype=float) * 100
print(X_meta.shape, y_meta.shape, w_meta.shape)
#+end_src

#+RESULTS:
: (4032, 3, 84) (4032, 16) (3, 3319)

** Save/Load

#+begin_src jupyter-python
dum = options['epochs'][0] + '_' + options['learning'] + '_laser_%d' % options['laser'] #  + '_DPA'
print(dum)
#+end_src

#+RESULTS:
: TASK_Expert_laser_0

#+begin_src jupyter-python
pkl_save(X_meta, 'meta_traj_' + dum, path="../data/pca/")
pkl_save(y_meta, 'meta_labels_' + dum, path="../data/pca/")
pkl_save(w_meta, 'meta_weights_' + dum, path="../data/pca/")
pkl_save(evr_meta, 'meta_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: saving to ../data/pca//meta_traj_TASK_Expert_laser_0.pkl
: saving to ../data/pca//meta_labels_TASK_Expert_laser_0.pkl
: saving to ../data/pca//meta_weights_TASK_Expert_laser_0.pkl
: saving to ../data/pca//meta_evr_TASK_Expert_laser_0.pkl

#+begin_src jupyter-python
X_meta = pkl_load('meta_traj_' + dum, path="../data/pca/")
y_meta = pkl_load( 'meta_labels_' + dum, path="../data/pca/")
w_meta = pkl_load( 'meta_weights_' + dum, path="../data/pca/")
evr_meta = pkl_load( 'meta_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: loading from ../data/pca//meta_traj_TASK_Expert_laser_0.pkl
: loading from ../data/pca//meta_labels_TASK_Expert_laser_0.pkl
: loading from ../data/pca//meta_weights_TASK_Expert_laser_0.pkl
: loading from ../data/pca//meta_evr_TASK_Expert_laser_0.pkl

** Trajectories

#+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse=-1

idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_meta.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height),)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = ['AC', 'AD', 'BD', 'BC']
xtime = np.linspace(0, 14, 84)

for i in range(4):
    mask = (y_meta.odor_pair==i) & (y_meta.laser==laser) & idx_mouse
    X_sel = X_meta[mask]

    X_avg = np.mean(X_sel, 0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = np.std(X_sel, 0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)

        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_odor_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_36.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = y_meta.tasks.unique()
xtime = np.linspace(0, 14, 84)

for i in range(len(pair)):
    mask = (y_meta.tasks==y_meta.tasks.unique()[i]) & (y_meta.laser==laser) & idx_mouse
    X_sel = X_meta[mask]

    X_avg = X_sel.mean(0)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=0)

        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_task_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_37.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#984ea3", "#4daf4a", "#ffae19"]

pair = ['A', 'B']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.sample_odor.values==i) & (y_meta.laser==laser) & idx_mouse
    X_sel = X_meta[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_sample_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_38.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8",  "#ffae19"]

pair = ['unpair', 'pair']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.pair==i) & (y_meta.laser==laser) & idx_mouse
    X_sel = X_meta[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_39.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['nolick', 'lick']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.choice==i) & (y_meta.laser==laser) & idx_mouse
    X_sel = X_meta[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_choice_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_40.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['C', 'D']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.test_odor==i) & (y_meta.laser==0) & idx_mouse
    X_sel = X_meta[mask]
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_test_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_41.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

pair = ['AC', 'AD', 'BD', 'BC']

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

for i in range(4):
    idx = (y_meta.odor_pair==i) & (y_meta.laser==laser) & idx_mouse

    X_avg = (X_meta[idx].mean(0))[:, :66]

    ax[0].plot(X_avg[0], X_avg[1], color=color[i], label=pair[i])
    ax[0].set_xlabel('PC 1')
    ax[0].set_ylabel('PC 2')

    ax[1].plot(X_avg[0], X_avg[2], color=color[i], label=pair[i])
    ax[1].set_xlabel('PC 1')
    ax[1].set_ylabel('PC 3')

    ax[2].plot(X_avg[1], X_avg[2], color=color[i], label=pair[i])
    ax[2].set_xlabel('PC 2')
    ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_42.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Embeddings
*** spatial filter

#+begin_src jupyter-python
z_lim =5
size = 0.1

import cmocean
cmap=cmocean.cm.phase

theta = np.arctan2(w_meta[1], w_meta[0]) * 180 / np.pi
idx = np.argsort(theta)

theta_norm = (theta+ 360) % (360)

counts, bins, patches = plt.hist(theta_norm, bins='auto', range=(0, 360), density=1)

bin_centers = 0.5*(bins[:-1] + bins[1:])
colors = [cmap(center/(360)) for center in bin_centers]

for patch, color in zip(patches, colors):
    patch.set_facecolor(color)

plt.xlabel('Neuron Loc (°)')
plt.ylabel('Density')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_44.png]]

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for k in range(n_comp):
    sc = ax[k].scatter(theta[idx], w_meta[k][idx], alpha=0.5, c=theta_norm[idx], cmap=cmap, rasterized=1)
    ax[k].plot(theta[idx], gaussian_filter1d(w_meta[k][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')
    ax[k].axhline(0, ls='--', color='k')
    ax[k].set_ylabel('Weights PC %d' % (k+1))
    ax[k].set_xlabel('Neuron Loc (°)')
    ax[k].set_ylim([-z_lim, z_lim])

ax[-1].set_ylim([-z_lim/10, z_lim/10])
plt.colorbar(sc, ax=ax[-1], label='Angle (°)')
plt.savefig('./figures/pca/pca_weights_%s.svg' % dum)
plt.show()
#+end_src



#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width))

ax[0].scatter(w_meta[0][idx], w_meta[1][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[0].plot(gaussian_filter1d(w_meta[0][idx], int(size*w_meta.shape[1]), mode='wrap'), gaussian_filter1d(w_meta[1][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')

ax[0].set_xlabel('PC 1')
ax[0].set_ylabel('PC 2')

ax[1].scatter(w_meta[0][idx], w_meta[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[1].plot(gaussian_filter1d(w_meta[0][idx], int(size*w_meta.shape[1]), mode='wrap'), gaussian_filter1d(w_meta[2][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')
ax[1].set_xlabel('PC 1')
ax[1].set_ylabel('PC 3')

sc = ax[2].scatter(w_meta[1][idx], w_meta[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[2].plot(gaussian_filter1d(w_meta[1][idx], int(size*w_meta.shape[1]), mode='wrap'), gaussian_filter1d(w_meta[2][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')
ax[2].set_xlabel('PC 2')
ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].set_xlim(-z_lim, z_lim)
    ax[k].set_ylim(-z_lim, z_lim)

ax[1].set_ylim(-z_lim/10, z_lim/10)
ax[2].set_ylim(-z_lim/10, z_lim/10)

plt.colorbar(sc, ax=ax[-1], label='Angle (°)')

plt.show()
#+end_src


#+begin_src jupyter-python
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

ax.plot(gaussian_filter1d(w_meta[0][idx], int(size*w_meta.shape[1]), mode='wrap'),
           gaussian_filter1d(w_meta[1][idx], int(size*w_meta.shape[1]), mode='wrap'),
           gaussian_filter1d(w_meta[2][idx], int(size*w_meta.shape[1]), mode='wrap'),
           rasterized=1, color='k')


sc = ax.scatter(w_meta[0][idx],
                w_meta[1][idx],
                w_meta[2][idx],
                c=theta_norm[idx], cmap=cmap,
                rasterized=1, alpha=0.5)

ax.tick_params(axis='both', which='major', labelsize=12)  # change both x and y (and z in 3D)
ax.tick_params(axis='z', which='major', labelsize=12)     # for the z-axis specifically

ax.set_xlabel('PC 1', fontsize=12)
ax.set_ylabel('PC 2', fontsize=12)
ax.set_zlabel('PC 3', fontsize=12)

ax.set_xlim([-z_lim, z_lim])
ax.set_ylim([-z_lim, z_lim])
ax.set_zlim([-z_lim/10, z_lim/10])

ax.grid(False)

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_47.png]]

*** theta space

#+begin_src jupyter-python
nbins = 32
theta_bins = np.linspace(0, 360, nbins+1)
theta_digitized = np.digitize(theta_norm, theta_bins) - 1

# For each bin, average w[0], w[1], and w[2]
w_binned = np.zeros((3, nbins))
for i in range(nbins):
    mask = theta_digitized == i
    for j in range(3):
        w_binned[j, i] = np.mean(w_meta[j][mask]) if np.any(mask) else np.nan

w_smooth = gaussian_filter1d(w_binned, sigma=2, axis=1, mode='wrap')
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for i, ax in enumerate(axs):
    ax.plot(theta_plot * 180 / np.pi, w_smooth[i], lw=2)
    ax.axhline(0, ls='--', color='k')
    ax.set_ylabel('Weights PC %d' % (i+1))
    ax.set_xlabel('Neuron Loc (°)')

axs[-1].axvline(45)
axs[-1].axvline(225)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_49.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

# Compute bin centers in degrees and radians
bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)  # for polar plots

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width), sharey=1)

# PC1 vs PC2
axs[0].plot(w_smooth[0], w_smooth[1], 'k-')
axs[0].set_xlabel('PC 1')
axs[0].set_ylabel('PC 2')

# PC1 vs PC3
axs[1].plot(w_smooth[0], w_smooth[2], 'k-')
axs[1].set_xlabel('PC 1')
axs[1].set_ylabel('PC 3')

# PC2 vs PC3
axs[2].plot(w_smooth[1], w_smooth[2], 'k-')
axs[2].set_xlabel('PC 2')
axs[2].set_ylabel('PC 3')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_50.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(1, 3, subplot_kw={'polar': True}, figsize=(n_comp*width, width))

for i, ax in enumerate(axs):
    ax.plot(theta_plot, w_smooth[i], lw=2)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_51.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Opto

#+begin_src jupyter-python
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15','JawsM18', 'ChRM04', 'ChRM23']
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM18', 'ChRM04', 'ChRM23']
# laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15','JawsM18']

traj_mouse = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_meta.mouse==mouse) & (y_meta.laser==0)
    X_idx = X_meta[idx]
    y_idx = y_meta[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i)  & (y_idx.tasks=='DPA') # & (y_idx.performance==1) & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_mouse.append(traj_)

traj_mouse = np.array(traj_mouse)
print(traj_mouse.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
traj_opto = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_meta.mouse==mouse) & (y_meta.laser==1)
    X_idx = X_meta[idx]
    y_idx = y_meta[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i) & (y_idx.tasks=='DPA') # & (y_idx.performance==1) & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_opto.append(traj_)

traj_opto = np.array(traj_opto)
print(traj_opto.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
fp_mouse = np.nanmean(traj_mouse[..., options['bins_LD']], -1)
fp_opto = np.nanmean(traj_opto[..., options['bins_LD']], -1)

print(fp_mouse.shape)

pc1 = fp_mouse[..., 0]
pc2 = fp_mouse[..., 1]

pc1_opto = fp_opto[..., 0]
pc2_opto = fp_opto[..., 1]
#+end_src

#+RESULTS:
: (6, 2, 3)

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*height, height), sharey=1)

for i in range(pc1.shape[0]):
    ax[0].scatter(pc1[i], pc2[i], label=options['mice'][i])
    ax[1].scatter(pc1_opto[i], pc2_opto[i], label=options['mice'][i])

for k in range(2):
    ax[k].axvline(0, color='k')
    ax[k].axhline(0, color='k')

    ax[k].set_xlabel('PC1')
    ax[k].set_ylabel('PC2')
# plt.legend(fontsize=12, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_56.png]]

#+begin_src jupyter-python
perf_off = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==0)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()
perf_on = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==1)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()

delta_dpa = (perf_on['performance'] - perf_off['performance']).values
print(perf_off.shape, perf_on.shape)
print(delta_dpa)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [ 0.00694444  0.03472222  0.0625      0.02083333  0.          0.
:   0.00694444 -0.04166667  0.01041667  0.09375     0.00694444 -0.00694444]

#+begin_src jupyter-python
perf_off = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==0)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()
perf_on = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==1)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()

delta_odr = (perf_on['odr_perf'] - perf_off['odr_perf']).values
print(perf_off.shape, perf_on.shape)
print(delta_odr)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [-0.05208333 -0.02083333 -0.015625   -0.0625      0.03125    -0.03125
:  -0.02083333  0.          0.          0.015625   -0.02083333  0.02083333]

#+begin_src jupyter-python
dPC1 = (pc1_opto - pc1).reshape(-1)
dPC2 = (pc2_opto - pc2).reshape(-1)
print(dPC1.shape, dPC2.shape)
#+end_src

#+RESULTS:
: (12,) (12,)

#+begin_src jupyter-python
df = perf_off[['mouse', 'sample_odor']]
df['delta_dpa'] = delta_dpa
df['delta_odr'] = delta_odr

df['mouse'] = pd.Categorical(df['mouse'], categories=laser_mice, ordered=True)
df = df.sort_values('mouse')

df['delta_pc1'] = dPC1
df['delta_pc2'] = dPC2

# df = df[~df['mouse'].str.contains('ChR')]

print(df.head())
#+end_src

#+RESULTS:
:      mouse  sample_odor  delta_dpa  delta_odr  delta_pc1  delta_pc2
: 4  JawsM01          0.0   0.000000   0.031250  -0.095731  -0.226824
: 5  JawsM01          1.0   0.000000  -0.031250  -0.094659  -0.166135
: 6  JawsM06          0.0   0.006944  -0.020833  -0.137230   0.079899
: 7  JawsM06          1.0  -0.041667   0.000000  -0.115407   0.048131
: 8  JawsM12          0.0   0.010417   0.000000   0.273573  -0.228024

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc1', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc1', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None)

    corr, p_value = pearsonr(df_['delta_pc1'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC1")
    ax[i].set_ylabel("$\\Delta$ Performance")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")
# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_61.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc2', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc2', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None)

    corr, p_value = pearsonr(df_['delta_pc2'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC2")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")

# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_62.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Binned Flow Fields
*** utils

#+begin_src jupyter-python
import numpy as np

def flow_field_from_trajectories(x, y, dt=1.0, bins=25, xrange=None, yrange=None,
                                 statistic="mean", min_count=1):
    """
    x, y: arrays (n_trials, n_time)
    dt: timestep
    bins: int or (nx, ny)
    xrange, yrange: (min, max); if None inferred from data
    statistic: "mean" (default). (You can extend to median easily.)
    Returns:
      xedges, yedges
      u, v: (nx, ny) average velocities in each spatial bin
      count: (nx, ny) number of samples per bin
    """
    x = np.asarray(x); y = np.asarray(y)
    n_trials, n_time = x.shape
    assert y.shape == x.shape

    # step velocities, shape (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # positions to bin (start of each step)
    xs = x[:, :-1]
    ys = y[:, :-1]

    if xrange is None:
        xrange = (xs.min(), xs.max())
    if yrange is None:
        yrange = (ys.min(), ys.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten all steps across trials/time
    xsf = xs.ravel()
    ysf = ys.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin index for each sample
    ix = np.searchsorted(xedges, xsf, side="right") - 1
    iy = np.searchsorted(yedges, ysf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate sums and counts
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    # mean velocity per bin
    ugrid = np.full((nx, ny), np.nan, dtype=float)
    vgrid = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    ugrid[mask] = usum[mask] / count[mask]
    vgrid[mask] = vsum[mask] / count[mask]

    return xedges, yedges, ugrid, vgrid, count


# Example usage:
# x, y = diffusion_2d(n_trials=200, n_time=2000, dt=0.01, D=0.5, seed=0)

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def flow_field_midpoint(x, y, dt=1.0, bins=25, xrange=None, yrange=None, min_count=1):
    """
    Mid-point binning: each velocity sample is assigned to the bin containing
    the segment midpoint ((x_t+x_{t+1})/2, (y_t+y_{t+1})/2).

    x, y: (n_trials, n_time)
    Returns: xedges, yedges, U, V, count with U,V,count shaped (nx, ny)
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape

    # step velocities (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # midpoints to bin (n_trials, n_time-1)
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    if xrange is None:
        xrange = (xm.min(), xm.max())
    if yrange is None:
        yrange = (ym.min(), ym.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten samples
    xf = xm.ravel()
    yf = ym.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin indices
    ix = np.searchsorted(xedges, xf, side="right") - 1
    iy = np.searchsorted(yedges, yf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    U = np.full((nx, ny), np.nan, dtype=float)
    V = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    U[mask] = usum[mask] / count[mask]
    V[mask] = vsum[mask] / count[mask]

    return xedges, yedges, U, V, count

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_speeds(x, y, dt=1.0):
    # step velocities at times t -> t+1
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]
    ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)  # [-pi, pi)

    # avoid r=0 issues
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    vr = (xs*vx + ys*vy) / r_safe
    omega = (xs*vy - ys*vx) / (r_safe**2)

    return r, theta, vr, omega

def bin_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nbin = len(edges) - 1
    valid = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(xvals)
    idx = idx[valid]
    yvals = yvals[valid]

    count = np.zeros(nbin, dtype=int)
    ysum  = np.zeros(nbin, dtype=float)
    np.add.at(count, idx, 1)
    np.add.at(ysum,  idx, yvals)

    ymean = np.full(nbin, np.nan, float)
    m = count >= min_count
    ymean[m] = ysum[m] / count[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, count
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_from_binned_uv(U, V, C, xedges, yedges, r_edges, th_edges,
                                 min_count_bin=1, min_count_1d=1):
    """
    Option (2): convert binned mean velocity field (U,V) into polar components at bin centers,
    then compute weighted 1D profiles vs radius r and angle theta using weights=C.

    Inputs:
      U,V,C: (nx, ny) arrays from flow_field_from_trajectories
      xedges,yedges: bin edges
      r_edges: 1D edges for radius bins
      th_edges: 1D edges for theta bins in [-pi, pi]
      min_count_bin: require C>=this to use a spatial bin at all
      min_count_1d: require total weight in a 1D bin >= this

    Returns:
      r_cent, vr_r, w_r
      th_cent, om_th, w_th
      plus (vr_grid, om_grid) for inspection
    """
    U = np.asarray(U); V = np.asarray(V); C = np.asarray(C)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    r = np.sqrt(Xc**2 + Yc**2)
    th = np.arctan2(Yc, Xc)
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    # polar components derived from mean flow vector in each spatial bin
    vr_grid = np.abs(Xc*U + Yc*V) / r_safe
    om_grid = np.abs(Xc*V - Yc*U) / (r_safe**2)   # angular speed dtheta/dt

    # flatten
    rf = r.ravel()
    thf = th.ravel()
    vrf = vr_grid.ravel()
    omf = om_grid.ravel()
    wf = C.ravel().astype(float)

    # keep only bins with enough samples and finite values
    valid = (wf >= min_count_bin) & np.isfinite(vrf) & np.isfinite(omf) & np.isfinite(rf) & np.isfinite(thf)
    rf, thf, vrf, omf, wf = rf[valid], thf[valid], vrf[valid], omf[valid], wf[valid]

    def weighted_bin_mean(xvals, yvals, wvals, edges, min_w=1.0):
        idx = np.searchsorted(edges, xvals, side="right") - 1
        nbin = len(edges) - 1
        ok = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(wvals)
        idx = idx[ok]; yvals = yvals[ok]; wvals = wvals[ok]

        wsum = np.zeros(nbin, float)
        ywsum = np.zeros(nbin, float)
        np.add.at(wsum, idx, wvals)
        np.add.at(ywsum, idx, wvals * yvals)

        ymean = np.full(nbin, np.nan, float)
        m = wsum >= min_w
        ymean[m] = ywsum[m] / wsum[m]
        centers = 0.5*(edges[:-1] + edges[1:])
        return centers, ymean, wsum

    r_cent, vr_r, w_r   = weighted_bin_mean(rf,  vrf, wf, r_edges,  min_w=min_count_1d)
    th_cent, om_th, w_th = weighted_bin_mean(thf, omf, wf, th_edges, min_w=min_count_1d)

    return r_cent, vr_r, w_r, th_cent, om_th, w_th, vr_grid, om_grid
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
from scipy.ndimage import gaussian_filter1d

def gaussian_filter1d_nan(x, sigma, mode="nearest", truncate=4.0):
    x = np.asarray(x, float)
    m = np.isfinite(x).astype(float)          # 1 where valid, 0 where NaN
    x0 = np.where(np.isfinite(x), x, 0.0)

    xs = gaussian_filter1d(x0, sigma=sigma, mode=mode, truncate=truncate)
    ms = gaussian_filter1d(m,  sigma=sigma, mode=mode, truncate=truncate)

    out = xs / ms
    out[ms == 0] = np.nan
    return out
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_coor, y_coor, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False, nbins=32):
    x = np.asarray(x_coor); y = np.asarray(y_coor)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    eps = 1e-12
    r_safe = np.maximum(r, eps)
    omega = (xs*vy - ys*vx) / (r_safe**2)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), nbins)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, nbins)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, np.abs(speed), r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, np.abs(speed), theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:

*** all mice

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
dt = 1
nbins = 32
min_count = 1  # choose based on how noisy you expect things to be
min_w=1
sigma_r, sigma_th= 5, 5
#+end_src

#+RESULTS:

**** cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse])
    X_delay = X_meta[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    (r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)
mean_sp_r = np.nanmean(uniform_filter1d(np.array(sp_r_list), sigma_r), 0)

th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = np.nanmean(uniform_filter1d(np.array(sp_th_list), sigma_th), 0)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, mean_sp_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_sp_th, 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v\rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_95.png]]

**** binned cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse])
    X_delay = X_meta[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=1, bins=nbins)

    speed = np.sqrt(U**2 + V**2)
    speed = np.where(C >= min_count, speed, np.nan)

    # bin centers -> R, TH
    xc = 0.5*(xedges[:-1] + xedges[1:])
    yc = 0.5*(yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
    R  = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)

    # speed vs radius (weighted by C)
    r_edges = np.linspace(0, np.nanmax(R), nbins)
    r_c, sp_r, cnt_r, wsum_r = weighted_binned_mean(R, speed, r_edges, weights=C,min_count=min_count, min_weight_1d=min_w)

    # speed vs theta (weighted by C)
    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, sp_th, cnt_th, wsum_th = weighted_binned_mean(TH, speed, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)

mean_sp_r = np.nanmean(sp_r_list, 0)
std_sp_r = np.nanstd(sp_r_list, 0) / np.sqrt(len(options['mice']))


th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = circmean(sp_th_list, -np.pi, np.pi, 0)
std_sp_th = np.nanstd(sp_th_list, 0) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
sigma_r = 5
sigma_th = 5


fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, uniform_filter1d(mean_sp_r, sigma_r), 'k')
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(mean_sp_th, sigma_th), 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v_{bin} \rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v_{bin}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_98.png]]

#+begin_src jupyter-python


#+end_src

#+RESULTS:

**** polar speeds

#+begin_src jupyter-python
r_list = []
avr_r_list, avr_th_list = [], []
avth_r_list, avth_th_list = [], []
aw_r_list, aw_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse])
    X_delay = X_meta[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    # --- compute components
    r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

    # magnitudes
    avr  = np.abs(vr)
    avth = np.abs(vth)
    aw = np.abs(omega)

    # --- bin vs radius
    r_edges = np.linspace(0, np.nanmax(r), nbins)
    r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
    _,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
    _, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
    _,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
    _, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)

    r_c /= np.nanmax(r_c)

    m_avr_r = np.nanmean(avr_r)
    std_avr_r = np.nanstd(avr_r)
    avr_r = (avr_r - m_avr_r) / std_avr_r

    m_avr_th = np.nanmean(avr_th)
    std_avr_th = np.nanstd(avr_th)
    avr_th = (avr_th - m_avr_th) / std_avr_th

    m_avth_r = np.nanmean(avth_r)
    std_avth_r = np.nanstd(avth_r)
    avth_r = (avth_r - m_avth_r) / std_avth_r

    m_avth_th = np.nanmean(avth_th)
    std_avth_th = np.nanstd(avth_th)
    avth_th = (avth_th - m_avth_th) / std_avth_th

    m_aw_r = np.nanmean(aw_r)
    std_aw_r = np.nanstd(aw_r)
    aw_r = (aw_r - m_aw_r) / std_aw_r

    m_aw_th = np.nanmean(aw_th)
    std_aw_th = np.nanstd(aw_th)
    aw_th = (aw_th - m_aw_th) / std_aw_th

    r_list.append(r_c)
    th_list.append(th_c)

    avr_r_list.append(avr_r)
    avr_th_list.append(avr_th)

    avth_r_list.append(avth_r)
    avth_th_list.append(avth_th)

    aw_r_list.append(aw_r)
    aw_th_list.append(aw_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
r_list = pad_list(r_list, axis=0, max_len=None)

avr_r_list = pad_list(avr_r_list, axis=0, max_len=None)
avth_r_list = pad_list(avth_r_list, axis=0, max_len=None)
aw_r_list = pad_list(aw_r_list, axis=0, max_len=None)

mean_avr_r = np.nanmean(uniform_filter1d(avr_r_list, sigma_r, axis=-1), 0)
mean_avth_r = np.nanmean(uniform_filter1d(avth_r_list, sigma_r, axis=-1), 0)
mean_aw_r = np.nanmean(uniform_filter1d(aw_r_list, sigma_r, axis=-1), 0)

mean_avr_r = uniform_filter1d(np.nanmean(avr_r_list, 0), sigma_r)
mean_avth_r = uniform_filter1d(np.nanmean(avth_r_list, 0), sigma_r)
mean_awr = uniform_filter1d(circmean(aw_r_list, low=-np.pi, high=np.pi, axis=0), sigma_r)

std_avr_r = uniform_filter1d(np.nanstd(avr_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_avth_r = uniform_filter1d(np.nanstd(avth_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_aw_r = uniform_filter1d(np.nanstd(aw_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))

th_list = pad_list(th_list, axis=0, max_len=None)

avr_th_list = pad_list(avr_th_list, axis=0, max_len=None)
avth_th_list = pad_list(avth_th_list, axis=0, max_len=None)
aw_th_list = pad_list(aw_th_list, axis=0, max_len=None)

mean_avr_th = uniform_filter1d(np.mean(avr_th_list, 0), sigma_th, mode='wrap')
mean_avth_th = uniform_filter1d(np.mean(avth_th_list, axis=0), sigma_th, mode='wrap')
mean_aw_th = uniform_filter1d(circmean(aw_th_list, low=-np.pi, high=np.pi, axis=0), sigma_th, mode='wrap')

std_avr_th = uniform_filter1d(np.nanstd(avr_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_avth_th = uniform_filter1d(np.nanstd(avth_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_aw_th = uniform_filter1d(np.nanstd(aw_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avr_r = avr_r_list[i]
    avr_th = avr_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avr_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avr_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_avr_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avr_th, 'k')

ax[0].fill_between(r_c, mean_avr_r-std_avr_r, mean_avr_r+std_avr_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avr_th-std_avr_th, mean_avr_th+std_avr_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_r>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_102.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avth_r = avth_r_list[i]
    avth_th = avth_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avth_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avth_th, sigma_th), alpha=0.25)

ax[0].plot(r_c, mean_avth_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avth_th, 'k')

ax[0].fill_between(r_c, mean_avth_r-std_avth_r, mean_avth_r+std_avth_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avth_th-std_avth_th, mean_avth_th+std_avth_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_\\theta>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_103.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    aw_r = aw_r_list[i]
    aw_th = aw_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(aw_r, sigma_r), alpha=0.2)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(aw_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_aw_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_aw_th, 'k')

ax[0].fill_between(r_c, mean_aw_r-std_aw_r, mean_aw_r+std_aw_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_aw_th-std_aw_th, mean_aw_th+std_aw_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_104.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

*** data
**** data

 #+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse = 5

idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_meta.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
dt = 1
nbins = 32
min_count = 1
min_w = 10
sigma_r, sigma_th= 15, 15
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d

# idx = (y_meta.tasks=='DPA') & (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse])
idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse])

X_delay = X_meta[idx].copy()

x_coor = X_delay[:, 0]
y_coor = X_delay[:, 1]

# x_coor = X_delay[:, 0, :options['bins_ED'][-1]]
# y_coor = X_delay[:, 1, :options['bins_ED'][-1]]

# x_coor = X_delay[:, 0, options['bins_DELAY']]
# y_coor = X_delay[:, 1, options['bins_DELAY']]

print(x_coor.shape)
#+end_src

#+RESULTS:
: (264, 84)

**** binned flows

#+begin_src jupyter-python
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_coor, y_coor, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=dt, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1, sharex=1)

ax[0].plot(x_coor.T, y_coor.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


# pcm = ax[2].pcolormesh(
#     xedges, yedges, speed.T, shading="auto",
#     norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
# )

# cbar = fig.colorbar(pcm, ax=ax[2])
# cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)
# ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

ax[0].set_xlim([-6, 6])
ax[0].set_ylim([-4, 4])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_110.png]]

#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(r)$')

ax[1].plot(th_c * 180 / np.pi, sp_th)
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_112.png]]


#+begin_src jupyter-python
import numpy as np

# per (x,y) bin:
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].plot(r_c, uniform_filter1d(speed_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].plot(th_c, uniform_filter1d(speed_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_114.png]]

#+begin_src jupyter-python
import numpy as np

def polar_components_from_steps(x, y, dt=1.0, eps=1e-12):
    vx = (x[:,1:] - x[:,:-1]) / dt
    vy = (y[:,1:] - y[:,:-1]) / dt
    xs = x[:,:-1]; ys = y[:,:-1]
    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)
    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe
    return r, th, vr, vth

def bin2d_mean(r, th, val, r_edges, th_edges, min_count=50):
    r = r.ravel(); th = th.ravel(); val = val.ravel()
    ir = np.searchsorted(r_edges, r, side="right") - 1
    it = np.searchsorted(th_edges, th, side="right") - 1
    nr = len(r_edges)-1; nt = len(th_edges)-1
    ok = (ir>=0)&(ir<nr)&(it>=0)&(it<nt)&np.isfinite(val)
    ir = ir[ok]; it = it[ok]; val = val[ok]

    cnt = np.zeros((nr, nt), int)
    s   = np.zeros((nr, nt), float)
    np.add.at(cnt, (ir, it), 1)
    np.add.at(s,   (ir, it), val)

    mean = np.full((nr, nt), np.nan)
    m = cnt >= min_count
    mean[m] = s[m] / cnt[m]
    return mean, cnt

def angular_anisotropy(mean_rt, eps=1e-12):
    # mean_rt: (nr, nt) array of mean quantity vs (r,theta)
    mu = np.nanmean(mean_rt, axis=1)          # mean over theta for each r
    sd = np.nanstd(mean_rt, axis=1)           # std over theta for each r
    A = sd / (np.abs(mu) + eps)               # relative angular modulation
    return A, mu, sd

# Example usage:
r, th, vr, vth = polar_components_from_steps(x_coor, y_coor, dt=dt)
r_edges  = np.linspace(0, np.nanmax(r), nbins)
th_edges = np.linspace(-np.pi, np.pi, nbins)
vr_rt, vr_cnt = bin2d_mean(r, th, np.abs(vr), r_edges, th_edges, min_count=min_w)
A_vr, vr_mu, vr_sd = angular_anisotropy(vr_rt)
vth_rt, vth_cnt = bin2d_mean(r, th, np.abs(vth), r_edges, th_edges, min_count=min_w)
#+end_src

#+RESULTS:

**** counts

 #+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

r_cent  = 0.5*(r_edges[:-1] + r_edges[1:])
th_cent = 0.5*(th_edges[:-1] + th_edges[1:])

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_rt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_rt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_116.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_cnt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_cnt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_117.png]]


#+begin_src jupyter-python

#+end_src

#+RESULTS:

**** speeds

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c * 180 / np.pi, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_120.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c* 180 / np.pi, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c* 180 / np.pi, uniform_filter1d(aw_th, sigma_th, mode='wrap'), color='k')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_121.png]]

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def binned_velocity_and_speed(
    x, y, dt,
    xedges, yedges,
    min_count=1,
    nan_empty=True,
):
    """
    Compute per-bin:
      U,V  = mean(vx), mean(vy)               (mean velocity components)
      S    = mean(speed) = mean(sqrt(vx^2+vy^2))  (mean speed; NOT sqrt(U^2+V^2))
      C    = counts per bin (# velocity samples falling in bin)

    x,y: arrays (n_trials, n_time)
    dt:  scalar timestep
    xedges,yedges: bin edges
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape
    if n_time < 2:
        raise ValueError("Need at least 2 timepoints per trial to compute velocity.")

    # per-sample velocities (n_trials, n_time-1)
    vx = np.diff(x, axis=1) / dt
    vy = np.diff(y, axis=1) / dt
    sp = np.sqrt(vx * vx + vy * vy)

    # position associated with each velocity sample: midpoint of segment
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    # flatten all samples
    xm = xm.ravel()
    ym = ym.ravel()
    vx = vx.ravel()
    vy = vy.ravel()
    sp = sp.ravel()

    # keep finite
    ok = np.isfinite(xm) & np.isfinite(ym) & np.isfinite(vx) & np.isfinite(vy) & np.isfinite(sp)
    xm, ym, vx, vy, sp = xm[ok], ym[ok], vx[ok], vy[ok], sp[ok]

    nx = len(xedges) - 1
    ny = len(yedges) - 1

    # bin indices
    ix = np.searchsorted(xedges, xm, side="right") - 1
    iy = np.searchsorted(yedges, ym, side="right") - 1
    inside = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)

    ix, iy = ix[inside], iy[inside]
    vx, vy, sp = vx[inside], vy[inside], sp[inside]

    # accumulate sums and counts
    C = np.zeros((nx, ny), dtype=np.int64)
    sum_vx = np.zeros((nx, ny), dtype=float)
    sum_vy = np.zeros((nx, ny), dtype=float)
    sum_sp = np.zeros((nx, ny), dtype=float)

    np.add.at(C, (ix, iy), 1)
    np.add.at(sum_vx, (ix, iy), vx)
    np.add.at(sum_vy, (ix, iy), vy)
    np.add.at(sum_sp, (ix, iy), sp)

    # means
    with np.errstate(invalid="ignore", divide="ignore"):
        U = sum_vx / C
        V = sum_vy / C
        S = sum_sp / C  # <-- mean speed per bin (the "fixed" part)

    if nan_empty:
        mask = C >= min_count
        U = np.where(mask, U, np.nan)
        V = np.where(mask, V, np.nan)
        S = np.where(mask, S, np.nan)

    return U, V, S, C


def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12, mask_r0=None):
    """
    Convert mean velocity components (U,V) defined at bin centers to polar components.
    Optionally mask low-count bins and optionally mask a central disk (mask_r0).
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    mask = np.isfinite(U) & np.isfinite(V)
    if C is not None:
        mask &= (C >= min_count)
    if mask_r0 is not None:
        mask &= (R >= mask_r0)

    Vr    = np.where(mask, Vr, np.nan)
    Vth   = np.where(mask, Vth, np.nan)
    Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega


# -------------------------
# Example usage:
# U,V are mean velocity components; S is mean speed (recommended for "speed map")
# -------------------------
# U, V, S, C = binned_velocity_and_speed(x, y, dt, xedges, yedges, min_count=10)
# Xc, Yc, R, TH, Vr, Vth, Omega = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=10, mask_r0=1e-6)
# speed_of_mean_flow = np.sqrt(U**2 + V**2)   # different quantity than S
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12):
    """
    xedges, yedges: bin edges (nx+1), (ny+1)
    U, V: mean velocity per bin, shape (nx, ny)
    C: counts per bin, shape (nx, ny) (optional but recommended)
    Returns:
      Xc, Yc, R, TH (nx, ny)
      Vr, Vth, Omega (nx, ny) with NaNs where invalid/low count
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    # mask out empty/low-sample bins
    if C is not None:
        mask = (C >= min_count) & np.isfinite(U) & np.isfinite(V)
        Vr    = np.where(mask, Vr, np.nan)
        Vth   = np.where(mask, Vth, np.nan)
        Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega
#+end_src

#+RESULTS:

#+begin_src jupyter-python
min_w = 1
U, V, S, C = binned_velocity_and_speed(x_coor, y_coor, dt, xedges, yedges, min_count=1)
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=1)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")


ax[1].plot(th_c * 180 / np.pi, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_125.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c * 180 / np.pi, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_126.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

*** Random walk
**** random 2D diffusion

#+begin_src jupyter-python
import numpy as np

def diffusion_2d(n_trials, n_time, dt=1.0, D=1.0, x0=0.0, y0=0.0, seed=None):
    """
    2D diffusion: dx = sqrt(2D) dW_x, dy = sqrt(2D) dW_y
    Returns x, y with shape (n_trials, n_time)
    """
    rng = np.random.default_rng(seed)

    sigma = np.sqrt(2 * D * dt)  # per-step std
    dx = sigma * rng.standard_normal((n_trials, n_time - 1))
    dy = sigma * rng.standard_normal((n_trials, n_time - 1))

    x = np.empty((n_trials, n_time), dtype=float)
    y = np.empty((n_trials, n_time), dtype=float)
    x[:, 0] = x0
    y[:, 0] = y0
    x[:, 1:] = x0 + np.cumsum(dx, axis=1)
    y[:, 1:] = y0 + np.cumsum(dy, axis=1)

    return x, y

# example
n_trials, n_time = x_coor.shape
x_diff, y_diff = diffusion_2d(n_trials, n_time, dt=0.1, D=1, seed=0)
print(x_diff.shape, y_diff.shape)
#+end_src

#+RESULTS:
: (264, 36) (264, 36)

**** binned flows

#+begin_src jupyter-python
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_diff, y_diff, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_diff, y_diff, dt=dt, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharey=1, sharex=1)

ax[0].plot(x_diff.T, y_diff.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


pcm = ax[2].pcolormesh(
    xedges, yedges, speed.T, shading="auto",
    norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
)

cbar = fig.colorbar(pcm, ax=ax[2])
cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)
ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

ax[0].set_xlim([-5, 5])
ax[0].set_ylim([-3, 3])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_130.png]]

#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_diff, y_diff, dt=dt, min_count=min_count, use_midpoint=True)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v \rangle(r)$')

ax[1].plot(th_c * 180 / np.pi, sp_th)
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_132.png]]

#+begin_src jupyter-python
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_134.png]]

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_diff, y_diff, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False):
    x = np.asarray(x_diff); y = np.asarray(y_diff)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), 50)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, 73)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, speed, r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, speed, theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)

# Example:
#+end_src

#+RESULTS:

#+begin_src jupyter-python

#+end_src

#+RESULTS:

**** speeds

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_diff, y_diff, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_139.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_140.png]]

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:

#+begin_src jupyter-python
min_w = 1
U, V, S, C = binned_velocity_and_speed(x_coor, y_coor, dt, xedges, yedges, min_count=1)
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=min_count)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_143.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_144.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

*** Shuffle

**** shuffle diff

#+begin_src jupyter-python
def shuffle_traj(x_coor, idx=None):
    x_rand = np.empty_like(x_coor)
    dx = np.diff(x_coor, axis=-1)
    rng = np.random.default_rng()

    if idx is None:
        idx = rng.random(dx.shape).argsort(axis=-1)

    shuf = np.take_along_axis(dx, idx, axis=-1)
    cum_sum = np.cumsum(shuf, axis=-1)

    x_rand[:, 0] = x_coor[:, 0]  # or any chosen starting value
    x_rand[:, 1:] = x_rand[:,0, np.newaxis] + cum_sum

    return x_rand, idx
#+end_src

#+RESULTS:

#+begin_src jupyter-python
x_shuff, idx = shuffle_traj(x_coor)
y_shuff, idx = shuffle_traj(y_coor)
#+end_src

#+RESULTS:

**** binned flows

#+begin_src jupyter-python
dt = 1
nbins = 32
min_count = 1  # choose based on how noisy you expect things to be
min_w=1
sigma_r, sigma_th= 1, 2
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_shuff, y_shuff, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_shuff, y_shuff, dt=1, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharey=1, sharex=1)

ax[0].plot(x_shuff.T, y_shuff.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


pcm = ax[2].pcolormesh(
    xedges, yedges, speed.T, shading="auto",
    norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
)

cbar = fig.colorbar(pcm, ax=ax[2])
cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)
ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

ax[0].set_xlim([-5, 5])
ax[0].set_ylim([-3, 3])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_149.png]]


#+begin_src jupyter-python
import numpy as np

# per (x,y) bin:
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_151.png]]

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_shuff, y_shuff, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False):
    x = np.asarray(x_shuff); y = np.asarray(y_shuff)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), 50)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, 73)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, speed, r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, speed, theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)

# Example:
#+end_src

#+RESULTS:

#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_shuff, y_shuff, dt=dt, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(r)$')

ax[1].plot(th_c, sp_th)
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_154.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

**** speeds

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_shuff, y_shuff, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_158.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_159.png]]

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12):
    """
    xedges, yedges: bin edges (nx+1), (ny+1)
    U, V: mean velocity per bin, shape (nx, ny)
    C: counts per bin, shape (nx, ny) (optional but recommended)
    Returns:
      Xc, Yc, R, TH (nx, ny)
      Vr, Vth, Omega (nx, ny) with NaNs where invalid/low count
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    # mask out empty/low-sample bins
    if C is not None:
        mask = (C >= min_count) & np.isfinite(U) & np.isfinite(V)
        Vr    = np.where(mask, Vr, np.nan)
        Vth   = np.where(mask, Vth, np.nan)
        Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:

#+begin_src jupyter-python
min_w = 1
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=min_count)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_163.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_164.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

* Single mouse
** Load

#+begin_src jupyter-python
X_all = pkl_load('X_all', path="../data/pca")
y_all = pkl_load('y_all', path="../data/pca")
#+end_src

#+RESULTS:
: loading from ../data/pca/X_all.pkl
: loading from ../data/pca/y_all.pkl

#+begin_src jupyter-python
print(y_all.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response', 'laser',
:        'day', 'choice', 'pair', 'odr_perf', 'odr_choice', 'odr_response',
:        'odor_pair', 'learning', 'performance', 'mouse'],
:       dtype='object')

** dPCA

#+begin_src jupyter-python
import numpy as np
from itertools import combinations

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.utils.validation import check_is_fitted
from sklearn.covariance import LedoitWolf, OAS

from scipy.linalg import cho_factor, cho_solve
from scipy.sparse.linalg import eigsh


def _as_1d(a):
    a = np.asarray(a)
    return a.reshape(-1)


def _factor_indices(y, factors):
    idxs, levels, dims = [], {}, []
    for k in factors:
        vals = _as_1d(y[k])
        lev = np.unique(vals)
        lev = np.sort(lev)
        levels[k] = lev
        idxs.append(np.searchsorted(lev, vals).astype(int))
        dims.append(len(lev))
    return np.stack(idxs, axis=1), levels, dims  # (B,F), dict, (F,)


def _flat_from_coords(coords, dims):
    dims = np.asarray(dims, dtype=int)
    if coords.shape[-1] == 1:
        return coords[..., 0].astype(int)
    mult = np.array([np.prod(dims[i + 1 :], dtype=int) for i in range(len(dims))], dtype=int)
    return (coords * mult).sum(axis=-1).astype(int)


def _compute_condition_means(X, cond_idx, n_cond):
    B, N, T = X.shape
    sums = np.zeros((n_cond, N, T), dtype=float)
    np.add.at(sums, cond_idx, X)
    counts = np.bincount(cond_idx, minlength=n_cond).astype(int)
    if np.any(counts == 0):
        raise ValueError("Missing conditions detected; this implementation assumes none missing.")
    return sums / counts[:, None, None], counts


def _ridge_fit(Y, X, alpha):
    """
    Solve B = Y X^T (X X^T + alpha I)^{-1}
    with Y, X shaped (N, S). Returns B shaped (N, N).
    """
    alpha = float(alpha)
    XXt = X @ X.T
    A = XXt + alpha * np.eye(XXt.shape[0], dtype=XXt.dtype)
    # Solve A * Z = (Y X^T)^T, then B = Z^T
    RHS = (Y @ X.T).T  # (N,N)
    c, lower = cho_factor(A, lower=True, check_finite=False)
    Z = cho_solve((c, lower), RHS, check_finite=False)
    return Z.T


def _top_components_from_predicted(B, Xmat, n_components):
    """
    Take top-k eigenvectors of (B X)(B X)^T.
    Returns W with shape (k, N), rows orthonormal.
    """
    N = B.shape[0]
    k = int(n_components)
    if k <= 0:
        raise ValueError("n_components must be >= 1")

    Ytilde = B @ Xmat           # (N,S)
    C = Ytilde @ Ytilde.T       # (N,N), PSD

    if N <= k:
        w, U = np.linalg.eigh(C)
        idx = np.argsort(w)[::-1][:k]
        return U[:, idx].T

    k_eff = min(k, N - 1)
    w, U = eigsh(C, k=k_eff, which="LA")
    idx = np.argsort(w)[::-1]
    return U[:, idx].T


def _shrinkage_to_ridge_alpha(shrinkage, cov):
    # Heuristic mapping; for robust results, prefer CV on alpha.
    p = cov.shape[0]
    mu = np.trace(cov) / max(1, p)
    s = float(shrinkage)
    s = min(max(s, 0.0), 0.999999)
    return (s / (1.0 - s)) * mu


class RegularizedDPCA(BaseEstimator, TransformerMixin):
    """
    Regularized dPCA (Kobak-style marginalizations from condition means),
    with single-trial projections and single-trial marginal reconstructions.

    X: (n_trials, n_neurons, n_time)
    y: dict-like, y[factor] is (n_trials,)

    Notes:
      - Learns marginal effects from condition-averaged data.
      - Uses trials to fit ridge map from X(trial) -> Y_m(trial) where Y_m is
        the marginal effect for that trial's condition.
      - Produces rank-k reconstruction operator per marginalization.
    """

    def __init__(
        self,
        factors,
        n_components=3,
        alpha="lw",  # "lw" or "oas"
        include_interactions=True,
        center=True,
        fit_on_trials=True,
    ):
        self.factors = list(factors)
        self.n_components = int(n_components)
        if alpha not in ("lw", "oas"):
            raise ValueError("alpha must be 'lw' or 'oas'")
        self.alpha = alpha
        self.include_interactions = bool(include_interactions)
        self.center = bool(center)
        self.fit_on_trials = bool(fit_on_trials)

    def _marginalizations(self):
        keys = self.factors
        out = [(k,) for k in keys]
        if self.include_interactions:
            for r in range(2, len(keys) + 1):
                out.extend(tuple(c) for c in combinations(keys, r))
        return out

    def _estimate_alpha(self, Xmat):
        # Xmat: (N,S) -> estimate covariance across neurons
        Z = Xmat.T  # (S,N)
        Z = Z - Z.mean(axis=0, keepdims=True)
        est = LedoitWolf().fit(Z) if self.alpha == "lw" else OAS().fit(Z)
        self.shrinkage_ = float(est.shrinkage_)
        return _shrinkage_to_ridge_alpha(self.shrinkage_, est.covariance_)

    def fit(self, X, y):
        X = np.asarray(X)
        if X.ndim != 3:
            raise ValueError("X must be (n_trials,n_neurons,n_time)")
        if not self.fit_on_trials:
            raise ValueError("This version is written for fit_on_trials=True.")

        B, N, T = X.shape
        for k in self.factors:
            if k not in y:
                raise ValueError(f"Missing factor '{k}' in y")

        fidxs, levels, dims = _factor_indices(y, self.factors)  # (B,F)
        F = fidxs.shape[1]
        n_cond = int(np.prod(dims))
        cond_idx = _flat_from_coords(fidxs, dims)  # (B,)

        means, counts = _compute_condition_means(X, cond_idx, n_cond)  # (C,N,T)

        # all condition coordinates in flat order
        grids = np.meshgrid(*[np.arange(d, dtype=int) for d in dims], indexing="ij")
        cond_coords = np.stack([g.reshape(-1) for g in grids], axis=1)  # (C,F)

        grand = means.mean(axis=0) if self.center else np.zeros((N, T), float)
        Xc = X - grand[None, :, :]
        means_c = means - grand[None, :, :]

        # Stack samples as trial x time
        Xmat = Xc.transpose(1, 0, 2).reshape(N, -1)  # (N, B*T)
        self.alpha_ = self._estimate_alpha(Xmat)

        # subset means for each subset of factors, stored as GRID arrays:
        # subset_means_grid[subset] has shape (*dims_subset, N, T)
        subset_means_grid = {}
        for r in range(1, F + 1):
            for subset in combinations(range(F), r):
                dims_s = [dims[i] for i in subset]
                coords_s = cond_coords[:, subset]
                combo = _flat_from_coords(coords_s, dims_s)
                n_combo = int(np.prod(dims_s))

                sums = np.zeros((n_combo, N, T), float)
                cnt = np.zeros((n_combo,), int)
                np.add.at(sums, combo, means_c)
                np.add.at(cnt, combo, 1)

                M = sums / cnt[:, None, None]  # (n_combo,N,T)
                subset_means_grid[subset] = M.reshape(*dims_s, N, T)

        # inclusion–exclusion in GRID space, then flatten at the end
        effects = {}  # effects[subset] is flattened (prod(dims_subset),N,T)
        for r in range(1, F + 1):
            for subset in combinations(range(F), r):
                dims_s = [dims[i] for i in subset]
                Egrid = subset_means_grid[subset].copy()  # (*dims_s,N,T)

                if r > 1:
                    for rr in range(1, r):
                        for subsub in combinations(subset, rr):
                            dims_ss = [dims[i] for i in subsub]
                            Esub_grid = effects[subsub].reshape(*dims_ss, N, T)

                            reshape_sizes = []
                            for i in subset:
                                reshape_sizes.append(dims[i] if i in subsub else 1)
                            Esub_in_subset = Esub_grid.reshape(*reshape_sizes, N, T)
                            Egrid -= Esub_in_subset

                effects[subset] = Egrid.reshape(-1, N, T)

        # Fit each marginalization
        self.components_ = {}       # W: (k,N) (projection/decoder axes)
        self.B_full_ = {}           # B: (N,N) full ridge map X->Y_m
        self.reconstructors_ = {}   # R: (N,N) rank-k reconstruction map X->X_m (actually -> predicted marginal signal subspace)
        self.marginalizations_ = [tuple(m) for m in self._marginalizations()]

        key_to_pos = {k: i for i, k in enumerate(self.factors)}

        for m in self.marginalizations_:
            pos = tuple(key_to_pos[k] for k in m)
            dims_m = [dims[i] for i in pos]
            Econd = effects[pos]  # (prod(dims_m), N, T)

            combo_id = _flat_from_coords(fidxs[:, pos], dims_m)  # (B,)
            Ytrial = Econd[combo_id]  # (B,N,T) target marginal signal per trial
            Ymat = Ytrial.transpose(1, 0, 2).reshape(N, -1)  # (N,B*T)

            # Full ridge map
            Bmap = _ridge_fit(Ymat, Xmat, self.alpha_)  # (N,N)

            # Top-k components from predicted marginal signal
            W = _top_components_from_predicted(Bmap, Xmat, self.n_components)  # (k,N)

            # Rank-k reconstructor: X -> (projected predicted marginal)
            # If W rows are orthonormal: P = W.T @ W is projector onto k-dim subspace.
            R = (W.T @ W) @ Bmap  # (N,N), rank <= k

            self.B_full_[m] = Bmap
            self.components_[m] = W
            self.reconstructors_[m] = R

        self.levels_ = levels
        self.dims_ = dims
        self.grand_mean_ = grand
        self.n_neurons_ = N
        self.n_time_ = T
        self.explained_variance_ratio_ = self._compute_evr_dict(X)
        return self

    def transform(self, X, marginalization):
        """
        Project single trials onto dPCA components for given marginalization.
        Returns (n_trials, k, n_time).
        """
        check_is_fitted(self, "components_")
        X = np.asarray(X)
        if X.ndim != 3:
            raise ValueError("X must be (n_trials,n_neurons,n_time)")
        if X.shape[1] != self.n_neurons_ or X.shape[2] != self.n_time_:
            raise ValueError("X shape mismatch vs fit()")

        m = tuple(marginalization) if isinstance(marginalization, (list, tuple)) else (marginalization,)
        W = self.components_[m]  # (k,N)
        Xc = X - self.grand_mean_[None, :, :]
        return np.einsum("kn,bnt->bkt", W, Xc)

    def reconstruct_marginal(self, X, marginalization):
        """
        Reconstruct the (rank-k) marginal signal on single trials.
        Returns (n_trials, n_neurons, n_time).
        """
        check_is_fitted(self, "reconstructors_")
        X = np.asarray(X)
        if X.ndim != 3:
            raise ValueError("X must be (n_trials,n_neurons,n_time)")
        if X.shape[1] != self.n_neurons_ or X.shape[2] != self.n_time_:
            raise ValueError("X shape mismatch vs fit()")

        m = tuple(marginalization) if isinstance(marginalization, (list, tuple)) else (marginalization,)
        R = self.reconstructors_[m]  # (N,N)
        Xc = X - self.grand_mean_[None, :, :]
        Xhat = np.einsum("nm,bmt->bnt", R, Xc)
        return Xhat + self.grand_mean_[None, :, :]

    def transform_demixed(self, X, marginalization):
        """
        Project the rank-k marginal reconstruction onto the same marginal's components.
        Often yields cleaner demixed trajectories.
        """
        Xm = self.reconstruct_marginal(X, marginalization=marginalization)
        return self.transform(Xm, marginalization=marginalization)

    def _compute_evr_dict(self, X):
        """
        Heuristic EVR per marginalization: Var(R_m Xc) / Var(Xc)
        where R_m is the rank-k reconstructor.
        """
        X = np.asarray(X)
        Xc = X - self.grand_mean_[None, :, :]
        den = np.var(Xc) + 1e-12

        evr = {}
        for m, R in self.reconstructors_.items():
            Xhat = np.einsum("nm,bmt->bnt", R, Xc)
            evr[m] = float(np.var(Xhat) / den)
        return evr
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold
from sklearn.decomposition import PCA
from tqdm import tqdm

def cross_val_avg_dpca(X, y, dpca, folds, factors):

    labels = y['mouse'].astype(str) + '_' + y['odor_pair'].astype(str) + '_' + y['tasks'].astype(str) + '_' + y['laser'].astype(str)

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    w_ref = None

    for train_idx, test_idx in tqdm(folds.split(X, labels), total=folds.get_n_splits(X, labels), desc=y.mouse.unique()[0]):

        X_train, y_train = X[train_idx], y.iloc[train_idx]
        # m_train = (y_train.laser==0) & (y_train.performance==1) & ((y_train.tasks=='DPA') | (y_train.odr_perf==1))
        # m_train = (y_train.laser==0) & (y_train.performance==1)
        m_train = (y_train.laser==0)

        X_train = X_train[m_train]
        y_train = y_train[m_train]
        X_train_epoch = X_train

        y_dict = {n: y_train[f"{n}"] for n in factors}

        dpca.fit(X_train_epoch, y=y_dict)

        w_fold = []
        for factor in factors:
            w_fold.append(dpca.components_[(factor,)])
        w_fold = np.concatenate(w_fold, axis=0)

        evr_fold = []
        for factor in factors:
            evr_fold.append(dpca.explained_variance_ratio_[(factor,)])
        evr_fold = np.array(evr_fold)

        X_test, y_test = X[test_idx], y.iloc[test_idx]

        X_fold = []
        for factor in factors:
            X_ = dpca.transform_demixed(X_test, factor)
            X_fold.append(X_)
        X_fold = np.concatenate(X_fold, axis=1)

        if w_ref is None:
            w_ref = w_fold

        X_fold, w_fold = align_fold_to_ref(w_fold, w_ref, np.swapaxes(X_fold, 1, 2))

        X_folds.append(np.swapaxes(X_fold, 1, 2))
        y_folds.append(y_test)
        w_folds.append(w_fold)

    X_folds = np.concatenate(X_folds, 0)
    y_folds = pd.concat(y_folds)

    w_folds = np.array(w_folds, dtype=object)

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import StratifiedGroupKFold, LeaveOneOut


def cv_dpca(
    X, y, dpca, folds, factors,
    group_col=None,
    show_pbar=True,
):
    # Clean subset used for fitting + CV
    m_clean = (y.laser == 0) & (y.performance == 1)
    # m_clean = (y.laser==0) & (y.performance==1) & ((y.tasks=='DPA') | (y.odr_perf==1))
    Xc = X[m_clean]
    yc = y.loc[m_clean].reset_index(drop=True)

    groups=None
    if group_col is not None:
        groups = yc[group_col].astype(str).values

    # Stratification label (adapt as you like)
    strata = (
        yc["odor_pair"].astype(str)
        + "_" + yc["tasks"].astype(str)
    ).values

    Z_folds, y_folds = [], []
    W_folds, EVR_folds = [], []
    w_ref = None

    it = folds.split(Xc, strata, groups=groups)
    if show_pbar:
        it = tqdm(it, total=folds.get_n_splits(Xc, strata), desc=y.mouse.unique()[0])

    for fold, (train, test) in enumerate(it):
        X_train, y_train = Xc[train], yc.iloc[train]
        X_test, y_test = Xc[test], yc.iloc[test]

        y_dict = {f: y_train[f].to_numpy() for f in factors}
        dpca.fit(X_train, y=y_dict)

        # stack W for alignment bookkeeping
        W = np.concatenate([dpca.components_[(f,)] for f in factors], axis=0)  # (Ktot,N)

        # demix held-out clean trials (out-of-fold)
        Z = np.concatenate([dpca.transform_demixed(X_test, f) for f in factors], axis=1)  # (Bte,Ktot,T)

        if w_ref is None:
            w_ref = W

        # align_fold_to_ref expects (B,T,K) in this example
        Z_aligned, W_aligned = align_fold_to_ref(W, w_ref, np.swapaxes(Z, 1, 2))
        Z_aligned = np.swapaxes(Z_aligned, 1, 2)  # back to (B,K,T)

        Z_folds.append(Z_aligned)
        y_folds.append(y_test)

        W_folds.append(W_aligned)
        EVR_folds.append({f: dpca.explained_variance_ratio_[(f,)] for f in factors})

    Z_folds = np.concatenate(Z_folds, 0)
    y_folds = pd.concat(y_folds)
    W_folds = np.array(W_folds, dtype=object)

    # Train once on all clean and apply to perturbed trials
    y_dict_all = {f: yc[f].to_numpy() for f in factors}
    dpca.fit(Xc, y=y_dict_all)

    W_all = np.concatenate([dpca.components_[(f,)] for f in factors], axis=0)
    if w_ref is None:
        w_ref = W_all

    EVR_all = {f: dpca.explained_variance_ratio_[(f,)] for f in factors}

    m_pert = ~m_clean
    Xp = X[m_pert]
    yp = y.loc[m_pert].reset_index(drop=True)

    Zp = np.concatenate([dpca.transform_demixed(Xp, f) for f in factors], axis=1)  # (Bp,K,T)
    Zp_aligned, W_all_aligned = align_fold_to_ref(W_all, w_ref, np.swapaxes(Zp, 1, 2))
    Zp_aligned = np.swapaxes(Zp_aligned, 1, 2)

    # Optional: concatenate clean+pert (clean first)
    Z_all = np.concatenate([Z_folds, Zp_aligned], axis=0)
    y_all = pd.concat([y_folds, yp], axis=0, ignore_index=True)

    return Z_all, y_all, W_folds, EVR_all
#+end_src

#+RESULTS:

#+begin_src jupyter-python
y_all['sample'] = y_all.sample_odor
y_all['test'] = y_all.test_odor
#+end_src

#+RESULTS:

#+begin_src jupyter-python
factors = ['sample', 'tasks', 'test']

n_splits = 5
n_repeats = 10
n_comp = 1

dpca = RegularizedDPCA(
    factors=factors,
    n_components=n_comp,
    alpha='lw', # 'lw' or 'oas'
    include_interactions=True,
    fit_on_trials=True,
)

folds = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)
# folds = LeaveOneOut()
#+end_src

#+RESULTS:

#+begin_src jupyter-python
X_mice, y_mice, w_mice, evr_mice = [], [], [], []

#options['mice'] = ['JawsM15']

for mouse in options['mice']:
    idx = (y_all.learning == options['learning'])  & (y_all['mouse'] == mouse)

    X_pca = X_all[idx]
    y_pca = y_all[idx]

    valid_neurons = ~np.all(np.isnan(X_pca), axis=(0, 2))
    X_pca = X_pca[:, valid_neurons, :]

    # try:
    if 1:
        # X_mouse, y_mouse, w_mouse, evr_mouse = cross_val_avg_dpca(X_pca, y_pca, dpca, folds, factors)
        X_mouse, y_mouse, w_mouse, evr_mouse = cv_dpca(X_pca, y_pca, dpca, folds, factors)

        X_mice.append(X_mouse)
        y_mice.append(y_mouse)
        w_mice.append(w_mouse)
        evr_mice.append(evr_mouse)
    # except:
    #     print('error', mouse)
    #     pass
#+end_src

#+RESULTS:
#+begin_example
JawsM01: 100% 50/50 [04:12<00:00,  5.05s/it]
JawsM06: 100% 50/50 [08:48<00:00, 10.56s/it]
JawsM12: 100% 50/50 [17:07<00:00, 20.54s/it]
JawsM15: 100% 50/50 [1:11:10<00:00, 85.41s/it]
JawsM18: 100% 50/50 [40:32<00:00, 48.64s/it]
ChRM04: 100% 50/50 [1:34:15<00:00, 113.12s/it]
ChRM23: 100% 50/50 [02:25<00:00,  2.90s/it]
ACCM03: 100% 50/50 [13:28<00:00, 16.18s/it]
ACCM04: 100% 50/50 [01:21<00:00,  1.64s/it]
#+end_example

#+begin_src jupyter-python
print(X_mice[0].shape, w_mice[0].shape)
#+end_src

#+RESULTS:
: (1011, 3, 84) (50, 3, 184)

#+begin_src jupyter-python
X_stack = np.vstack(X_mice)
y_single = pd.concat(y_mice)
w_stack = np.concatenate(w_mice, -1)
evr_single = np.stack(evr_mice)
print(X_stack.shape, w_stack.shape)
#+end_src

#+RESULTS:
: (22509, 3, 84) (50, 3, 3319)

#+begin_src jupyter-python
X_single = np.array(X_stack, dtype=float)
# X_single = np.swapaxes(X_single, 1, 2)
w_single = np.mean(w_stack, 0, dtype=float) * 100
# w_single = w_stack * 100
print(X_single.shape, y_single.shape, w_single.shape)
#+end_src

#+RESULTS:
: (22509, 3, 84) (22509, 18) (3, 3319)

** Save/Load

#+begin_src jupyter-python
dum = options['learning'] + '_laser_%d' % options['laser'] + '_lw'
print(dum)
#+end_src

#+RESULTS:
: Expert_laser_0_lw

#+begin_src jupyter-python
pkl_save(X_single, 'single_traj_' + dum, path="../data/pca/")
pkl_save(y_single, 'single_labels_' + dum, path="../data/pca/")
pkl_save(w_single, 'single_weights_' + dum, path="../data/pca/")
pkl_save(evr_single, 'single_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: saving to ../data/pca//single_traj_Expert_laser_0_lw.pkl
: saving to ../data/pca//single_labels_Expert_laser_0_lw.pkl
: saving to ../data/pca//single_weights_Expert_laser_0_lw.pkl
: saving to ../data/pca//single_evr_Expert_laser_0_lw.pkl

#+begin_src jupyter-python
X_single = pkl_load('single_traj_' + dum, path="../data/pca/")
y_single = pkl_load( 'single_labels_' + dum, path="../data/pca/")
w_single = pkl_load( 'single_weights_' + dum, path="../data/pca/")
evr_single = pkl_load( 'single_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: loading from ../data/pca//single_traj_Expert_laser_0_lw.pkl
: loading from ../data/pca//single_labels_Expert_laser_0_lw.pkl
: loading from ../data/pca//single_weights_Expert_laser_0_lw.pkl
: loading from ../data/pca//single_evr_Expert_laser_0_lw.pkl

** Trajectories

#+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse= -1

idx_mouse = 1 # (y_single.laser==0) & (y_single.performance==1) & ((y_single.tasks=='DPA') | (y_single.odr_perf==1))
if i_mouse !=-1:
    idx_mouse = (y_single.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height),)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = ['AC', 'AD', 'BD', 'BC']
xtime = np.linspace(0, 14, 84)

for i in range(4):
    mask = (y_single.odor_pair==i) & (y_single.laser==laser) & idx_mouse
    X_sel = X_single[mask]

    X_avg = np.mean(X_sel, 0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = np.std(X_sel, 0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)

        ax[k].legend(fontsize=12, frameon=0, loc='best')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_160.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = y_single.tasks.unique()
xtime = np.linspace(0, 14, 84)

for i in range(len(pair)):
    mask = (y_single.tasks==y_single.tasks.unique()[i]) & (y_single.laser==laser) & idx_mouse
    X_sel = X_single[mask]

    X_avg = X_sel.mean(0)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=0)

        ax[k].legend(fontsize=12, frameon=0, loc='best')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_161.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#984ea3", "#4daf4a", "#ffae19"]

pair = ['A', 'B']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.sample_odor.values==i) & (y_single.laser==laser) & idx_mouse
    X_sel = X_single[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_162.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8",  "#ffae19"]

pair = ['unpair', 'pair']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.pair==i) & (y_single.laser==laser) & idx_mouse
    X_sel = X_single[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_163.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['nolick', 'lick']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.choice==i) & (y_single.laser==laser) & idx_mouse
    X_sel = X_single[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_164.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['C', 'D']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.test_odor==i) & (y_single.laser==0) & idx_mouse
    X_sel = X_single[mask]
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_165.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

pair = ['AC', 'AD', 'BD', 'BC']

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

for i in range(4):
    idx = (y_single.odor_pair==i) & (y_single.laser==laser) & idx_mouse

    X_avg = (X_single[idx].mean(0))[:, :66]

    ax[0].plot(X_avg[0], X_avg[1], color=color[i], label=pair[i])
    ax[0].set_xlabel('PC 1')
    ax[0].set_ylabel('PC 2')

    ax[1].plot(X_avg[0], X_avg[2], color=color[i], label=pair[i])
    ax[1].set_xlabel('PC 1')
    ax[1].set_ylabel('PC 3')

    ax[2].plot(X_avg[1], X_avg[2], color=color[i], label=pair[i])
    ax[2].set_xlabel('PC 2')
    ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_166.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Embeddings
*** spatial filter

#+begin_src jupyter-python
n_comp=3
z_lim =5
size = 0.1

import cmocean
cmap=cmocean.cm.phase

theta = np.arctan2(w_single[1], w_single[0]) * 180 / np.pi
idx = np.argsort(theta)

theta_norm = (theta+ 360) % (360)

counts, bins, patches = plt.hist(theta_norm, bins='auto', range=(0, 360), density=1)

bin_centers = 0.5*(bins[:-1] + bins[1:])
colors = [cmap(center/(360)) for center in bin_centers]

for patch, color in zip(patches, colors):
    patch.set_facecolor(color)

plt.xlabel('Neuron Loc (°)')
plt.ylabel('Density')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_168.png]]

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, gaussian_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for k in range(n_comp):
    sc = ax[k].scatter(theta[idx], w_single[k][idx], alpha=0.5, c=theta_norm[idx], cmap=cmap, rasterized=1)
    ax[k].plot(theta[idx], gaussian_filter1d(w_single[k][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')
    ax[k].axhline(0, ls='--', color='k')
    ax[k].set_ylabel('Weights PC %d' % (k+1))
    ax[k].set_xlabel('Neuron Loc (°)')
    ax[k].set_ylim([-z_lim, z_lim])

ax[-1].set_ylim([-z_lim/2, z_lim/2])
plt.colorbar(sc, ax=ax[-1], label='Angle (°)')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_169.png]]

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width))

ax[0].scatter(w_single[0][idx], w_single[1][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[0].plot(gaussian_filter1d(w_single[0][idx], int(size*w_single.shape[1]), mode='wrap'), gaussian_filter1d(w_single[1][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')

ax[0].set_xlabel('PC 1')
ax[0].set_ylabel('PC 2')

ax[1].scatter(w_single[0][idx], w_single[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[1].plot(gaussian_filter1d(w_single[0][idx], int(size*w_single.shape[1]), mode='wrap'), gaussian_filter1d(w_single[2][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')
ax[1].set_xlabel('PC 1')
ax[1].set_ylabel('PC 3')

sc = ax[2].scatter(w_single[1][idx], w_single[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[2].plot(gaussian_filter1d(w_single[1][idx], int(size*w_single.shape[1]), mode='wrap'), gaussian_filter1d(w_single[2][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')
ax[2].set_xlabel('PC 2')
ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].set_xlim(-z_lim, z_lim)
    ax[k].set_ylim(-z_lim, z_lim)

plt.colorbar(sc, ax=ax[-1], label='Angle (°)')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_170.png]]

#+begin_src jupyter-python
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

ax.plot(gaussian_filter1d(w_single[0][idx], int(size*w_single.shape[1]), mode='wrap'),
           gaussian_filter1d(w_single[1][idx], int(size*w_single.shape[1]), mode='wrap'),
           gaussian_filter1d(w_single[2][idx], int(size*w_single.shape[1]), mode='wrap'),
           rasterized=1, color='k')


sc = ax.scatter(w_single[0][idx],
                w_single[1][idx],
                w_single[2][idx],
                c=theta_norm[idx], cmap=cmap,
                rasterized=1, alpha=0.5)

ax.tick_params(axis='both', which='major', labelsize=12)  # change both x and y (and z in 3D)
ax.tick_params(axis='z', which='major', labelsize=12)     # for the z-axis specifically

ax.set_xlabel('PC 1', fontsize=12)
ax.set_ylabel('PC 2', fontsize=12)
ax.set_zlabel('PC 3', fontsize=12)

ax.set_xlim([-z_lim, z_lim])
ax.set_ylim([-z_lim, z_lim])
ax.set_zlim([-z_lim/10, z_lim/10])

ax.grid(False)

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_171.png]]

*** theta space

#+begin_src jupyter-python
nbins = 32
theta_bins = np.linspace(0, 360, nbins+1)
theta_digitized = np.digitize(theta_norm, theta_bins) - 1

# For each bin, average w[0], w[1], and w[2]
w_binned = np.zeros((3, nbins))
for i in range(nbins):
    mask = theta_digitized == i
    for j in range(3):
        w_binned[j, i] = np.mean(w_single[j][mask]) if np.any(mask) else np.nan

w_smooth = gaussian_filter1d(w_binned, sigma=1, axis=1, mode='wrap')
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for i, ax in enumerate(axs):
    ax.plot(theta_plot * 180 / np.pi, w_smooth[i], lw=2)
    ax.axhline(0, ls='--', color='k')
    ax.set_ylabel('Weights PC %d' % (i+1))
    ax.set_xlabel('Neuron Loc (°)')

axs[-1].axvline(45)
axs[-1].axvline(225)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_173.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

# Compute bin centers in degrees and radians
bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)  # for polar plots

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width), sharey=1)

# PC1 vs PC2
axs[0].plot(w_smooth[0], w_smooth[1], 'k-')
axs[0].set_xlabel('PC 1')
axs[0].set_ylabel('PC 2')

# PC1 vs PC3
axs[1].plot(w_smooth[0], w_smooth[2], 'k-')
axs[1].set_xlabel('PC 1')
axs[1].set_ylabel('PC 3')

# PC2 vs PC3
axs[2].plot(w_smooth[1], w_smooth[2], 'k-')
axs[2].set_xlabel('PC 2')
axs[2].set_ylabel('PC 3')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_174.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(1, 3, subplot_kw={'polar': True}, figsize=(n_comp*width, width))

for i, ax in enumerate(axs):
    ax.plot(theta_plot, w_smooth[i], lw=2)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_175.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Opto

#+begin_src jupyter-python
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM18', 'ChRM04', 'ChRM23']

traj_mouse = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_single.mouse==mouse) & (y_single.laser==0)
    X_idx = X_single[idx]
    y_idx = y_single[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i)  & (y_idx.tasks=='DPA') & (y_idx.performance==1) # & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_mouse.append(traj_)

traj_mouse = np.array(traj_mouse)
print(traj_mouse.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
traj_opto = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_single.mouse==mouse) & (y_single.laser==1)
    X_idx = X_single[idx]
    y_idx = y_single[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i) & (y_idx.tasks=='DPA') & (y_idx.performance==1) # & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_opto.append(traj_)

traj_opto = np.array(traj_opto)
print(traj_opto.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
fp_mouse = np.nanmean(traj_mouse[..., options['bins_LD']], -1)
fp_opto = np.nanmean(traj_opto[..., options['bins_LD']], -1)

print(fp_mouse.shape)

pc1 = fp_mouse[..., 0]
pc2 = fp_mouse[..., 1]

pc1_opto = fp_opto[..., 0]
pc2_opto = fp_opto[..., 1]
#+end_src

#+RESULTS:
: (6, 2, 3)

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*height, height), sharey=1)

for i in range(pc1.shape[0]):
    ax[0].scatter(pc1[i], pc2[i], label=options['mice'][i])
    ax[1].scatter(pc1_opto[i], pc2_opto[i], label=options['mice'][i])

for k in range(2):
    ax[k].axvline(0, color='k')
    ax[k].axhline(0, color='k')

    ax[k].set_xlabel('PC1')
    ax[k].set_ylabel('PC2')
# plt.legend(fontsize=12, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_180.png]]

#+begin_src jupyter-python
perf_off = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==0)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()

perf_on = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==1)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()

delta_dpa = (perf_on['performance'] - perf_off['performance']).values
print(perf_off.shape, perf_on.shape)
print(delta_dpa)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [-0.06737988 -0.0396021  -0.17252066 -0.17067931 -0.03733766 -0.05587748
:  -0.15799916 -0.12211829 -0.23317643 -0.12399194 -0.01176575 -0.01942686]

#+begin_src jupyter-python
perf_off = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==0)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()
perf_on = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==1)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()

delta_odr = (perf_on['odr_perf'] - perf_off['odr_perf']).values
print(perf_off.shape, perf_on.shape)
print(delta_odr)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [-0.0574187  -0.02349727 -0.08366935 -0.05637376  0.03311258 -0.03125
:  -0.06242079 -0.0412756  -0.03478145  0.03151151 -0.02957529  0.02112907]

#+begin_src jupyter-python
dPC1 = (pc1_opto - pc1).reshape(-1)
dPC2 = -(pc2_opto - pc2).reshape(-1)
print(dPC1.shape, dPC2.shape)
#+end_src

#+RESULTS:
: (12,) (12,)

#+begin_src jupyter-python
df = perf_off[['mouse', 'sample_odor']]
df['delta_dpa'] = delta_dpa
df['delta_odr'] = delta_odr

df['mouse'] = pd.Categorical(df['mouse'], categories=laser_mice, ordered=True)
df = df.sort_values('mouse')

df['delta_pc1'] = dPC1
df['delta_pc2'] = dPC2

# df = df[~df['mouse'].str.contains('ChR')]

print(df.head())
#+end_src

#+RESULTS:
:      mouse  sample_odor  delta_dpa  delta_odr  delta_pc1  delta_pc2
: 4  JawsM01          0.0  -0.037338   0.033113  -0.064185  -0.304679
: 5  JawsM01          1.0  -0.055877  -0.031250  -0.402270  -0.254520
: 6  JawsM06          0.0  -0.157999  -0.062421  -0.303530  -0.262344
: 7  JawsM06          1.0  -0.122118  -0.041276  -0.096990  -0.164270
: 8  JawsM12          0.0  -0.233176  -0.034781  -0.331445  -0.377275

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc1', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc1', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None, rasterized=1)

    corr, p_value = pearsonr(df_['delta_pc1'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC1")
    ax[i].set_ylabel("$\\Delta$ Performance")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")
# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_185.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc2', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc2', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None, rasterized=1)

    corr, p_value = pearsonr(df_['delta_pc2'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC2")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")

# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/dpca/figure_186.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:
: ec9f0c5f-ce23-4547-9231-52c6ae928fdc

** Binned Flow Fields
*** utils

#+begin_src jupyter-python
import numpy as np

def flow_field_from_trajectories(x, y, dt=1.0, bins=25, xrange=None, yrange=None,
                                 statistic="mean", min_count=1):
    """
    x, y: arrays (n_trials, n_time)
    dt: timestep
    bins: int or (nx, ny)
    xrange, yrange: (min, max); if None inferred from data
    statistic: "mean" (default). (You can extend to median easily.)
    Returns:
      xedges, yedges
      u, v: (nx, ny) average velocities in each spatial bin
      count: (nx, ny) number of samples per bin
    """
    x = np.asarray(x); y = np.asarray(y)
    n_trials, n_time = x.shape
    assert y.shape == x.shape

    # step velocities, shape (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # positions to bin (start of each step)
    xs = x[:, :-1]
    ys = y[:, :-1]

    if xrange is None:
        xrange = (xs.min(), xs.max())
    if yrange is None:
        yrange = (ys.min(), ys.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten all steps across trials/time
    xsf = xs.ravel()
    ysf = ys.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin index for each sample
    ix = np.searchsorted(xedges, xsf, side="right") - 1
    iy = np.searchsorted(yedges, ysf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate sums and counts
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    # mean velocity per bin
    ugrid = np.full((nx, ny), np.nan, dtype=float)
    vgrid = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    ugrid[mask] = usum[mask] / count[mask]
    vgrid[mask] = vsum[mask] / count[mask]

    return xedges, yedges, ugrid, vgrid, count


# Example usage:
# x, y = diffusion_2d(n_trials=200, n_time=2000, dt=0.01, D=0.5, seed=0)

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def flow_field_midpoint(x, y, dt=1.0, bins=25, xrange=None, yrange=None, min_count=1):
    """
    Mid-point binning: each velocity sample is assigned to the bin containing
    the segment midpoint ((x_t+x_{t+1})/2, (y_t+y_{t+1})/2).

    x, y: (n_trials, n_time)
    Returns: xedges, yedges, U, V, count with U,V,count shaped (nx, ny)
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape

    # step velocities (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # midpoints to bin (n_trials, n_time-1)
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    if xrange is None:
        xrange = (xm.min(), xm.max())
    if yrange is None:
        yrange = (ym.min(), ym.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten samples
    xf = xm.ravel()
    yf = ym.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin indices
    ix = np.searchsorted(xedges, xf, side="right") - 1
    iy = np.searchsorted(yedges, yf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    U = np.full((nx, ny), np.nan, dtype=float)
    V = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    U[mask] = usum[mask] / count[mask]
    V[mask] = vsum[mask] / count[mask]

    return xedges, yedges, U, V, count

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_speeds(x, y, dt=1.0):
    # step velocities at times t -> t+1
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]
    ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)  # [-pi, pi)

    # avoid r=0 issues
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    vr = (xs*vx + ys*vy) / r_safe
    omega = (xs*vy - ys*vx) / (r_safe**2)

    return r, theta, vr, omega

def bin_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nbin = len(edges) - 1
    valid = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(xvals)
    idx = idx[valid]
    yvals = yvals[valid]

    count = np.zeros(nbin, dtype=int)
    ysum  = np.zeros(nbin, dtype=float)
    np.add.at(count, idx, 1)
    np.add.at(ysum,  idx, yvals)

    ymean = np.full(nbin, np.nan, float)
    m = count >= min_count
    ymean[m] = ysum[m] / count[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, count
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_from_binned_uv(U, V, C, xedges, yedges, r_edges, th_edges,
                                 min_count_bin=1, min_count_1d=1):
    """
    Option (2): convert binned mean velocity field (U,V) into polar components at bin centers,
    then compute weighted 1D profiles vs radius r and angle theta using weights=C.

    Inputs:
      U,V,C: (nx, ny) arrays from flow_field_from_trajectories
      xedges,yedges: bin edges
      r_edges: 1D edges for radius bins
      th_edges: 1D edges for theta bins in [-pi, pi]
      min_count_bin: require C>=this to use a spatial bin at all
      min_count_1d: require total weight in a 1D bin >= this

    Returns:
      r_cent, vr_r, w_r
      th_cent, om_th, w_th
      plus (vr_grid, om_grid) for inspection
    """
    U = np.asarray(U); V = np.asarray(V); C = np.asarray(C)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    r = np.sqrt(Xc**2 + Yc**2)
    th = np.arctan2(Yc, Xc)
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    # polar components derived from mean flow vector in each spatial bin
    vr_grid = np.abs(Xc*U + Yc*V) / r_safe
    om_grid = np.abs(Xc*V - Yc*U) / (r_safe**2)   # angular speed dtheta/dt

    # flatten
    rf = r.ravel()
    thf = th.ravel()
    vrf = vr_grid.ravel()
    omf = om_grid.ravel()
    wf = C.ravel().astype(float)

    # keep only bins with enough samples and finite values
    valid = (wf >= min_count_bin) & np.isfinite(vrf) & np.isfinite(omf) & np.isfinite(rf) & np.isfinite(thf)
    rf, thf, vrf, omf, wf = rf[valid], thf[valid], vrf[valid], omf[valid], wf[valid]

    def weighted_bin_mean(xvals, yvals, wvals, edges, min_w=1.0):
        idx = np.searchsorted(edges, xvals, side="right") - 1
        nbin = len(edges) - 1
        ok = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(wvals)
        idx = idx[ok]; yvals = yvals[ok]; wvals = wvals[ok]

        wsum = np.zeros(nbin, float)
        ywsum = np.zeros(nbin, float)
        np.add.at(wsum, idx, wvals)
        np.add.at(ywsum, idx, wvals * yvals)

        ymean = np.full(nbin, np.nan, float)
        m = wsum >= min_w
        ymean[m] = ywsum[m] / wsum[m]
        centers = 0.5*(edges[:-1] + edges[1:])
        return centers, ymean, wsum

    r_cent, vr_r, w_r   = weighted_bin_mean(rf,  vrf, wf, r_edges,  min_w=min_count_1d)
    th_cent, om_th, w_th = weighted_bin_mean(thf, omf, wf, th_edges, min_w=min_count_1d)

    return r_cent, vr_r, w_r, th_cent, om_th, w_th, vr_grid, om_grid
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
from scipy.ndimage import gaussian_filter1d

def gaussian_filter1d_nan(x, sigma, mode="nearest", truncate=4.0):
    x = np.asarray(x, float)
    m = np.isfinite(x).astype(float)          # 1 where valid, 0 where NaN
    x0 = np.where(np.isfinite(x), x, 0.0)

    xs = gaussian_filter1d(x0, sigma=sigma, mode=mode, truncate=truncate)
    ms = gaussian_filter1d(m,  sigma=sigma, mode=mode, truncate=truncate)

    out = xs / ms
    out[ms == 0] = np.nan
    return out
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_coor, y_coor, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False, nbins=32):
    x = np.asarray(x_coor); y = np.asarray(y_coor)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    eps = 1e-12
    r_safe = np.maximum(r, eps)
    omega = (xs*vy - ys*vx) / (r_safe**2)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), nbins)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, nbins)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, np.abs(speed), r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, np.abs(speed), theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:

*** all mice

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
dt = 1
nbins = 32
min_count = 1  # choose based on how noisy you expect things to be
min_w=1
sigma_r, sigma_th= 5, 5
#+end_src

#+RESULTS:

**** cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
    X_delay = X_single[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    (r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)
mean_sp_r = np.nanmean(uniform_filter1d(np.array(sp_r_list), sigma_r), 0)

th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = np.nanmean(uniform_filter1d(np.array(sp_th_list), sigma_th), 0)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, mean_sp_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_sp_th, 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v\rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_196.png]]

**** binned cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
    X_delay = X_single[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=1, bins=nbins)

    speed = np.sqrt(U**2 + V**2)
    speed = np.where(C >= min_count, speed, np.nan)

    # bin centers -> R, TH
    xc = 0.5*(xedges[:-1] + xedges[1:])
    yc = 0.5*(yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
    R  = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)

    # speed vs radius (weighted by C)
    r_edges = np.linspace(0, np.nanmax(R), nbins)
    r_c, sp_r, cnt_r, wsum_r = weighted_binned_mean(R, speed, r_edges, weights=C,min_count=min_count, min_weight_1d=min_w)

    # speed vs theta (weighted by C)
    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, sp_th, cnt_th, wsum_th = weighted_binned_mean(TH, speed, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)

mean_sp_r = np.nanmean(sp_r_list, 0)
std_sp_r = np.nanstd(sp_r_list, 0) / np.sqrt(len(options['mice']))


th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = circmean(sp_th_list, -np.pi, np.pi, 0)
std_sp_th = np.nanstd(sp_th_list, 0) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
sigma_r = 5
sigma_th = 5


fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, uniform_filter1d(mean_sp_r, sigma_r), 'k')
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(mean_sp_th, sigma_th), 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v_{bin} \rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v_{bin}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_199.png]]

#+begin_src jupyter-python


#+end_src

#+RESULTS:

**** polar speeds

#+begin_src jupyter-python
r_list = []
avr_r_list, avr_th_list = [], []
avth_r_list, avth_th_list = [], []
aw_r_list, aw_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
    X_delay = X_single[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    # --- compute components
    r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

    # magnitudes
    avr  = np.abs(vr)
    avth = np.abs(vth)
    aw = np.abs(omega)

    # --- bin vs radius
    r_edges = np.linspace(0, np.nanmax(r), nbins)
    r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
    _,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
    _, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
    _,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
    _, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)

    r_c /= np.nanmax(r_c)

    m_avr_r = np.nanmean(avr_r)
    std_avr_r = np.nanstd(avr_r)
    avr_r = (avr_r - m_avr_r) / std_avr_r

    m_avr_th = np.nanmean(avr_th)
    std_avr_th = np.nanstd(avr_th)
    avr_th = (avr_th - m_avr_th) / std_avr_th

    m_avth_r = np.nanmean(avth_r)
    std_avth_r = np.nanstd(avth_r)
    avth_r = (avth_r - m_avth_r) / std_avth_r

    m_avth_th = np.nanmean(avth_th)
    std_avth_th = np.nanstd(avth_th)
    avth_th = (avth_th - m_avth_th) / std_avth_th

    m_aw_r = np.nanmean(aw_r)
    std_aw_r = np.nanstd(aw_r)
    aw_r = (aw_r - m_aw_r) / std_aw_r

    m_aw_th = np.nanmean(aw_th)
    std_aw_th = np.nanstd(aw_th)
    aw_th = (aw_th - m_aw_th) / std_aw_th

    r_list.append(r_c)
    th_list.append(th_c)

    avr_r_list.append(avr_r)
    avr_th_list.append(avr_th)

    avth_r_list.append(avth_r)
    avth_th_list.append(avth_th)

    aw_r_list.append(aw_r)
    aw_th_list.append(aw_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
r_list = pad_list(r_list, axis=0, max_len=None)

avr_r_list = pad_list(avr_r_list, axis=0, max_len=None)
avth_r_list = pad_list(avth_r_list, axis=0, max_len=None)
aw_r_list = pad_list(aw_r_list, axis=0, max_len=None)

mean_avr_r = np.nanmean(uniform_filter1d(avr_r_list, sigma_r, axis=-1), 0)
mean_avth_r = np.nanmean(uniform_filter1d(avth_r_list, sigma_r, axis=-1), 0)
mean_aw_r = np.nanmean(uniform_filter1d(aw_r_list, sigma_r, axis=-1), 0)

mean_avr_r = uniform_filter1d(np.nanmean(avr_r_list, 0), sigma_r)
mean_avth_r = uniform_filter1d(np.nanmean(avth_r_list, 0), sigma_r)
mean_awr = uniform_filter1d(circmean(aw_r_list, low=-np.pi, high=np.pi, axis=0), sigma_r)

std_avr_r = uniform_filter1d(np.nanstd(avr_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_avth_r = uniform_filter1d(np.nanstd(avth_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_aw_r = uniform_filter1d(np.nanstd(aw_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))

th_list = pad_list(th_list, axis=0, max_len=None)

avr_th_list = pad_list(avr_th_list, axis=0, max_len=None)
avth_th_list = pad_list(avth_th_list, axis=0, max_len=None)
aw_th_list = pad_list(aw_th_list, axis=0, max_len=None)

mean_avr_th = uniform_filter1d(np.mean(avr_th_list, 0), sigma_th, mode='wrap')
mean_avth_th = uniform_filter1d(np.mean(avth_th_list, axis=0), sigma_th, mode='wrap')
mean_aw_th = uniform_filter1d(circmean(aw_th_list, low=-np.pi, high=np.pi, axis=0), sigma_th, mode='wrap')

std_avr_th = uniform_filter1d(np.nanstd(avr_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_avth_th = uniform_filter1d(np.nanstd(avth_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_aw_th = uniform_filter1d(np.nanstd(aw_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avr_r = avr_r_list[i]
    avr_th = avr_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avr_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avr_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_avr_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avr_th, 'k')

ax[0].fill_between(r_c, mean_avr_r-std_avr_r, mean_avr_r+std_avr_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avr_th-std_avr_th, mean_avr_th+std_avr_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_r>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_203.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avth_r = avth_r_list[i]
    avth_th = avth_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avth_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avth_th, sigma_th), alpha=0.25)

ax[0].plot(r_c, mean_avth_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avth_th, 'k')

ax[0].fill_between(r_c, mean_avth_r-std_avth_r, mean_avth_r+std_avth_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avth_th-std_avth_th, mean_avth_th+std_avth_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_\\theta>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_204.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    aw_r = aw_r_list[i]
    aw_th = aw_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(aw_r, sigma_r), alpha=0.2)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(aw_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_aw_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_aw_th, 'k')

ax[0].fill_between(r_c, mean_aw_r-std_aw_r, mean_aw_r+std_aw_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_aw_th-std_aw_th, mean_aw_th+std_aw_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_205.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

*** data
**** data

 #+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse = -1

idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_single.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
dt = 1
nbins = 32
min_count = 1
min_w = 1
sigma_r, sigma_th= 15, 15
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d

idx = (y_single.tasks=='DPA') & (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
# idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])

X_delay = X_single[idx].copy()

x_coor = X_delay[:, 0]
y_coor = X_delay[:, 1]

# x_coor = X_delay[:, 0, :options['bins_ED'][-1]]
# y_coor = X_delay[:, 1, :options['bins_ED'][-1]]

x_coor = X_delay[:, 0, options['bins_DELAY']]
y_coor = X_delay[:, 1, options['bins_DELAY']]

print(x_coor.shape)
#+end_src

#+RESULTS:
: (96, 36)

**** binned flows

#+begin_src jupyter-python
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_coor, y_coor, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=dt, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1, sharex=1)

ax[0].plot(x_coor.T, y_coor.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


# pcm = ax[2].pcolormesh(
#     xedges, yedges, speed.T, shading="auto",
#     norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
# )

# cbar = fig.colorbar(pcm, ax=ax[2])
# cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.2)
# ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

# ax[0].set_xlim([-6, 6])
# ax[0].set_ylim([-4, 4])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_212.png]]


#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(r)$')

ax[1].plot(th_c * 180 / np.pi, sp_th)
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_214.png]]


#+begin_src jupyter-python
import numpy as np

# per (x,y) bin:
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].plot(r_c, uniform_filter1d(speed_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].plot(th_c, uniform_filter1d(speed_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_216.png]]

#+begin_src jupyter-python
import numpy as np

def polar_components_from_steps(x, y, dt=1.0, eps=1e-12):
    vx = (x[:,1:] - x[:,:-1]) / dt
    vy = (y[:,1:] - y[:,:-1]) / dt
    xs = x[:,:-1]; ys = y[:,:-1]
    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)
    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe
    return r, th, vr, vth

def bin2d_mean(r, th, val, r_edges, th_edges, min_count=50):
    r = r.ravel(); th = th.ravel(); val = val.ravel()
    ir = np.searchsorted(r_edges, r, side="right") - 1
    it = np.searchsorted(th_edges, th, side="right") - 1
    nr = len(r_edges)-1; nt = len(th_edges)-1
    ok = (ir>=0)&(ir<nr)&(it>=0)&(it<nt)&np.isfinite(val)
    ir = ir[ok]; it = it[ok]; val = val[ok]

    cnt = np.zeros((nr, nt), int)
    s   = np.zeros((nr, nt), float)
    np.add.at(cnt, (ir, it), 1)
    np.add.at(s,   (ir, it), val)

    mean = np.full((nr, nt), np.nan)
    m = cnt >= min_count
    mean[m] = s[m] / cnt[m]
    return mean, cnt

def angular_anisotropy(mean_rt, eps=1e-12):
    # mean_rt: (nr, nt) array of mean quantity vs (r,theta)
    mu = np.nanmean(mean_rt, axis=1)          # mean over theta for each r
    sd = np.nanstd(mean_rt, axis=1)           # std over theta for each r
    A = sd / (np.abs(mu) + eps)               # relative angular modulation
    return A, mu, sd

# Example usage:
r, th, vr, vth = polar_components_from_steps(x_coor, y_coor, dt=dt)
r_edges  = np.linspace(0, np.nanmax(r), nbins)
th_edges = np.linspace(-np.pi, np.pi, nbins)
vr_rt, vr_cnt = bin2d_mean(r, th, np.abs(vr), r_edges, th_edges, min_count=min_w)
A_vr, vr_mu, vr_sd = angular_anisotropy(vr_rt)
vth_rt, vth_cnt = bin2d_mean(r, th, np.abs(vth), r_edges, th_edges, min_count=min_w)
#+end_src

#+RESULTS:

**** counts

 #+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

r_cent  = 0.5*(r_edges[:-1] + r_edges[1:])
th_cent = 0.5*(th_edges[:-1] + th_edges[1:])

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_rt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_rt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_218.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_cnt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_cnt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_219.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

**** speeds

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c * 180 / np.pi, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_222.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c* 180 / np.pi, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c* 180 / np.pi, uniform_filter1d(aw_th, sigma_th, mode='wrap'), color='k')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_223.png]]

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def binned_velocity_and_speed(
    x, y, dt,
    xedges, yedges,
    min_count=1,
    nan_empty=True,
):
    """
    Compute per-bin:
      U,V  = mean(vx), mean(vy)               (mean velocity components)
      S    = mean(speed) = mean(sqrt(vx^2+vy^2))  (mean speed; NOT sqrt(U^2+V^2))
      C    = counts per bin (# velocity samples falling in bin)

    x,y: arrays (n_trials, n_time)
    dt:  scalar timestep
    xedges,yedges: bin edges
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape
    if n_time < 2:
        raise ValueError("Need at least 2 timepoints per trial to compute velocity.")

    # per-sample velocities (n_trials, n_time-1)
    vx = np.diff(x, axis=1) / dt
    vy = np.diff(y, axis=1) / dt
    sp = np.sqrt(vx * vx + vy * vy)

    # position associated with each velocity sample: midpoint of segment
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    # flatten all samples
    xm = xm.ravel()
    ym = ym.ravel()
    vx = vx.ravel()
    vy = vy.ravel()
    sp = sp.ravel()

    # keep finite
    ok = np.isfinite(xm) & np.isfinite(ym) & np.isfinite(vx) & np.isfinite(vy) & np.isfinite(sp)
    xm, ym, vx, vy, sp = xm[ok], ym[ok], vx[ok], vy[ok], sp[ok]

    nx = len(xedges) - 1
    ny = len(yedges) - 1

    # bin indices
    ix = np.searchsorted(xedges, xm, side="right") - 1
    iy = np.searchsorted(yedges, ym, side="right") - 1
    inside = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)

    ix, iy = ix[inside], iy[inside]
    vx, vy, sp = vx[inside], vy[inside], sp[inside]

    # accumulate sums and counts
    C = np.zeros((nx, ny), dtype=np.int64)
    sum_vx = np.zeros((nx, ny), dtype=float)
    sum_vy = np.zeros((nx, ny), dtype=float)
    sum_sp = np.zeros((nx, ny), dtype=float)

    np.add.at(C, (ix, iy), 1)
    np.add.at(sum_vx, (ix, iy), vx)
    np.add.at(sum_vy, (ix, iy), vy)
    np.add.at(sum_sp, (ix, iy), sp)

    # means
    with np.errstate(invalid="ignore", divide="ignore"):
        U = sum_vx / C
        V = sum_vy / C
        S = sum_sp / C  # <-- mean speed per bin (the "fixed" part)

    if nan_empty:
        mask = C >= min_count
        U = np.where(mask, U, np.nan)
        V = np.where(mask, V, np.nan)
        S = np.where(mask, S, np.nan)

    return U, V, S, C


def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12, mask_r0=None):
    """
    Convert mean velocity components (U,V) defined at bin centers to polar components.
    Optionally mask low-count bins and optionally mask a central disk (mask_r0).
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    mask = np.isfinite(U) & np.isfinite(V)
    if C is not None:
        mask &= (C >= min_count)
    if mask_r0 is not None:
        mask &= (R >= mask_r0)

    Vr    = np.where(mask, Vr, np.nan)
    Vth   = np.where(mask, Vth, np.nan)
    Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega


# -------------------------
# Example usage:
# U,V are mean velocity components; S is mean speed (recommended for "speed map")
# -------------------------
# U, V, S, C = binned_velocity_and_speed(x, y, dt, xedges, yedges, min_count=10)
# Xc, Yc, R, TH, Vr, Vth, Omega = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=10, mask_r0=1e-6)
# speed_of_mean_flow = np.sqrt(U**2 + V**2)   # different quantity than S
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12):
    """
    xedges, yedges: bin edges (nx+1), (ny+1)
    U, V: mean velocity per bin, shape (nx, ny)
    C: counts per bin, shape (nx, ny) (optional but recommended)
    Returns:
      Xc, Yc, R, TH (nx, ny)
      Vr, Vth, Omega (nx, ny) with NaNs where invalid/low count
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    # mask out empty/low-sample bins
    if C is not None:
        mask = (C >= min_count) & np.isfinite(U) & np.isfinite(V)
        Vr    = np.where(mask, Vr, np.nan)
        Vth   = np.where(mask, Vth, np.nan)
        Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega
#+end_src

#+RESULTS:

#+begin_src jupyter-python
min_w = 1
U, V, S, C = binned_velocity_and_speed(x_coor, y_coor, dt, xedges, yedges, min_count=1)
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=1)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")


ax[1].plot(th_c * 180 / np.pi, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_227.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c * 180 / np.pi, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle θ (°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_228.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:
