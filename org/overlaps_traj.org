#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session overlaps :kernel dual_data :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Imports

#+begin_src ipython
  import warnings
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd
  import seaborn as sns

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
  from src.decode.bump import circcvl
  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator #.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_.named_steps["model"]

    norm_w = np.linalg.norm(coef) + 1e-6

    # try:
    #     X_test = clf.named_steps["scaler"].transform(X_test)
    # except:
    #     pass

    # try:
    #     X_test = clf.named_steps["pca"].transform(X_test)
    # except:
    #     pass

    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / norm_w # / X_test.shape[1] * 1000
        # dot_product = (2*y_test -1) * clf.named_steps["model"].decision_function(X_test)
        # dot_product = (2*y_test -1) * clf.decision_function(X_test) / norm_w
    else:
        # dot_product = clf.decision_function(X_test) / norm_w
        # dot_product = clf.named_steps["model"].decision_function(X_test)
        dot_product = np.dot(X_test, coef) / norm_w # / X_test.shape[1] * 1000

    return np.nanmean(dot_product)
#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:
#+begin_example
During startup - Warning messages:
1: package ‘methods’ was built under R version 4.4.3
2: package ‘datasets’ was built under R version 4.4.3
3: package ‘utils’ was built under R version 4.4.3
4: package ‘grDevices’ was built under R version 4.4.3
5: package ‘graphics’ was built under R version 4.4.3
6: package ‘stats’ was built under R version 4.4.3
R[write to console]: In addition:
R[write to console]: Warning message:
R[write to console]: package ‘tools’ was built under R version 4.4.3
#+end_example

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0, ls='-', label=None, colors=None, cis=None, **kwargs):
    if day=='all':
        df_ = df.copy()
    else:
        df_ = df[df.day == day].copy()

    if colors is None:
        colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        if label is None:
            ax.plot(time_points, mean_overlaps[task], label=f"{task}", color=colors[i], ls=ls, **kwargs)
            # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)
        else:
            ax.plot(time_points, mean_overlaps[task], label=label, color=colors[i], ls=ls, **kwargs)

        if cis is not None:
            ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')
    ax.legend(fontsize=10)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlaps_traj(df, df2, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0, ls='-', label=None, colors=None, cis=None, **kwargs):
    if day=='all':
        df_ = df.copy()
        df2_ = df2.copy()
    else:
        df_ = df[df.day == day].copy()
        df2_ = df[df.day == day].copy()

    if colors is None:
        colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
        mean_overlaps2 = df2_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
        mean_overlaps2 = df2_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        if label is None:
            ax.plot(time_points, mean_overlaps[task], label=f"{task}", color=colors[i], ls=ls, **kwargs)
            # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)
        else:
            ax.plot(time_points, mean_overlaps[task], label=label, color=colors[i], ls=ls, **kwargs)

        if cis is not None:
            ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')
    ax.legend(fontsize=10)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_mat(X, ax, vmin=-1, vmax=1, palette='bwr'):
  im = ax.imshow(
    X,
    interpolation=None,
    origin="lower",
    cmap=palette,
    extent=[0, 14, 0, 14],
    vmin=vmin,
    vmax=vmax,
  )

  add_vdashed(ax)
  ax.set_xlim([2, 12])
  ax.set_xticks([2, 4, 6, 8, 10, 12])
  ax.set_ylim([2, 12])
  ax.set_yticks([2, 4, 6, 8, 10, 12])

  ax.set_xlabel("Testing Time (s)")
  ax.set_ylabel("Training Time (s)")
  return im
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt

def add_vdashed(ax=None, mouse=""):
    # Define time intervals
    t_STIM = [2, 3]
    t_DIST = [4.5, 5.5]
    t_CUE = [6.5, 7]
    t_TEST = [9, 10]

    # Add vertical dashed lines and text labels for each interval
    if ax is not None:
        # Draw vertical lines
        for t in [t_STIM, t_DIST, t_TEST]:
            ax.axvline(x=t[0], linestyle='--', color='k', lw=2)
            ax.axvline(x=t[1], linestyle='--', color='k', lw=2)

            ax.axhline(y=t[0], linestyle='--', color='k', lw=2)
            ax.axhline(y=t[1], linestyle='--', color='k', lw=2)

        # Add text labels at the middle of each interval
        ax.text((t_STIM[0] + t_STIM[1]) / 2, 12.5, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_DIST[0] + t_DIST[1]) / 2, 12.5, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        # ax.text((t_CUE[0] + t_CUE[1]) / 2, 12.5, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_TEST[0] + t_TEST[1]) / 2, 12.5, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)

        ax.text(12.5, (t_STIM[0] + t_STIM[1]) / 2, 'STIM', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        ax.text(12.5, (t_DIST[0] + t_DIST[1]) / 2, 'DIST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical',fontsize=16)
        # ax.text(12.5, (t_CUE[0] + t_CUE[1]) / 2, 'CUE', color='black',
        #         horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)
        ax.text(12.5, (t_TEST[0] + t_TEST[1]) / 2, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', rotation='vertical', fontsize=16)

#+end_src

#+RESULTS:

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title=''):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  old_mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']

  # mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
  mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
  # mice = ['ACCM03', 'ACCM04']
  # mice = Jaws_mice
  # mice = ['JawsM15']

  tasks = ['DPA', 'DualGo', 'DualNoGo']

  kwargs = {
      'mice': mice,
      'mouse': mice[0], 'laser': 0,
      'trials': 'correct', 'reload': 0, 'data_type': 'df',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': 0, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 5, 'n_repeats': 10,
      'class_weight': 0,
      'multilabel': 0,
      'mne_estimator':'generalizing', # sliding or generalizing
      'n_jobs': 64,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  safe_f1 = make_scorer(safe_f1_score, needs_proba=True)

  dum = 'overlaps_loocv_correct_l1'
  dum = 'overlaps_loocv_sub_l1_robust'

  # dum = 'overlaps_loocv_laser_only'
  # dum = 'overlaps_loocv_laser_all_l2'
  # options['cv_B'] = True
  # dum = 'overlaps_all_loocv'
#+end_src

#+RESULTS:

* Decoding vs days
** utils

#+begin_src ipython
def decode_axis(model, **options):
    new_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'ChRM23']
    options['NEW_DATA'] = 0

    dfs = []
    for mouse in options['mice']:
        df_mouse = []
        options['mouse'] = mouse
        options = set_options(**options)
        days = options['days']

        if mouse in new_mice:
            options['reload'] = 0
            options['NEW_DATA'] = 1
        else:
            options['reload'] = 0
            options['NEW_DATA'] = 0

        for task in ['all']:
            options['task'] = task

            for day in days:
                options['day'] = day

                if 0==0:
                # try:
                    overlaps = get_classification(model, RETURN='df_scores', **options)
                    options['reload'] = 0
                    df_mouse.append(overlaps)
                # except:
                #     pass

        df_mouse = pd.concat(df_mouse)
        df_mouse['mouse'] = mouse
        dfs.append(df_mouse)

    return pd.concat(dfs)
    #+end_src

#+RESULTS:

#+begin_src ipython
def save_overlaps(df, marg, dum, **options):
    if len(options['days'])>3:
        name = 'df_%s_%s_days' % (marg, dum)
    elif len(options['days'])==2:
        name = 'df_%s_%s_early_late' % (marg, dum)
    else:
        name = 'df_%s_%s' % (marg, dum)

    if len(mice)==1:
        pkl_save(df, '%s' % name, path="/storage/leon/dual_task/data/%s/overlaps" % options['mouse'])
    elif len(mice)==2:
        pkl_save(df, '%s' % name, path="/storage/leon/dual_task/data/mice/overlaps_ACC")
    else:
        pkl_save(df, '%s' % name, path="/storage/leon/dual_task/data/mice/overlaps")
#+end_src

#+RESULTS:

** run

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
from src.torch.stratified_subsample_kfold import ChoiceLimitedStratifiedKFold
#+end_src

#+RESULTS:

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=64, fit_intercept=True)
params = {'model__C': np.logspace(-3, 3, 10)}

# net = LogisticRegression(penalty='elasticnet', solver='saga', n_jobs=64, class_weight='balanced', fit_intercept=True)
# params = {'model__C': np.logspace(-3, 3, 10), 'model__l1_ratio': np.linspace(0, 1, 10)}

options['hp_scoring'] = lambda estimator, X_test, y_test: overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1)
options['scoring'] = overlaps_scorer

options['n_jobs'] = -1
options['reload'] = 0

options['cv'] = LeaveOneOut()
options['verbose'] = 1

model = ClassificationCV(net, params, **options)
#+end_src

#+RESULTS:
: PCA False 0

#+begin_src ipython
options['features'] = 'sample'
options['cv'] = ChoiceLimitedStratifiedKFold(n_splits=5, stratify_col=options['features']+'_odor')
options['epochs'] = ['ED']
options['T_WINDOW'] = 0.0

options = set_options(**options)
df_sample = decode_axis(model, **options)
 #+end_src

#+RESULTS:
#+begin_example
Loading files from /storage/leon/dual_task/data/ACCM03
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
y_labels (220, 16) ['DPA' 'DualGo' 'DualNoGo'] (220,)
X (220, 361, 84) nans 0.0 y (220,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 21s
{'model__C': 0.09999999999999999}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc9df046890>
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 51s
scores (220, 84, 84) 0.5907769327116394
df_A (220, 17) scores (220, 7056) labels (220, 16)
df (220, 17)
Loading files from /storage/leon/dual_task/data/ACCM03
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
y_labels (501, 16) ['DualNoGo' 'DualGo' 'DPA'] (501,)
X (501, 361, 84) nans 0.0 y (501,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 23s
{'model__C': 10.0}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc9df046890>
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 6s
scores (501, 84, 84) 0.9249393414584473
df_A (501, 17) scores (501, 7056) labels (501, 16)
df (501, 17)
Loading files from /storage/leon/dual_task/data/ACCM04
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
y_labels (209, 16) ['DualNoGo' 'DPA' 'DualGo'] (209,)
X (209, 113, 84) nans 0.0 y (209,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 23s
{'model__C': 0.09999999999999999}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc9df046890>
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 27s
scores (209, 84, 84) -0.16507918336467026
df_A (209, 17) scores (209, 7056) labels (209, 16)
df (209, 17)
Loading files from /storage/leon/dual_task/data/ACCM04
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
y_labels (406, 16) ['DPA' 'DualNoGo' 'DualGo'] (406,)
X (406, 113, 84) nans 0.0 y (406,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 26s
{'model__C': 0.021544346900318832}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc9df046890>
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 53s
scores (406, 84, 84) -0.3829189478766102
df_A (406, 17) scores (406, 7056) labels (406, 16)
df (406, 17)
#+end_example

#+begin_src ipython
print(df_sample.head())
#+end_src

#+RESULTS:
#+begin_example
   index  sample_odor  test_odor     response     tasks  laser    day  \
0      2          0.0        0.0  correct_hit       DPA    0.0  first
1      6          0.0        0.0  correct_hit       DPA    0.0  first
2      9          0.0        0.0  correct_hit    DualGo    0.0  first
3     10          0.0        0.0  correct_hit    DualGo    0.0  first
4     12          0.0        0.0  correct_hit  DualNoGo    0.0  first

   dist_odor  choice  performance  pair  odor_pair  odr_response  odr_choice  \
0        NaN     1.0            1     1        0.0             0         NaN
1        NaN     1.0            1     1        0.0             0         NaN
2        0.0     1.0            1     1        0.0             1         1.0
3        0.0     1.0            1     1        0.0             1         1.0
4        1.0     1.0            1     1        0.0             4         0.0

   odr_perf  idx                                           overlaps   mouse
0       NaN    2  [2.784743186497345, 2.3729780301369825, 3.6623...  ACCM03
1       NaN    6  [1.2194357528871906, 1.4754688762679082, 1.267...  ACCM03
2       1.0    9  [-0.4339977652544159, -1.005626043763314, -0.9...  ACCM03
3       1.0   10  [-0.08612670781397293, -1.055910987105277, 0.0...  ACCM03
4       1.0   12  [1.717376235396499, 2.7180987729316333, 0.9639...  ACCM03
#+end_example

#+begin_src ipython
df_sample['performance'] = df_sample['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_sample['pair'] = df_sample['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
save_overlaps(df_sample, 'sample', dum, **options)
#+end_src

#+RESULTS:
: saving to /storage/leon/dual_task/data/mice/overlaps/df_sample_overlaps_loocv_sub_l1_robust_early_late.pkl

#+begin_src ipython
options['features'] = 'test'
options['cv'] = ChoiceLimitedStratifiedKFold(n_splits=5, stratify_col=options['features']+'_odor')
options['epochs'] = ['TEST']

options['T_WINDOW'] = 0.5
options = set_options(**options)

df_test = decode_axis(model, **options)

df_test['performance'] = df_test['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_test['pair'] = df_test['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
save_overlaps(df_test, 'test', dum, **options)
#+end_src

#+RESULTS:
#+begin_example
Loading files from /storage/leon/dual_task/data/ACCM03
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES test TASK all TRIALS correct DAYS first LASER 0
y_labels (220, 16) ['DPA' 'DualGo' 'DualNoGo'] (220,)
X (220, 361, 84) nans 0.0 y (220,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 20s
{'model__C': 0.021544346900318832}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc91e3615d0>
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 50s
scores (220, 84, 84) -0.48696135108989097
df_A (220, 17) scores (220, 7056) labels (220, 16)
df (220, 17)
Loading files from /storage/leon/dual_task/data/ACCM03
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES test TASK all TRIALS correct DAYS last LASER 0
y_labels (501, 16) ['DualNoGo' 'DualGo' 'DPA'] (501,)
X (501, 361, 84) nans 0.0 y (501,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 21s
{'model__C': 0.021544346900318832}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc91e3615d0>
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 7s
scores (501, 84, 84) 0.47001212563830114
df_A (501, 17) scores (501, 7056) labels (501, 16)
df (501, 17)
Loading files from /storage/leon/dual_task/data/ACCM04
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES test TASK all TRIALS correct DAYS first LASER 0
y_labels (209, 16) ['DualNoGo' 'DPA' 'DualGo'] (209,)
X (209, 113, 84) nans 0.0 y (209,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 20s
{'model__C': 0.021544346900318832}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc91e3615d0>
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 24s
scores (209, 84, 84) -0.2651300525308849
df_A (209, 17) scores (209, 7056) labels (209, 16)
df (209, 17)
Loading files from /storage/leon/dual_task/data/ACCM04
PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR True
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES test TASK all TRIALS correct DAYS last LASER 0
y_labels (406, 16) ['DPA' 'DualNoGo' 'DualGo'] (406,)
X (406, 113, 84) nans 0.0 y (406,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 20s
{'model__C': 0.004641588833612777}
<src.torch.stratified_subsample_kfold.ChoiceLimitedStratifiedKFold object at 0x7fc91e3615d0>
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 49s
scores (406, 84, 84) -0.21089571355905873
df_A (406, 17) scores (406, 7056) labels (406, 16)
df (406, 17)
saving to /storage/leon/dual_task/data/mice/overlaps_ACC/df_test_overlaps_loocv_sub_l1_robust_ACC_early_late.pkl
#+end_example


#+begin_src ipython
options['laser'] = 0
options['trials'] = 'all'
# options['cv'] = ChoiceLimitedStratifiedKFold(n_splits=5, stratify_col=options['features'])
options['features'] = 'choice'
options['epochs'] = ['TEST']

options['T_WINDOW'] = 0.5
options = set_options(**options)

df_choice = decode_axis(model, **options)
#+end_src

#+RESULTS:
#+begin_example
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 15) ['DualGo' 'DPA' 'DualNoGo'] (192,)
X (192, 184, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 13s
{'model__C': 1000.0}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 21s
scores (192, 84, 84) 0.003213022415781118
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (192, 15) ['DPA' 'DualGo' 'DualNoGo'] (192,)
X (192, 184, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 15s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 23s
scores (192, 84, 84) -0.036215365402513
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 15) ['DPA' 'DualNoGo' 'DualGo'] (192,)
X (192, 201, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 16s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 24s
scores (192, 84, 84) 0.02153327126736581
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (384, 15) ['DPA' 'DualNoGo' 'DualGo'] (384,)
X (384, 201, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 16s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 9s
scores (384, 84, 84) 0.023598981357823484
df_A (384, 16) scores (384, 7056) labels (384, 15)
df (384, 16)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 15) ['DPA' 'DualGo' 'DualNoGo'] (192,)
X (192, 423, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 16s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 42s
scores (192, 84, 84) 0.04232369389578304
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (288, 15) ['DualNoGo' 'DualGo' 'DPA'] (288,)
X (288, 423, 84) nans 0.0 y (288,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 18s
scores (288, 84, 84) 0.007525898716754195
df_A (288, 16) scores (288, 7056) labels (288, 15)
df (288, 16)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 16) ['DualGo' 'DPA' 'DualNoGo'] (192,)
X (192, 693, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 0s
scores (192, 84, 84) 0.18593582739418602
df_A (192, 17) scores (192, 7056) labels (192, 16)
df (192, 17)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (384, 16) ['DPA' 'DualGo' 'DualNoGo'] (384,)
X (384, 693, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 21s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 21s
scores (384, 84, 84) 0.03414236925361378
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 16) ['DPA' 'DualNoGo' 'DualGo'] (192,)
X (192, 444, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 43s
scores (192, 84, 84) 0.16340695921847886
df_A (192, 17) scores (192, 7056) labels (192, 16)
df (192, 17)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (384, 16) ['DPA' 'DualGo' 'DualNoGo'] (384,)
X (384, 444, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 16s
scores (384, 84, 84) 0.12211036071691493
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 16) ['DualNoGo' 'DualGo' 'DPA'] (192,)
X (192, 668, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 58s
scores (192, 84, 84) 0.08250728139284026
df_A (192, 17) scores (192, 7056) labels (192, 16)
df (192, 17)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (384, 16) ['DPA' 'DualGo' 'DualNoGo'] (384,)
X (384, 668, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 17s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 15s
scores (384, 84, 84) 0.04098062066055788
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 0
y_labels (192, 15) ['DualGo' 'DPA' 'DualNoGo'] (192,)
X (192, 232, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 29s
scores (192, 84, 84) -0.09202233820224553
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 0
y_labels (288, 15) ['DualNoGo' 'DualGo' 'DPA'] (288,)
X (288, 232, 84) nans 0.0 y (288,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 53s
scores (288, 84, 84) 0.08374256233451655
df_A (288, 16) scores (288, 7056) labels (288, 15)
df (288, 16)
#+end_example

#+begin_src ipython
dum = 'overlaps_loocv_l1'
df_choice['performance'] = df_choice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_choice['pair'] = df_choice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
save_overlaps(df_choice, 'choice', dum, **options)
#+end_src

#+RESULTS:
: saving to /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_l1_early_late.pkl

#+begin_src ipython
options['laser'] = 1
# options['cv'] = ChoiceLimitedStratifiedKFold(n_splits=5, stratify_col=options['features'])
options['trials'] = 'all'
options['features'] = 'choice'
options['epochs'] = ['TEST']

options['T_WINDOW'] = 0.5
options = set_options(**options)

df_choice_on = decode_axis(model, **options)
#+end_src

#+RESULTS:
#+begin_example
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 15) ['DualNoGo' 'DPA' 'DualGo'] (192,)
X (192, 184, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 15s
{'model__C': 1000.0}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 22s
scores (192, 84, 84) 0.06765882852980697
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (192, 15) ['DPA' 'DualNoGo' 'DualGo'] (192,)
X (192, 184, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 15s
{'model__C': 2.154434690031882}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 23s
scores (192, 84, 84) -0.007094457306839168
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 15) ['DualGo' 'DPA' 'DualNoGo'] (192,)
X (192, 201, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 15s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 24s
scores (192, 84, 84) 0.06367289673783395
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (384, 15) ['DualGo' 'DPA' 'DualNoGo'] (384,)
X (384, 201, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 16s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 9s
scores (384, 84, 84) 0.044999578243767345
df_A (384, 16) scores (384, 7056) labels (384, 15)
df (384, 16)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 15) ['DPA' 'DualGo' 'DualNoGo'] (192,)
X (192, 423, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 16s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 42s
scores (192, 84, 84) 0.010077710810578852
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (288, 15) ['DualGo' 'DualNoGo' 'DPA'] (288,)
X (288, 423, 84) nans 0.0 y (288,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 1m 17s
scores (288, 84, 84) 0.0006109952512366323
df_A (288, 16) scores (288, 7056) labels (288, 15)
df (288, 16)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 16) ['DualNoGo' 'DPA' 'DualGo'] (192,)
X (192, 693, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 16s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 58s
scores (192, 84, 84) 0.06253745038424847
df_A (192, 17) scores (192, 7056) labels (192, 16)
df (192, 17)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (384, 16) ['DualNoGo' 'DualGo' 'DPA'] (384,)
X (384, 693, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 21s
scores (384, 84, 84) -0.07445597219585186
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 16) ['DPA' 'DualNoGo' 'DualGo'] (192,)
X (192, 444, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 17s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 43s
scores (192, 84, 84) -0.04371126752934534
df_A (192, 17) scores (192, 7056) labels (192, 16)
df (192, 17)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (384, 16) ['DPA' 'DualGo' 'DualNoGo'] (384,)
X (384, 444, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 17s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 2m 17s
scores (384, 84, 84) 0.01821334055115838
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 16) ['DualNoGo' 'DualGo' 'DPA'] (192,)
X (192, 668, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 21s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 59s
scores (192, 84, 84) 0.0337400952500146
df_A (192, 17) scores (192, 7056) labels (192, 16)
df (192, 17)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (384, 16) ['DualGo' 'DPA' 'DualNoGo'] (384,)
X (384, 668, 84) nans 0.0 y (384,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 19s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 3m 16s
scores (384, 84, 84) 0.08511372564914381
df_A (384, 17) scores (384, 7056) labels (384, 16)
df (384, 17)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS first LASER 1
y_labels (192, 15) ['DualNoGo' 'DualGo' 'DPA'] (192,)
X (192, 232, 84) nans 0.0 y (192,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 18s
{'model__C': 0.4641588833612777}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 30s
scores (192, 84, 84) -0.0818927376558715
df_A (192, 16) scores (192, 7056) labels (192, 15)
df (192, 16)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS all DAYS last LASER 1
y_labels (288, 15) ['DualGo' 'DualNoGo' 'DPA'] (288,)
X (288, 232, 84) nans 0.0 y (288,) [0. 1.]
Fitting hyperparameters on single epoch ...
Elapsed (with compilation) = 0h 0m 17s
{'model__C': 0.09999999999999999}
LeaveOneOut()
Computing cv scores ...
Elapsed (with compilation) = 0h 0m 50s
scores (288, 84, 84) 0.11939183020847478
df_A (288, 16) scores (288, 7056) labels (288, 15)
df (288, 16)
#+end_example


#+begin_src ipython
df_choice_on['performance'] = df_choice_on['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_choice_on['pair'] = df_choice_on['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
save_overlaps(df_choice_on, 'choice', dum + '_laser', **options)
#+end_src

#+RESULTS:
: saving to /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_l1_laser_early_late.pkl

#+begin_src ipython
df_choice_on.laser.unique()
#+end_src

#+RESULTS:
: array([1.])

#+begin_src ipython

#+end_src

#+RESULTS:

* Data
** utils

#+begin_src ipython
def load_data(marg, dum, **options):
    if len(options['days'])>3:
        name = 'df_%s_%s_days' % (marg, dum)
    elif len(options['days'])==2:
        name = 'df_%s_%s_early_late' % (marg, dum)
    else:
        name = 'df_%s_%s' % (marg, dum)

    if len(options['mice'])==1:
        df = pkl_load('%s' % name, path="/storage/leon/dual_task/data/%s/overlaps" % options['mouse'])
    elif len(options['mice'])==2:
        df = pkl_load('%s' % name, path="/storage/leon/dual_task/data/mice/overlaps_ACC")
    else:
        df = pkl_load('%s' % name, path="/storage/leon/dual_task/data/mice/overlaps")#.reset_index()

    return df
#+end_src

#+RESULTS:

#+begin_src ipython
def get_avg_overlaps(df, epoch_list, **options):

        df['overlaps_diag'] = df['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))

        features = options['features']
        if (options['features']=='sample') or (options['features']=='test'):
            features +='_odor'

        if options['features'] =='distractor':
            features = 'dist_odor'

        df['sign_overlaps_diag'] = (2.0 * df[features] -1 )  * df['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))

        for epoch2 in epoch_list:
                options['epochs'] = [epoch2]
                df['overlaps_diag_%s' % epoch2] = df['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
                df['sign_overlaps_diag_%s' % epoch2] = df['sign_overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))

        for epoch in epoch_list:
                options['epochs'] = [epoch]
                df['overlaps_%s' % epoch] = df['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
                df['sign_overlaps_%s' % epoch] = (2.0 * df[features] -1 ) * df['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))

                for epoch2 in epoch_list:
                        options['epochs'] = [epoch2]
                        df['overlaps_%s_%s' % (epoch, epoch2)] = df['overlaps_%s' % epoch].apply(lambda x: avg_epochs(np.array(x), **options))
                        df['sign_overlaps_%s_%s' % (epoch, epoch2)] = df['sign_overlaps_%s' % epoch].apply(lambda x: avg_epochs(np.array(x), **options))


        return df
#+end_src

#+RESULTS:

** run
*** load

#+begin_src ipython
options['T_WINDOW'] = 0.5
options = set_options(**options)
#+end_src

#+RESULTS:

#+begin_src ipython
dum = 'overlaps_loocv_correct_l1'
print(dum)
#+end_src

#+RESULTS:
: overlaps_loocv_correct_l1

#+begin_src ipython
options['features'] = 'sample'
df_sample = load_data('sample', dum, **options)
df_sample = get_avg_overlaps(df_sample, ['ED', 'MD', 'LD', 'TEST'], **options)
#+end_src

#+RESULTS:
: loading from /storage/leon/dual_task/data/mice/overlaps/df_sample_overlaps_loocv_correct_l1_early_late.pkl


#+begin_src ipython
options['features'] = 'choice'
df_choice = load_data('choice', dum, **options)
# df_choice = load_data('choice', 'overlaps_loocv_sub_0.5', **options)
df_choice = get_avg_overlaps(df_choice,  ['ED', 'MD', 'LD', 'TEST', 'CHOICE'], **options)
#+end_src

#+RESULTS:
: loading from /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_l1_early_late.pkl

#+begin_src ipython
df_choice_on = load_data('choice', dum + '_laser', **options)
# df_choice_on = load_data('choice', 'overlaps_loocv_correct_l1_laser', **options)
# df_choice_on = load_data('choice', 'overlaps_loocv_sub_laser_on_0.5', **options)
df_choice_on = get_avg_overlaps(df_choice_on,  ['ED', 'LD', 'TEST', 'CHOICE'], **options)
#+end_src

#+RESULTS:
: loading from /storage/leon/dual_task/data/mice/overlaps/df_choice_overlaps_loocv_l1_laser_early_late.pkl

#+begin_src ipython
print(df_choice.mouse.unique())
#+end_src

#+RESULTS:
: ['JawsM01' 'JawsM06' 'JawsM12' 'JawsM15' 'JawsM18' 'ChRM04' 'ChRM23']

*** Correlations off on

#+begin_src ipython
from scipy.stats import pearsonr
name = 'overlaps_TEST_LD'
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18'] #, 'ChRM04', 'ChRM23']

df = df_choice[['mouse', 'performance', 'odr_perf', name, 'laser', 'sample_odor', 'day', 'tasks']]
df = df[df.mouse.isin(laser_mice)]
#df = df[df.tasks!='DualGo']
df = df.drop(columns='tasks')

df2 = df_choice_on[['mouse', 'performance', 'odr_perf', name, 'laser', 'sample_odor', 'day', 'tasks']]
df2 = df2[df2.mouse.isin(laser_mice)]
#df2 = df2[df2.tasks!='DualGo'].drop(columns='tasks')
df2 = df2.drop(columns='tasks')

df_off = df[df.laser==0].groupby(['mouse', 'day', 'sample_odor']).mean().reset_index()
df_on = df2[df2.laser==1].groupby(['mouse', 'day', 'sample_odor']).mean().reset_index()

# df_off = df[df.laser==0].groupby(['mouse', 'day']).mean().reset_index()
# df_on = df2[df2.laser==1].groupby(['mouse', 'day']).mean().reset_index()

delta_df = df_off.drop(columns=[name, 'performance', 'odr_perf', 'laser'])

delta_df['overlaps_off'] = df_off[name] #  * (2 * df_off['sample_odor'] -1)
delta_df['overlaps_on'] = df_on[name]  # * (2* df_on['sample_odor'] -1)

delta_df['delta_overlaps'] = delta_df['overlaps_on'] - delta_df['overlaps_off']

delta_df['perf_off'] = df_off['performance']
delta_df['perf_on'] = df_on['performance']

delta_df['odr_perf_off'] = df_off['odr_perf']
delta_df['odr_perf_on'] = df_on['odr_perf']

delta_df['delta_perf'] = delta_df['perf_on'] - delta_df['perf_off']
delta_df['delta_odr_perf'] = delta_df['odr_perf_on'] - delta_df['odr_perf_off']

# print(delta_df.head())
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

# Set a clean seaborn style and context for better aesthetics
# sns.set(style="whitegrid", context="talk")

# Create the figure and axis with an appropriate size
fig, ax = plt.subplots()

# Make a copy of your data frame (modify filters as needed)
df_ = delta_df.copy()
# df_ = df_[df_.mouse!='ChRM04']
# df_= delta_df.copy()[delta_df.day=='last']

# Plot the regression line with a confidence interval using regplot
sns.regplot(data=df_, x='delta_overlaps', y='delta_perf', scatter=True,
            fit_reg=True, ci=95, ax=ax, marker='o',
            scatter_kws={'s': 0, 'alpha': 0.7},
            line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

# Overlay a scatterplot that distinguishes data points by 'mouse'
sns.scatterplot(data=df_, x='delta_overlaps', y='delta_perf',
                hue='mouse', style=None, s=80, alpha=0.8, ax=ax,
                legend=None)

# Compute Pearson correlation statistics
corr, p_value = pearsonr(df_['delta_overlaps'], df_['delta_perf'])

# Annotate the computed correlation statistics on the plot
annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
ax.annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
            backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
            bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

# Set title and axis labels using LaTeX formatting for mathematical symbols
# ax.set_title("Correlation of Changes in Overlap and Performance", fontsize=18)
ax.set_xlabel("$\\Delta$ Choice Overlap On-Off")
ax.set_ylabel("$\\Delta$ DPA Perf On-Off")

# Adjust tick parameters for better readability
# ax.tick_params(labelsize=14)

# Optionally, adjust or add a legend (if necessary)
# ax.legend(title="Mouse", fontsize=12, title_fontsize=12, loc='best')

# Optimize layout and save the final figure
plt.tight_layout()
plt.savefig('dpa_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_41.png]]

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

# Set a clean seaborn style and context for better aesthetics
# sns.set(style="whitegrid", context="talk")

# Create the figure and axis with an appropriate size
fig, ax = plt.subplots()

# Make a copy of your data frame (modify filters as needed)
df_ = delta_df.copy()
# df_= delta_df.copy()[delta_df.day=='last']

# Plot the regression line with a confidence interval using regplot
sns.regplot(data=df_, x='delta_overlaps', y='delta_odr_perf', scatter=True,
            fit_reg=True, ci=95, ax=ax,
            scatter_kws={'s': 0, 'alpha': 0.7},
            line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

# Overlay a scatterplot that distinguishes data points by 'mouse'
sns.scatterplot(data=df_, x='delta_overlaps', y='delta_odr_perf',
                hue='mouse', style=None, s=80, alpha=0.8, ax=ax,
                legend=None)

# Compute Pearson correlation statistics
corr, p_value = pearsonr(df_['delta_overlaps'], df_['delta_odr_perf'])

# Annotate the computed correlation statistics on the plot
annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
ax.annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
            backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
            bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

# Set title and axis labels using LaTeX formatting for mathematical symbols
# ax.set_title("Correlation of Changes in Overlap and Performance", fontsize=18)
ax.set_xlabel("$\\Delta$ Choice Overlap On-Off")
ax.set_ylabel("$\\Delta$ GoNoGo Perf On-Off")

# Adjust tick parameters for better readability
# ax.tick_params(labelsize=14)

# Optionally, adjust or add a legend (if necessary)
# ax.legend(title="Mouse", fontsize=12, title_fontsize=12, loc='best')

# Optimize layout and save the final figure
plt.tight_layout()
plt.savefig('gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_42.png]]


#+begin_src ipython
sns.scatterplot(data=df_, x=np.arange(20), y='delta_overlaps',
                hue='mouse', style=None, s=80, alpha=0.8,
                legend=None)

plt.ylabel("$\\Delta$ Choice Overlap On-Off")
plt.xlabel('Mouse #')

plt.axhline(0, ls='--', color='k')
plt.xticks([1.5, 5.5, 9.5, 13.5, 17.5], [1, 2, 3, 4, 5])
plt.savefig('./figures/bernstein/gng_mice.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_43.png]]

*** scatter

#+begin_src ipython
df_ = df_sample[(df_sample.tasks=='DPA') & (df_sample.day=='last')]
overlaps = df_.groupby(['tasks', 'mouse'])['sign_overlaps_diag'].apply(lambda x: np.nanmean(np.stack(x), axis=0)).reset_index()
exploded = overlaps.explode('sign_overlaps_diag').reset_index(drop=True)

exploded['overlaps_norm'] = exploded.groupby('mouse')['sign_overlaps_diag'].transform(lambda x: x / np.linalg.norm(x))
exploded['point'] = exploded.groupby('mouse').cumcount()

for mouse, group in exploded.groupby('mouse'):
    plt.plot(group['point'], group['overlaps_norm'], label=mouse, alpha=0.5)

plt.xlabel('Time')
plt.ylabel('Overlaps')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_39.png]]

#+begin_src ipython
df_ = df_choice[(df_choice.tasks=='DPA') & (df_choice.day=='last')]
overlaps = df_.groupby(['tasks', 'mouse'])['overlaps_TEST'].apply(lambda x: np.nanmean(np.stack(x), axis=0)).reset_index()
exploded = overlaps.explode('overlaps_TEST').reset_index(drop=True)

exploded['overlaps_norm'] = exploded.groupby('mouse')['overlaps_TEST'].transform(lambda x: x / np.linalg.norm(x))
exploded['point'] = exploded.groupby('mouse').cumcount()

for mouse, group in exploded.groupby('mouse'):
    plt.plot(group['point'], group['overlaps_norm'], label=mouse, alpha=0.5)

plt.xlabel('Time')
plt.ylabel('Overlaps')
#plt.legend(fontsize=12)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_40.png]]

#+begin_src ipython
name = 'overlaps_diag_ED'
name2 = 'overlaps_diag_ED'

laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18'] #, 'ChRM04', 'ChRM23']

df = df_choice[['mouse',  name, 'laser', 'sample_odor', 'day', 'tasks']]
df2 = df_sample[['mouse', name2, 'laser', 'sample_odor', 'day', 'tasks']]

df_off = df[df.laser==0].groupby(['mouse', 'day', 'tasks', 'sample_odor']).mean().reset_index()
df_on = df2[df2.laser==0].groupby(['mouse', 'day', 'tasks', 'sample_odor']).mean().reset_index()

delta_df = df_off.drop(columns=['laser'])

delta_df['overlaps_y'] = df_off[name] #  * (2 * df_off['sample_odor'] -1)
delta_df['overlaps_x'] = df_on[name2]  # * (2* df_on['sample_odor'] -1)

# print(delta_df.head())
#+end_src

#+RESULTS:

#+begin_src ipython
df_ = delta_df[(delta_df.tasks=='DPA') & (delta_df.day=='last')]

sns.scatterplot(data=df_, x='overlaps_x', y='overlaps_y', hue='mouse', legend=None)

for i in range(2):
    df__ = df_[df_.sample_odor==i]
    mean_x = df__['overlaps_x'].mean()
    mean_y = df__['overlaps_y'].mean()
    plt.scatter(mean_x, mean_y, color='k', s=200, marker='o', label='Mean')

# plt.xlim([-0.5, 0.5])
# plt.ylim([-0.5, 0.1])
plt.axvline(0, ls='--')
plt.axhline(0, ls='--')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_42.png]]

*** scatter LD

#+begin_src ipython
from scipy.stats import pearsonr

name = 'overlaps_diag_LD'
name2 = 'overlaps_diag_LD'

laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18'] #, 'ChRM04', 'ChRM23']

df = df_choice[['mouse',  name, 'laser', 'sample_odor', 'day', 'tasks']]
df2 = df_sample[['mouse', name2, 'laser', 'sample_odor', 'day', 'tasks']]

df_off = df[df.laser==0].groupby(['mouse', 'day', 'tasks', 'sample_odor']).mean().reset_index()
df_on = df2[df2.laser==0].groupby(['mouse', 'day', 'tasks', 'sample_odor']).mean().reset_index()

delta_df = df_off.drop(columns=['laser'])

delta_df['overlaps_y'] = df_off[name]
delta_df['overlaps_x'] = df_on[name2]
#+end_src

#+RESULTS:

#+begin_src ipython
df_ = delta_df[(delta_df.tasks=='DPA') & (delta_df.day=='last')]
sns.scatterplot(data=df_, x='overlaps_x', y='overlaps_y', hue='mouse', legend=None)

for i in range(2):
    df__ = df_[df_.sample_odor==i]
    mean_x = df__['overlaps_x'].mean()
    mean_y = df__['overlaps_y'].mean()
    plt.scatter(mean_x, mean_y, color='k', s=200, marker='o', label='Mean')

# plt.xlim([-0.5, 0.5])
# plt.ylim([-0.5, 0.1])
plt.axvline(0, ls='--')
plt.axhline(0, ls='--')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_44.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

*** overlaps
**** Utils

#+begin_src ipython
def plot_overlaps_mean(df, day, epoch, ax, title='', y0=0.5, size=84, if_proba=0, ls='-', label=None, colors=None, cis=None, **kwargs):
    if day=='all':
        df_ = df.copy()
    else:
        df_ = df[df.day == day].copy()

    if colors is None:
        colors = ['r', 'b', 'g']

    if if_proba:
        mean_overlaps = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['sign_overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    else:
        mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))

        if cis is not None:
            lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
            upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    time_points = np.linspace(0, 14, size)

    for i, task in enumerate(mean_overlaps.index):
        dum = np.mean(mean_overlaps[task][:14])
        if label is None:
            ax.plot(time_points, mean_overlaps[task]-dum, label=f"{task}", color=colors[i], ls=ls, **kwargs)
            # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)
        else:
            ax.plot(time_points, mean_overlaps[task]-dum, label=label, color=colors[i], ls=ls, **kwargs)

        if cis is not None:
            ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    # ax.set_ylabel('%s Overlap' % title)
    add_vlines(ax)
    ax.axhline(y0, ls='--', color='k')
    ax.legend(fontsize=10)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
# Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']
# Jaws_mice = ['JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']

df = df_sample.copy()
df1 = df_choice.copy()

print(df.laser.unique(), df1.laser.unique())

df = df[df.mouse.isin(Jaws_mice)]
df1 = df1[df1.mouse.isin(Jaws_mice)]

period = 'first'

epoch= 'diag'
epoch1= 'diag'

# df = df[df.laser==1]
# df1 = df1[df1.laser==1]

# df = df[df.performance==1]
# df1 = df1[df1.performance==1]

# df = df[df.mouse=='JawsM15']
# df1 = df1[df1.mouse=='JawsM15']

ls = ['-', '--', '--', '-']
colors = ['r', 'b', 'g']
labels = ['AC', 'BC', 'AD', 'BD']
tasks = ['DPA', 'DualGo', 'DualNoGo']
#+end_src

#+RESULTS:
: [0.] [0.]

 #+begin_src ipython
n_ = len(options['days'])+1
fig, ax = plt.subplots(nrows=3, ncols=n_, figsize=(0.9*n_*width, 0.9*3*height))

for k in range(3):
    df_ = df[df.tasks==tasks[k]]
    df1_ = df1[df1.tasks==tasks[k]]

    for j in range(2):
        for i in range(2):
            df__ = df_[(df_.sample_odor==i) & (df_.test_odor==j)]
            df1__ = df1_[(df1_.sample_odor==i) & (df1_.test_odor==j)]

            plot_overlaps(df__, period, epoch, ax[k][0], y0=0., if_proba=0, label=labels[2*i+j],
                          cis=None, ls=ls[2*i+j], colors=[colors[k]], alpha=(i+1)/2)
            plot_overlaps(df1__, period, epoch1, ax[k][1], y0=0., if_proba=0, label=labels[2*i+j],
                          cis=None, ls=ls[2*i+j], colors=[colors[k]], alpha=(i+1)/2)

            overlaps = df__[df__.day==period].groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.nanmean(np.stack(x), axis=0))
            overlaps1 = df1__[df1__.day==period].groupby('tasks')['overlaps_%s' % epoch1].apply(lambda x: np.nanmean(np.stack(x), axis=0))

            ax[k][2].plot(overlaps[0][:65]-np.mean(overlaps[0][:14]), overlaps1[0][:65]-np.mean(overlaps1[0][:14]), label=labels[2*i+j],
                          ls=ls[2*i+j], color=colors[k], alpha=(i+1)/2)

            # ax[k][2].set_aspect('equal')

        ax[k][0].set_xlabel('Time (s)')
        ax[k][0].set_ylabel('Sample Overlap')

        ax[k][1].set_xlabel('Time (s)')
        ax[k][1].set_ylabel('Choice Overlap')

        ax[k][2].set_xlabel('Sample Overlap')
        ax[k][2].set_ylabel('Choice Overlap')

ax[0][-1].legend(fontsize=10)

plt.savefig('figures/icrm/%s_overlaps_%s_%s.svg' % (period, epoch, epoch1), dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_38.png]]

#+begin_src ipython
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
palette = sns.diverging_palette(360, 0, as_cmap=True)
palette = 'bwr'
# palette='jet'

def plot_overlaps_mat(df, day, vmin=-1, vmax=1, title='', palette=palette):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

    for i, task in enumerate(df_.tasks.unique()):
        df_task = df_[df_.tasks==task]
        overlaps = df_task
        overlaps = np.array(df_task['overlaps'].tolist())

        mean_o = np.nanmean(overlaps, axis=0)

        im = plot_mat(mean_o.reshape(84, 84), ax[i], vmin, vmax, palette)

    cax = inset_axes(ax[-1], width="5%", height="100%", loc='center right',
                     bbox_to_anchor=(0.12, 0, 1, 1), bbox_transform=ax[-1].transAxes, borderpad=0)

    # Add colorbar to the new axis
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label("%s Overlaps" % title)

    plt.subplots_adjust(right=0.85)  # Adjust figure to allocate space

#+end_src

#+RESULTS:

**** All

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'ED'

for task in tasks:
    df = df_sample.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        plot_overlaps(
            df_, day, epoch, ax[task['ax_idx']],
            title='', y0=0., if_proba=1, colors=colors,
            alpha=alpha, label=label, ls=ls, cis=1)

        ax[task['ax_idx']].set_ylim([-0.1, 0.6])
        ax[task['ax_idx']].set_xlim([0, 12])
        ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))

ax[0].set_ylabel('|Sample Overlap|')

plt.savefig(f'figures/bernstein/sample_overlaps_first_last.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_39.png]]

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'TEST'
ls = '-'

for task in tasks:
    df = df_choice.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        plot_overlaps(
            df_, day, epoch, ax[task['ax_idx']],
            title='', y0=0., if_proba=0, colors=colors,
            alpha=alpha, label=label, ls=ls, cis=True)

        ax[task['ax_idx']].set_ylim([-0.3, 0.5])
        ax[task['ax_idx']].set_xlim([0, 12])
        ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))
        ax[task['ax_idx']].set_yticks(np.linspace(-0.3, 0.5, 5))

ax[0].set_ylabel('Choice Overlap')
plt.savefig(f'figures/bernstein/choice_overlaps_first_last.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_41.png]]

#+begin_src ipython

#+end_src

**** Paired

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'ED'

for task in tasks:
    df = df_sample.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(1, '-')]:# (1, '-')]:
            df__ = df_[df_.pair == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=1, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=1)

            # ax[task['ax_idx']].set_ylim([-0.1, 0.6])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))

ax[0].set_ylabel('|Sample Overlap|')

plt.savefig(f'figures/bernstein/sample_overlaps_first_last_paired.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_53.png]]

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'CHOICE'

for task in tasks:
    df = df_choice.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(1, '-')]:
            df__ = df_[df_.pair == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=0, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=True)

            # ax[task['ax_idx']].set_ylim([-0.3, 0.5])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))
            # ax[task['ax_idx']].set_yticks(np.linspace(-0.3, 0.5, 5))

ax[0].set_ylabel('Choice Overlap')
plt.savefig(f'figures/bernstein/choice_overlaps_first_last_paired.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/overlaps/figure_54.png]]

#+begin_src ipython

#+end_src

#+RESULTS:


****  Unpaired

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'ED'

for task in tasks:
    df = df_sample.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(0, '-')]:# (1, '-')]:
            df__ = df_[df_.pair == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=1, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=1)

            ax[task['ax_idx']].set_ylim([-0.1, 0.6])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))

ax[0].set_ylabel('|Sample Overlap|')

plt.savefig(f'figures/bernstein/sample_overlaps_first_last_unpaired.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_47.png]]

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'TEST'

for task in tasks:
    df = df_choice.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(0, '-')]:
            df__ = df_[df_.pair == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=0, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=True)

            ax[task['ax_idx']].set_ylim([-0.3, 0.5])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))
            ax[task['ax_idx']].set_yticks(np.linspace(-0.3, 0.5, 5))

ax[0].set_ylabel('Choice Overlap')
plt.savefig(f'figures/bernstein/choice_overlaps_first_last_unpaired.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_48.png]]

#+begin_src ipython

#+end_src

**** Lick

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'ED'

for task in tasks:
    df = df_sample.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(1, '-')]:# (1, '-')]:
            df__ = df_[df_.choice == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=1, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=1)

            ax[task['ax_idx']].set_ylim([-0.1, 0.6])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))

ax[0].set_ylabel('|Sample Overlap|')

plt.savefig(f'figures/bernstein/sample_overlaps_first_last_licks.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_47.png]]

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'TEST'

for task in tasks:
    df = df_choice.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(1, '-')]:
            df__ = df_[df_.choice == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=0, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=True)

            ax[task['ax_idx']].set_ylim([-0.3, 0.6])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))
            ax[task['ax_idx']].set_yticks(np.linspace(-0.3, 0.6, 4))

ax[0].set_ylabel('Choice Overlap')
plt.savefig(f'figures/bernstein/choice_overlaps_first_last_lick.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_50.png]]

#+begin_src ipython

#+end_src

**** No Lick

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'ED'

for task in tasks:
    df = df_sample.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(0, '-')]:# (1, '-')]:
            df__ = df_[df_.choice == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=1, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=1)

            ax[task['ax_idx']].set_ylim([-0.1, 0.6])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))

ax[0].set_ylabel('|Sample Overlap|')

plt.savefig(f'figures/bernstein/sample_overlaps_first_last_nolick.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_51.png]]

#+begin_src ipython
tasks = [
    dict(name='DPA', ax_idx=0, color=None),
    dict(name='DualGo', ax_idx=1, color=['b']),
    dict(name='DualNoGo', ax_idx=2, color=['g']),
]

n_ = len(options['days'])+1
fig, ax = plt.subplots(1, n_, figsize=(n_*width, height), sharex=True)
epoch = 'TEST'

for task in tasks:
    df = df_choice.copy()
    df = df[(df.laser == 0) & (df.tasks == task['name'])]

    colors = task.get('color')

    for day, label, alpha in [('first', 'First', 0.5), ('last', 'Last', 1)]:
        df_ = df[df.day == day]

        for pair, ls in [(0, '-')]:
            df__ = df_[df_.choice == pair]

            plot_overlaps(
                df__, day, epoch, ax[task['ax_idx']],
                title='', y0=0., if_proba=0, colors=colors,
                alpha=alpha, label=label, ls=ls, cis=True)

            ax[task['ax_idx']].set_ylim([-0.4, 0.5])
            ax[task['ax_idx']].set_xlim([0, 12])
            ax[task['ax_idx']].set_xticks(np.arange(0, 14, 2))
            ax[task['ax_idx']].set_yticks(np.linspace(-0.4, 0.5, 4))

ax[0].set_ylabel('Choice Overlap')
plt.savefig(f'figures/bernstein/choice_overlaps_first_last_nolick.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_53.png]]


#+begin_src ipython

#+end_src


**** Matrix

#+begin_src ipython
plot_overlaps_mat(df1[df1.pair==1], 'last', vmin=-1, vmax=1, title='Choice')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_39.png]]

#+begin_src ipython
plot_overlaps_mat(df[df.sample_odor==1], 'last', vmin=-.5, vmax=.5, title='Sample')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_40.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

*** flow

#+begin_src ipython
import numpy as np
from scipy.interpolate import griddata
from scipy.ndimage import gaussian_filter
from scipy.spatial import cKDTree

def create_mesh(x, y, size=100, sigma=1, interp_method='linear', mask_radius=10):
    """
    x, y: arrays of shape (n_traj, n_points)
    size: grid size along each axis
    sigma: Gaussian smoothing for velocities (0=none)
    interp_method: 'linear', 'cubic', or 'nearest'
    mask_radius: mask out grid points farther than this multiple of median point spacing

    Returns: xi, yi, ui, vi (masked arrays)
    """
    x = np.asarray(x)
    y = np.asarray(y)

    # Flatten for easier handling
    x_flat = x.flatten()
    y_flat = y.flatten()

    # Compute dense grid
    x_min, x_max = np.min(x_flat)-1, np.max(x_flat)+1
    y_min, y_max = np.min(y_flat)-1, np.max(y_flat)+1

    xi, yi = np.meshgrid(np.linspace(x_min, x_max, size),
                         np.linspace(y_min, y_max, size))

    # Compute velocities (finite differences along time axis)
    dx = np.gradient(x, axis=1)
    dy = np.gradient(y, axis=1)

    # Optional smoothing of velocities
    if sigma > 0:
        dx = gaussian_filter(dx, sigma=sigma)
        dy = gaussian_filter(dy, sigma=sigma)

    dx_flat = dx.flatten()
    dy_flat = dy.flatten()

    # Prepare for griddata interpolation
    points = np.vstack((x_flat, y_flat)).T

    # Interpolate velocity components onto grid
    ui = griddata(points, dx_flat, (xi, yi), method=interp_method, fill_value=np.nan)
    vi = griddata(points, dy_flat, (xi, yi), method=interp_method, fill_value=np.nan)

    # Find where it failed
    mask = np.isnan(ui)

    # Interpolate only those points with 'nearest'
    if np.any(mask):
        ui_nearest = griddata(points, dx_flat, (xi, yi), method='nearest')
        vi_nearest = griddata(points, dy_flat, (xi, yi), method='nearest')
        ui[mask] = ui_nearest[mask]
        vi[mask] = vi_nearest[mask]

    # # Mask far-from-data regions (optional)
    # tree = cKDTree(points)
    # dists, _ = tree.query(np.column_stack([xi.flatten(), yi.flatten()]), k=1)
    # dists = dists.reshape(xi.shape)
    # median_spacing = np.median(np.sqrt(np.diff(x_flat)**2 + np.diff(y_flat)**2))
    # mask = dists > (mask_radius * median_spacing)
    # ui = np.ma.masked_where(mask, ui)
    # vi = np.ma.masked_where(mask, vi)

    return xi, yi, ui, vi
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib as mpl

def plot_field(x, y, ax, window, IF_FP=0, task=0):
    # x = overlaps[:, window:, 0]
    # y = overlaps[:, window:, 1]

    xi, yi, ui, vi = create_mesh(x, y, size=100)
    speed = np.sqrt(ui**2+vi**2)
    speed = (speed - np.mean(speed)) / (np.std(speed) + 1e-6)

    # center, center_ = get_fp(overlaps, window, task, GRID_TEST=0)
    # ax.plot(center.T[0], center.T[1], 'o', color='k', ms=14)

    # vmin, vmax = np.nanpercentile(speed, [1, 99])
    norm = mpl.colors.Normalize(vmin=-1.5, vmax=1.5)

    heatmap = ax.streamplot(xi, yi, ui, vi, density=0.75, arrowsize=2, norm=norm, color='w')
    heatmap = ax.pcolormesh(xi, yi, speed, cmap='coolwarm', shading='gouraud', norm=norm)
    # heatmap = ax.imshow(speed, extent=(yi.min(), yi.max(), yi.min(), yi.max()), cmap='jet', norm=norm, origin='lower', aspect='auto')

    # ax.set_aspect('equal')
    # ax.set_xlim([yi.min(), yi.max()])
    # ax.set_ylim([yi.min(), yi.max()])

    # cbar = plt.colorbar(heatmap, ax=ax)
    # cbar.set_label('Norm. Speed')

    ax.set_xlabel('A/B Overlap')
    ax.set_ylabel('Choice Overlap')
#+end_src

#+RESULTS:

#+begin_src ipython
df = df_sample.copy()
df = df[df.day=='last']
df = df[df.mouse=='JawsM15']
epoch = 'diag'
x = df.groupby('tasks')['overlaps_%s' % epoch].agg(list).to_numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
df = df_choice.copy()
df = df[df.day=='last']
df = df[df.mouse=='JawsM15']
df = df[df.laser==0]
epoch = 'diag'
y = df.groupby('tasks')['overlaps_%s' % epoch].agg(list).to_numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
print(np.array(x[0]).shape,  np.array(y[0]).shape)
#+end_src

#+RESULTS:
: (96, 84) (192, 84)

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(width, width))
plot_field(np.array(x[0]), np.array(y[0])[:96], ax, 0)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_38.png]]

*** glm

#+begin_src ipython
import statsmodels.api as sm
import statsmodels.formula.api as smf

df = pd.concat((df_choice, df_choice_on))
df = df[df.day=='last']

formula = 'performance ~ overlaps_CHOICE_LD * laser'

model = smf.glm(formula=formula, data=df, family=sm.families.Binomial())
results = model.fit()

print(results.summary())
#+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:            performance   No. Observations:                 8064
Model:                            GLM   Df Residuals:                     8060
Model Family:                Binomial   Df Model:                            3
Link Function:                  Logit   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -3226.2
Date:                Tue, 17 Jun 2025   Deviance:                       6452.4
Time:                        00:59:34   Pearson chi2:                 8.07e+03
No. Iterations:                     5   Pseudo R-squ. (CS):           0.003913
Covariance Type:            nonrobust
============================================================================================
                               coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------
Intercept                    1.7998      0.042     42.926      0.000       1.718       1.882
overlaps_CHOICE_LD          -0.2659      0.075     -3.538      0.000      -0.413      -0.119
laser                        0.2091      0.073      2.865      0.004       0.066       0.352
overlaps_CHOICE_LD:laser     0.4813      0.092      5.217      0.000       0.300       0.662
============================================================================================
[...] Output truncated [...]
 #+end_example

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
# df = df_choice.copy()
df = pd.concat((df_choice, df_choice_on)).reset_index(drop=True)
df = df[df.day=='last']
# formula = 'performance ~ overlaps_CHOICE_LD * day + (1 + overlaps_CHOICE_LD + day | mouse)'
formula = 'performance ~ overlaps_CHOICE_LD * laser + (1 | mouse)'

model = Lmer(formula=formula, data=df, family='binomial')
results = model.fit()
random_effects = model.ranef

print(results)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_CHOICE_LD*laser+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 8064	 Groups: {'mouse': 9.0}

Log-likelihood: -3014.339 	 AIC: 6038.678

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.804  0.897

No random effect correlations specified

Fixed effects:

                          Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
[...] Output truncated [...]
 #+end_example

#+begin_src ipython
def generate_colors(N, cmap_name='viridis'):
    cmap = plt.get_cmap(cmap_name)
    return cmap(np.linspace(0, 1, N))
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_betas(results, random_effects, title):

    fig, ax = plt.subplots(figsize=(1.5*width, 1.25*height))

    colors = generate_colors(random_effects.shape[0], 'plasma')
    space = np.random.normal(0, .05, random_effects.shape[0])

    keys = results.Estimate.keys()

    for i, key in enumerate(keys):
        res = results.Estimate[key]

        try:
            res += random_effects[key]
        except:
            res += random_effects['(Intercept)']
            pass

        mean_value = res.mean()
        std_dev = res.std()

        if results['P-val'][key]<0.001:
            plt.text(i,   3, '***', ha='center', va='bottom')
        elif results['P-val'][key]<0.01:
            plt.text(i,   3, '**', ha='center', va='bottom')
        elif results['P-val'][key]<0.05:
            plt.text(i,   3, '*', ha='center', va='bottom')
        elif results['P-val'][key]<0.1:
            plt.text(i,   3, '.', ha='center', va='bottom')

        plt.scatter(i * np.ones(res.shape[0]) + space, res, color=colors)
        plt.plot(i, mean_value, '_k', ms=20)
        plt.errorbar(i * np.ones(res.shape[0]),
                     [mean_value]*len(res),
                     yerr=[std_dev]*len(res), fmt='-', color='k', capsize=15)

    plt.axhline(y=0, color='black', ls='--')

    plt.xticks(np.arange(len(keys)), keys, fontsize=14, rotation=45)

    plt.ylabel('$\\beta$')
    plt.title(title)
    plt.savefig('beta_response.svg')
    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
print(results.Estimate.keys())
print(random_effects.keys())
# random_effects['overlaps_CHOICE_LD:daylast'] = random_effects['daylast:overlaps_CHOICE_LD']
#+end_src

#+RESULTS:
: Index(['(Intercept)', 'overlaps_CHOICE_LD', 'laser',
:        'overlaps_CHOICE_LD:laser'],
:       dtype='object')
: Index(['(Intercept)'], dtype='object')

#+begin_src ipython
plot_betas(results, random_effects, '')
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_52.png]]


#+begin_src ipython
import matplotlib.pyplot as plt
import numpy as np

# Set the random seed for reproducibility
np.random.seed(0)

# Generate synthetic data for two classes
# Class 0 (red): centered around (-2, -2)
class0 = np.random.randn(50, 2) * 0.8 + np.array([-2, -2])
# Class 1 (blue): centered around (2, 2)
class1 = np.random.randn(50, 2) * 0.8 + np.array([2, 2])

# Create a new figure
fig, ax = plt.subplots(figsize=(8, 6))

# Plot the data points for each class
ax.scatter(class0[:, 0], class0[:, 1], color='red', label='Class 0')
ax.scatter(class1[:, 0], class1[:, 1], color='blue', label='Class 1')

# Define and plot a decision boundary. Here we use a simple linear boundary.
# For example, suppose the decision rule is: x1 + x2 = 0 => x2 = -x1.
x_vals = np.linspace(-5, 5, 100)
y_vals = -x_vals
ax.plot(x_vals, y_vals, color='black', linestyle='--', lw=2, label='Decision Boundary')

# Annotate decision regions for clarity
ax.text(-4.5, -4.5, 'odor A', fontsize=18, color='red', bbox=dict(facecolor='white', alpha=0.7))
ax.text(2, 2.5, 'Odor B', fontsize=18, color='blue', bbox=dict(facecolor='white', alpha=0.7))

# Add labels, title, and legend
ax.set_xlabel('Neuron 1')
ax.set_ylabel('Neuron 2')
ax.set_title('Sample Encoding Axis')
# ax.legend(fontsize=12)

plt.tight_layout()
plt.savefig('sample_axis.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_62.png]]

#+begin_src ipython
import matplotlib.pyplot as plt
import numpy as np

# Set the random seed for reproducibility
np.random.seed(10)

# Generate synthetic data for two classes
# Class 0 (red): centered around (-2, -2)
class0 = np.random.randn(50, 2) * 0.8 + np.array([-2, -2])
# Class 1 (blue): centered around (2, 2)
class1 = np.random.randn(50, 2) * 0.8 + np.array([2, 2])

# Create a new figure
fig, ax = plt.subplots(figsize=(8, 6))

# Plot the data points for each class
ax.scatter(class0[:, 0], class0[:, 1], color='k', label='Class 0')
ax.scatter(class1[:, 0], class1[:, 1], color='grey', label='Class 1')

# Define and plot a decision boundary. Here we use a simple linear boundary.
# For example, suppose the decision rule is: x1 + x2 = 0 => x2 = -x1.
x_vals = np.linspace(-5, 5, 100)
y_vals = -x_vals
ax.plot(x_vals, y_vals, color='black', linestyle='--', lw=2, label='Decision Boundary')

# Annotate decision regions for clarity
ax.text(-4.5, -4.5, 'Lick', fontsize=18, color='k', bbox=dict(facecolor='white', alpha=0.7))
ax.text(2, 2.5, 'No Lick', fontsize=18, color='grey', bbox=dict(facecolor='white', alpha=0.7))

# Add labels, title, and legend
ax.set_xlabel('Neuron 1')
ax.set_ylabel('Neuron 2')
ax.set_title('Choice Encoding Axis')
# ax.legend(fontsize=12)

plt.tight_layout()
plt.savefig('choice_axis.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_63.png]]
