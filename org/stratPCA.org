#+STARTUP: fold
#+PROPERTY: header-args:jupyter-python :results both :exports both :async yes :session pca :kernel dual :output-dir ./figures/pca :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src jupyter-python
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual/bin/python

* Imports

#+begin_src jupyter-python
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd
  import seaborn as sns

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
  from src.decode.bump import circcvl
  from src.torch.classificationCV import ClassificationCV
  from src.torch.classify import get_classification
#+end_src

#+RESULTS:

* Helpers
** scalers
#+begin_src jupyter-python
import numpy as np

class StandardScaler:
    def __init__(self, axis=0, if_scale=1):
        self.axis = axis
        self.center_ = None
        self.scale_ = None
        self.if_scale_ = if_scale

    def fit(self, X):
        self.center_ = np.nanmean(X, axis=self.axis, keepdims=True)
        self.scale_ = np.nanstd(X, axis=(0, -1), keepdims=True)
        # Prevent division by zero
        self.scale_ = np.where(self.scale_==0, 1, self.scale_)
        # self.scale_ = np.where(np.abs(self.scale_)<1e-3, 1, self.scale_)
        return self

    def transform(self, X):
        if self.if_scale_:
            return (X - self.center_) / self.scale_
        return (X - self.center_)

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

class RobustScaler:
    def __init__(self, axis=0):
        self.axis = axis
        self.center_ = None
        self.scale_ = None

    def fit(self, X):
        self.center_ = np.nanmedian(X, axis=self.axis, keepdims=True)
        q75 = np.nanpercentile(X, 75, axis=self.axis, keepdims=True)
        q25 = np.nanpercentile(X, 25, axis=self.axis, keepdims=True)
        self.scale_ = q75 - q25
        # Prevent division by zero
        self.scale_ = np.where(self.scale_ == 0, 1, self.scale_)
        return self

    def transform(self, X):
        return (X - self.center_) / self.scale_

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
#+end_src

#+RESULTS:

** pad

#+begin_src jupyter-python
def pad_list(arrays, axis=0, max_len=None):
    """
    Pads a list of arrays along the specified axis with NaNs so all have the same size along that axis.
    Returns a list of padded arrays.
    """
    # Find maximum size along specified axis
    if max_len is None:
        max_len = max(arr.shape[axis] for arr in arrays)

    padded = []
    for arr in arrays:
        pad_width = [(0, 0)] * arr.ndim


        n_pad = max_len - arr.shape[axis]

        if n_pad > 0:
            pad_width[axis] = (0, n_pad)
            arr_padded = np.pad(arr, pad_width, mode='constant', constant_values=np.nan)
        else:
            arr_padded = arr
        padded.append(arr_padded)

    return padded
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

** save

#+begin_src jupyter-python
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src jupyter-python
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

** cv pca

#+begin_src jupyter-python
from scipy.linalg import orthogonal_procrustes

def align_fold_to_ref(W_fold, W_ref, X_pca_fold):
    """
    Align W_fold to W_ref using orthogonal Procrustes and
    rotate fold's projected data accordingly.

    W_ref, W_fold: (n_comp, n_neurons)
    X_pca_fold: (n_trials, T, n_comp)

    Returns: X_pca_aligned, W_fold_aligned
    """
    if W_ref is None:
        W_ref = W_fold
    # Procrustes finds R that best maps W_fold -> W_ref:  W_fold @ R â‰ˆ W_ref
    R, _ = orthogonal_procrustes(W_fold.T, W_ref.T)  # shapes (n_neurons, n_comp)

    # R is (n_neurons, n_comp), so mapping in component space is R_comp = R.T
    R_comp = R.T  # (n_comp, n_neurons) is W-aligned space; rotation in PC space is R_comp.T

    # rotate projections: (n_trials * T, n_comp) @ (n_comp, n_comp)
    n_trials, T, n_comp = X_pca_fold.shape
    X_flat = X_pca_fold.reshape(-1, n_comp)
    X_aligned = X_flat @ R_comp.T
    X_aligned = X_aligned.reshape(n_trials, T, n_comp)

    W_aligned = (W_fold.T @ R).T  # still (n_comp, n_neurons)
    return X_aligned, W_aligned
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import itertools
from functools import reduce
import operator

def cv_avg_cond(X, y, condition='odor_pair'):
    # Ensure condition is a list
    if isinstance(condition, str):
        condition = [condition]

    # Find unique values for each condition
    unique_vals = [y[c].unique() for c in condition]

    X_avg = []
    combos = list(itertools.product(*unique_vals))
    for combo in combos:
        # Build boolean mask for all conditions
        idx = reduce(operator.and_, [(y[c]==v) for c,v in zip(condition, combo)])
        if idx.any():
            X_avg.append(np.nanmean(X[idx], axis=0))

    return np.array(X_avg)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold
from sklearn.decomposition import PCA
from tqdm import tqdm

def cross_val_avg_pca(X, y, pca, folds, factors, epoch):

    labels = y['mouse'].astype(str) + '_' + y['odor_pair'].astype(str) + '_' + y['tasks'].astype(str) + '_' + y['laser'].astype(str)

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    w_ref = None
    for train_idx, test_idx in tqdm(folds.split(X, labels), total=folds.get_n_splits(X, labels), desc=y.mouse.unique()[0]):

        X_train, y_train = X[train_idx], y.iloc[train_idx]

        m_train = (y_train.performance==1) & (y_train.laser==0)
        # m_train = (y_train.performance==1) & ((y_train.tasks=='DPA') | (y_train.odr_perf==1)) & (y_train.laser==0)
        # m_train = (y_train.laser==0)

        X_train = X_train[m_train]
        y_train = y_train[m_train]

        X_train_epoch = X_train[..., epoch]

        X_train_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_flat, axis=0, keepdims=True)

        X_avg_epoch = cv_avg_cond(X_train_epoch, y_train, factors)
        X_avg_flat = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
        X_cent = X_avg_flat - X_mean

        pca.fit(X_cent)
        w_fold = pca.components_
        evr_folds.append(pca.explained_variance_ratio_)

        X_test, y_test = X[test_idx], y.iloc[test_idx]

        X_test_flat = X_test.transpose(0, 2, 1).reshape(-1, X_test.shape[1])
        X_cent_test = X_test_flat - X_mean
        X_out = pca.transform(X_cent_test).reshape(X_test.shape[0], X_test.shape[-1], -1)

        X_pca_aligned, w_fold_aligned = align_fold_to_ref(w_fold, w_ref, X_out)

        w_folds.append(w_fold_aligned)

        if w_ref is None:
                w_ref = w_folds[0]

        X_folds.append(X_pca_aligned)
        y_folds.append(y_test)

    X_folds = np.concatenate(X_folds, 0)
    y_folds = pd.concat(y_folds)

    w_folds = np.array(w_folds, dtype=object)
    evr_folds = np.array(evr_folds, dtype=object)

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import StratifiedGroupKFold

def cv_pca(
    X, y, pca, folds, factors, epoch,
    group_col=None,
    show_pbar=True,
):

    # Clean subset used for fitting + CV

    # m_clean = (y.laser == 0)
    m_clean = (y.laser == 0) & (y.performance == 1)
    # m_clean = (y.laser==0) & (y.performance==1) & ((y.tasks=='DPA') | (y.odr_perf==1))

    Xc = X[m_clean]
    yc = y.loc[m_clean].reset_index(drop=True)

    groups=None
    if group_col is not None:
        groups = yc[group_col].astype(str).values

    strata = (
        yc["odor_pair"].astype(str)
        + "_" + yc["mouse"].astype(str)
        + "_" + yc["day"].astype(str)
        + "_" + yc["tasks"].astype(str)
    ).values

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    w_ref = None

    it = folds.split(Xc, strata, groups=groups)
    if show_pbar:
        it = tqdm(it, total=folds.get_n_splits(Xc, strata), desc=y.mouse.unique()[0])

    for fold, (train, test) in enumerate(it):
        X_train, y_train = Xc[train], yc.iloc[train]
        X_test, y_test = Xc[test], yc.iloc[test]

        X_train_epoch = X_train
        if epoch is not None:
            X_train_epoch = X_train[..., epoch]

        X_train_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_flat, axis=0, keepdims=True)

        X_avg_epoch = cv_avg_cond(X_train_epoch, y_train, factors)
        X_avg_flat = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
        X_cent = X_avg_flat - X_mean

        pca.fit(X_cent)
        w_fold = pca.components_
        evr_folds.append(pca.explained_variance_ratio_)

        X_test_flat = X_test.transpose(0, 2, 1).reshape(-1, X_test.shape[1])
        X_cent_test = X_test_flat - X_mean
        X_out = pca.transform(X_cent_test).reshape(X_test.shape[0], X_test.shape[-1], -1)

        X_pca_aligned, w_fold_aligned = align_fold_to_ref(w_fold, w_ref, X_out)

        w_folds.append(w_fold_aligned)

        if w_ref is None:
                w_ref = w_fold

        X_folds.append(X_pca_aligned)
        y_folds.append(y_test)

    X_folds = np.concatenate(X_folds, 0)
    y_folds = pd.concat(y_folds)

    w_folds = np.mean(w_folds, 0)
    evr_folds = np.array(evr_folds, dtype=object)

    Xc_epoch = Xc
    if epoch is not None:
        Xc_epoch = Xc[..., epoch]

    Xc_flat = Xc_epoch.transpose(0, 2, 1).reshape(-1, Xc_epoch.shape[1])
    X_mean = np.nanmean(Xc_flat, axis=0, keepdims=True)

    X_avg_epoch = cv_avg_cond(Xc_epoch, yc, factors)
    X_avg_flat = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
    X_cent = X_avg_flat - X_mean

    pca.fit(X_cent)
    w_fold = pca.components_

    m_pert = ~m_clean
    if m_pert.mean()!=0:
        Xp = X[m_pert]
        yp = y.loc[m_pert].reset_index(drop=True)

        Xp_flat = Xp.transpose(0, 2, 1).reshape(-1, Xp.shape[1])
        X_centp = Xp_flat - X_mean
        X_out = pca.transform(X_centp).reshape(Xp.shape[0], Xp.shape[-1], -1)

        Xp_aligned, w_fold_aligned = align_fold_to_ref(w_fold, w_ref, X_out)

        Z_all = np.concatenate([X_folds, Xp_aligned], axis=0)
        y_all = pd.concat([y_folds, yp], axis=0, ignore_index=True)

        return Z_all, y_all, w_folds, evr_folds

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import griddata
from scipy.ndimage import gaussian_filter

def polar_velocities(x, y, sigma_r=1, sigma_t=1, sigma_time=1):
    """
    x, y: (n_traj, n_points)
    sigma: gaussian smoothing in time (in points)
    Returns:
      dr_s, dtheta_s: (n_traj, n_points): smoothed radial and angular velocities
      r, theta: positions at each point, for later conversion
    """

    r = np.sqrt(x**2 + y**2)
    theta = np.arctan2(y, x)
    theta_u = np.unwrap(theta, axis=1)

    # r_s = gaussian_filter1d(r, sigma=sigma_r)
    # theta_s = gaussian_filter1d(theta_u, sigma=sigma_t)

    r_s = gaussian_filter(r, sigma=(sigma_r, sigma_time))
    theta_s = gaussian_filter(theta_u, sigma=(sigma_t, sigma_time))

    dr_s = np.gradient(r_s, axis=1)
    dtheta_s = np.gradient(theta_s, axis=1)

    return dr_s, dtheta_s, r_s, theta_s
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def pol2cart(dr, dtheta, r, theta):
    """
    Converts smoothed polar velocities to Cartesian velocities.
    All arrays shape: (n_traj, n_points)
    """
    u = dr * np.cos(theta) - r * dtheta * np.sin(theta)
    v = dr * np.sin(theta) + r * dtheta * np.cos(theta)
    return u, v
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def create_field(x, y, u, v, grid_size=100, method='linear', z_lim=5):
    """
    Interpolate velocity field to a regular grid.
    Inputs: x,y,u,v all (n_samples,) or (n_traj, n_points) -- flatten them first.
    Returns: xi, yi, ui, vi: all (grid_size, grid_size) arrays.
    """
    x_flat = x.flatten()
    y_flat = y.flatten()
    u_flat = u.flatten()
    v_flat = v.flatten()

    # xi, yi = np.meshgrid(
    #     np.linspace(np.min(x_flat), np.max(x_flat), grid_size),
    #     np.linspace(np.min(y_flat), np.max(y_flat), grid_size),
    # )

    x_min, x_max = np.min(x_flat)-1, np.max(x_flat)+1
    y_min, y_max = np.min(y_flat)-1, np.max(y_flat)+1

    if z_lim is 0:
        z_min = np.min((x_min, y_min))
        z_max = np.min((x_max, y_max))
    else:
        z_min = -z_lim
        z_max = z_lim

    xi, yi = np.meshgrid(np.linspace(z_min, z_max, grid_size),
                         np.linspace(z_min, z_max, grid_size))


    ui = griddata((x_flat, y_flat), u_flat, (xi, yi), method=method, fill_value=np.nan)
    vi = griddata((x_flat, y_flat), v_flat, (xi, yi), method=method, fill_value=np.nan)

    # Fill nans with nearest
    mask = np.isnan(ui)
    if np.any(mask):
        ui[mask] = griddata((x_flat, y_flat), u_flat, (xi, yi), method='nearest')[mask]
        vi[mask] = griddata((x_flat, y_flat), v_flat, (xi, yi), method='nearest')[mask]

    return xi, yi, ui, vi

#+end_src

#+RESULTS:

#+begin_src jupyter-python
def plot_field(xi, yi, ui, vi, ax=None, density=1.0, show_cbar=0):
    speed = np.sqrt(ui**2 + vi**2)
    if ax is None:
        fig, ax = plt.subplots(figsize=(5,5))
    # Normalize for coloring
    import matplotlib as mpl
    vmin, vmax = np.nanpercentile(speed, [5, 95])
    norm = mpl.colors.Normalize(vmin, vmax)
    # strm = ax.streamplot(xi, yi, ui, vi, density=density, color=speed, cmap='coolwarm', norm=norm)
    heatmap = ax.pcolormesh(xi, yi, speed, cmap='coolwarm', shading='gouraud', norm=norm)

    if show_cbar:
        plt.colorbar(strm.lines, ax=ax, label='Speed')

    ax.set_aspect('equal')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    return ax
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

from scipy.ndimage import gaussian_filter1d, gaussian_filter
from scipy.interpolate import Rbf

def create_field_rbf(
    x, y, u, v,
    grid_size=32,
    z_lim=5,
    method='multiquadric',
    epsilon=None,
    smooth=0.0
):
    """
    Interpolate velocity field to a regular grid using RBFs.

    Inputs:
      x, y, u, v: (n_traj, n_points) or (n_samples,) arrays
      grid_size: number of grid points per dimension
      z_lim: if 0, use bounding box of data; otherwise [-z_lim, z_lim]^2
      function: RBF type ('multiquadric', 'inverse', 'gaussian', 'linear', etc.)
      epsilon: shape parameter; if None, Rbf chooses something heuristic
      smooth: smoothing parameter passed to Rbf (regularization)

    Returns:
      xi, yi, ui, vi: all (grid_size, grid_size) arrays
    """
    x_flat = x.flatten()
    y_flat = y.flatten()
    u_flat = u.flatten()
    v_flat = v.flatten()

    # Domain limits
    if z_lim == 0:
        x_min, x_max = x_flat.min() - 1, x_flat.max() + 1
        y_min, y_max = y_flat.min() - 1, y_flat.max() + 1
        z_min = min(x_min, y_min)
        z_max = max(x_max, y_max)
    else:
        z_min, z_max = -z_lim, z_lim

    xi, yi = np.meshgrid(np.linspace(z_min, z_max, grid_size),
                         np.linspace(z_min, z_max, grid_size))

    # One RBF for u, one for v
    rbfu = Rbf(
        x_flat, y_flat, u_flat,
        function=method,
        epsilon=epsilon,
        smooth=smooth
    )
    rbfv = Rbf(
        x_flat, y_flat, v_flat,
        function=method,
        epsilon=epsilon,
        smooth=smooth
    )

    ui = rbfu(xi, yi)
    vi = rbfv(xi, yi)

    return xi, yi, ui, vi
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

from scipy.ndimage import gaussian_filter1d, gaussian_filter
from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator

def create_field(x, y, u, v, grid_size=100, method='linear', z_lim=5):
    """
    Interpolate velocity field to a regular grid.

    Inputs:
      x, y, u, v: (n_traj, n_points) or (n_samples,) arrays
      grid_size: number of grid points per dimension
      method: 'linear' (via LinearNDInterpolator) or any method supported
              by griddata ('linear', 'nearest', 'cubic') if not 'linear' here.
      z_lim: if 0, use bounding box of data; otherwise domain = [-z_lim, z_lim]^2

    Returns:
      xi, yi, ui, vi: all (grid_size, grid_size) arrays
    """
    x_flat = x.flatten()
    y_flat = y.flatten()
    u_flat = u.flatten()
    v_flat = v.flatten()

    # Domain limits
    if z_lim == 0:
        x_min, x_max = x_flat.min() - 1, x_flat.max() + 1
        y_min, y_max = y_flat.min() - 1, y_flat.max() + 1
        z_min = min(x_min, y_min)
        z_max = max(x_max, y_max)
    else:
        z_min, z_max = -z_lim, z_lim

    xi, yi = np.meshgrid(np.linspace(z_min, z_max, grid_size),
                         np.linspace(z_min, z_max, grid_size))

    # Interpolation
    if method == 'linear':
        # Use LinearNDInterpolator + NearestNDInterpolator fallback
        pts = np.column_stack((x_flat, y_flat))
        lin_u = LinearNDInterpolator(pts, u_flat)
        lin_v = LinearNDInterpolator(pts, v_flat)

        ui = lin_u(xi, yi)
        vi = lin_v(xi, yi)

        mask = np.isnan(ui)
        if np.any(mask):
            near_u = NearestNDInterpolator(pts, u_flat)
            near_v = NearestNDInterpolator(pts, v_flat)
            ui[mask] = near_u(xi[mask], yi[mask])
            vi[mask] = near_v(xi[mask], yi[mask])
    else:
        from scipy.interpolate import griddata
        ui = griddata((x_flat, y_flat), u_flat, (xi, yi),
                      method=method, fill_value=np.nan)
        vi = griddata((x_flat, y_flat), v_flat, (xi, yi),
                      method=method, fill_value=np.nan)

        mask = np.isnan(ui)
        if np.any(mask):
            ui[mask] = griddata((x_flat, y_flat), u_flat, (xi, yi),
                                method='nearest')[mask]
            vi[mask] = griddata((x_flat, y_flat), v_flat, (xi, yi),
                                method='nearest')[mask]

    return xi, yi, ui, vi
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def get_mean_velo(r_s, dr_s, n_bins=32, z_lim=10):

    r_all  = r_s.flatten()
    dr_all = dr_s.flatten()

    bins = np.linspace(np.nanmin(r_all), np.nanmax(r_all), n_bins)

    bin_centers = 0.5*(bins[:-1] + bins[1:])
    digitized = np.digitize(r_all, bins)

    dr_mean = np.array([np.nanmean(dr_all[digitized == i]) for i in range(1, len(bins))])

    return dr_mean, bins, bin_centers, digitized
#+end_src

#+RESULTS:

* Parameters

#+begin_src jupyter-python
old_mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
Jaws_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18']

mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
# mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23']
# mice = ['JawsM15', 'JawsM18', 'ChRM04']

tasks = ['Dual'] # all

kwargs = {
   'mice': mice,
   'tasks': tasks,
   'mouse': mice[0], 'laser': 0,
   'trials': '', 'reload': 0, 'data_type': 'dF',
   'prescreen': None, 'pval': 0.05,
   'preprocess': False, 'scaler_BL': 'standard',
   'avg_noise':False, 'unit_var_BL': False,
   'random_state': None, 'T_WINDOW': 0.0,
   'l1_ratio': 0.95,
   'n_comp': 3, 'pca': 'pca',
   'scaler': None,
   'bootstrap': 1, 'n_boots': 128,
   'n_splits': 5, 'n_repeats': 10,
   'class_weight': 0,
   'multilabel': 0,
   'mne_estimator':'generalizing', # sliding or generalizing
   'n_jobs': 64,
}

# kwargs['days'] = ['first', 'middle', 'last']
kwargs['days'] = ['first', 'last']
# kwargs['days'] = 'all'
options = set_options(**kwargs)
options['cv_B'] = False
#+end_src

#+RESULTS:

* Load Data

#+begin_src jupyter-python
X_trials, y_trials = [], []

n_neurons = 3319
counter = 0
for mouse in options['mice']:

    options['mouse'] = mouse
    options = set_options(**options)
    X, y = get_X_y_days(**options)

    print(mouse, X.shape, y.shape, options['n_days'])

    X_scale = X.copy()
    for day in range(1, options['n_days']+1):
        # idx = (y.day==day) & (y.laser==0) & (y.performance==1)
        idx = (y.day==day) & (y.laser==0)

        mean_ = np.nanmean(X[idx], 0, keepdims=1)
        std_ = np.nanstd(X[idx], (0, -1), keepdims=1)
        std_ = np.where(std_<=1e-2, 1, std_)

        X_scale[idx] = (X[idx] - mean_) / std_

        # idx = (y.day==day) & ((y.laser==1) | (y.performance==0))
        idx = (y.day==day) & (y.laser==1)
        X_scale[idx] = (X[idx] - mean_) / std_

        # for tasks in ['DPA', 'DualGo', 'DualNoGo']:
        #     idx = (y.day==day) & (y.laser==0) & (y.tasks==tasks)

        #     mean_ = np.nanmean(X[idx], 0, keepdims=1)
        #     std_ = np.nanstd(X[idx], (0, -1), keepdims=1)
        #     std_ = np.where(std_==0, 1, std_)

        #     X_scale[idx] = (X[idx] - mean_) / std_

        #     idx = (y.day==day) & (y.laser==1) & (y.tasks==tasks)
        #     X_scale[idx] = (X[idx] - mean_) / std_

    X_trial = np.zeros((X.shape[0], n_neurons, X.shape[-1])) * np.nan
    X_trial[:, counter:X.shape[1]+counter, :] = X_scale

    counter += X.shape[1]

    X_trials.append(X_trial)

    y['mouse'] = mouse
    y_trials.append(y)

X_trials = np.array(X_trials, dtype=object)
y_trials = np.array(y_trials, dtype=object)
#+end_src

#+RESULTS:
: JawsM01 (768, 184, 84) (768, 15) 4
: JawsM06 (1152, 201, 84) (1152, 15) 6
: JawsM12 (960, 423, 84) (960, 15) 5
: JawsM15 (1152, 693, 84) (1152, 15) 6
: JawsM18 (1152, 444, 84) (1152, 15) 6
: ChRM04 (1152, 668, 84) (1152, 15) 6
: ChRM23 (960, 232, 84) (960, 15) 5
: ACCM03 (960, 361, 84) (960, 15) 5
: ACCM04 (960, 113, 84) (960, 15) 5

#+begin_src python
X_trials, y_trials = [], []
mouse_slices = {}

n_neurons_total = 3319
counter = 0

for mouse in options['mice']:
    options['mouse'] = mouse
    options = set_options(**options)
    X, y = get_X_y_days(**options)   # X: (n_trials, n_neur_mouse, n_time)

    n_mouse_neur = X.shape[1]
    sl = slice(counter, counter + n_mouse_neur)
    mouse_slices[str(mouse)] = sl

    # ---- per-day scaling using laser==0 as reference ----
    X_scale = X.copy()
    for day in range(1, options['n_days'] + 1):
        idx0 = (y.day == day) & (y.laser == 0)
        mean_ = np.nanmean(X[idx0], axis=0, keepdims=True)                 # (1, n_neur, T)

        std_  = np.nanstd (X[idx0], axis=(0, -1), keepdims=True)           # (1, n_neur, 1)
        std_  = np.where(std_ <= 1e-2, 1.0, std_)

        idxd = (y.day == day)
        X_scale[idxd] = (X[idxd] - mean_) / std_

    # ---- mouse-level gain (optional but recommended for global PCA) ----
    # choose clean trials to estimate gain (match your later m_clean)
    idx_clean = (y.laser == 0) & (y.performance == 1)
    Xm = X_scale[idx_clean]  # (n_clean_trials, n_neur_mouse, T)

    # RMS-based gain; after z-scoring s2 ~ 1, but this also controls for mouse/neuron-count dominance
    s2 = np.nanmean(Xm**2)
    g = 1.0 / (np.sqrt(s2) + 1e-8)

    # if you want each mouse to contribute ~equally regardless of neuron count:
    g = g / (np.sqrt(n_mouse_neur) + 1e-8)

    X_scale = X_scale * g

    # ---- pad into global neuron axis (use zeros, not NaNs) ----
    X_trial = np.zeros((X.shape[0], n_neurons_total, X.shape[-1]), dtype=np.float32)
    X_trial[:, sl, :] = np.nan_to_num(X_scale, nan=0.0, posinf=0.0, neginf=0.0)

    counter += n_mouse_neur

    X_trials.append(X_trial)
    y = y.copy()
    y["mouse"] = str(mouse)
    y_trials.append(y)

# stack across mice/trials as you prefer later
X_trials = np.array(X_trials, dtype=object)
y_trials = np.array(y_trials, dtype=object)
#+end_src


#+begin_src jupyter-python
X_trials, y_trials = [], []
mouse_slices = {}

n_neurons_total = 3319
counter = 0

for mouse in options['mice']:
    options['mouse'] = mouse
    options = set_options(**options)
    X, y = get_X_y_days(**options)   # X: (n_trials, n_neur_mouse, n_time)

    n_mouse_neur = X.shape[1]
    sl = slice(counter, counter + n_mouse_neur)
    mouse_slices[str(mouse)] = sl

    # ---- per-day scaling using laser==0 as reference ----
    X_scale = X.copy()
    for day in range(1, options['n_days'] + 1):
        idx0 = (y.day == day) & (y.laser == 0)
        mean_ = np.nanmean(X[idx0], axis=0, keepdims=True)                 # (1, n_neur, T)
        std_  = np.nanstd (X[idx0], axis=(0, -1), keepdims=True)           # (1, n_neur, 1)
        std_  = np.where(std_ <= 1e-2, 1.0, std_)

        idxd = (y.day == day)
        X_scale[idxd] = (X[idxd] - mean_) / std_

    # ---- mouse-level gain (optional but recommended for global PCA) ----
    # choose clean trials to estimate gain (match your later m_clean)
    idx_clean = (y.laser == 0) & (y.performance == 1)
    Xm = X_scale[idx_clean]  # (n_clean_trials, n_neur_mouse, T)

    # RMS-based gain; after z-scoring s2 ~ 1, but this also controls for mouse/neuron-count dominance
    s2 = np.nanmean(Xm**2)
    g = 1.0 / (np.sqrt(s2) + 1e-8)

    # if you want each mouse to contribute ~equally regardless of neuron count:
    g = g / (np.sqrt(n_mouse_neur) + 1e-8)

    X_scale = X_scale * g

    # ---- pad into global neuron axis (use zeros, not NaNs) ----
    X_trial = np.zeros((X.shape[0], n_neurons_total, X.shape[-1]), dtype=np.float32)
    X_trial[:, sl, :] = np.nan_to_num(X_scale, nan=0.0, posinf=0.0, neginf=0.0)

    counter += n_mouse_neur

    X_trials.append(X_trial)
    y = y.copy()
    y["mouse"] = str(mouse)
    y_trials.append(y)

# stack across mice/trials as you prefer later
X_trials = np.array(X_trials, dtype=object)
y_trials = np.array(y_trials, dtype=object)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
X_all = np.concatenate(X_trials, 0)
y_all = pd.concat(y_trials)
print(X_all.shape, y_all.shape)
#+end_src

#+RESULTS:
: (9216, 3319, 84) (9216, 16)

#+begin_src jupyter-python
pkl_save(X_all, 'X_all', path="../data/pca")
pkl_save(y_all, 'y_all', path="../data/pca")
#+end_src

#+RESULTS:
: saving to ../data/pca/X_all.pkl
: saving to ../data/pca/y_all.pkl

* Meta Mouse
** Load

#+begin_src jupyter-python
X_all = pkl_load('X_all', path="../data/pca")
y_all = pkl_load('y_all', path="../data/pca")
#+end_src

#+RESULTS:
: loading from ../data/pca/X_all.pkl
: loading from ../data/pca/y_all.pkl

#+begin_src jupyter-python
y_all['sample'] = y_all.sample_odor
y_all['test'] = y_all.test_odor
#+end_src

#+RESULTS:

#+begin_src jupyter-python
print(y_all.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response', 'laser',
:        'day', 'choice', 'pair', 'odr_perf', 'odr_choice', 'odr_response',
:        'odor_pair', 'learning', 'performance', 'mouse', 'sample', 'test'],
:       dtype='object')

** Model

#+begin_src jupyter-python
import numpy as np
import pandas as pd
import itertools
from functools import reduce
import operator
from tqdm import tqdm
from scipy.linalg import orthogonal_procrustes

def nan_to_zero(X):
    return np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

def cv_avg_cond(X, y, condition='odor_pair', levels=None):
    if isinstance(condition, str):
        condition = [condition]

    if levels is None:
        unique_vals = [list(pd.unique(y[c])) for c in condition]
    else:
        unique_vals = [list(levels[c]) for c in condition]

    combos = list(itertools.product(*unique_vals))

    X_avg = []
    for combo in combos:
        idx = reduce(operator.and_, [(y[c] == v) for c, v in zip(condition, combo)])
        if idx.any():
            X_avg.append(np.nanmean(X[idx], axis=0))
        else:
            X_avg.append(np.full_like(X[0], np.nan))

    return np.asarray(X_avg)

def align_fold_to_ref(W_fold, W_ref, X_pca_fold):
    if W_ref is None:
        return X_pca_fold, W_fold

    # (W_fold.T @ R) ~= W_ref.T, R is (n_comp, n_comp)
    R, _ = orthogonal_procrustes(W_fold.T, W_ref.T)

    n_trials, T, n_comp = X_pca_fold.shape
    X_flat = X_pca_fold.reshape(-1, n_comp)
    X_aligned = (X_flat @ R).reshape(n_trials, T, n_comp)

    W_aligned = (R.T @ W_fold)
    return X_aligned, W_aligned

def cv_pca(
    X, y, pca, folds, factors, epoch,
    group_col=None,
    levels=None,
    show_pbar=True,
):
    # clean subset used for fitting + CV
    m_clean = (y.laser == 0) & (y.performance == 1)

    Xc = X[m_clean]
    yc = y.loc[m_clean].reset_index(drop=True)

    groups = None
    if group_col is not None:
        groups = yc[group_col].astype(str).values

    strata = (
        yc["odor_pair"].astype(str)
        + "_" + yc["mouse"].astype(str)
        + "_" + yc["day"].astype(str)
        + "_" + yc["tasks"].astype(str)
    ).values

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    w_ref = None

    it = folds.split(Xc, strata, groups=groups)
    if show_pbar:
        it = tqdm(it, total=folds.get_n_splits(Xc, strata), desc=str(y.mouse.unique()[0]))

    for fold, (train, test) in enumerate(it):
        X_train, y_train = Xc[train], yc.iloc[train]
        X_test,  y_test  = Xc[test],  yc.iloc[test]

        X_train_epoch = X_train if epoch is None else X_train[..., epoch]

        # mean from trialwise training data (ignore NaNs)
        X_train_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_flat, axis=0, keepdims=True)

        # Xb = X_train[..., :11]                      # (trials, neurons, tb)
        # Xb_flat = Xb.transpose(0,2,1).reshape(-1, X.shape[1])
        # X_mean = np.nanmean(Xb_flat, axis=0, keepdims=True)

        # fit PCA on condition averages
        X_avg_epoch = cv_avg_cond(X_train_epoch, y_train, condition=factors, levels=levels)
        X_avg_flat  = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
        X_cent = nan_to_zero(X_avg_flat - X_mean)

        pca.fit(X_cent)
        w_fold = pca.components_
        evr_folds.append(pca.explained_variance_ratio_)

        # project test trials
        X_test_flat = X_test.transpose(0, 2, 1).reshape(-1, X_test.shape[1])
        X_cent_test = nan_to_zero(X_test_flat - X_mean)
        X_out = pca.transform(X_cent_test).reshape(X_test.shape[0], X_test.shape[-1], -1)

        X_aligned, w_aligned = align_fold_to_ref(w_fold, w_ref, X_out)

        if w_ref is None:
            w_ref = w_fold

        X_folds.append(X_aligned)
        y_folds.append(y_test)
        w_folds.append(w_aligned)

    # ---- end CV: concatenate + average weights ----
    X_folds = np.concatenate(X_folds, axis=0)
    y_folds = pd.concat(y_folds, axis=0)

    w_folds = np.mean(np.stack(w_folds, axis=0), axis=0)
    evr_folds = np.asarray(evr_folds, dtype=object)

    # ---- refit PCA on ALL clean data (condition averages) for perturbation projection ----
    Xc_epoch = Xc if epoch is None else Xc[..., epoch]

    Xc_flat = Xc_epoch.transpose(0, 2, 1).reshape(-1, Xc_epoch.shape[1])
    X_mean = np.nanmean(Xc_flat, axis=0, keepdims=True)

    # Xb = Xc[..., :11]                      # (trials, neurons, tb)
    # Xb_flat = Xb.transpose(0,2,1).reshape(-1, X.shape[1])
    # X_mean = np.nanmean(Xb_flat, axis=0, keepdims=True)

    X_avg_epoch = cv_avg_cond(Xc_epoch, yc, condition=factors, levels=levels)
    X_avg_flat  = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
    X_cent = nan_to_zero(X_avg_flat - X_mean)

    pca.fit(X_cent)
    w_fold = pca.components_

    # ---- project perturbed trials (laser==1 or performance!=1 etc) ----
    m_pert = ~m_clean
    if m_pert.mean() != 0:
        Xp = X[m_pert]
        yp = y.loc[m_pert].reset_index(drop=True)

        Xp_flat = Xp.transpose(0, 2, 1).reshape(-1, Xp.shape[1])
        X_centp = nan_to_zero(Xp_flat - X_mean)
        X_out = pca.transform(X_centp).reshape(Xp.shape[0], Xp.shape[-1], -1)

        Xp_aligned, _ = align_fold_to_ref(w_fold, w_ref, X_out)

        Z_all = np.concatenate([X_folds, Xp_aligned], axis=0)
        y_all = pd.concat([y_folds, yp], axis=0, ignore_index=True)

        return Z_all, y_all, w_folds, evr_folds

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import pandas as pd
from tqdm import tqdm
from scipy.linalg import orthogonal_procrustes

# ---------- helpers: anchors + mouse equalization ----------

def _anchors_from_Z(Z, y_df, factor="odor_pair"):
    """
    Anchors = condition-averaged latent trajectories.
    Z: (n_trials, n_time, n_comp)
    Returns A: (n_cond*n_time, n_comp) with consistent condition order.
    """
    conds = np.unique(y_df[factor].values)
    conds = np.sort(conds.astype(str))

    yf = y_df[factor].astype(str).values
    A = []
    for c in conds:
        m = (yf == c)
        A.append(np.nanmean(Z[m], axis=0))  # (n_time, n_comp)
    A = np.stack(A, axis=0)                # (n_cond, n_time, n_comp)
    return A.reshape(-1, Z.shape[-1])


def fit_mouse_scales(X_train, y_train, epoch=None, target="median", eps=1e-12):
    """
    Fit per-mouse scalar scales so that each mouse has equal mean per-neuron variance.
    Uses TRAIN data only. Works with NaN-padded neuron dimensions (ignored by nanvar).
    """
    Xe = X_train if epoch is None else X_train[..., epoch]
    mice = y_train["mouse"].astype(str).values
    uniq = np.unique(mice)

    v = {}
    for m in uniq:
        idx = (mice == m)
        Xm = Xe[idx]  # (n_trials_m, n_neurons_total, n_time_epoch)

        # per-neuron variance across trials and time
        vn = np.nanvar(Xm, axis=(0, 2))
        vn = vn[np.isfinite(vn)]  # drop padded neurons (NaNs)
        v[m] = np.nanmean(vn)

    vals = np.array([v[m] for m in uniq], float)
    v_tgt = np.nanmedian(vals) if target == "median" else np.nanmean(vals)

    scales = {m: np.sqrt(v_tgt / (v[m] + eps)) for m in uniq}
    return scales


def apply_mouse_scales(X, y, scales):
    """Apply pre-fit scales dict(mouse->scalar) to all trials of that mouse."""
    Xs = X.copy()
    mice = y["mouse"].astype(str).values
    for m, s in scales.items():
        idx = (mice == m)
        Xs[idx] = Xs[idx] * s
    return Xs


# ---------- main ----------

def cv_pca(
    X, y, pca, folds, factors, epoch,
    group_col=None,
    show_pbar=True,
    equalize_mice=True,
    equalize_target="median",
):
    """
    CV PCA with:
      - PCA fit on TRAIN condition-averages restricted to `epoch`
      - fold alignment learned from TRAIN projections in `epoch` (anchors in score space)
      - TEST projections returned for FULL time
      - optional per-mouse variance equalization (fit on TRAIN only per fold)
      - optional "fit on all clean" model to project perturbed data, using scales fit on clean

    Inputs
    ------
    X: (n_trials, n_neurons_total, n_time), can be NaN-padded for absent neurons.
    y: DataFrame aligned with X trials, must contain:
         ['laser','performance','tasks','odr_perf','mouse','day','odor_pair', ...]
    pca: sklearn PCA-like object
    folds: splitter with .split(X, y, groups=...)
    factors: column name defining condition for anchors and cv_avg_cond (e.g. "odor_pair")
    epoch: None or time indices/slice used for fitting/alignment only
    group_col: optional column for GroupKFold-type split
    """

    # ---- clean subset used for fitting + CV
    m_clean = (y.laser == 0) & (y.performance == 1) & ((y.tasks == "DPA") | (y.odr_perf == 1))
    Xc = X[m_clean]
    yc = y.loc[m_clean].reset_index(drop=True)

    groups = None
    if group_col is not None:
        groups = yc[group_col].astype(str).values

    # your original strata
    strata = (
        yc["odor_pair"].astype(str)
        + "_" + yc["mouse"].astype(str)
        + "_" + yc["day"].astype(str)
        + "_" + yc["tasks"].astype(str)
    ).values

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    A_ref = None  # reference anchors (fold-0 train, score space)

    it = folds.split(Xc, strata, groups=groups)
    if show_pbar:
        it = tqdm(it, total=folds.get_n_splits(Xc, strata), desc=str(y.mouse.unique()[0]))

    # ===================== CV loop =====================
    for fold, (train, test) in enumerate(it):
        X_train, y_train = Xc[train], yc.iloc[train].reset_index(drop=True)
        X_test,  y_test  = Xc[test],  yc.iloc[test].reset_index(drop=True)

        # ---- optional equalize mouse contribution (fit on TRAIN only)
        if equalize_mice:
            scales = fit_mouse_scales(X_train, y_train, epoch=epoch, target=equalize_target)
            X_train = apply_mouse_scales(X_train, y_train, scales)
            X_test  = apply_mouse_scales(X_test,  y_test,  scales)

        # epoch-restricted arrays for fitting/alignment
        X_train_epoch = X_train if epoch is None else X_train[..., epoch]
        X_test_epoch  = X_test  if epoch is None else X_test[..., epoch]

        # FULL time arrays for final output
        X_test_full = X_test

        # mean computed on TRAIN epoch only
        X_train_epoch_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_epoch_flat, axis=0, keepdims=True)

        # fit PCA on TRAIN condition-averages in epoch
        X_avg_epoch = cv_avg_cond(X_train_epoch, y_train, factors)  # (n_cond, n_neurons, n_time_epoch)
        X_avg_flat  = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
        X_cent_fit  = X_avg_flat - X_mean

        pca.fit(X_cent_fit)
        W_fold = pca.components_  # (n_comp, n_neurons)
        evr_folds.append(pca.explained_variance_ratio_)

        # project TRAIN epoch -> anchors -> rotation R
        Z_train_epoch = pca.transform(X_train_epoch_flat - X_mean).reshape(
            X_train_epoch.shape[0], X_train_epoch.shape[-1], -1
        )
        A_train = _anchors_from_Z(Z_train_epoch, y_train, factor=factors)

        if A_ref is None:
            A_ref = A_train
            R = np.eye(Z_train_epoch.shape[-1])
        else:
            R, _ = orthogonal_procrustes(A_train, A_ref)  # (n_comp, n_comp)

        # project TEST FULL time, then rotate
        X_test_full_flat = X_test_full.transpose(0, 2, 1).reshape(-1, X_test_full.shape[1])
        Z_test_full = pca.transform(X_test_full_flat - X_mean).reshape(
            X_test_full.shape[0], X_test_full.shape[-1], -1
        )

        Z_test_aligned = Z_test_full @ R
        W_fold_aligned = (R.T @ W_fold)

        X_folds.append(Z_test_aligned)
        y_folds.append(y_test)
        w_folds.append(W_fold_aligned)

    # ---- collect CV outputs
    X_folds = np.concatenate(X_folds, axis=0)
    y_folds = pd.concat(y_folds, axis=0, ignore_index=True)
    w_folds = np.mean(np.stack(w_folds, axis=0), axis=0)
    evr_folds = np.array(evr_folds, dtype=object)

    # ===================== fit on ALL clean + project perturbed =====================
    m_pert = ~m_clean
    if m_pert.mean() == 0:
        return X_folds, y_folds, w_folds, evr_folds

    Xp = X[m_pert]
    yp = y.loc[m_pert].reset_index(drop=True)

    # ---- optional equalize using scales fit on ALL CLEAN only, then apply to CLEAN+PERT
    if equalize_mice:
        scales_all = fit_mouse_scales(Xc, yc, epoch=epoch, target=equalize_target)
        Xc_s = apply_mouse_scales(Xc, yc, scales_all)
        Xp_s = apply_mouse_scales(Xp, yp, scales_all)
    else:
        Xc_s = Xc
        Xp_s = Xp

    # fit PCA on scaled CLEAN epoch
    Xc_epoch = Xc_s if epoch is None else Xc_s[..., epoch]
    Xc_epoch_flat = Xc_epoch.transpose(0, 2, 1).reshape(-1, Xc_epoch.shape[1])
    X_mean_all = np.nanmean(Xc_epoch_flat, axis=0, keepdims=True)

    X_avg_epoch_all = cv_avg_cond(Xc_epoch, yc, factors)
    X_avg_flat_all  = X_avg_epoch_all.transpose(0, 2, 1).reshape(-1, X_avg_epoch_all.shape[1])
    X_cent_all = X_avg_flat_all - X_mean_all

    pca.fit(X_cent_all)

    # reference anchors from CLEAN epoch projections (same anchor definition as CV alignment)
    Zc_epoch = pca.transform(Xc_epoch_flat - X_mean_all).reshape(
        Xc_epoch.shape[0], Xc_epoch.shape[-1], -1
    )
    A_ref_all = _anchors_from_Z(Zc_epoch, yc, factor=factors)

    # project PERTURBED FULL time
    Xp_full_flat = Xp_s.transpose(0, 2, 1).reshape(-1, Xp_s.shape[1])
    Zp_full = pca.transform(Xp_full_flat - X_mean_all).reshape(
        Xp_s.shape[0], Xp_s.shape[-1], -1
    )

    # compute perturbed epoch anchors to estimate rotation into CLEAN anchor space
    Xp_epoch = Xp_s if epoch is None else Xp_s[..., epoch]
    Xp_epoch_flat = Xp_epoch.transpose(0, 2, 1).reshape(-1, Xp_epoch.shape[1])
    Zp_epoch = pca.transform(Xp_epoch_flat - X_mean_all).reshape(
        Xp_epoch.shape[0], Xp_epoch.shape[-1], -1
    )
    A_p = _anchors_from_Z(Zp_epoch, yp, factor=factors)

    R_p, _ = orthogonal_procrustes(A_p, A_ref_all)
    Zp_aligned = Zp_full @ R_p

    Z_all = np.concatenate([X_folds, Zp_aligned], axis=0)
    y_all = pd.concat([y_folds, yp], axis=0, ignore_index=True)
    return Z_all, y_all, w_folds, evr_folds
#+end_src

#+RESULTS:

#+begin_src jupyter-python
options['learning'] = 'Expert'
options['epochs'] = ['POST_GNG']
epoch = options['bins_' + options['epochs'][0]]

factors = 'odor_pair'
# factors = ['sample', 'tasks', 'test']
# factors = ['sample', 'choice', 'test']
#+end_src

#+RESULTS:

#+begin_src jupyter-python
idx = (y_all.learning == options['learning']) # & (y_all.tasks=='DPA')  # & (~y_all['mouse'].str.contains('ACC')) # & (y_all.laser==options['laser'])

X_pca = X_all[idx]
y_pca = y_all[idx]

pca_mask = np.isnan(X_pca)
X_pca[pca_mask] = 0

print(X_pca.shape, y_pca.shape)
#+end_src

#+RESULTS:
: (4032, 3319, 84) (4032, 18)

#+begin_src jupyter-python
n_splits = 5
n_repeats = 1
n_comp = 3

pca = PCA(n_components=n_comp, svd_solver='randomized')
folds = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
# X_cv, y_cv, w_cv, evr_cv = cross_val_avg_pca(X_pca, y_pca, pca, folds, factors, epoch)
X_cv, y_cv, w_cv, evr_cv = cv_pca(X_pca, y_pca, pca, folds, factors, epoch)
#+end_src

#+RESULTS:
: JawsM01: 100% 5/5 [08:20<00:00, 100.05s/it]

#+begin_src jupyter-python
print(X_cv.shape, y_cv.shape, w_cv.shape, evr_cv.shape)
#+end_src

#+RESULTS:
: (4032, 84, 3) (4032, 18) (3, 3319) (5, 3)

#+begin_src jupyter-python
X_meta = np.array(X_cv, dtype=float)
X_meta = np.swapaxes(X_meta, 1, 2)
y_meta = y_cv
evr_meta = evr_cv
w_meta = np.mean(w_cv, 0, dtype=float) * 100
w_meta = w_cv * 100
print(X_meta.shape, y_meta.shape, w_meta.shape)
#+end_src

#+RESULTS:
: (4032, 3, 84) (4032, 18) (3, 3319)

** Save/Load

#+begin_src jupyter-python
dum = options['epochs'][0] + '_' + options['learning'] + '_laser_%d' % options['laser']
print(dum)
#+end_src

#+RESULTS:
: POST_GNG_Expert_laser_0

#+begin_src jupyter-python
pkl_save(X_meta, 'meta_traj_' + dum, path="../data/pca/")
pkl_save(y_meta, 'meta_labels_' + dum, path="../data/pca/")
pkl_save(w_meta, 'meta_weights_' + dum, path="../data/pca/")
pkl_save(evr_meta, 'meta_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: saving to ../data/pca//meta_traj_POST_GNG_Expert_laser_0.pkl
: saving to ../data/pca//meta_labels_POST_GNG_Expert_laser_0.pkl
: saving to ../data/pca//meta_weights_POST_GNG_Expert_laser_0.pkl
: saving to ../data/pca//meta_evr_POST_GNG_Expert_laser_0.pkl

 #+begin_src jupyter-python
X_meta = pkl_load('meta_traj_' + dum, path="../data/pca/")
y_meta = pkl_load( 'meta_labels_' + dum, path="../data/pca/")
w_meta = pkl_load( 'meta_weights_' + dum, path="../data/pca/")
evr_meta = pkl_load( 'meta_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: loading from ../data/pca//meta_traj_POST_GNG_Expert_laser_0.pkl
: loading from ../data/pca//meta_labels_POST_GNG_Expert_laser_0.pkl
: loading from ../data/pca//meta_weights_POST_GNG_Expert_laser_0.pkl
: loading from ../data/pca//meta_evr_POST_GNG_Expert_laser_0.pkl

** Trajectories

#+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse = -1

idx_correct = 1 # (y_meta.performance==1)
idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_meta.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height),)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = ['AC', 'AD', 'BD', 'BC']
xtime = np.linspace(0, 14, 84)

for i in range(4):
    mask = (y_meta.odor_pair==i) & (y_meta.laser==laser) & idx_mouse & idx_correct
    X_sel = X_meta[mask] * 10

    X_avg = np.mean(X_sel, 0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = np.std(X_sel, 0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)

        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_odor_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_39.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = y_meta.tasks.unique()
xtime = np.linspace(0, 14, 84)

for i in range(len(pair)):
    mask = (y_meta.tasks==y_meta.tasks.unique()[i]) & (y_meta.laser==laser) & idx_mouse & idx_correct
    X_sel = X_meta[mask]

    X_avg = X_sel.mean(0)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=0)

        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_task_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_40.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#984ea3", "#4daf4a", "#ffae19"]

pair = ['A', 'B']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.sample_odor==i) & (y_meta.laser==laser) & idx_mouse & idx_correct
    X_sel = X_meta[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_sample_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_41.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8",  "#ffae19"]

pair = ['unpair', 'pair']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.pair==i) & (y_meta.laser==laser) & idx_mouse & idx_correct
    X_sel = X_meta[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_42.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['nolick', 'lick']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.choice==i) & (y_meta.laser==laser) & idx_mouse & idx_correct
    X_sel = X_meta[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_choice_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_43.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['C', 'D']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_meta.test_odor==i) & (y_meta.laser==laser) & idx_mouse & idx_correct
    X_sel = X_meta[mask]
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.savefig('./figures/pca/pca_test_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_44.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

pair = ['AC', 'AD', 'BD', 'BC']

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

for i in range(4):
    idx = (y_meta.odor_pair==i) & (y_meta.laser==laser) & idx_mouse & idx_correct

    X_avg = (X_meta[idx].mean(0))[:, :66]

    ax[0].plot(X_avg[0], X_avg[1], color=color[i], label=pair[i])
    ax[0].set_xlabel('PC 1')
    ax[0].set_ylabel('PC 2')

    ax[1].plot(X_avg[0], X_avg[2], color=color[i], label=pair[i])
    ax[1].set_xlabel('PC 1')
    ax[1].set_ylabel('PC 3')

    ax[2].plot(X_avg[1], X_avg[2], color=color[i], label=pair[i])
    ax[2].set_xlabel('PC 2')
    ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_45.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Embeddings
*** spatial filter

#+begin_src jupyter-python
z_lim =5
size = 0.1

import cmocean
cmap=cmocean.cm.phase

theta = np.arctan2(w_meta[1], w_meta[0]) * 180 / np.pi
idx = np.argsort(theta)

theta_norm = (theta+ 360) % (360)

counts, bins, patches = plt.hist(theta_norm, bins='auto', range=(0, 360), density=1)

bin_centers = 0.5*(bins[:-1] + bins[1:])
colors = [cmap(center/(360)) for center in bin_centers]

for patch, color in zip(patches, colors):
    patch.set_facecolor(color)

plt.xlabel('Neuron Loc (Â°)')
plt.ylabel('Density')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_46.png]]

 #+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for k in range(n_comp):
    sc = ax[k].scatter(theta[idx], w_meta[k][idx], alpha=0.5, c=theta_norm[idx], cmap=cmap, rasterized=1)
    ax[k].plot(theta[idx], gaussian_filter1d(w_meta[k][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')
    ax[k].axhline(0, ls='--', color='k')
    ax[k].set_ylabel('Weights PC %d' % (k+1))
    ax[k].set_xlabel('Neuron Loc (Â°)')
    ax[k].set_ylim([-z_lim, z_lim])

ax[-1].set_ylim([-z_lim/10, z_lim/10])
plt.colorbar(sc, ax=ax[-1], label='Angle (Â°)')
plt.savefig('./figures/pca/pca_weights_%s.svg' % dum)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_47.png]]

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width))

ax[0].scatter(w_meta[0][idx], w_meta[1][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[0].plot(gaussian_filter1d(w_meta[0][idx], int(size*w_meta.shape[1]), mode='wrap'), gaussian_filter1d(w_meta[1][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')

ax[0].set_xlabel('PC 1')
ax[0].set_ylabel('PC 2')

ax[1].scatter(w_meta[0][idx], w_meta[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[1].plot(gaussian_filter1d(w_meta[0][idx], int(size*w_meta.shape[1]), mode='wrap'), gaussian_filter1d(w_meta[2][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')
ax[1].set_xlabel('PC 1')
ax[1].set_ylabel('PC 3')

sc = ax[2].scatter(w_meta[1][idx], w_meta[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[2].plot(gaussian_filter1d(w_meta[1][idx], int(size*w_meta.shape[1]), mode='wrap'), gaussian_filter1d(w_meta[2][idx], int(size*w_meta.shape[1]), mode='wrap'), 'k')
ax[2].set_xlabel('PC 2')
ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].set_xlim(-z_lim, z_lim)
    ax[k].set_ylim(-z_lim, z_lim)

ax[1].set_ylim(-z_lim/10, z_lim/10)
ax[2].set_ylim(-z_lim/10, z_lim/10)

plt.colorbar(sc, ax=ax[-1], label='Angle (Â°)')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_48.png]]

#+begin_src jupyter-python
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

ax.plot(gaussian_filter1d(w_meta[0][idx], int(size*w_meta.shape[1]), mode='wrap'),
           gaussian_filter1d(w_meta[1][idx], int(size*w_meta.shape[1]), mode='wrap'),
           gaussian_filter1d(w_meta[2][idx], int(size*w_meta.shape[1]), mode='wrap'),
           rasterized=1, color='k')


sc = ax.scatter(w_meta[0][idx],
                w_meta[1][idx],
                w_meta[2][idx],
                c=theta_norm[idx], cmap=cmap,
                rasterized=1, alpha=0.5)

ax.tick_params(axis='both', which='major', labelsize=12)  # change both x and y (and z in 3D)
ax.tick_params(axis='z', which='major', labelsize=12)     # for the z-axis specifically

ax.set_xlabel('PC 1', fontsize=12)
ax.set_ylabel('PC 2', fontsize=12)
ax.set_zlabel('PC 3', fontsize=12)

ax.set_xlim([-z_lim, z_lim])
ax.set_ylim([-z_lim, z_lim])
ax.set_zlim([-z_lim/10, z_lim/10])

ax.grid(False)

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_49.png]]

*** theta space

#+begin_src jupyter-python
nbins = 32
theta_bins = np.linspace(0, 360, nbins+1)
theta_digitized = np.digitize(theta_norm, theta_bins) - 1

# For each bin, average w[0], w[1], and w[2]
w_binned = np.zeros((3, nbins))
for i in range(nbins):
    mask = theta_digitized == i
    for j in range(3):
        w_binned[j, i] = np.mean(w_meta[j][mask]) if np.any(mask) else np.nan

w_smooth = gaussian_filter1d(w_binned, sigma=2, axis=1, mode='wrap')
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for i, ax in enumerate(axs):
    ax.plot(theta_plot * 180 / np.pi, w_smooth[i], lw=2)
    ax.axhline(0, ls='--', color='k')
    ax.set_ylabel('Weights PC %d' % (i+1))
    ax.set_xlabel('Neuron Loc (Â°)')

axs[-1].axvline(45)
axs[-1].axvline(225)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_51.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

# Compute bin centers in degrees and radians
bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)  # for polar plots

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width), sharey=1)

# PC1 vs PC2
axs[0].plot(w_smooth[0], w_smooth[1], 'k-')
axs[0].set_xlabel('PC 1')
axs[0].set_ylabel('PC 2')

# PC1 vs PC3
axs[1].plot(w_smooth[0], w_smooth[2], 'k-')
axs[1].set_xlabel('PC 1')
axs[1].set_ylabel('PC 3')

# PC2 vs PC3
axs[2].plot(w_smooth[1], w_smooth[2], 'k-')
axs[2].set_xlabel('PC 2')
axs[2].set_ylabel('PC 3')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_54.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(1, 3, subplot_kw={'polar': True}, figsize=(n_comp*width, width))

for i, ax in enumerate(axs):
    ax.plot(theta_plot, w_smooth[i], lw=2)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_52.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Opto

#+begin_src jupyter-python
# laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15','JawsM18', 'ChRM04', 'ChRM23']
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM18', 'ChRM04', 'ChRM23']
# laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15','JawsM18']

traj_mouse = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_meta.mouse==mouse) & (y_meta.laser==0)
    X_idx = X_meta[idx]
    y_idx = y_meta[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i)  & (y_idx.tasks=='DPA') & (y_idx.performance==1) # & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_mouse.append(traj_)

traj_mouse = np.array(traj_mouse)
print(traj_mouse.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
traj_opto = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_meta.mouse==mouse) & (y_meta.laser==1)
    X_idx = X_meta[idx]
    y_idx = y_meta[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i) & (y_idx.tasks=='DPA') & (y_idx.performance==1) # & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_opto.append(traj_)

traj_opto = np.array(traj_opto)
print(traj_opto.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
fp_mouse = np.nanmean(traj_mouse[..., options['bins_LD']], -1)
fp_opto = np.nanmean(traj_opto[..., options['bins_LD']], -1)

print(fp_mouse.shape)

pc1 = fp_mouse[..., 0]
pc2 = fp_mouse[..., 1]

pc1_opto = fp_opto[..., 0]
pc2_opto = fp_opto[..., 1]
#+end_src

#+RESULTS:
: (6, 2, 3)

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*height, height), sharey=1)

for i in range(pc1.shape[0]):
    ax[0].scatter(pc1[i], pc2[i], label=options['mice'][i])
    ax[1].scatter(pc1_opto[i], pc2_opto[i], label=options['mice'][i])

for k in range(2):
    ax[k].axvline(0, color='k')
    ax[k].axhline(0, color='k')

    ax[k].set_xlabel('PC1')
    ax[k].set_ylabel('PC2')
# plt.legend(fontsize=12, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_58.png]]

#+begin_src jupyter-python
perf_off = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==0)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()
perf_on = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==1)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()

delta_dpa = (perf_on['performance'] - perf_off['performance']).values
print(perf_off.shape, perf_on.shape)
print(delta_dpa)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [ 0.00694444  0.03472222  0.0625      0.02083333  0.          0.
:   0.00694444 -0.04166667  0.01041667  0.09375     0.00694444 -0.00694444]

#+begin_src jupyter-python
perf_off = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==0)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()
perf_on = y_meta[y_meta['mouse'].isin(laser_mice) & (y_meta.laser==1)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()

delta_odr = (perf_on['odr_perf'] - perf_off['odr_perf']).values
print(perf_off.shape, perf_on.shape)
print(delta_odr)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [-0.05208333 -0.02083333 -0.015625   -0.0625      0.03125    -0.03125
:  -0.02083333  0.          0.          0.015625   -0.02083333  0.02083333]

#+begin_src jupyter-python
dPC1 = (pc1_opto - pc1).reshape(-1)
dPC2 = (pc2_opto - pc2).reshape(-1)
print(dPC1.shape, dPC2.shape)
#+end_src

#+RESULTS:
: (12,) (12,)

#+begin_src jupyter-python
df = perf_off[['mouse', 'sample_odor']]
df['delta_dpa'] = delta_dpa
df['delta_odr'] = delta_odr

df['mouse'] = pd.Categorical(df['mouse'], categories=laser_mice, ordered=True)
df = df.sort_values('mouse')

df['delta_pc1'] = dPC1
df['delta_pc2'] = dPC2

# df = df[~df['mouse'].str.contains('ChR')]

print(df.head())
#+end_src

#+RESULTS:
:      mouse  sample_odor  delta_dpa  delta_odr  delta_pc1  delta_pc2
: 4  JawsM01          0.0   0.000000   0.031250  -0.584971  -0.480631
: 5  JawsM01          1.0   0.000000  -0.031250  -0.431848  -0.318978
: 6  JawsM06          0.0   0.006944  -0.020833   0.083898  -0.142953
: 7  JawsM06          1.0  -0.041667   0.000000   0.062524  -0.096413
: 8  JawsM12          0.0   0.010417   0.000000  -0.384625   0.633108

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc1', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc1', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None)

    corr, p_value = pearsonr(df_['delta_pc1'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC1")
    ax[i].set_ylabel("$\\Delta$ Performance")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")
# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_63.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc2', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc2', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None)

    corr, p_value = pearsonr(df_['delta_pc2'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC2")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")

# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_64.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Binned Flow Fields
*** utils

#+begin_src jupyter-python
import numpy as np

def flow_field_from_trajectories(x, y, dt=1.0, bins=25, xrange=None, yrange=None,
                                 statistic="mean", min_count=1):
    """
    x, y: arrays (n_trials, n_time)
    dt: timestep
    bins: int or (nx, ny)
    xrange, yrange: (min, max); if None inferred from data
    statistic: "mean" (default). (You can extend to median easily.)
    Returns:
      xedges, yedges
      u, v: (nx, ny) average velocities in each spatial bin
      count: (nx, ny) number of samples per bin
    """
    x = np.asarray(x); y = np.asarray(y)
    n_trials, n_time = x.shape
    assert y.shape == x.shape

    # step velocities, shape (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # positions to bin (start of each step)
    xs = x[:, :-1]
    ys = y[:, :-1]

    if xrange is None:
        xrange = (xs.min(), xs.max())
    if yrange is None:
        yrange = (ys.min(), ys.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten all steps across trials/time
    xsf = xs.ravel()
    ysf = ys.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin index for each sample
    ix = np.searchsorted(xedges, xsf, side="right") - 1
    iy = np.searchsorted(yedges, ysf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate sums and counts
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    # mean velocity per bin
    ugrid = np.full((nx, ny), np.nan, dtype=float)
    vgrid = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    ugrid[mask] = usum[mask] / count[mask]
    vgrid[mask] = vsum[mask] / count[mask]

    return xedges, yedges, ugrid, vgrid, count


# Example usage:
# x, y = diffusion_2d(n_trials=200, n_time=2000, dt=0.01, D=0.5, seed=0)

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def flow_field_midpoint(x, y, dt=1.0, bins=25, xrange=None, yrange=None, min_count=1):
    """
    Mid-point binning: each velocity sample is assigned to the bin containing
    the segment midpoint ((x_t+x_{t+1})/2, (y_t+y_{t+1})/2).

    x, y: (n_trials, n_time)
    Returns: xedges, yedges, U, V, count with U,V,count shaped (nx, ny)
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape

    # step velocities (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # midpoints to bin (n_trials, n_time-1)
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    if xrange is None:
        xrange = (xm.min(), xm.max())
    if yrange is None:
        yrange = (ym.min(), ym.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten samples
    xf = xm.ravel()
    yf = ym.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin indices
    ix = np.searchsorted(xedges, xf, side="right") - 1
    iy = np.searchsorted(yedges, yf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    U = np.full((nx, ny), np.nan, dtype=float)
    V = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    U[mask] = usum[mask] / count[mask]
    V[mask] = vsum[mask] / count[mask]

    return xedges, yedges, U, V, count

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_speeds(x, y, dt=1.0):
    # step velocities at times t -> t+1
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]
    ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)  # [-pi, pi)

    # avoid r=0 issues
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    vr = (xs*vx + ys*vy) / r_safe
    omega = (xs*vy - ys*vx) / (r_safe**2)

    return r, theta, vr, omega

def bin_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nbin = len(edges) - 1
    valid = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(xvals)
    idx = idx[valid]
    yvals = yvals[valid]

    count = np.zeros(nbin, dtype=int)
    ysum  = np.zeros(nbin, dtype=float)
    np.add.at(count, idx, 1)
    np.add.at(ysum,  idx, yvals)

    ymean = np.full(nbin, np.nan, float)
    m = count >= min_count
    ymean[m] = ysum[m] / count[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, count
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_from_binned_uv(U, V, C, xedges, yedges, r_edges, th_edges,
                                 min_count_bin=1, min_count_1d=1):
    """
    Option (2): convert binned mean velocity field (U,V) into polar components at bin centers,
    then compute weighted 1D profiles vs radius r and angle theta using weights=C.

    Inputs:
      U,V,C: (nx, ny) arrays from flow_field_from_trajectories
      xedges,yedges: bin edges
      r_edges: 1D edges for radius bins
      th_edges: 1D edges for theta bins in [-pi, pi]
      min_count_bin: require C>=this to use a spatial bin at all
      min_count_1d: require total weight in a 1D bin >= this

    Returns:
      r_cent, vr_r, w_r
      th_cent, om_th, w_th
      plus (vr_grid, om_grid) for inspection
    """
    U = np.asarray(U); V = np.asarray(V); C = np.asarray(C)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    r = np.sqrt(Xc**2 + Yc**2)
    th = np.arctan2(Yc, Xc)
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    # polar components derived from mean flow vector in each spatial bin
    vr_grid = np.abs(Xc*U + Yc*V) / r_safe
    om_grid = np.abs(Xc*V - Yc*U) / (r_safe**2)   # angular speed dtheta/dt

    # flatten
    rf = r.ravel()
    thf = th.ravel()
    vrf = vr_grid.ravel()
    omf = om_grid.ravel()
    wf = C.ravel().astype(float)

    # keep only bins with enough samples and finite values
    valid = (wf >= min_count_bin) & np.isfinite(vrf) & np.isfinite(omf) & np.isfinite(rf) & np.isfinite(thf)
    rf, thf, vrf, omf, wf = rf[valid], thf[valid], vrf[valid], omf[valid], wf[valid]

    def weighted_bin_mean(xvals, yvals, wvals, edges, min_w=1.0):
        idx = np.searchsorted(edges, xvals, side="right") - 1
        nbin = len(edges) - 1
        ok = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(wvals)
        idx = idx[ok]; yvals = yvals[ok]; wvals = wvals[ok]

        wsum = np.zeros(nbin, float)
        ywsum = np.zeros(nbin, float)
        np.add.at(wsum, idx, wvals)
        np.add.at(ywsum, idx, wvals * yvals)

        ymean = np.full(nbin, np.nan, float)
        m = wsum >= min_w
        ymean[m] = ywsum[m] / wsum[m]
        centers = 0.5*(edges[:-1] + edges[1:])
        return centers, ymean, wsum

    r_cent, vr_r, w_r   = weighted_bin_mean(rf,  vrf, wf, r_edges,  min_w=min_count_1d)
    th_cent, om_th, w_th = weighted_bin_mean(thf, omf, wf, th_edges, min_w=min_count_1d)

    return r_cent, vr_r, w_r, th_cent, om_th, w_th, vr_grid, om_grid
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
from scipy.ndimage import gaussian_filter1d

def gaussian_filter1d_nan(x, sigma, mode="nearest", truncate=4.0):
    x = np.asarray(x, float)
    m = np.isfinite(x).astype(float)          # 1 where valid, 0 where NaN
    x0 = np.where(np.isfinite(x), x, 0.0)

    xs = gaussian_filter1d(x0, sigma=sigma, mode=mode, truncate=truncate)
    ms = gaussian_filter1d(m,  sigma=sigma, mode=mode, truncate=truncate)

    out = xs / ms
    out[ms == 0] = np.nan
    return out
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_coor, y_coor, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False, nbins=32):
    x = np.asarray(x_coor); y = np.asarray(y_coor)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    eps = 1e-12
    r_safe = np.maximum(r, eps)
    omega = (xs*vy - ys*vx) / (r_safe**2)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), nbins)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, nbins)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, np.abs(speed), r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, np.abs(speed), theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:

*** all mice

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
dt = 1
nbins = 32
min_count = 1  # choose based on how noisy you expect things to be
min_w=1
sigma_r, sigma_th= 5, 5
#+end_src

#+RESULTS:

**** cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse]) & (y_meta.tasks=='DPA')
    X_delay = X_meta[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    (r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)
mean_sp_r = np.nanmean(uniform_filter1d(np.array(sp_r_list), sigma_r), 0)

th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = np.nanmean(uniform_filter1d(np.array(sp_th_list), sigma_th), 0)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, mean_sp_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_sp_th, 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v\rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_76.png]]

**** binned cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse]) & (y_meta.tasks=='DPA')
    X_delay = X_meta[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=1, bins=nbins)

    speed = np.sqrt(U**2 + V**2)
    speed = np.where(C >= min_count, speed, np.nan)

    # bin centers -> R, TH
    xc = 0.5*(xedges[:-1] + xedges[1:])
    yc = 0.5*(yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
    R  = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)

    # speed vs radius (weighted by C)
    r_edges = np.linspace(0, np.nanmax(R), nbins)
    r_c, sp_r, cnt_r, wsum_r = weighted_binned_mean(R, speed, r_edges, weights=C,min_count=min_count, min_weight_1d=min_w)

    # speed vs theta (weighted by C)
    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, sp_th, cnt_th, wsum_th = weighted_binned_mean(TH, speed, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)

mean_sp_r = np.nanmean(sp_r_list, 0)
std_sp_r = np.nanstd(sp_r_list, 0) / np.sqrt(len(options['mice']))


th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = circmean(sp_th_list, -np.pi, np.pi, 0)
std_sp_th = np.nanstd(sp_th_list, 0) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
sigma_r = 5
sigma_th = 5


fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, uniform_filter1d(mean_sp_r, sigma_r), 'k')
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(mean_sp_th, sigma_th), 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v_{bin} \rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v_{bin}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_79.png]]

#+begin_src jupyter-python


#+end_src

#+RESULTS:

**** polar speeds

#+begin_src jupyter-python
r_list = []
avr_r_list, avr_th_list = [], []
avth_r_list, avth_th_list = [], []
aw_r_list, aw_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_meta.laser==0) & (y_meta.mouse==options['mice'][i_mouse]) & (y_meta.tasks=='DPA')
    X_delay = X_meta[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    # --- compute components
    r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

    # magnitudes
    avr  = np.abs(vr)
    avth = np.abs(vth)
    aw = np.abs(omega)

    # --- bin vs radius
    r_edges = np.linspace(0, np.nanmax(r), nbins)
    r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
    _,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
    _, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
    _,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
    _, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)

    r_c /= np.nanmax(r_c)

    m_avr_r = np.nanmean(avr_r)
    std_avr_r = np.nanstd(avr_r)
    avr_r = (avr_r - m_avr_r) / std_avr_r

    m_avr_th = np.nanmean(avr_th)
    std_avr_th = np.nanstd(avr_th)
    avr_th = (avr_th - m_avr_th) / std_avr_th

    m_avth_r = np.nanmean(avth_r)
    std_avth_r = np.nanstd(avth_r)
    avth_r = (avth_r - m_avth_r) / std_avth_r

    m_avth_th = np.nanmean(avth_th)
    std_avth_th = np.nanstd(avth_th)
    avth_th = (avth_th - m_avth_th) / std_avth_th

    m_aw_r = np.nanmean(aw_r)
    std_aw_r = np.nanstd(aw_r)
    aw_r = (aw_r - m_aw_r) / std_aw_r

    m_aw_th = np.nanmean(aw_th)
    std_aw_th = np.nanstd(aw_th)
    aw_th = (aw_th - m_aw_th) / std_aw_th

    r_list.append(r_c)
    th_list.append(th_c)

    avr_r_list.append(avr_r)
    avr_th_list.append(avr_th)

    avth_r_list.append(avth_r)
    avth_th_list.append(avth_th)

    aw_r_list.append(aw_r)
    aw_th_list.append(aw_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
r_list = pad_list(r_list, axis=0, max_len=None)

avr_r_list = pad_list(avr_r_list, axis=0, max_len=None)
avth_r_list = pad_list(avth_r_list, axis=0, max_len=None)
aw_r_list = pad_list(aw_r_list, axis=0, max_len=None)

mean_avr_r = np.nanmean(uniform_filter1d(avr_r_list, sigma_r, axis=-1), 0)
mean_avth_r = np.nanmean(uniform_filter1d(avth_r_list, sigma_r, axis=-1), 0)
mean_aw_r = np.nanmean(uniform_filter1d(aw_r_list, sigma_r, axis=-1), 0)

mean_avr_r = uniform_filter1d(np.nanmean(avr_r_list, 0), sigma_r)
mean_avth_r = uniform_filter1d(np.nanmean(avth_r_list, 0), sigma_r)
mean_awr = uniform_filter1d(circmean(aw_r_list, low=-np.pi, high=np.pi, axis=0), sigma_r)

std_avr_r = uniform_filter1d(np.nanstd(avr_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_avth_r = uniform_filter1d(np.nanstd(avth_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_aw_r = uniform_filter1d(np.nanstd(aw_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))

th_list = pad_list(th_list, axis=0, max_len=None)

avr_th_list = pad_list(avr_th_list, axis=0, max_len=None)
avth_th_list = pad_list(avth_th_list, axis=0, max_len=None)
aw_th_list = pad_list(aw_th_list, axis=0, max_len=None)

mean_avr_th = uniform_filter1d(np.mean(avr_th_list, 0), sigma_th, mode='wrap')
mean_avth_th = uniform_filter1d(np.mean(avth_th_list, axis=0), sigma_th, mode='wrap')
mean_aw_th = uniform_filter1d(circmean(aw_th_list, low=-np.pi, high=np.pi, axis=0), sigma_th, mode='wrap')

std_avr_th = uniform_filter1d(np.nanstd(avr_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_avth_th = uniform_filter1d(np.nanstd(avth_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_aw_th = uniform_filter1d(np.nanstd(aw_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avr_r = avr_r_list[i]
    avr_th = avr_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avr_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avr_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_avr_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avr_th, 'k')

ax[0].fill_between(r_c, mean_avr_r-std_avr_r, mean_avr_r+std_avr_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avr_th-std_avr_th, mean_avr_th+std_avr_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_r>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_83.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avth_r = avth_r_list[i]
    avth_th = avth_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avth_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avth_th, sigma_th), alpha=0.25)

ax[0].plot(r_c, mean_avth_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avth_th, 'k')

ax[0].fill_between(r_c, mean_avth_r-std_avth_r, mean_avth_r+std_avth_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avth_th-std_avth_th, mean_avth_th+std_avth_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_\\theta>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_84.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    aw_r = aw_r_list[i]
    aw_th = aw_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(aw_r, sigma_r), alpha=0.2)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(aw_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_aw_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_aw_th, 'k')

ax[0].fill_between(r_c, mean_aw_r-std_aw_r, mean_aw_r+std_aw_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_aw_th-std_aw_th, mean_aw_th+std_aw_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_85.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

*** data
**** data

 #+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse = 3

idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_meta.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
dt = 1
nbins = 16
min_count = 1
min_w = 1
sigma_r, sigma_th= 5, 5
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d

idx = (y_meta.tasks=='DPA') & (y_meta.laser==0) & idx_mouse # & (y_meta.performance==1)
idx = (y_meta.laser==0) & idx_mouse # & (y_meta.performance==1)

X_delay = X_meta[idx].copy()

x_coor = X_delay[:, 0]
y_coor = X_delay[:, 1]

x_coor = X_delay[:, 0, :options['bins_DELAY'][-1]]
y_coor = X_delay[:, 1, :options['bins_DELAY'][-1]]

# x_coor = X_delay[:, 0, :options['bins_ED'][-1]]
# y_coor = X_delay[:, 1, :options['bins_ED'][-1]]

x_coor = X_delay[:, 0, options['bins_DELAY']]
y_coor = X_delay[:, 1, options['bins_DELAY']]

# bins = np.concatenate( (options['bins_BL'], options['bins_DELAY']))

# x_coor = X_delay[:, 0, bins]
# y_coor = X_delay[:, 1, bins]

print(x_coor.shape)
#+end_src

#+RESULTS:
: (288, 36)

**** binned flows

#+begin_src jupyter-python
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_coor, y_coor, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=dt, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1, sharex=1)

ax[0].plot(x_coor.T, y_coor.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


# pcm = ax[2].pcolormesh(
#     xedges, yedges, speed.T, shading="auto",
#     norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
# )

# cbar = fig.colorbar(pcm, ax=ax[2])
# cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)
# ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

# ax[0].set_xlim([-6, 6])
# ax[0].set_ylim([-4, 4])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_91.png]]

#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(r)$')

ax[1].plot(th_c * 180 / np.pi, sp_th)
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_93.png]]


#+begin_src jupyter-python
import numpy as np

# per (x,y) bin:
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].plot(r_c, uniform_filter1d(speed_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].plot(th_c, uniform_filter1d(speed_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_95.png]]

#+begin_src jupyter-python
import numpy as np

def polar_components_from_steps(x, y, dt=1.0, eps=1e-12):
    vx = (x[:,1:] - x[:,:-1]) / dt
    vy = (y[:,1:] - y[:,:-1]) / dt
    xs = x[:,:-1]; ys = y[:,:-1]
    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)
    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe
    return r, th, vr, vth

def bin2d_mean(r, th, val, r_edges, th_edges, min_count=50):
    r = r.ravel(); th = th.ravel(); val = val.ravel()
    ir = np.searchsorted(r_edges, r, side="right") - 1
    it = np.searchsorted(th_edges, th, side="right") - 1
    nr = len(r_edges)-1; nt = len(th_edges)-1
    ok = (ir>=0)&(ir<nr)&(it>=0)&(it<nt)&np.isfinite(val)
    ir = ir[ok]; it = it[ok]; val = val[ok]

    cnt = np.zeros((nr, nt), int)
    s   = np.zeros((nr, nt), float)
    np.add.at(cnt, (ir, it), 1)
    np.add.at(s,   (ir, it), val)

    mean = np.full((nr, nt), np.nan)
    m = cnt >= min_count
    mean[m] = s[m] / cnt[m]
    return mean, cnt

def angular_anisotropy(mean_rt, eps=1e-12):
    # mean_rt: (nr, nt) array of mean quantity vs (r,theta)
    mu = np.nanmean(mean_rt, axis=1)          # mean over theta for each r
    sd = np.nanstd(mean_rt, axis=1)           # std over theta for each r
    A = sd / (np.abs(mu) + eps)               # relative angular modulation
    return A, mu, sd

# Example usage:
r, th, vr, vth = polar_components_from_steps(x_coor, y_coor, dt=dt)
r_edges  = np.linspace(0, np.nanmax(r), nbins)
th_edges = np.linspace(-np.pi, np.pi, nbins)
vr_rt, vr_cnt = bin2d_mean(r, th, np.abs(vr), r_edges, th_edges, min_count=min_w)
A_vr, vr_mu, vr_sd = angular_anisotropy(vr_rt)
vth_rt, vth_cnt = bin2d_mean(r, th, np.abs(vth), r_edges, th_edges, min_count=min_w)
#+end_src

#+RESULTS:

**** counts

 #+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

r_cent  = 0.5*(r_edges[:-1] + r_edges[1:])
th_cent = 0.5*(th_edges[:-1] + th_edges[1:])

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_rt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_rt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_97.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_cnt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_cnt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_98.png]]


#+begin_src jupyter-python

#+end_src

#+RESULTS:

**** speeds

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c * 180 / np.pi, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_101.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c* 180 / np.pi, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c* 180 / np.pi, uniform_filter1d(aw_th, sigma_th, mode='wrap'), color='k')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_102.png]]

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def binned_velocity_and_speed(
    x, y, dt,
    xedges, yedges,
    min_count=1,
    nan_empty=True,
):
    """
    Compute per-bin:
      U,V  = mean(vx), mean(vy)               (mean velocity components)
      S    = mean(speed) = mean(sqrt(vx^2+vy^2))  (mean speed; NOT sqrt(U^2+V^2))
      C    = counts per bin (# velocity samples falling in bin)

    x,y: arrays (n_trials, n_time)
    dt:  scalar timestep
    xedges,yedges: bin edges
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape
    if n_time < 2:
        raise ValueError("Need at least 2 timepoints per trial to compute velocity.")

    # per-sample velocities (n_trials, n_time-1)
    vx = np.diff(x, axis=1) / dt
    vy = np.diff(y, axis=1) / dt
    sp = np.sqrt(vx * vx + vy * vy)

    # position associated with each velocity sample: midpoint of segment
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    # flatten all samples
    xm = xm.ravel()
    ym = ym.ravel()
    vx = vx.ravel()
    vy = vy.ravel()
    sp = sp.ravel()

    # keep finite
    ok = np.isfinite(xm) & np.isfinite(ym) & np.isfinite(vx) & np.isfinite(vy) & np.isfinite(sp)
    xm, ym, vx, vy, sp = xm[ok], ym[ok], vx[ok], vy[ok], sp[ok]

    nx = len(xedges) - 1
    ny = len(yedges) - 1

    # bin indices
    ix = np.searchsorted(xedges, xm, side="right") - 1
    iy = np.searchsorted(yedges, ym, side="right") - 1
    inside = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)

    ix, iy = ix[inside], iy[inside]
    vx, vy, sp = vx[inside], vy[inside], sp[inside]

    # accumulate sums and counts
    C = np.zeros((nx, ny), dtype=np.int64)
    sum_vx = np.zeros((nx, ny), dtype=float)
    sum_vy = np.zeros((nx, ny), dtype=float)
    sum_sp = np.zeros((nx, ny), dtype=float)

    np.add.at(C, (ix, iy), 1)
    np.add.at(sum_vx, (ix, iy), vx)
    np.add.at(sum_vy, (ix, iy), vy)
    np.add.at(sum_sp, (ix, iy), sp)

    # means
    with np.errstate(invalid="ignore", divide="ignore"):
        U = sum_vx / C
        V = sum_vy / C
        S = sum_sp / C  # <-- mean speed per bin (the "fixed" part)

    if nan_empty:
        mask = C >= min_count
        U = np.where(mask, U, np.nan)
        V = np.where(mask, V, np.nan)
        S = np.where(mask, S, np.nan)

    return U, V, S, C


def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12, mask_r0=None):
    """
    Convert mean velocity components (U,V) defined at bin centers to polar components.
    Optionally mask low-count bins and optionally mask a central disk (mask_r0).
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    mask = np.isfinite(U) & np.isfinite(V)
    if C is not None:
        mask &= (C >= min_count)
    if mask_r0 is not None:
        mask &= (R >= mask_r0)

    Vr    = np.where(mask, Vr, np.nan)
    Vth   = np.where(mask, Vth, np.nan)
    Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega


# -------------------------
# Example usage:
# U,V are mean velocity components; S is mean speed (recommended for "speed map")
# -------------------------
# U, V, S, C = binned_velocity_and_speed(x, y, dt, xedges, yedges, min_count=10)
# Xc, Yc, R, TH, Vr, Vth, Omega = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=10, mask_r0=1e-6)
# speed_of_mean_flow = np.sqrt(U**2 + V**2)   # different quantity than S
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12):
    """
    xedges, yedges: bin edges (nx+1), (ny+1)
    U, V: mean velocity per bin, shape (nx, ny)
    C: counts per bin, shape (nx, ny) (optional but recommended)
    Returns:
      Xc, Yc, R, TH (nx, ny)
      Vr, Vth, Omega (nx, ny) with NaNs where invalid/low count
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    # mask out empty/low-sample bins
    if C is not None:
        mask = (C >= min_count) & np.isfinite(U) & np.isfinite(V)
        Vr    = np.where(mask, Vr, np.nan)
        Vth   = np.where(mask, Vth, np.nan)
        Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega
#+end_src

#+RESULTS:

#+begin_src jupyter-python
min_w = 1
U, V, S, C = binned_velocity_and_speed(x_coor, y_coor, dt, xedges, yedges, min_count=1)
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=1)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")


ax[1].plot(th_c * 180 / np.pi, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_106.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c * 180 / np.pi, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_107.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:
: 5d77e2c0-f036-491a-adc9-93c4a396ae34

*** Random walk
**** random 2D diffusion

#+begin_src jupyter-python
import numpy as np

def diffusion_2d(n_trials, n_time, dt=1.0, D=1.0, x0=0.0, y0=0.0, seed=None):
    """
    2D diffusion: dx = sqrt(2D) dW_x, dy = sqrt(2D) dW_y
    Returns x, y with shape (n_trials, n_time)
    """
    rng = np.random.default_rng(seed)

    sigma = np.sqrt(2 * D * dt)  # per-step std
    dx = sigma * rng.standard_normal((n_trials, n_time - 1))
    dy = sigma * rng.standard_normal((n_trials, n_time - 1))

    x = np.empty((n_trials, n_time), dtype=float)
    y = np.empty((n_trials, n_time), dtype=float)
    x[:, 0] = x0
    y[:, 0] = y0
    x[:, 1:] = x0 + np.cumsum(dx, axis=1)
    y[:, 1:] = y0 + np.cumsum(dy, axis=1)

    return x, y

# example
n_trials, n_time = 128, 84# x_coor.shape
x_diff, y_diff = diffusion_2d(n_trials, n_time, dt=0.1, D=1, seed=0)
print(x_diff.shape, y_diff.shape)
#+end_src

#+RESULTS:
: (128, 84) (128, 84)

**** binned flows

#+begin_src jupyter-python
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_diff, y_diff, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_diff, y_diff, dt=dt, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharey=1, sharex=1)

ax[0].plot(x_diff.T, y_diff.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


pcm = ax[2].pcolormesh(
    xedges, yedges, speed.T, shading="auto",
    norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
)

cbar = fig.colorbar(pcm, ax=ax[2])
cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)
ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

# ax[0].set_xlim([-5, 5])
# ax[0].set_ylim([-3, 3])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')
plt.savefig('./figures/pca/random_walk.svg')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_114.png]]

#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_diff, y_diff, dt=dt, min_count=min_count, use_midpoint=True)
#+end_src

#+RESULTS:
: 70f33977-3bc7-4924-ba26-d5e3414eb3ff

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v \rangle(r)$')

ax[1].plot(th_c * 180 / np.pi, sp_th)
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
: 81d262fa-a93a-475e-9078-a7e8b250770b

#+begin_src jupyter-python
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:
: d597ca30-c0a3-4e91-9976-efa6efb25990

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
: 91106be7-fe7a-4ee3-a253-ee3a81aa6987

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_diff, y_diff, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False):
    x = np.asarray(x_diff); y = np.asarray(y_diff)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), 50)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, 73)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, speed, r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, speed, theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)

# Example:
#+end_src

#+RESULTS:
: dee69d78-7e8e-4a7c-9a0c-69049029c2e4

#+begin_src jupyter-python

#+end_src

#+RESULTS:
: 012a4972-cd57-4456-8f0f-076f0d6b7d2a

**** speeds

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:
: a7134ea0-425a-4d46-a3f0-2d3e0bbb92cb

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_diff, y_diff, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:
: db8367c6-ae78-48aa-927d-0f28cafa80e4

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
: 8cb54688-4679-4f96-98d3-f098c0149ed2

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
: a24aed20-5548-426f-b11a-f3119acd76bc

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:
: 3add8c69-95e4-4bc4-9d3c-7e51cd741068

#+begin_src jupyter-python
min_w = 1
U, V, S, C = binned_velocity_and_speed(x_coor, y_coor, dt, xedges, yedges, min_count=1)
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=min_count)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:
: 194ee857-5126-4c97-9a07-f07b6d47da76

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
: 2ebbf5f9-d518-46c0-868b-fa69c2ff45e5

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
: fd07be47-289e-46ab-aea2-082a46d4e61a

#+begin_src jupyter-python

#+end_src

#+RESULTS:
: 5e4d32ae-ce4b-450c-8ba9-70bb91b58f37

*** Shuffle

**** shuffle diff

#+begin_src jupyter-python
def shuffle_traj(x_coor, idx=None):
    x_rand = np.empty_like(x_coor)
    dx = np.diff(x_coor, axis=-1)
    rng = np.random.default_rng()

    if idx is None:
        idx = rng.random(dx.shape).argsort(axis=-1)

    shuf = np.take_along_axis(dx, idx, axis=-1)
    cum_sum = np.cumsum(shuf, axis=-1)

    x_rand[:, 0] = x_coor[:, 0]  # or any chosen starting value
    x_rand[:, 1:] = x_rand[:,0, np.newaxis] + cum_sum

    return x_rand, idx
#+end_src

#+RESULTS:
: f0129bbf-efec-4986-b2cd-d26a81baa61d

#+begin_src jupyter-python
x_shuff, idx = shuffle_traj(x_coor)
y_shuff, idx = shuffle_traj(y_coor)
#+end_src

#+RESULTS:
: 20114c3b-8854-479e-8151-e244dbea3fbd

**** binned flows

#+begin_src jupyter-python
dt = 1
nbins = 32
min_count = 1  # choose based on how noisy you expect things to be
min_w=1
sigma_r, sigma_th= 1, 2
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_shuff, y_shuff, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_shuff, y_shuff, dt=1, bins=nbins)
#+end_src

#+RESULTS:
: e95c8da5-affa-4795-a1d0-49a02b8b5c01

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharey=1, sharex=1)

ax[0].plot(x_shuff.T, y_shuff.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


pcm = ax[2].pcolormesh(
    xedges, yedges, speed.T, shading="auto",
    norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
)

cbar = fig.colorbar(pcm, ax=ax[2])
cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)
ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

ax[0].set_xlim([-5, 5])
ax[0].set_ylim([-3, 3])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
: 66f0bbee-0cc4-4897-896d-90dd231f0f4e


#+begin_src jupyter-python
import numpy as np

# per (x,y) bin:
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:
: 20473bb6-4d25-47c3-918c-05cab9c14279

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
: 24853c7d-0dde-4620-9f5e-af516d1b4603

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_shuff, y_shuff, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False):
    x = np.asarray(x_shuff); y = np.asarray(y_shuff)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), 50)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, 73)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, speed, r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, speed, theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)

# Example:
#+end_src

#+RESULTS:
: dca026a5-d351-42c9-a9ff-f6feee81962e

#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_shuff, y_shuff, dt=dt, min_count=min_count)
#+end_src

#+RESULTS:
: f65a8e85-c956-4d9b-86fd-0db09d48bd41

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(r)$')

ax[1].plot(th_c, sp_th)
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
: 259dc9fe-b5fd-4e8d-b9f2-a79a30c30c5d

#+begin_src jupyter-python

#+end_src

#+RESULTS:
: a1387cf1-406f-43d6-97cc-727e149d3c31

**** speeds

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:
: 89b3d94a-b4de-4088-a365-549748a176a4

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_shuff, y_shuff, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:
: 5becaa93-68b0-45ae-a49a-5a0270a8f934

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
: 0a2dc4d4-6d66-413d-842b-479dccdf49ed

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
: 0fa652f5-e43a-4c0e-9ce0-38b2ec4415ae

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12):
    """
    xedges, yedges: bin edges (nx+1), (ny+1)
    U, V: mean velocity per bin, shape (nx, ny)
    C: counts per bin, shape (nx, ny) (optional but recommended)
    Returns:
      Xc, Yc, R, TH (nx, ny)
      Vr, Vth, Omega (nx, ny) with NaNs where invalid/low count
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    # mask out empty/low-sample bins
    if C is not None:
        mask = (C >= min_count) & np.isfinite(U) & np.isfinite(V)
        Vr    = np.where(mask, Vr, np.nan)
        Vth   = np.where(mask, Vth, np.nan)
        Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega
#+end_src

#+RESULTS:
: 21934103-1cfd-4f8d-8a11-597da006b820

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:
: 7120dd0d-5923-4ea3-9432-17bf99fe3e64

#+begin_src jupyter-python
min_w = 1
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=min_count)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:
: 5a236cd3-3cf1-49f2-9e7e-cf6eb8388bbe

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
: 2b17d1db-fdd5-4f10-8252-e0f5e1b2c759

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (rad)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
: 7e91b5fb-38f5-43cd-821e-b38fab09f2b3

#+begin_src jupyter-python

#+end_src

#+RESULTS:
: 01fbb128-eb3e-4b82-8fc9-d24542b22235

* Single mouse
** Load

#+begin_src jupyter-python
X_all = pkl_load('X_all', path="../data/pca")
y_all = pkl_load('y_all', path="../data/pca")
#+end_src

#+RESULTS:
: loading from ../data/pca/X_all.pkl
: loading from ../data/pca/y_all.pkl

#+begin_src jupyter-python
y_all['sample'] = y_all.sample_odor
y_all['test'] = y_all.test_odor
#+end_src

#+RESULTS:

#+begin_src jupyter-python
print(y_all.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'dist_odor', 'test_odor', 'tasks', 'response', 'laser',
:        'day', 'choice', 'pair', 'odr_perf', 'odr_choice', 'odr_response',
:        'odor_pair', 'learning', 'performance', 'mouse', 'sample', 'test'],
:       dtype='object')

** PCA
*** utils

#+begin_src jupyter-python
import numpy as np
import pandas as pd
from tqdm import tqdm
from scipy.linalg import orthogonal_procrustes

def _anchors_from_Z(Z, y_df, factor="odor_pair"):
    """
    Anchors = condition-averaged latent trajectories.
    Z: (n_trials, n_time, n_comp)
    returns A: (n_cond*n_time, n_comp)
    """
    conds = np.unique(y_df[factor].values)
    conds = np.sort(conds.astype(str))

    A = []
    yf = y_df[factor].astype(str).values
    for c in conds:
        m = (yf == c)
        A.append(np.nanmean(Z[m], axis=0))  # (n_time, n_comp)
    A = np.stack(A, axis=0)                # (n_cond, n_time, n_comp)
    return A.reshape(-1, Z.shape[-1])

def cv_pca(
    X, y, pca, folds, factors, epoch,
    group_col=None,
    show_pbar=True,
):
    """
    - Fit PCA on TRAIN condition-averages restricted to `epoch`
    - Learn fold alignment rotation R from TRAIN projections in `epoch`
    - Project TEST using FULL time (all time points), then rotate by R
    - Return aligned W as well (W_aligned = R.T @ W_fold)

    X: (n_trials, n_neurons, n_time)
    y: DataFrame aligned with trials
    factors: column name defining condition (e.g. "odor_pair")
    epoch: None or time indices/slice used only for fitting/alignment
    """

    # --- clean subset used for fitting + CV
    m_clean = (y.laser==0) & (y.performance==1) # & ((y.tasks=='DPA') | (y.odr_perf==1))
    Xc = X[m_clean]
    yc = y.loc[m_clean].reset_index(drop=True)

    groups = None
    if group_col is not None:
        groups = yc[group_col].astype(str).values

    strata = (
        yc["odor_pair"].astype(str)
        + "_" + yc["mouse"].astype(str)
        + "_" + yc["day"].astype(str)
        + "_" + yc["tasks"].astype(str)
    ).values

    X_folds, y_folds = [], []
    w_folds, evr_folds = [], []
    A_ref = None  # reference anchors (latent space), fold 0 train

    it = folds.split(Xc, strata, groups=groups)
    if show_pbar:
        it = tqdm(it, total=folds.get_n_splits(Xc, strata), desc=str(y.mouse.unique()[0]))

    for fold, (train, test) in enumerate(it):
        X_train, y_train = Xc[train], yc.iloc[train].reset_index(drop=True)
        X_test,  y_test  = Xc[test],  yc.iloc[test].reset_index(drop=True)

        # --- fit scaling on TRAIN only (use epoch to match PCA fit)
        scales = fit_mouse_scales(X_train, y_train, epoch=epoch, target="median")

        # --- apply to FULL data (so projections return all time points consistently)
        X_train = apply_mouse_scales(X_train, y_train, scales)
        X_test  = apply_mouse_scales(X_test,  y_test,  scales)

        # recompute epoch views after scaling
        X_train_epoch = X_train if epoch is None else X_train[..., epoch]
        X_test_epoch  = X_test  if epoch is None else X_test[..., epoch]

        # FULL time arrays for final output projection
        X_train_full = X_train
        X_test_full  = X_test

        # mean computed on TRAIN epoch only (ignoring NaNs)
        X_train_epoch_flat = X_train_epoch.transpose(0, 2, 1).reshape(-1, X_train_epoch.shape[1])
        X_mean = np.nanmean(X_train_epoch_flat, axis=0, keepdims=True)

        # fit PCA on TRAIN condition-averages in epoch
        X_avg_epoch = cv_avg_cond(X_train_epoch, y_train, factors)  # (n_cond, n_neurons, n_time_epoch)
        X_avg_flat  = X_avg_epoch.transpose(0, 2, 1).reshape(-1, X_avg_epoch.shape[1])
        X_cent_fit  = X_avg_flat - X_mean

        pca.fit(X_cent_fit)
        W_fold = pca.components_  # (n_comp, n_neurons)
        evr_folds.append(pca.explained_variance_ratio_)

        # project TRAIN epoch (for anchors -> alignment rotation)
        Z_train_epoch = pca.transform(X_train_epoch_flat - X_mean).reshape(
            X_train_epoch.shape[0], X_train_epoch.shape[-1], -1
        )
        A_train = _anchors_from_Z(Z_train_epoch, y_train, factor=factors)

        if A_ref is None:
            A_ref = A_train
            R = np.eye(Z_train_epoch.shape[-1])
        else:
            # R s.t. A_train @ R ~= A_ref
            R, _ = orthogonal_procrustes(A_train, A_ref)  # (n_comp, n_comp)

        # project TEST FULL time, then rotate by R
        X_test_full_flat = X_test_full.transpose(0, 2, 1).reshape(-1, X_test_full.shape[1])
        Z_test_full = pca.transform(X_test_full_flat - X_mean).reshape(
            X_test_full.shape[0], X_test_full.shape[-1], -1
        )

        Z_test_aligned = Z_test_full @ R
        W_fold_aligned = (R.T @ W_fold)

        X_folds.append(Z_test_aligned)
        y_folds.append(y_test)
        w_folds.append(W_fold_aligned)

    # concat CV outputs
    X_folds = np.concatenate(X_folds, axis=0)
    y_folds = pd.concat(y_folds, axis=0, ignore_index=True)

    w_folds = np.mean(np.stack(w_folds, axis=0), axis=0)
    evr_folds = np.array(evr_folds, dtype=object)

    # ----- Fit PCA on all CLEAN data (epoch) to project perturbed data (full time)
    Xc_epoch = Xc if epoch is None else Xc[..., epoch]
    Xc_epoch_flat = Xc_epoch.transpose(0, 2, 1).reshape(-1, Xc_epoch.shape[1])
    X_mean_all = np.nanmean(Xc_epoch_flat, axis=0, keepdims=True)

    X_avg_epoch_all = cv_avg_cond(Xc_epoch, yc, factors)
    X_avg_flat_all  = X_avg_epoch_all.transpose(0, 2, 1).reshape(-1, X_avg_epoch_all.shape[1])
    X_cent_all = X_avg_flat_all - X_mean_all

    pca.fit(X_cent_all)

    # anchors reference for "all-fit" PCA (built from CLEAN epoch projections)
    Zc_epoch = pca.transform(Xc_epoch_flat - X_mean_all).reshape(
        Xc_epoch.shape[0], Xc_epoch.shape[-1], -1
    )
    A_ref_all = _anchors_from_Z(Zc_epoch, yc, factor=factors)

    m_pert = ~m_clean
    if m_pert.mean() != 0:
        Xp = X[m_pert]
        yp = y.loc[m_pert].reset_index(drop=True)

        # project perturbed FULL time using PCA fit on clean epoch
        Xp_full_flat = Xp.transpose(0, 2, 1).reshape(-1, Xp.shape[1])
        Zp_full = pca.transform(Xp_full_flat - X_mean_all).reshape(
            Xp.shape[0], Xp.shape[-1], -1
        )

        # estimate R_p using perturbed epoch anchors (so anchor sizes match A_ref_all)
        Xp_epoch = Xp if epoch is None else Xp[..., epoch]
        Xp_epoch_flat = Xp_epoch.transpose(0, 2, 1).reshape(-1, Xp_epoch.shape[1])
        Zp_epoch = pca.transform(Xp_epoch_flat - X_mean_all).reshape(
            Xp_epoch.shape[0], Xp_epoch.shape[-1], -1
        )
        A_p = _anchors_from_Z(Zp_epoch, yp, factor=factors)
        R_p, _ = orthogonal_procrustes(A_p, A_ref_all)

        Zp_aligned = Zp_full @ R_p

        Z_all = np.concatenate([X_folds, Zp_aligned], axis=0)
        y_all = pd.concat([y_folds, yp], axis=0, ignore_index=True)
        return Z_all, y_all, w_folds, evr_folds

    return X_folds, y_folds, w_folds, evr_folds
#+end_src

#+RESULTS:

*** model

#+begin_src jupyter-python
options['learning'] = 'Expert'
options['epochs'] = ['POST_GNG']
epoch = options['bins_' + options['epochs'][0]]
#+end_src

#+RESULTS:

#+begin_src jupyter-python
# factors = ['sample', 'tasks', 'test']
factors = 'odor_pair'
n_splits = 5
n_repeats = 1
n_comp = 3

pca = PCA(n_components=n_comp, svd_solver='randomized')
folds = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)
folds = LeaveOneOut()
#+end_src

#+RESULTS:

 #+begin_src jupyter-python
X_mice, y_mice, w_mice, evr_mice = [], [], [], []

# options['mice'] = ['JawsM15', 'JawsM18']

for mouse in options['mice']:
    idx = (y_all.learning == options['learning'])  & (y_all['mouse'] == mouse)

    X_pca = X_all[idx]
    y_pca = y_all[idx]

    valid_neurons = ~np.all(np.isnan(X_pca), axis=(0, 2))
    X_pca = X_pca[:, valid_neurons, :]

    # X_mouse, y_mouse, w_mouse, evr_mouse = cross_val_avg_pca(X_pca, y_pca, pca, folds, factors, epoch)
    X_mouse, y_mouse, w_mouse, evr_mouse = cv_pca(X_pca, y_pca, pca, folds, factors, epoch)

    idx_list = np.arange(n_comp)

    sample = np.zeros(3)
    for i in range(2):
        idx = (y_mouse.sample_odor==i)
        X_ = X_mouse[idx][options['bins_DELAY']]
        m_ = np.nanmean(X_, axis=(0, 1))
        sample += (-1)**i * m_

    idx_0 = np.argmax(np.abs(sample))
    idx_1 = np.delete(idx_list, idx_0)

    choice = np.zeros(2)
    for i in range(2):
        idx = (y_mouse.choice==i)
        X_ = X_mouse[idx][options['bins_TEST'][-1]:]
        m_ = np.nanmean(X_[..., idx_1], axis=(0, 1))
        choice += (-1)**i * m_

    idx_1 = np.argmax(np.abs(choice))

    if idx_0==1 & idx_1==1:
        idx_1=2

    if idx_0==0:
        idx_1+=1

    idx_2 = np.delete(idx_list, (idx_0, idx_1))[0]

    idx = np.array([idx_0, idx_1, idx_2])

    X_mice.append(X_mouse[..., idx])
    y_mice.append(y_mouse)
    w_mice.append(w_mouse[idx])
    evr_mice.append(evr_mouse)
#+end_src

#+RESULTS:
#+begin_example
JawsM01: 100% 91/91 [00:00<00:00, 157.67it/s]
JawsM06: 100% 248/248 [00:04<00:00, 58.05it/s]
JawsM12: 100% 141/141 [00:03<00:00, 38.92it/s]
JawsM15: 100% 249/249 [00:18<00:00, 13.57it/s]
JawsM18: 100% 283/283 [00:14<00:00, 19.52it/s]
ChRM04: 100% 264/264 [00:18<00:00, 14.34it/s]
ChRM23: 100% 145/145 [00:01<00:00, 80.25it/s]
ACCM03: 100% 349/349 [00:18<00:00, 19.34it/s]
ACCM04: 100% 283/283 [00:03<00:00, 84.55it/s]
#+end_example

#+begin_src jupyter-python
from scipy.linalg import orthogonal_procrustes
import numpy as np
import pandas as pd

def anchors_from_Z(Z, y_df, factor="odor_pair"):
    # Z: (n_trials, T, d)
    conds = np.sort(np.unique(y_df[factor].astype(str).values))
    A = []
    for c in conds:
        m = (y_df[factor].astype(str).values == c)
        A.append(np.nanmean(Z[m], axis=0))  # (T, d)
    A = np.stack(A, axis=0)                # (n_cond, T, d)
    return A.reshape(-1, Z.shape[-1])      # (n_cond*T, d)

X_mice, y_mice, w_mice, evr_mice = [], [], [], []

# --- run per-mouse CV PCA (no cross-mouse alignment yet)
for mouse in options['mice']:
    idx = (y_all.learning == options['learning']) & (y_all['mouse'] == mouse)

    X_pca = X_all[idx]
    y_pca = y_all.loc[idx].reset_index(drop=True)

    # drop padded neurons for this mouse
    valid_neurons = ~np.all(np.isnan(X_pca), axis=(0, 2))
    X_pca = X_pca[:, valid_neurons, :]

    Z_mouse, y_mouse, W_mouse, evr_mouse = cv_pca(X_pca, y_pca, pca, folds, factors, epoch)

    X_mice.append(Z_mouse)     # (n_trials_mouse, T, n_comp)
    y_mice.append(y_mouse)     # DataFrame aligned with trials
    w_mice.append(W_mouse)     # (n_comp, n_neurons_mouse) averaged across folds
    evr_mice.append(evr_mouse)

# --- align mice in latent space (PC score space) using condition/time anchors
ref_idx = 3
A_ref = anchors_from_Z(X_mice[ref_idx], y_mice[ref_idx], factor=factors)

X_mice_aligned = []
R_mice = []
for Z_mouse, y_mouse in zip(X_mice, y_mice):
    A = anchors_from_Z(Z_mouse, y_mouse, factor=factors)
    R, _ = orthogonal_procrustes(A, A_ref)     # (n_comp, n_comp)
    X_mice_aligned.append(Z_mouse @ R)         # rotate scores into ref space
    R_mice.append(R)

# optional: concatenate aligned latents across mice
X_aligned_all = np.concatenate(X_mice_aligned, axis=0)   # (sum_trials, T, n_comp)
y_aligned_all = pd.concat(y_mice, ignore_index=True)
#+end_src

#+RESULTS:
#+begin_example
JawsM01: 100% 91/91 [00:00<00:00, 123.55it/s]
JawsM06: 100% 248/248 [00:05<00:00, 47.83it/s]
JawsM12: 100% 141/141 [00:04<00:00, 34.74it/s]
JawsM15: 100% 249/249 [00:18<00:00, 13.20it/s]
JawsM18: 100% 283/283 [00:18<00:00, 15.01it/s]
ChRM04: 100% 264/264 [00:20<00:00, 12.84it/s]
ChRM23: 100% 145/145 [00:02<00:00, 70.02it/s]
ACCM03: 100% 349/349 [00:20<00:00, 17.32it/s]
ACCM04: 100% 283/283 [00:04<00:00, 65.50it/s]
#+end_example

#+begin_src jupyter-python
print(X_aligned_all.shape, y_aligned_all.shape, w_mice[0].shape)
#+end_src

#+RESULTS:
: (4032, 84, 3) (4032, 18) (3, 184)

#+begin_src jupyter-python
w_stack = np.concatenate(w_mice, -1)
print(w_stack.shape)
#+end_src

#+RESULTS:
: (3, 3319)

#+begin_src jupyter-python
X_single = np.swapaxes(X_aligned_all, 1, 2)
y_single = y_aligned_all
w_single = w_stack * 100
print(X_single.shape, y_single.shape)
#+end_src

#+RESULTS:
: (4032, 3, 84) (4032, 18)

#+begin_src jupyter-python
print(X_mice[0].shape, w_mice[0].shape, evr_mice[0].shape)
#+end_src

#+RESULTS:
: (192, 84, 3) (3, 184) (91, 3)

#+begin_src jupyter-python
X_stack = np.vstack(X_mice)
y_single = pd.concat(y_mice)
w_stack = np.concatenate(w_mice, -1)
evr_single = np.concatenate(evr_mice, 0)
print(X_stack.shape, w_stack.shape)
#+end_src

#+RESULTS:
: (4032, 84, 3) (3, 3319)

#+begin_src jupyter-python
X_single = np.array(X_stack, dtype=float)
X_single = np.swapaxes(X_single, 1, 2)
# w_single = np.mean(w_stack, 0, dtype=float) * 100
w_single = w_stack * 100
print(X_single.shape, y_single.shape, w_single.shape)
#+end_src

#+RESULTS:
: (4032, 3, 84) (4032, 18) (3, 3319)

** Save/Load

#+begin_src jupyter-python
dum = options['epochs'][0] + '_' + options['learning'] + '_laser_%d' % options['laser']
print(dum)
#+end_src

#+RESULTS:
: TASK_Expert_laser_0

#+begin_src jupyter-python
pkl_save(X_single, 'single_traj_' + dum, path="../data/pca/")
pkl_save(y_single, 'single_labels_' + dum, path="../data/pca/")
pkl_save(w_single, 'single_weights_' + dum, path="../data/pca/")
pkl_save(evr_single, 'single_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
:RESULTS:
: saving to ../data/pca//single_traj_TASK_Expert_laser_0.pkl
: saving to ../data/pca//single_labels_TASK_Expert_laser_0.pkl
: saving to ../data/pca//single_weights_TASK_Expert_laser_0.pkl
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[82], line 4
:       2 pkl_save(y_single, 'single_labels_' + dum, path="../data/pca/")
:       3 pkl_save(w_single, 'single_weights_' + dum, path="../data/pca/")
: ----> 4 pkl_save(evr_single, 'single_evr_' + dum, path="../data/pca/")
:
: NameError: name 'evr_single' is not defined
:END:

 #+begin_src jupyter-python
X_single = pkl_load('single_traj_' + dum, path="../data/pca/")
y_single = pkl_load( 'single_labels_' + dum, path="../data/pca/")
w_single = pkl_load( 'single_weights_' + dum, path="../data/pca/")
evr_single = pkl_load( 'single_evr_' + dum, path="../data/pca/")
#+end_src

#+RESULTS:
: loading from ../data/pca//single_traj_POST_GNG_Expert_laser_0.pkl
: loading from ../data/pca//single_labels_POST_GNG_Expert_laser_0.pkl
: loading from ../data/pca//single_weights_POST_GNG_Expert_laser_0.pkl
: loading from ../data/pca//single_evr_POST_GNG_Expert_laser_0.pkl

** Trajectories

#+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse= 5

idx_correct =  (y_single.performance==1)
idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_single.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height),)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = ['AC', 'AD', 'BD', 'BC']
xtime = np.linspace(0, 14, 84)

for i in range(4):
    mask = (y_single.odor_pair==i) & (y_single.laser==laser) & idx_mouse & idx_correct
    X_sel = X_single[mask]

    X_avg = np.mean(X_sel, 0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = np.std(X_sel, 0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)

        ax[k].legend(fontsize=12, frameon=0, loc='best')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_165.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

pair = y_single.tasks.unique()
xtime = np.linspace(0, 14, 84)

for i in range(len(pair)):
    mask = (y_single.tasks==y_single.tasks.unique()[i]) & (y_single.laser==laser) & idx_mouse & idx_correct
    X_sel = X_single[mask]

    X_avg = X_sel.mean(0)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=0)

        ax[k].legend(fontsize=12, frameon=0, loc='best')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_166.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#984ea3", "#4daf4a", "#ffae19"]

pair = ['A', 'B']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.sample_odor==i) & (y_single.laser==laser) & idx_mouse & idx_correct
    X_sel = X_single[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_167.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['nolick', 'lick']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.choice==i) & (y_single.laser==laser) & idx_mouse & idx_correct
    X_sel = X_single[mask]          # Subselect rows
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_168.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height), sharey=1)

color = ["#377eb8", "#4daf4a"]

pair = ['C', 'D']
xtime = np.linspace(0, 14, 84)

for i in range(2):
    mask = (y_single.test_odor==i) & (y_single.laser==0) & idx_mouse & idx_correct
    X_sel = X_single[mask]
    X_avg = X_sel.mean(0)    # Mean over trials/samples, shape: (n_comp, n_time)
    X_sem = X_sel.std(0) / np.sqrt(X_sel.shape[0])  # SEM

    for k in range(n_comp):
        y_avg = X_avg[k]
        y_sem = X_sem[k]
        ax[k].plot(xtime, y_avg, color=color[i], label=pair[i])
        ax[k].fill_between(xtime, y_avg-y_sem, y_avg+y_sem, color=color[i], alpha=0.2)
        ax[k].axhline(0, ls='--', color='k')
        ax[k].set_xlabel('Time')
        ax[k].set_ylabel('PC %d' % (k+1))
        add_vlines(ax[k], if_dpa=1)
        ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_169.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height))

pair = ['AC', 'AD', 'BD', 'BC']

color = ['#332288', '#88CCEE', '#117733', '#44AA99']

for i in range(4):
    idx = (y_single.odor_pair==i) & (y_single.laser==laser) & idx_mouse & idx_correct

    X_avg = (X_single[idx].mean(0))[:, :66]

    ax[0].plot(X_avg[0], X_avg[1], color=color[i], label=pair[i])
    ax[0].set_xlabel('PC 1')
    ax[0].set_ylabel('PC 2')

    ax[1].plot(X_avg[0], X_avg[2], color=color[i], label=pair[i])
    ax[1].set_xlabel('PC 1')
    ax[1].set_ylabel('PC 3')

    ax[2].plot(X_avg[1], X_avg[2], color=color[i], label=pair[i])
    ax[2].set_xlabel('PC 2')
    ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].legend(fontsize=12, frameon=0, loc='best')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_170.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Embeddings
*** spatial filter

#+begin_src jupyter-python
z_lim =5
size = 0.1

import cmocean
cmap=cmocean.cm.phase

theta = np.arctan2(w_single[0], w_single[1]) * 180 / np.pi
idx = np.argsort(theta)

theta_norm = (theta+ 360) % (360)

counts, bins, patches = plt.hist(theta_norm, bins='auto', range=(0, 360), density=1)

bin_centers = 0.5*(bins[:-1] + bins[1:])
colors = [cmap(center/(360)) for center in bin_centers]

for patch, color in zip(patches, colors):
    patch.set_facecolor(color)

plt.xlabel('Neuron Loc (Â°)')
plt.ylabel('Density')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_172.png]]

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, gaussian_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for k in range(n_comp):
    sc = ax[k].scatter(theta[idx], w_single[k][idx], alpha=0.5, c=theta_norm[idx], cmap=cmap, rasterized=1)
    ax[k].plot(theta[idx], gaussian_filter1d(w_single[k][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')
    ax[k].axhline(0, ls='--', color='k')
    ax[k].set_ylabel('Weights PC %d' % (k+1))
    ax[k].set_xlabel('Neuron Loc (Â°)')
    ax[k].set_ylim([-z_lim, z_lim])

ax[-1].set_ylim([-z_lim/2, z_lim/2])
plt.colorbar(sc, ax=ax[-1], label='Angle (Â°)')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_173.png]]

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width))

ax[0].scatter(w_single[0][idx], w_single[1][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[0].plot(gaussian_filter1d(w_single[0][idx], int(size*w_single.shape[1]), mode='wrap'), gaussian_filter1d(w_single[1][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')

ax[0].set_xlabel('PC 1')
ax[0].set_ylabel('PC 2')

ax[1].scatter(w_single[0][idx], w_single[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[1].plot(gaussian_filter1d(w_single[0][idx], int(size*w_single.shape[1]), mode='wrap'), gaussian_filter1d(w_single[2][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')
ax[1].set_xlabel('PC 1')
ax[1].set_ylabel('PC 3')

sc = ax[2].scatter(w_single[1][idx], w_single[2][idx], c=theta_norm[idx], cmap=cmap, alpha=0.5, rasterized=1)
ax[2].plot(gaussian_filter1d(w_single[1][idx], int(size*w_single.shape[1]), mode='wrap'), gaussian_filter1d(w_single[2][idx], int(size*w_single.shape[1]), mode='wrap'), 'k')
ax[2].set_xlabel('PC 2')
ax[2].set_ylabel('PC 3')

for k in range(3):
    ax[k].set_xlim(-z_lim, z_lim)
    ax[k].set_ylim(-z_lim, z_lim)

plt.colorbar(sc, ax=ax[-1], label='Angle (Â°)')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_174.png]]

#+begin_src jupyter-python
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

ax.plot(gaussian_filter1d(w_single[0][idx], int(size*w_single.shape[1]), mode='wrap'),
           gaussian_filter1d(w_single[1][idx], int(size*w_single.shape[1]), mode='wrap'),
           gaussian_filter1d(w_single[2][idx], int(size*w_single.shape[1]), mode='wrap'),
           rasterized=1, color='k')


sc = ax.scatter(w_single[0][idx],
                w_single[1][idx],
                w_single[2][idx],
                c=theta_norm[idx], cmap=cmap,
                rasterized=1, alpha=0.5)

ax.tick_params(axis='both', which='major', labelsize=12)  # change both x and y (and z in 3D)
ax.tick_params(axis='z', which='major', labelsize=12)     # for the z-axis specifically

ax.set_xlabel('PC 1', fontsize=12)
ax.set_ylabel('PC 2', fontsize=12)
ax.set_zlabel('PC 3', fontsize=12)

ax.set_xlim([-z_lim, z_lim])
ax.set_ylim([-z_lim, z_lim])
ax.set_zlim([-z_lim/10, z_lim/10])

ax.grid(False)

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_175.png]]

*** theta space

#+begin_src jupyter-python
nbins = 32
theta_bins = np.linspace(0, 360, nbins+1)
theta_digitized = np.digitize(theta_norm, theta_bins) - 1

# For each bin, average w[0], w[1], and w[2]
w_binned = np.zeros((3, nbins))
for i in range(nbins):
    mask = theta_digitized == i
    for j in range(3):
        w_binned[j, i] = np.mean(w_single[j][mask]) if np.any(mask) else np.nan

w_smooth = gaussian_filter1d(w_binned, sigma=2, axis=1, mode='wrap')
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, height))

for i, ax in enumerate(axs):
    ax.plot(theta_plot * 180 / np.pi, w_smooth[i], lw=2)
    ax.axhline(0, ls='--', color='k')
    ax.set_ylabel('Weights PC %d' % (i+1))
    ax.set_xlabel('Neuron Loc (Â°)')

axs[-1].axvline(45)
axs[-1].axvline(225)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_177.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

# Compute bin centers in degrees and radians
bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)  # for polar plots

fig, axs = plt.subplots(nrows=1, ncols=n_comp, figsize=(n_comp*width, width), sharey=1)

# PC1 vs PC2
axs[0].plot(w_smooth[0], w_smooth[1], 'k-')
axs[0].set_xlabel('PC 1')
axs[0].set_ylabel('PC 2')

# PC1 vs PC3
axs[1].plot(w_smooth[0], w_smooth[2], 'k-')
axs[1].set_xlabel('PC 1')
axs[1].set_ylabel('PC 3')

# PC2 vs PC3
axs[2].plot(w_smooth[1], w_smooth[2], 'k-')
axs[2].set_xlabel('PC 2')
axs[2].set_ylabel('PC 3')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_178.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
from numpy import deg2rad

bin_centers = 0.5 * (theta_bins[:-1] + theta_bins[1:])
theta_plot = deg2rad(bin_centers)

fig, axs = plt.subplots(1, 3, subplot_kw={'polar': True}, figsize=(n_comp*width, width))

for i, ax in enumerate(axs):
    ax.plot(theta_plot, w_smooth[i], lw=2)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_179.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Opto

#+begin_src jupyter-python
# laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15','JawsM18', 'ChRM04', 'ChRM23']
laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM18', 'ChRM04', 'ChRM23']
# laser_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15','JawsM18']

traj_mouse = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_single.mouse==mouse) & (y_single.laser==0)
    X_idx = X_single[idx]
    y_idx = y_single[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i)  & (y_idx.tasks=='DPA') # & (y_idx.performance==1) & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_mouse.append(traj_)

traj_mouse = np.array(traj_mouse)
print(traj_mouse.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
traj_opto = []
for i_mouse, mouse in enumerate(laser_mice):
    idx = (y_single.mouse==mouse) & (y_single.laser==1)
    X_idx = X_single[idx]
    y_idx = y_single[idx]

    traj_ = []
    for i in range(2):
        mask = (y_idx.sample_odor==i) & (y_idx.tasks=='DPA') # & (y_idx.performance==1) & ((y_idx.tasks=='DPA') | (y_idx.odr_perf==1))
        traj_.append(X_idx[mask].mean(0))

    traj_opto.append(traj_)

traj_opto = np.array(traj_opto)
print(traj_opto.shape)
#+end_src

#+RESULTS:
: (6, 2, 3, 84)

#+begin_src jupyter-python
fp_mouse = np.nanmean(traj_mouse[..., options['bins_LD']], -1)
fp_opto = np.nanmean(traj_opto[..., options['bins_LD']], -1)

print(fp_mouse.shape)

pc1 = fp_mouse[..., 0]
pc2 = fp_mouse[..., 1]

pc1_opto = fp_opto[..., 0]
pc2_opto = fp_opto[..., 1]
#+end_src

#+RESULTS:
: (6, 2, 3)

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*height, height), sharey=1)

for i in range(pc1.shape[0]):
    ax[0].scatter(pc1[i], pc2[i], label=options['mice'][i])
    ax[1].scatter(pc1_opto[i], pc2_opto[i], label=options['mice'][i])

for k in range(2):
    ax[k].axvline(0, color='k')
    ax[k].axhline(0, color='k')

    ax[k].set_xlabel('PC1')
    ax[k].set_ylabel('PC2')
# plt.legend(fontsize=12, frameon=0)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_184.png]]

#+begin_src jupyter-python
perf_off = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==0)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()

perf_on = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==1)].groupby(['mouse', 'sample_odor'])['performance'].mean().reset_index()

delta_dpa = (perf_on['performance'] - perf_off['performance']).values
print(perf_off.shape, perf_on.shape)
print(delta_dpa)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [ 0.00694444  0.03472222  0.0625      0.02083333  0.          0.
:   0.00694444 -0.04166667  0.01041667  0.09375     0.00694444 -0.00694444]

#+begin_src jupyter-python
perf_off = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==0)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()
perf_on = y_single[y_single['mouse'].isin(laser_mice) & (y_single.laser==1)].groupby(['mouse', 'sample_odor'])['odr_perf'].mean().reset_index()

delta_odr = (perf_on['odr_perf'] - perf_off['odr_perf']).values
print(perf_off.shape, perf_on.shape)
print(delta_odr)
#+end_src

#+RESULTS:
: (12, 3) (12, 3)
: [-0.05208333 -0.02083333 -0.015625   -0.0625      0.03125    -0.03125
:  -0.02083333  0.          0.          0.015625   -0.02083333  0.02083333]

#+begin_src jupyter-python
dPC1 = (pc1_opto - pc1).reshape(-1)
dPC2 = (pc2_opto - pc2).reshape(-1)
print(dPC1.shape, dPC2.shape)
#+end_src

#+RESULTS:
: (12,) (12,)

#+begin_src jupyter-python
df = perf_off[['mouse', 'sample_odor']]
df['delta_dpa'] = delta_dpa
df['delta_odr'] = delta_odr

df['mouse'] = pd.Categorical(df['mouse'], categories=laser_mice, ordered=True)
df = df.sort_values('mouse')

df['delta_pc1'] = dPC1
df['delta_pc2'] = dPC2

# df = df[~df['mouse'].str.contains('ChR')]

print(df.head())
#+end_src

#+RESULTS:
:      mouse  sample_odor  delta_dpa  delta_odr  delta_pc1  delta_pc2
: 4  JawsM01          0.0   0.000000   0.031250   3.463402  -0.523150
: 5  JawsM01          1.0   0.000000  -0.031250   2.095075  -0.374704
: 6  JawsM06          0.0   0.006944  -0.020833   1.013763   0.428729
: 7  JawsM06          1.0  -0.041667   0.000000   0.838401  -0.156393
: 8  JawsM12          0.0   0.010417   0.000000   1.243234  -1.492684

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc1', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc1', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None, rasterized=1)

    corr, p_value = pearsonr(df_['delta_pc1'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC1")
    ax[i].set_ylabel("$\\Delta$ Performance")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")
# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_189.png]]

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import pearsonr

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1)

df_ = df.copy()

for i, delta_perf in enumerate(['delta_dpa', 'delta_odr']):
    sns.regplot(data=df_, x='delta_pc2', y=delta_perf, scatter=True,
                fit_reg=True, ci=95, ax=ax[i],
                scatter_kws={'s': 0, 'alpha': 0.7},
                line_kws={'color': 'k', 'lw': 2, 'ls':'--'})

    sns.scatterplot(data=df_, x='delta_pc2', y=delta_perf,
                    hue='mouse', style=None, s=80, alpha=0.8, ax=ax[i],
                    legend=None, rasterized=1)

    corr, p_value = pearsonr(df_['delta_pc2'].dropna(), df_[delta_perf].dropna())

    annotation = f"Pearson r = {corr:.2f}\np-value = {p_value:.3f}"
    ax[i].annotate(annotation, xy=(.65, 0.95), xycoords='axes fraction', fontsize=14,
                backgroundcolor='white', verticalalignment='top', horizontalalignment='left',
                bbox=dict(edgecolor=None, facecolor='white', boxstyle='round'))

    ax[i].set_xlabel("$\\Delta$ PC2")

ax[0].set_ylabel("$\\Delta$ Performance")
ax[1].set_ylabel("")

# plt.savefig('./figures/bernstein/gng_corr.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_190.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

** Binned Flow Fields
*** utils

#+begin_src jupyter-python
import numpy as np

def flow_field_from_trajectories(x, y, dt=1.0, bins=25, xrange=None, yrange=None,
                                 statistic="mean", min_count=1):
    """
    x, y: arrays (n_trials, n_time)
    dt: timestep
    bins: int or (nx, ny)
    xrange, yrange: (min, max); if None inferred from data
    statistic: "mean" (default). (You can extend to median easily.)
    Returns:
      xedges, yedges
      u, v: (nx, ny) average velocities in each spatial bin
      count: (nx, ny) number of samples per bin
    """
    x = np.asarray(x); y = np.asarray(y)
    n_trials, n_time = x.shape
    assert y.shape == x.shape

    # step velocities, shape (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # positions to bin (start of each step)
    xs = x[:, :-1]
    ys = y[:, :-1]

    if xrange is None:
        xrange = (xs.min(), xs.max())
    if yrange is None:
        yrange = (ys.min(), ys.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten all steps across trials/time
    xsf = xs.ravel()
    ysf = ys.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin index for each sample
    ix = np.searchsorted(xedges, xsf, side="right") - 1
    iy = np.searchsorted(yedges, ysf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate sums and counts
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    # mean velocity per bin
    ugrid = np.full((nx, ny), np.nan, dtype=float)
    vgrid = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    ugrid[mask] = usum[mask] / count[mask]
    vgrid[mask] = vsum[mask] / count[mask]

    return xedges, yedges, ugrid, vgrid, count


# Example usage:
# x, y = diffusion_2d(n_trials=200, n_time=2000, dt=0.01, D=0.5, seed=0)

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def flow_field_midpoint(x, y, dt=1.0, bins=25, xrange=None, yrange=None, min_count=1):
    """
    Mid-point binning: each velocity sample is assigned to the bin containing
    the segment midpoint ((x_t+x_{t+1})/2, (y_t+y_{t+1})/2).

    x, y: (n_trials, n_time)
    Returns: xedges, yedges, U, V, count with U,V,count shaped (nx, ny)
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape

    # step velocities (n_trials, n_time-1)
    u = (x[:, 1:] - x[:, :-1]) / dt
    v = (y[:, 1:] - y[:, :-1]) / dt

    # midpoints to bin (n_trials, n_time-1)
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    if xrange is None:
        xrange = (xm.min(), xm.max())
    if yrange is None:
        yrange = (ym.min(), ym.max())

    if isinstance(bins, int):
        nx = ny = bins
    else:
        nx, ny = bins

    xedges = np.linspace(xrange[0], xrange[1], nx + 1)
    yedges = np.linspace(yrange[0], yrange[1], ny + 1)

    # flatten samples
    xf = xm.ravel()
    yf = ym.ravel()
    uf = u.ravel()
    vf = v.ravel()

    # bin indices
    ix = np.searchsorted(xedges, xf, side="right") - 1
    iy = np.searchsorted(yedges, yf, side="right") - 1

    valid = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)
    ix = ix[valid]; iy = iy[valid]
    uf = uf[valid]; vf = vf[valid]

    # accumulate
    count = np.zeros((nx, ny), dtype=int)
    usum  = np.zeros((nx, ny), dtype=float)
    vsum  = np.zeros((nx, ny), dtype=float)

    np.add.at(count, (ix, iy), 1)
    np.add.at(usum,  (ix, iy), uf)
    np.add.at(vsum,  (ix, iy), vf)

    U = np.full((nx, ny), np.nan, dtype=float)
    V = np.full((nx, ny), np.nan, dtype=float)
    mask = count >= min_count
    U[mask] = usum[mask] / count[mask]
    V[mask] = vsum[mask] / count[mask]

    return xedges, yedges, U, V, count

#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_speeds(x, y, dt=1.0):
    # step velocities at times t -> t+1
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]
    ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)  # [-pi, pi)

    # avoid r=0 issues
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    vr = (xs*vx + ys*vy) / r_safe
    omega = (xs*vy - ys*vx) / (r_safe**2)

    return r, theta, vr, omega

def bin_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nbin = len(edges) - 1
    valid = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(xvals)
    idx = idx[valid]
    yvals = yvals[valid]

    count = np.zeros(nbin, dtype=int)
    ysum  = np.zeros(nbin, dtype=float)
    np.add.at(count, idx, 1)
    np.add.at(ysum,  idx, yvals)

    ymean = np.full(nbin, np.nan, float)
    m = count >= min_count
    ymean[m] = ysum[m] / count[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, count
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def radial_angular_from_binned_uv(U, V, C, xedges, yedges, r_edges, th_edges,
                                 min_count_bin=1, min_count_1d=1):
    """
    Option (2): convert binned mean velocity field (U,V) into polar components at bin centers,
    then compute weighted 1D profiles vs radius r and angle theta using weights=C.

    Inputs:
      U,V,C: (nx, ny) arrays from flow_field_from_trajectories
      xedges,yedges: bin edges
      r_edges: 1D edges for radius bins
      th_edges: 1D edges for theta bins in [-pi, pi]
      min_count_bin: require C>=this to use a spatial bin at all
      min_count_1d: require total weight in a 1D bin >= this

    Returns:
      r_cent, vr_r, w_r
      th_cent, om_th, w_th
      plus (vr_grid, om_grid) for inspection
    """
    U = np.asarray(U); V = np.asarray(V); C = np.asarray(C)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    r = np.sqrt(Xc**2 + Yc**2)
    th = np.arctan2(Yc, Xc)
    eps = 1e-12
    r_safe = np.maximum(r, eps)

    # polar components derived from mean flow vector in each spatial bin
    vr_grid = np.abs(Xc*U + Yc*V) / r_safe
    om_grid = np.abs(Xc*V - Yc*U) / (r_safe**2)   # angular speed dtheta/dt

    # flatten
    rf = r.ravel()
    thf = th.ravel()
    vrf = vr_grid.ravel()
    omf = om_grid.ravel()
    wf = C.ravel().astype(float)

    # keep only bins with enough samples and finite values
    valid = (wf >= min_count_bin) & np.isfinite(vrf) & np.isfinite(omf) & np.isfinite(rf) & np.isfinite(thf)
    rf, thf, vrf, omf, wf = rf[valid], thf[valid], vrf[valid], omf[valid], wf[valid]

    def weighted_bin_mean(xvals, yvals, wvals, edges, min_w=1.0):
        idx = np.searchsorted(edges, xvals, side="right") - 1
        nbin = len(edges) - 1
        ok = (idx >= 0) & (idx < nbin) & np.isfinite(yvals) & np.isfinite(wvals)
        idx = idx[ok]; yvals = yvals[ok]; wvals = wvals[ok]

        wsum = np.zeros(nbin, float)
        ywsum = np.zeros(nbin, float)
        np.add.at(wsum, idx, wvals)
        np.add.at(ywsum, idx, wvals * yvals)

        ymean = np.full(nbin, np.nan, float)
        m = wsum >= min_w
        ymean[m] = ywsum[m] / wsum[m]
        centers = 0.5*(edges[:-1] + edges[1:])
        return centers, ymean, wsum

    r_cent, vr_r, w_r   = weighted_bin_mean(rf,  vrf, wf, r_edges,  min_w=min_count_1d)
    th_cent, om_th, w_th = weighted_bin_mean(thf, omf, wf, th_edges, min_w=min_count_1d)

    return r_cent, vr_r, w_r, th_cent, om_th, w_th, vr_grid, om_grid
#+end_src

#+RESULTS:
: 5d87a51e-5374-454a-8df7-e0f296c46627

#+begin_src jupyter-python
import numpy as np
from scipy.ndimage import gaussian_filter1d

def gaussian_filter1d_nan(x, sigma, mode="nearest", truncate=4.0):
    x = np.asarray(x, float)
    m = np.isfinite(x).astype(float)          # 1 where valid, 0 where NaN
    x0 = np.where(np.isfinite(x), x, 0.0)

    xs = gaussian_filter1d(x0, sigma=sigma, mode=mode, truncate=truncate)
    ms = gaussian_filter1d(m,  sigma=sigma, mode=mode, truncate=truncate)

    out = xs / ms
    out[ms == 0] = np.nan
    return out
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def weighted_binned_mean(xvals, yvals, edges, weights=None,
                         min_count=1, min_weight_1d=1.0):
    """
    Bin yvals as a function of xvals using weighted mean.

    min_count: require at least this many contributing samples in each 1D bin
    min_weight_1d: require at least this much total weight in each 1D bin
    """
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()

    if weights is None:
        weights = np.ones_like(yvals, float)
    else:
        weights = np.asarray(weights).ravel().astype(float)

    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1

    ok = (
        (idx >= 0) & (idx < nb) &
        np.isfinite(xvals) & np.isfinite(yvals) &
        np.isfinite(weights) & (weights > 0)
    )
    idx = idx[ok]
    yvals = yvals[ok]
    weights = weights[ok]

    wsum  = np.zeros(nb, float)
    ywsum = np.zeros(nb, float)
    cnt   = np.zeros(nb, int)

    np.add.at(wsum,  idx, weights)
    np.add.at(ywsum, idx, weights * yvals)
    np.add.at(cnt,   idx, 1)

    ymean = np.full(nb, np.nan)
    m = (cnt >= min_count) & (wsum >= min_weight_1d)
    ymean[m] = ywsum[m] / wsum[m]

    centers = 0.5 * (edges[:-1] + edges[1:])
    return centers, ymean, cnt, wsum
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def binned_mean_1d(xvals, yvals, edges, min_count=1):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt

def speed_vs_r_theta(x_coor, y_coor, dt=1.0,
                     r_edges=None, theta_edges=None,
                     min_count=50, use_midpoint=False, nbins=32):
    x = np.asarray(x_coor); y = np.asarray(y_coor)

    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    speed = np.sqrt(vx**2 + vy**2)  # (n_trials, n_time-1)

    if use_midpoint:
        xs = 0.5*(x[:, 1:] + x[:, :-1])
        ys = 0.5*(y[:, 1:] + y[:, :-1])
    else:
        xs = x[:, :-1]
        ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    theta = np.arctan2(ys, xs)

    eps = 1e-12
    r_safe = np.maximum(r, eps)
    omega = (xs*vy - ys*vx) / (r_safe**2)

    if r_edges is None:
        r_edges = np.linspace(0, np.nanmax(r), nbins)
    if theta_edges is None:
        theta_edges = np.linspace(-np.pi, np.pi, nbins)

    r_cent, speed_r, r_cnt = binned_mean_1d(r, np.abs(speed), r_edges, min_count=min_count)
    th_cent, speed_th, th_cnt = binned_mean_1d(theta, np.abs(speed), theta_edges, min_count=min_count)

    return (r_cent, speed_r, r_cnt), (th_cent, speed_th, th_cnt)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

def vr_vth_omega_from_xy(x, y, dt=1.0, eps=1e-12):
    x = np.asarray(x); y = np.asarray(y)
    vx = (x[:, 1:] - x[:, :-1]) / dt
    vy = (y[:, 1:] - y[:, :-1]) / dt
    xs = x[:, :-1]; ys = y[:, :-1]

    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)

    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe              # = (xs*vy - ys*vx)/r
    omega = (xs*vy - ys*vx) / (r_safe**2)        # = vth / r
    return r, th, vr, vth, omega

def binned_mean(xvals, yvals, edges, min_count=50):
    xvals = np.asarray(xvals).ravel()
    yvals = np.asarray(yvals).ravel()
    idx = np.searchsorted(edges, xvals, side="right") - 1
    nb = len(edges) - 1
    ok = (idx >= 0) & (idx < nb) & np.isfinite(xvals) & np.isfinite(yvals)
    idx = idx[ok]; yvals = yvals[ok]

    cnt = np.zeros(nb, int)
    ysum = np.zeros(nb, float)
    np.add.at(cnt, idx, 1)
    np.add.at(ysum, idx, yvals)

    ymean = np.full(nb, np.nan)
    m = cnt >= min_count
    ymean[m] = ysum[m] / cnt[m]
    centers = 0.5*(edges[:-1] + edges[1:])
    return centers, ymean, cnt
#+end_src

#+RESULTS:

*** all mice

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
dt = 1
nbins = 32
min_count = 1  # choose based on how noisy you expect things to be
min_w=1
sigma_r, sigma_th= 5, 5
#+end_src

#+RESULTS:

**** cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
    X_delay = X_single[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    (r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)
mean_sp_r = np.nanmean(uniform_filter1d(np.array(sp_r_list), sigma_r), 0)

th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = np.nanmean(uniform_filter1d(np.array(sp_th_list), sigma_th), 0)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, mean_sp_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_sp_th, 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v\rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_196.png]]

**** binned cartesian speeds

#+begin_src jupyter-python
r_list, sp_r_list = [], []
th_list, sp_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
    X_delay = X_single[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=1, bins=nbins)

    speed = np.sqrt(U**2 + V**2)
    speed = np.where(C >= min_count, speed, np.nan)

    # bin centers -> R, TH
    xc = 0.5*(xedges[:-1] + xedges[1:])
    yc = 0.5*(yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
    R  = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)

    # speed vs radius (weighted by C)
    r_edges = np.linspace(0, np.nanmax(R), nbins)
    r_c, sp_r, cnt_r, wsum_r = weighted_binned_mean(R, speed, r_edges, weights=C,min_count=min_count, min_weight_1d=min_w)

    # speed vs theta (weighted by C)
    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, sp_th, cnt_th, wsum_th = weighted_binned_mean(TH, speed, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    r_list.append(r_c)
    th_list.append(th_c)

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    sp_r_list.append(sp_r)
    sp_th_list.append(sp_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.stats import circmean
r_list = pad_list(r_list, axis=0, max_len=None)
sp_r_list = pad_list(sp_r_list, axis=0, max_len=None)

mean_sp_r = np.nanmean(sp_r_list, 0)
std_sp_r = np.nanstd(sp_r_list, 0) / np.sqrt(len(options['mice']))


th_list = pad_list(th_list, axis=0, max_len=None)
sp_th_list = pad_list(sp_th_list, axis=0, max_len=None)
mean_sp_th = circmean(sp_th_list, -np.pi, np.pi, 0)
std_sp_th = np.nanstd(sp_th_list, 0) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
sigma_r = 5
sigma_th = 5


fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    sp_r = sp_r_list[i]

    r_c /= np.nanmax(r_c)

    m_sp_r = np.nanmean(sp_r)
    std_sp_r = np.nanstd(sp_r)

    sp_r = (sp_r - m_sp_r) / std_sp_r

    ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), alpha=0.25)

    th_c = th_list[i]
    sp_th = sp_th_list[i]

    m_sp_th = np.nanmean(sp_th)
    std_sp_th = np.nanstd(sp_th)

    sp_th = (sp_th - m_sp_th) / std_sp_th

    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), alpha=0.25)

ax[0].plot(r_c, uniform_filter1d(mean_sp_r, sigma_r), 'k')
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(mean_sp_th, sigma_th), 'k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle v_{bin} \rangle(r)$')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle v_{bin}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_199.png]]

#+begin_src jupyter-python


#+end_src

#+RESULTS:

**** polar speeds

#+begin_src jupyter-python
r_list = []
avr_r_list, avr_th_list = [], []
avth_r_list, avth_th_list = [], []
aw_r_list, aw_th_list = [], []

for i_mouse in range(len(options['mice'])):
    idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
    X_delay = X_single[idx].copy()

    x_coor = X_delay[:, 0, options['bins_DELAY']]
    y_coor = X_delay[:, 1, options['bins_DELAY']]

    # --- compute components
    r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

    # magnitudes
    avr  = np.abs(vr)
    avth = np.abs(vth)
    aw = np.abs(omega)

    # --- bin vs radius
    r_edges = np.linspace(0, np.nanmax(r), nbins)
    r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
    _,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
    _, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

    th_edges = np.linspace(-np.pi, np.pi, nbins)
    th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
    _,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
    _, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)

    r_c /= np.nanmax(r_c)

    m_avr_r = np.nanmean(avr_r)
    std_avr_r = np.nanstd(avr_r)
    avr_r = (avr_r - m_avr_r) / std_avr_r

    m_avr_th = np.nanmean(avr_th)
    std_avr_th = np.nanstd(avr_th)
    avr_th = (avr_th - m_avr_th) / std_avr_th

    m_avth_r = np.nanmean(avth_r)
    std_avth_r = np.nanstd(avth_r)
    avth_r = (avth_r - m_avth_r) / std_avth_r

    m_avth_th = np.nanmean(avth_th)
    std_avth_th = np.nanstd(avth_th)
    avth_th = (avth_th - m_avth_th) / std_avth_th

    m_aw_r = np.nanmean(aw_r)
    std_aw_r = np.nanstd(aw_r)
    aw_r = (aw_r - m_aw_r) / std_aw_r

    m_aw_th = np.nanmean(aw_th)
    std_aw_th = np.nanstd(aw_th)
    aw_th = (aw_th - m_aw_th) / std_aw_th

    r_list.append(r_c)
    th_list.append(th_c)

    avr_r_list.append(avr_r)
    avr_th_list.append(avr_th)

    avth_r_list.append(avth_r)
    avth_th_list.append(avth_th)

    aw_r_list.append(aw_r)
    aw_th_list.append(aw_th)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
r_list = pad_list(r_list, axis=0, max_len=None)

avr_r_list = pad_list(avr_r_list, axis=0, max_len=None)
avth_r_list = pad_list(avth_r_list, axis=0, max_len=None)
aw_r_list = pad_list(aw_r_list, axis=0, max_len=None)

mean_avr_r = np.nanmean(uniform_filter1d(avr_r_list, sigma_r, axis=-1), 0)
mean_avth_r = np.nanmean(uniform_filter1d(avth_r_list, sigma_r, axis=-1), 0)
mean_aw_r = np.nanmean(uniform_filter1d(aw_r_list, sigma_r, axis=-1), 0)

mean_avr_r = uniform_filter1d(np.nanmean(avr_r_list, 0), sigma_r)
mean_avth_r = uniform_filter1d(np.nanmean(avth_r_list, 0), sigma_r)
mean_awr = uniform_filter1d(circmean(aw_r_list, low=-np.pi, high=np.pi, axis=0), sigma_r)

std_avr_r = uniform_filter1d(np.nanstd(avr_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_avth_r = uniform_filter1d(np.nanstd(avth_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))
std_aw_r = uniform_filter1d(np.nanstd(aw_r_list, 0), sigma_r) / np.sqrt(len(options['mice']))

th_list = pad_list(th_list, axis=0, max_len=None)

avr_th_list = pad_list(avr_th_list, axis=0, max_len=None)
avth_th_list = pad_list(avth_th_list, axis=0, max_len=None)
aw_th_list = pad_list(aw_th_list, axis=0, max_len=None)

mean_avr_th = uniform_filter1d(np.mean(avr_th_list, 0), sigma_th, mode='wrap')
mean_avth_th = uniform_filter1d(np.mean(avth_th_list, axis=0), sigma_th, mode='wrap')
mean_aw_th = uniform_filter1d(circmean(aw_th_list, low=-np.pi, high=np.pi, axis=0), sigma_th, mode='wrap')

std_avr_th = uniform_filter1d(np.nanstd(avr_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_avth_th = uniform_filter1d(np.nanstd(avth_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
std_aw_th = uniform_filter1d(np.nanstd(aw_th_list, 0), sigma_th) / np.sqrt(len(options['mice']))
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avr_r = avr_r_list[i]
    avr_th = avr_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avr_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avr_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_avr_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avr_th, 'k')

ax[0].fill_between(r_c, mean_avr_r-std_avr_r, mean_avr_r+std_avr_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avr_th-std_avr_th, mean_avr_th+std_avr_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_r>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_203.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    avth_r = avth_r_list[i]
    avth_th = avth_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(avth_r, sigma_r), alpha=0.25)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(avth_th, sigma_th), alpha=0.25)

ax[0].plot(r_c, mean_avth_r, 'k')
ax[1].plot(th_c*180 / np.pi, mean_avth_th, 'k')

ax[0].fill_between(r_c, mean_avth_r-std_avth_r, mean_avth_r+std_avth_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_avth_th-std_avth_th, mean_avth_th+std_avth_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_\\theta>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_204.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

for i in range(len(options['mice'])):
    r_c = r_list[i]
    th_c = th_list[i]

    aw_r = aw_r_list[i]
    aw_th = aw_th_list[i]

    ax[0].plot(r_c, uniform_filter1d(aw_r, sigma_r), alpha=0.2)
    ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(aw_th, sigma_th), alpha=0.2)

ax[0].plot(r_c, mean_aw_r, 'k')
ax[1].plot(th_c * 180 / np.pi, mean_aw_th, 'k')

ax[0].fill_between(r_c, mean_aw_r-std_aw_r, mean_aw_r+std_aw_r, alpha=.2)
ax[1].fill_between(th_c*180/np.pi, mean_aw_th-std_aw_th, mean_aw_th+std_aw_th, alpha=.2)

ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/stratpca/figure_205.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

*** data
**** data

 #+begin_src jupyter-python
n_comp = 3
laser = 0
i_mouse = 3

idx_mouse = True
if i_mouse !=-1:
    idx_mouse = (y_single.mouse==options['mice'][i_mouse])
#+end_src

#+RESULTS:

#+begin_src jupyter-python
dt = 1
nbins = 16
min_count = 1
min_w = 1
sigma_r, sigma_th= 15, 15
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from scipy.ndimage import gaussian_filter1d, uniform_filter1d

idx = (y_single.tasks=='DPA') & (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])
# idx = (y_single.laser==0) & (y_single.mouse==options['mice'][i_mouse])

X_delay = X_single[idx].copy()

x_coor = X_delay[:, 0]
y_coor = X_delay[:, 1]

bins = np.concatenate( (options['bins_BL'], options['bins_DELAY']))

x_coor = X_delay[:, 0, bins]
y_coor = X_delay[:, 1, bins]

# x_coor = X_delay[:, 0, :options['bins_DELAY'][-1]]
# y_coor = X_delay[:, 1, :options['bins_DELAY'][-1]]

# x_coor = X_delay[:, 0, options['bins_DELAY']]
# y_coor = X_delay[:, 1, options['bins_DELAY']]

print(x_coor.shape)
#+end_src

#+RESULTS:
: (96, 48)

**** binned flows

#+begin_src jupyter-python
# xedges, yedges, U, V, C = flow_field_from_trajectories(x_coor, y_coor, dt=1, bins=32)
xedges, yedges, U, V, C = flow_field_midpoint(x_coor, y_coor, dt=dt, bins=nbins)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from matplotlib import colors

speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)

vmin = 0.0
vmax = np.nanpercentile(speed, 95)  # robust upper limit

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height), sharey=1, sharex=1)

ax[0].plot(x_coor.T, y_coor.T, alpha=0.3)

pcm = ax[1].pcolormesh(xedges, yedges, speed.T, shading="auto", vmin=vmin, vmax=vmax)

cbar = fig.colorbar(pcm, ax=ax[1])
cbar.set_label("Speed")


# pcm = ax[2].pcolormesh(
#     xedges, yedges, speed.T, shading="auto",
#     norm=colors.LogNorm(vmin=np.nanmin(speed[speed>0]), vmax=vmax)
# )

# cbar = fig.colorbar(pcm, ax=ax[2])
# cbar.set_label("Speed (log)")

# optional: overlay flow direction
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
ax[1].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.2)
# ax[2].quiver(Xc, Yc, U, V, color="w", angles="xy", scale_units="xy", scale=.25)

# ax[0].set_xlim([-6, 6])
# ax[0].set_ylim([-4, 4])
ax[0].set_xlabel('PC1')
ax[0].set_ylabel('PC2')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_218.png]]


#+begin_src jupyter-python
(r_c, sp_r, r_cnt), (th_c, sp_th, th_cnt) = speed_vs_r_theta(x_coor, y_coor, dt=dt, min_count=min_count, use_midpoint=True)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, sp_r)
ax[0].plot(r_c, uniform_filter1d(sp_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(r)$')

ax[1].plot(th_c * 180 / np.pi, sp_th)
ax[1].plot(th_c * 180 / np.pi, uniform_filter1d(sp_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle \sqrt{v_x^2+v_y^2}\rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_214.png]]


#+begin_src jupyter-python
import numpy as np

# per (x,y) bin:
speed = np.sqrt(U**2 + V**2)
speed = np.where(C >= min_count, speed, np.nan)  # optional mask low-occupancy bins

# bin centers -> R, TH
xc = 0.5*(xedges[:-1] + xedges[1:])
yc = 0.5*(yedges[:-1] + yedges[1:])
Xc, Yc = np.meshgrid(xc, yc, indexing="ij")
R  = np.sqrt(Xc**2 + Yc**2)
TH = np.arctan2(Yc, Xc)

# speed vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, speed_r, cnt_r, wsum_r = weighted_binned_mean(
    R, speed, r_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)

# speed vs theta (weighted by C)
th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, speed_th, cnt_th, wsum_th = weighted_binned_mean(
    TH, speed, th_edges, weights=C,
    min_count=min_count, min_weight_1d=min_w
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, speed_r)
ax[0].plot(r_c, uniform_filter1d(speed_r, sigma_r), color='k')

ax[0].set_xlabel("r")
ax[0].set_ylabel(r'$\langle |\mathbf{v}| \rangle(r)$')


ax[1].plot(th_c, speed_th)
ax[1].plot(th_c, uniform_filter1d(speed_th, sigma_th, mode='wrap'), color='k')

ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel(r'$\langle |\mathbf{v}| \rangle(\theta)$')
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_217.png]]

#+begin_src jupyter-python
import numpy as np

def polar_components_from_steps(x, y, dt=1.0, eps=1e-12):
    vx = (x[:,1:] - x[:,:-1]) / dt
    vy = (y[:,1:] - y[:,:-1]) / dt
    xs = x[:,:-1]; ys = y[:,:-1]
    r = np.sqrt(xs**2 + ys**2)
    th = np.arctan2(ys, xs)
    r_safe = np.maximum(r, eps)
    vr  = (xs*vx + ys*vy) / r_safe
    vth = (-ys*vx + xs*vy) / r_safe
    return r, th, vr, vth

def bin2d_mean(r, th, val, r_edges, th_edges, min_count=50):
    r = r.ravel(); th = th.ravel(); val = val.ravel()
    ir = np.searchsorted(r_edges, r, side="right") - 1
    it = np.searchsorted(th_edges, th, side="right") - 1
    nr = len(r_edges)-1; nt = len(th_edges)-1
    ok = (ir>=0)&(ir<nr)&(it>=0)&(it<nt)&np.isfinite(val)
    ir = ir[ok]; it = it[ok]; val = val[ok]

    cnt = np.zeros((nr, nt), int)
    s   = np.zeros((nr, nt), float)
    np.add.at(cnt, (ir, it), 1)
    np.add.at(s,   (ir, it), val)

    mean = np.full((nr, nt), np.nan)
    m = cnt >= min_count
    mean[m] = s[m] / cnt[m]
    return mean, cnt

def angular_anisotropy(mean_rt, eps=1e-12):
    # mean_rt: (nr, nt) array of mean quantity vs (r,theta)
    mu = np.nanmean(mean_rt, axis=1)          # mean over theta for each r
    sd = np.nanstd(mean_rt, axis=1)           # std over theta for each r
    A = sd / (np.abs(mu) + eps)               # relative angular modulation
    return A, mu, sd

# Example usage:
r, th, vr, vth = polar_components_from_steps(x_coor, y_coor, dt=dt)
r_edges  = np.linspace(0, np.nanmax(r), nbins)
th_edges = np.linspace(-np.pi, np.pi, nbins)
vr_rt, vr_cnt = bin2d_mean(r, th, np.abs(vr), r_edges, th_edges, min_count=min_w)
A_vr, vr_mu, vr_sd = angular_anisotropy(vr_rt)
vth_rt, vth_cnt = bin2d_mean(r, th, np.abs(vth), r_edges, th_edges, min_count=min_w)
#+end_src

#+RESULTS:

**** counts

 #+begin_src jupyter-python
import numpy as np
import matplotlib.pyplot as plt

r_cent  = 0.5*(r_edges[:-1] + r_edges[1:])
th_cent = 0.5*(th_edges[:-1] + th_edges[1:])

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_rt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_rt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_219.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].pcolormesh(th_edges, r_edges, vr_cnt, shading="auto")
ax[0].set_xlabel(r'$\theta$ (rad)')
ax[0].set_ylabel('r')

ax[1].pcolormesh(th_edges, r_edges, vth_cnt, shading="auto")
ax[1].set_xlabel(r'$\theta$ (rad)')
ax[1].set_ylabel('r')

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/strat_dpca/figure_219.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:

**** speeds

#+begin_src jupyter-python
# --- compute components
r, th, vr, vth, omega = vr_vth_omega_from_xy(x_coor, y_coor, dt=dt)

# magnitudes
avr  = np.abs(vr)
avth = np.abs(vth)
aw = np.abs(omega)

# --- bin vs radius
r_edges = np.linspace(0, np.nanmax(r), nbins)
r_c, avr_r,  _ = binned_mean(r,  avr,  r_edges, min_count=min_count)
_,   avth_r, _ = binned_mean(r,  avth, r_edges, min_count=min_count)
_, aw_r, _ = binned_mean(r, aw, r_edges, min_count=min_count)

th_edges = np.linspace(-np.pi, np.pi, nbins)  # ~5 degree bins
th_c, avr_th,  _ = binned_mean(th, avr,  th_edges, min_count=min_count)
_,    avth_th, _ = binned_mean(th, avth, th_edges, min_count=min_count)
_, aw_th, _ = binned_mean(th, aw, th_edges, min_count=min_count)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, avr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, avth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")

ax[1].plot(th_c * 180 / np.pi, avr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, avth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

# plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_223.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aw_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")


ax[1].plot(th_c* 180 / np.pi, aw_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c* 180 / np.pi, uniform_filter1d(aw_th, sigma_th, mode='wrap'), color='k')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_224.png]]

**** speeds from binned field

#+begin_src jupyter-python
import numpy as np

def binned_velocity_and_speed(
    x, y, dt,
    xedges, yedges,
    min_count=1,
    nan_empty=True,
):
    """
    Compute per-bin:
      U,V  = mean(vx), mean(vy)               (mean velocity components)
      S    = mean(speed) = mean(sqrt(vx^2+vy^2))  (mean speed; NOT sqrt(U^2+V^2))
      C    = counts per bin (# velocity samples falling in bin)

    x,y: arrays (n_trials, n_time)
    dt:  scalar timestep
    xedges,yedges: bin edges
    """
    x = np.asarray(x); y = np.asarray(y)
    assert x.shape == y.shape
    n_trials, n_time = x.shape
    if n_time < 2:
        raise ValueError("Need at least 2 timepoints per trial to compute velocity.")

    # per-sample velocities (n_trials, n_time-1)
    vx = np.diff(x, axis=1) / dt
    vy = np.diff(y, axis=1) / dt
    sp = np.sqrt(vx * vx + vy * vy)

    # position associated with each velocity sample: midpoint of segment
    xm = 0.5 * (x[:, 1:] + x[:, :-1])
    ym = 0.5 * (y[:, 1:] + y[:, :-1])

    # flatten all samples
    xm = xm.ravel()
    ym = ym.ravel()
    vx = vx.ravel()
    vy = vy.ravel()
    sp = sp.ravel()

    # keep finite
    ok = np.isfinite(xm) & np.isfinite(ym) & np.isfinite(vx) & np.isfinite(vy) & np.isfinite(sp)
    xm, ym, vx, vy, sp = xm[ok], ym[ok], vx[ok], vy[ok], sp[ok]

    nx = len(xedges) - 1
    ny = len(yedges) - 1

    # bin indices
    ix = np.searchsorted(xedges, xm, side="right") - 1
    iy = np.searchsorted(yedges, ym, side="right") - 1
    inside = (ix >= 0) & (ix < nx) & (iy >= 0) & (iy < ny)

    ix, iy = ix[inside], iy[inside]
    vx, vy, sp = vx[inside], vy[inside], sp[inside]

    # accumulate sums and counts
    C = np.zeros((nx, ny), dtype=np.int64)
    sum_vx = np.zeros((nx, ny), dtype=float)
    sum_vy = np.zeros((nx, ny), dtype=float)
    sum_sp = np.zeros((nx, ny), dtype=float)

    np.add.at(C, (ix, iy), 1)
    np.add.at(sum_vx, (ix, iy), vx)
    np.add.at(sum_vy, (ix, iy), vy)
    np.add.at(sum_sp, (ix, iy), sp)

    # means
    with np.errstate(invalid="ignore", divide="ignore"):
        U = sum_vx / C
        V = sum_vy / C
        S = sum_sp / C  # <-- mean speed per bin (the "fixed" part)

    if nan_empty:
        mask = C >= min_count
        U = np.where(mask, U, np.nan)
        V = np.where(mask, V, np.nan)
        S = np.where(mask, S, np.nan)

    return U, V, S, C


def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12, mask_r0=None):
    """
    Convert mean velocity components (U,V) defined at bin centers to polar components.
    Optionally mask low-count bins and optionally mask a central disk (mask_r0).
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    mask = np.isfinite(U) & np.isfinite(V)
    if C is not None:
        mask &= (C >= min_count)
    if mask_r0 is not None:
        mask &= (R >= mask_r0)

    Vr    = np.where(mask, Vr, np.nan)
    Vth   = np.where(mask, Vth, np.nan)
    Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega


# -------------------------
# Example usage:
# U,V are mean velocity components; S is mean speed (recommended for "speed map")
# -------------------------
# U, V, S, C = binned_velocity_and_speed(x, y, dt, xedges, yedges, min_count=10)
# Xc, Yc, R, TH, Vr, Vth, Omega = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=10, mask_r0=1e-6)
# speed_of_mean_flow = np.sqrt(U**2 + V**2)   # different quantity than S
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import numpy as np

def polar_from_binned_field(xedges, yedges, U, V, C=None, min_count=1, eps=1e-12):
    """
    xedges, yedges: bin edges (nx+1), (ny+1)
    U, V: mean velocity per bin, shape (nx, ny)
    C: counts per bin, shape (nx, ny) (optional but recommended)
    Returns:
      Xc, Yc, R, TH (nx, ny)
      Vr, Vth, Omega (nx, ny) with NaNs where invalid/low count
    """
    U = np.asarray(U); V = np.asarray(V)
    nx, ny = U.shape

    xc = 0.5 * (xedges[:-1] + xedges[1:])
    yc = 0.5 * (yedges[:-1] + yedges[1:])
    Xc, Yc = np.meshgrid(xc, yc, indexing="ij")  # (nx, ny)

    R = np.sqrt(Xc**2 + Yc**2)
    TH = np.arctan2(Yc, Xc)
    R_safe = np.maximum(R, eps)

    Vr  = (Xc*U + Yc*V) / R_safe
    Vth = (-Yc*U + Xc*V) / R_safe
    Omega = (Xc*V - Yc*U) / (R_safe**2)

    # mask out empty/low-sample bins
    if C is not None:
        mask = (C >= min_count) & np.isfinite(U) & np.isfinite(V)
        Vr    = np.where(mask, Vr, np.nan)
        Vth   = np.where(mask, Vth, np.nan)
        Omega = np.where(mask, Omega, np.nan)

    return Xc, Yc, R, TH, Vr, Vth, Omega
#+end_src

#+RESULTS:

#+begin_src jupyter-python
min_w = 1
U, V, S, C = binned_velocity_and_speed(x_coor, y_coor, dt, xedges, yedges, min_count=1)
Xc, Yc, R, TH, Vr, Vth, Om = polar_from_binned_field(xedges, yedges, U, V, C=C, min_count=1)

# magnitudes per bin
aVr  = np.abs(Vr)
aVth = np.abs(Vth)
aOm  = np.abs(Om)

# vs radius (weighted by C)
r_edges = np.linspace(0, np.nanmax(R), nbins)
r_c, aVr_r,  _, _ = weighted_binned_mean(R,  aVr,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aVth_r, _, _ = weighted_binned_mean(R,  aVth, r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,   aOm_r,  _, _ = weighted_binned_mean(R,  aOm,  r_edges, weights=C, min_count=min_count, min_weight_1d=min_w)

th_edges = np.linspace(-np.pi, np.pi, nbins)
th_c, aVr_th,  _, _ = weighted_binned_mean(TH, aVr,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aVth_th, _, _ = weighted_binned_mean(TH, aVth, th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
_,    aOm_th,  _, _ = weighted_binned_mean(TH, aOm,  th_edges, weights=C, min_count=min_count, min_weight_1d=min_w)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aVr_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].plot(r_c, aVth_r, label=r'$\langle|v_\theta|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<v_r>, <v_\\theta>$")


ax[1].plot(th_c * 180 / np.pi, aVr_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].plot(th_c * 180 / np.pi, aVth_th, label=r'$\langle|v_\theta|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<v_r>, <v_\\theta>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_228.png]]

#+begin_src jupyter-python
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(2*width, height),)

ax[0].plot(r_c, aOm_r,  label=r'$\langle|v_r|\rangle(r)$')
ax[0].axhline(0, color='k', ls='--')
ax[0].set_xlabel("radius r")
ax[0].set_ylabel("$<\\omega>$")

ax[1].plot(th_c * 180 / np.pi, aOm_th,  label=r'$\langle|v_r|\rangle(\theta)$')
ax[1].axhline(0, color='k', ls='--')
ax[1].set_xlabel("angle Î¸ (Â°)")
ax[1].set_ylabel("$<\\omega>$")

plt.show()
#+end_src

#+RESULTS:
[[file:./figures/pca/figure_229.png]]

#+begin_src jupyter-python

#+end_src

#+RESULTS:
