#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session landscape :kernel dual_data :exports results :output-dir ./figures/landscape :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
:RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python
: <Figure size 600x370.82 with 0 Axes>
:END:

* Imports

#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  from time import perf_counter

  import torch
  import torch.nn as nn
  import torch.optim as optim
  from skorch import NeuralNetClassifier

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.ensemble import BaggingClassifier
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.pipeline import Pipeline
  from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, LeaveOneOut
  from sklearn.decomposition import PCA

  from mne.decoding import SlidingEstimator, cross_val_multiscore, GeneralizingEstimator, get_coef

  from src.attractor.energy import run_energy, plot_energy
  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.decode.bump import decode_bump, circcvl
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
#+end_src

#+RESULTS:

* Helpers
** Model
#+begin_src ipython
  def get_bagged_coefs(clf, n_estimators):
      coefs_list = []
      bias_list = []
      for i in range(n_estimators):
          model = clf.estimators_[i]
          try:
              coefs = model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
              bias = model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
          except:
              coefs = model.named_steps['net'].coef_[0]
              bias = model.named_steps['net'].intercept_[0]

          # coefs, bias = rescale_coefs(model, coefs, bias)

          coefs_list.append(coefs)
          bias_list.append(bias)

      return np.array(coefs_list).mean(0), np.array(bias_list).mean(0)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/classificationCV.py
    from time import perf_counter
    from sklearn.ensemble import BaggingClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.pipeline import Pipeline
    from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, LeaveOneOut
    from sklearn.decomposition import PCA

    from mne.decoding import SlidingEstimator, cross_val_multiscore

    class ClassificationCV():
        def __init__(self, net, params, **kwargs):

            pipe = []
            self.scaler = kwargs['scaler']
            if self.scaler is not None and self.scaler !=0 :
                pipe.append(("scaler", StandardScaler()))

            self.n_comp = kwargs['n_comp']
            if kwargs['n_comp'] is not None:
                self.n_comp = kwargs['n_comp']
                pipe.append(("pca", PCA(n_components=self.n_comp)))

            pipe.append(("net", net))
            self.model = Pipeline(pipe)

            self.num_features = kwargs['num_features']
            self.scoring =  kwargs['scoring']

            if  kwargs['n_splits']==-1:
                self.cv = LeaveOneOut()
            else:
                self.cv = RepeatedStratifiedKFold(n_splits=kwargs['n_splits'], n_repeats=kwargs['n_repeats'])

            self.params = params
            self.verbose =  kwargs['verbose']
            self.n_jobs =  kwargs['n_jobs']

        def fit(self, X, y):
            start = perf_counter()
            if self.verbose:
                print('Fitting hyperparameters ...')

            try:
                self.model['net'].module__num_features = self.num_features
            except:
                pass

            grid = GridSearchCV(self.model, self.params, refit=True, cv=self.cv, scoring=self.scoring, n_jobs=self.n_jobs)
            grid.fit(X.astype('float32'), y.astype('float32'))
            end = perf_counter()
            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            self.best_model = grid.best_estimator_
            self.best_params = grid.best_params_

            if self.verbose:
                print(self.best_params)

            try:
                self.coefs = self.best_model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
                self.bias = self.best_model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
            except:
                self.coefs = self.best_model.named_steps['net'].coef_[0]
                self.bias = self.best_model.named_steps['net'].intercept_[0]

        def get_bootstrap_coefs(self, X, y, n_boots=10):
            start = perf_counter()
            if self.verbose:
                print('Bootstrapping coefficients ...')

            self.bagging_clf = BaggingClassifier(base_estimator=self.best_model, n_estimators=n_boots)
            self.bagging_clf.fit(X.astype('float32'), y.astype('float32'))
            end = perf_counter()

            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            self.coefs, self.bias = get_bagged_coefs(self.bagging_clf, n_estimators=n_boots)

            return self.coefs, self.bias

        def get_overlap(self, model, X):
            try:
                coefs = model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
                bias = model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
            except:
                coefs = model.named_steps['net'].coef_[0]
                bias = model.named_steps['net'].intercept_[0]

            if self.scaler is not None and self.scaler!=0:
                scaler = model.named_steps['scaler']
                for i in range(X.shape[-1]):
                    X[..., i] = scaler.transform(X[..., i])

            if self.n_comp is not None:
                pca = model.named_steps['pca']
                X_pca = np.zeros((X.shape[0], self.n_comp, X.shape[-1]))

                for i in range(X.shape[-1]):
                    X_pca[..., i] = pca.transform(X[..., i])

                self.overlaps = (np.swapaxes(X_pca, 1, -1) @ coefs + bias) / np.linalg.norm(coefs)
            else:
                self.overlaps = -(np.swapaxes(X, 1, -1) @ coefs + bias) / np.linalg.norm(coefs)

            return self.overlaps

        def get_bootstrap_overlaps(self, X):
            start = perf_counter()
            if self.verbose:
                print('Getting bootstrapped overlaps ...')

            X_copy = np.copy(X)
            overlaps_list = []
            n_boots = len(self.bagging_clf.estimators_)

            for i in range(n_boots):
                model = self.bagging_clf.estimators_[i]
                overlaps = self.get_overlap(model, X_copy)
                overlaps_list.append(overlaps)

            end = perf_counter()
            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            return np.array(overlaps_list).mean(0)

        def get_cv_scores(self, X, y, scoring):
            start = perf_counter()
            if self.verbose:
                print('Computing cv scores ...')

            estimator = SlidingEstimator(clone(self.best_model), n_jobs=1,
                                         scoring=scoring, verbose=False)

            self.scores = cross_val_multiscore(estimator, X.astype('float32'), y.astype('float32'),
                                               cv=self.cv, n_jobs=-1, verbose=False)
            end = perf_counter()
            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            return self.scores
#+end_src

#+RESULTS:


  #+begin_src ipython :tangle ../src/torch/main.py
      from src.common.get_data import get_X_y_days, get_X_y_S1_S2
      from src.preprocess.helpers import avg_epochs

      def get_classification(model, RETURN='overlaps', **options):
              start = perf_counter()

              dum = 0
              if options['features'] == 'distractor':
                      if options['task'] != 'Dual':
                              task = options['task']
                              options['task'] = 'Dual'
                              dum = 1

              X_days, y_days = get_X_y_days(**options)
              X, y = get_X_y_S1_S2(X_days, y_days, **options)
              y[y==-1] = 0
              if options['verbose']:
                  print('X', X.shape, 'y', y.shape)

              X_avg = avg_epochs(X, **options).astype('float32')
              if dum:
                      options['features'] = 'sample'
                      options['task'] = task
                      X, _ = get_X_y_S1_S2(X_days, y_days, **options)

              index = mice.index(options['mouse'])
              model.num_features = N_NEURONS[index]

              if options['class_weight']:
                      pos_weight = torch.tensor(np.sum(y==0) / np.sum(y==1), device=DEVICE).to(torch.float32)
                      print('imbalance', pos_weight)
                      model.criterion__pos_weight = pos_weight

              model.fit(X_avg, y)

              if 'scores' in RETURN:
                  scores = model.get_cv_scores(X, y, options['scoring'])
                  end = perf_counter()
                  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                  return scores
              if 'overlaps' in RETURN:
                  if options['n_boots']>1:
                          coefs, bias = model.get_bootstrap_coefs(X_avg, y, n_boots=options['n_boots'])
                          overlaps = model.get_bootstrap_overlaps(X)
                  else:
                          coefs = model.coefs
                          bias = model.bias
                          overlaps = model.get_overlap(model, X)

                  end = perf_counter()
                  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                  return overlaps
              if 'coefs' in RETURN:
                  if options['n_boots']>1:
                          coefs, bias = model.get_bootstrap_coefs(X_avg, y, n_boots=options['n_boots'])
                  else:
                          coefs = model.coefs
                          bias = model.bias
                  end = perf_counter()
                  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                  return coefs, bias
#+end_src

#+RESULTS:

** Other

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython
def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      cos_theta = A_norm @ B_norm.T
      angle_radians = np.arccos(np.clip(cos_theta, -1.0, 1.0))

      return np.degrees(angle_radians)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

** Plots

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          for i in range(b.shape[0]):
              v[i] = b[i] - (b[i] @ a[i]) * a[i] / (a[i] @ a[i])

      if IF_NORM:
          for i in range(b.shape[0]):
              u[i] = u[i] / np.linalg.norm(u[i])
              v[i] = v[i] / np.linalg.norm(v[i])

      return np.arctan2(v, u) % (2.0 * np.pi)
#+end_src

#+RESULTS:


#+begin_src ipython
  def get_energy(X, y, task, num_bins, bins, bins0, window, IF_BOOT=0, IF_NORM=0, IF_HMM=0, n_iter=10):
    ci_ = None
    energy_ = run_energy(X, num_bins, bins, bins0, task, window, VERBOSE=0, IF_HMM=IF_HMM, n_iter=n_iter)
    if IF_BOOT:
        _, ci_ = my_boots_ci(X, lambda x: run_energy(x, num_bins, bins, task, window, IF_HMM=IF_HMM, n_iter=n_iter), n_samples=1000)
    if ci_ is not None:
      ci_ = ci_ / 2.0
    return energy_, ci_
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_theta_energy(theta, energy, ci=None, window=.9, ax=None, SMOOTH=0, color='r'):
      if ax is None:
          fig, ax = plt.subplots()

      theta = np.linspace(0, 360, energy.shape[0], endpoint=False)
      # theta = np.linspace(-180, 180, energy.shape[0], endpoint=False)
      energy = energy[1:]
      theta = theta[1:]

      windowSize = int(window * energy.shape[0])
      if SMOOTH:
          # window = np.ones(windowSize) / windowSize
          # energy = np.convolve(energy, window, mode='same')
          # theta = circcvl(theta, windowSize=windowSize)
          energy = circcvl(energy, windowSize=windowSize)

      ax.plot(theta, energy * 100, lw=4, color=color)

      if ci is not None:
          ax.fill_between(
              theta,
              (energy - ci[:, 0]) * 100,
              (energy + ci[:, 1]) * 100,
              alpha=0.1, color=color
          )

      ax.set_ylabel('Energy')
      ax.set_xlabel('Pref. Location (°)')
      ax.set_xticks([0, 90, 180, 270, 360])
#+end_src

#+RESULTS:

#+begin_src ipython
  import numpy as np

  def circcvl(signal, windowSize=10, axis=-1):
      signal_copy = signal.copy()

      if axis != -1 and signal.ndim != 1:
          signal_copy = np.swapaxes(signal_copy, axis, -1)

      # Save the nan positions before replacing them
      nan_mask = np.isnan(signal_copy)
      signal_copy[nan_mask] = np.interp(np.flatnonzero(nan_mask),
                                        np.flatnonzero(~nan_mask),
                                        signal_copy[~nan_mask])

      # Ensure the window size is odd for a centered kernel
      if windowSize % 2 == 0:
          windowSize += 1

      # Create a centered averaging kernel
      kernel = np.ones(windowSize) / windowSize

      # Apply convolution along the last axis or specified axis
      smooth_signal = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='valid'), axis=-1, arr=signal_copy)

      # Substitute the original nan positions back into the result
      smooth_signal[nan_mask] = np.nan

      if axis != -1 and signal.ndim != 1:
          smooth_signal = np.swapaxes(smooth_signal, axis, -1)

      return smooth_signal
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

def circcvl(signal, windowSize=10, axis=-1):
    signal_copy = signal.copy()

    if axis != -1 and signal.ndim != 1:
        signal_copy = np.swapaxes(signal_copy, axis, -1)

    # Save the NaN positions before replacing them
    nan_mask = np.isnan(signal_copy)
    signal_copy[nan_mask] = np.interp(
        np.flatnonzero(nan_mask),
        np.flatnonzero(~nan_mask),
        signal_copy[~nan_mask]
    )

    # Ensure the window size is odd for a centered kernel
    if windowSize % 2 == 0:
        windowSize += 1

    # Create a centered averaging kernel
    kernel = np.ones(windowSize) / windowSize

    # Number of elements to pad on each side
    pad_width = windowSize // 2

    # Pad the signal circularly
    if signal.ndim == 1:
        padded_signal = np.pad(signal_copy, pad_width, mode='wrap')
    else:
        padding = [(0, 0)] * (signal.ndim - 1) + [(pad_width, pad_width)]
        padded_signal = np.pad(signal_copy, padding, mode='wrap')

    # Apply convolution along the last axis or specified axis
    smooth_signal = np.apply_along_axis(
        lambda m: np.convolve(m, kernel, mode='same'),
        axis=-1,
        arr=padded_signal
    )

    # Remove padding
    if signal.ndim == 1:
        smooth_signal = smooth_signal[pad_width:-pad_width]
    else:
        indexer = [slice(None)] * (smooth_signal.ndim - 1) + [slice(pad_width, -pad_width)]
        smooth_signal = smooth_signal[tuple(indexer)]

    # Substitute the original NaN positions back into the result
    smooth_signal[nan_mask] = np.nan

    if axis != -1 and signal.ndim != 1:
        smooth_signal = np.swapaxes(smooth_signal, axis, -1)

    return smooth_signal
#+end_src

#+RESULTS:

#+begin_src ipython
def circular_distance(angle1, angle2, mod):
    difference = (angle2 - angle1) % mod
    circular_distance = min(difference, mod - difference)
    return circular_distance

def remove_close_entries(nums, threshold, modulus):
    # First, remove duplicates:
    unique_nums = list(set(nums))

    # Sort the numbers
    unique_nums.sort()

    # Filter entries based on circular distance threshold
    filtered_nums = []
    for num in unique_nums:
        if not filtered_nums:  # If the list is empty, add the first element
            filtered_nums.append(num)
        elif all(circular_distance(num, existing_num, modulus) >= threshold for existing_num in filtered_nums):
            filtered_nums.append(num)

    return filtered_nums

# Example usage:
nums = [10.4, 22.2, 10, 5.2, 30, 22, 24]
threshold = 3
modulus = 40
result = remove_close_entries(nums, threshold, modulus)
print(result)
#+end_src

#+RESULTS:
: [5.2, 10, 22, 30]

#+begin_src ipython
def remove_close_entries_with_indices(nums, threshold, modulus):
    # Create a list of tuples (value, index)
    indexed_nums = list(enumerate(nums))

    # Sort based on the values but keep the original indices
    indexed_nums.sort(key=lambda x: x[1])

    # Function to calculate circular distance
    def circular_distance(x, y, mod):
        return min((x - y) % mod, (y - x) % mod)

    filtered_indices = []
    filtered_nums = []

    for idx, num in indexed_nums:
        if not filtered_nums:
            filtered_nums.append(num)
            filtered_indices.append(idx)
        elif all(circular_distance(num, existing_num, modulus) >= threshold for existing_num in filtered_nums):
            filtered_nums.append(num)
            filtered_indices.append(idx)

    return filtered_indices

# Example usage:
nums = [10, 22, 10, 5, 30, 22]
threshold = 10
modulus = 360
result_indices = remove_close_entries_with_indices(nums, threshold, modulus)
print(result_indices)
elements = [nums[i] for i in result_indices]
print(elements)
#+end_src

#+RESULTS:
: [3, 1]
: [5, 22]

#+begin_src ipython
import numpy as np
from scipy.optimize import differential_evolution
from scipy.interpolate import interp1d
import matplotlib.pyplot as plt

def find_multiple_minima_from_values(x_vals, y_vals, num_runs=100, tol=0.05, popsize=2, maxiter=1000, min_distance=35):

    energy_function = interp1d(x_vals, y_vals, kind='cubic', fill_value="extrapolate")
    bounds = [(x_vals.min(), x_vals.max())]
    results = []

    result_old = 999
    for _ in range(num_runs):
        result = differential_evolution(energy_function, bounds, strategy='rand1bin',
                                        maxiter=maxiter, popsize=popsize, tol=tol,
                                        seed=np.random.randint(0, 10000))

        results.append((result.x[0], result.fun))

    results = np.array(results)
    indices = remove_close_entries_with_indices(results[:, 0], min_distance, 360)
    results = results[indices]

    return results
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_named_steps["model"]

    norm_w = np.linalg.norm(coef)

    if IF_SIGN:
        # dot_product = (2*y_test -1) * np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)
        dot_product = (2*y_test -1) * clf.decision_function(X_test)
    else:
        dot_product = clf.decision_function(X_test)
        # dot_product = -np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)

    return np.nanmean(dot_product) / coef.shape[0] / norm_w
#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  #  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  mice = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12']
  # mice = ['PP09', 'PP17']

  kwargs = {
      'mouse': mice[1], 'laser': 0,
      'trials': 'correct', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05, 'n_comp': 0,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise': True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 1000,
      'n_splits': 5, 'n_repeats': 1,
      'class_weight': 0,
      'multilabel':0,
      'mne_estimator': 'generalizing', # sliding or generalizing
      'n_jobs': 128,
      'bolasso_penalty': 'l2',
      'bolasso_pval': 0.05,
  }

  kwargs['days'] = ['first', 'middle', 'last']
  # kwargs['days'] = ['first', 'last']
  kwargs['days'] = 'all'
  options = set_options(**kwargs)
  print(options['days'])
  options['cv'] = 5 # LeaveOneOut()
  options['mice'] = mice

  IF_BOOT = 0
  # options['hp_scoring'] = lambda estimator, X_test, y_test: np.abs(overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1))
  options['hp_scoring'] = 'f1_weighted'
  options['scoring'] = options['hp_scoring']
  options['scoring'] = overlaps_scorer
#+end_src

#+RESULTS:
: [1 2 3 4 5 6]

* Landscape vs days

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
#+end_src

#+RESULTS:

#+begin_src ipython
#  from src.torch.classificationCV import ClassificationCV
from src.torch.classify import get_classification
#+end_src

#+RESULTS:

 #+begin_src ipython
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.svm import LinearSVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

Cs = np.logspace(-3, 3, 20)

if IF_BOOT:
    net = LogisticRegression(penalty='l1', solver='liblinear', n_jobs=None, tol=0.001)
    # net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)
    # net = LinearDiscriminantAnalysis(solver="lsqr", shrinkage=1)
else:
    # net = LinearSVC(penalty='l1', class_weight='balanced')
    net = LogisticRegressionCV(penalty='l1', solver='liblinear', n_jobs=None, tol=0.001, cv=5, Cs=Cs)
    # net = LogisticRegressionCV(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratios=[0.5], Cs=Cs, cv=3)

params = {'model__C': Cs}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['verbose'] = 1
#+end_src

#+RESULTS:
: PCA False None

     #+begin_src ipython
# options['mice'] = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
options['mice'] = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
# options['mice'] = ['ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
# options['mice'] = ['JawsM15']
     #+end_src

#+RESULTS:

#+begin_src ipython
coefs_mice = []

for mouse in options['mice']:
    options['mouse'] = mouse
    options = set_options(**options)

    coefs_sample = []
    coefs_dist = []
    coefs_choice = []

    bias_sample = []
    bias_dist = []
    bias_choice = []

    theta_day = []
    index_day = []

    for day in options['days']:
        options['day'] = day

        options['trials'] = 'correct'
        options['task'] = 'all'
        options['features'] = 'sample'
        options['epochs'] = ['ED']

        try:
            if IF_BOOT:
                coefs, bias = get_classification(model, RETURN='coefs', **options)
                coefs_sample.append(coefs[:, 0])
            else:
                coefs, bias = get_classification(model, RETURN='bolasso', **options)
                coefs_sample.append(coefs)
        except:
            if IF_BOOT:
                coefs_sample.append(coefs[:, 0] * np.nan)
            else:
                coefs_sample.append(coefs * np.nan)

        # options['task'] = 'all'
        # options['features'] = 'distractor'
        # options['trials'] = ''
        # options['epochs'] = ['MD']

        # try:
        #     if IF_BOOT:
        #         coefs, bias = get_classification(model, RETURN='coefs', **options)
        #         coefs_dist.append(coefs[:, 0])
        #     else:
        #         coefs, bias = get_classification(model, RETURN='bolasso', **options)
        #         coefs_dist.append(coefs)
        # except:
        #     if IF_BOOT:
        #         coefs_dist.append(coefs[:, 0] * np.nan)
        #     else:
        #         coefs_dist.append(coefs * np.nan)

        options['task'] = 'all'
        options['features'] = 'choice'
        options['epochs'] = ['CHOICE']
        options['trials'] = ''

        try:
            if IF_BOOT:
                 coefs, bias = get_classification(model, RETURN='coefs', **options)
                 coefs_choice.append(coefs[:, 0])
            else:
                coefs, bias = get_classification(model, RETURN='bolasso', **options)
                coefs_choice.append(coefs)
        except:
            if IF_BOOT:
                coefs_choice.append(coefs[:, 0] * np.nan)
            else:
                coefs_choice.append(coefs * np.nan)

    coefs_save = np.stack((coefs_sample, coefs_choice, coefs_choice))
    coefs_mice.append(coefs_save)

    print(coefs_save.shape)
    pkl_save(coefs_save, '%s_coefs_%.2f_l1_ratio%s' % (options['mouse'], options['l1_ratio'], options['fname']), path="/storage/leon/dual_task/data/%s/" % options['mouse'])
    #+end_src

#+RESULTS:
#+begin_example
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (54, 15) ['DualNoGo' 'DualGo' 'DPA']
X (54, 184, 84) nans 0.0 y (54,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 105
X_fs (54, 105)
samples (54,) features (184,) non zero 105
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 15) ['DualGo' 'DPA' 'DualNoGo']
X (96, 184, 84) nans 0.0 y (96,) [0. 1.]
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (71, 15) ['DPA' 'DualGo' 'DualNoGo']
X (71, 184, 84) nans 0.0 y (71,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 165
X_fs (71, 165)
samples (71,) features (184,) non zero 165
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 15) ['DPA' 'DualGo' 'DualNoGo']
X (96, 184, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 162
X_fs (96, 162)
samples (96,) features (184,) non zero 162
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (91, 15) ['DPA' 'DualNoGo' 'DualGo']
X (91, 184, 84) nans 0.0 y (91,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 167
X_fs (91, 167)
samples (91,) features (184,) non zero 167
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 15) ['DPA' 'DualGo' 'DualNoGo']
X (96, 184, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 165
X_fs (96, 165)
samples (96,) features (184,) non zero 165
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (91, 15) ['DPA' 'DualGo' 'DualNoGo']
X (91, 184, 84) nans 0.0 y (91,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 161
X_fs (91, 161)
samples (91,) features (184,) non zero 161
Loading files from /storage/leon/dual_task/data/JawsM01
X_days (768, 184, 84) y_days (768, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 15) ['DPA' 'DualGo' 'DualNoGo']
X (96, 184, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 167
X_fs (96, 167)
samples (96,) features (184,) non zero 167
(3, 4, 184)
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (52, 15) ['DualNoGo' 'DualGo' 'DPA']
X (52, 201, 84) nans 0.0 y (52,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 174
X_fs (52, 174)
samples (52,) features (201,) non zero 174
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 15) ['DPA' 'DualNoGo' 'DualGo']
X (96, 201, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 183
X_fs (96, 183)
samples (96,) features (201,) non zero 183
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (63, 15) ['DualGo' 'DualNoGo' 'DPA']
X (63, 201, 84) nans 0.0 y (63,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 179
X_fs (63, 179)
samples (63,) features (201,) non zero 179
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 15) ['DualGo' 'DualNoGo' 'DPA']
X (96, 201, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 177
X_fs (96, 177)
samples (96,) features (201,) non zero 177
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (68, 15) ['DualNoGo' 'DualGo' 'DPA']
X (68, 201, 84) nans 0.0 y (68,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 181
X_fs (68, 181)
samples (68,) features (201,) non zero 181
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 15) ['DPA' 'DualNoGo' 'DualGo']
X (96, 201, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 173
X_fs (96, 173)
samples (96,) features (201,) non zero 173
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (76, 15) ['DualGo' 'DualNoGo' 'DPA']
X (76, 201, 84) nans 0.0 y (76,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 180
X_fs (76, 180)
samples (76,) features (201,) non zero 180
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 15) ['DualGo' 'DualNoGo' 'DPA']
X (96, 201, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 176
X_fs (96, 176)
samples (96,) features (201,) non zero 176
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (82, 15) ['DPA' 'DualNoGo' 'DualGo']
X (82, 201, 84) nans 0.0 y (82,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 181
X_fs (82, 181)
samples (82,) features (201,) non zero 181
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (96, 15) ['DPA' 'DualNoGo' 'DualGo']
X (96, 201, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 170
X_fs (96, 170)
samples (96,) features (201,) non zero 170
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 6 LASER 0
y_labels (90, 15) ['DualNoGo' 'DualGo' 'DPA']
X (90, 201, 84) nans 0.0 y (90,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 182
X_fs (90, 182)
samples (90,) features (201,) non zero 182
Loading files from /storage/leon/dual_task/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 6 LASER 0
y_labels (96, 15) ['DPA' 'DualGo' 'DualNoGo']
X (96, 201, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 162
X_fs (96, 162)
samples (96,) features (201,) non zero 162
(3, 6, 201)
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (58, 15) ['DPA' 'DualGo' 'DualNoGo']
X (58, 423, 84) nans 0.0 y (58,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 358
X_fs (58, 358)
samples (58,) features (423,) non zero 358
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 15) ['DPA' 'DualGo' 'DualNoGo']
X (96, 423, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 370
X_fs (96, 370)
samples (96,) features (423,) non zero 370
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (63, 15) ['DualNoGo' 'DualGo' 'DPA']
X (63, 423, 84) nans 0.0 y (63,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 370
X_fs (63, 370)
samples (63,) features (423,) non zero 370
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 15) ['DualGo' 'DualNoGo' 'DPA']
X (96, 423, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 360
X_fs (96, 360)
samples (96,) features (423,) non zero 360
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (61, 15) ['DualNoGo' 'DualGo' 'DPA']
X (61, 423, 84) nans 0.0 y (61,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 381
X_fs (61, 381)
samples (61,) features (423,) non zero 381
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 15) ['DualNoGo' 'DualGo' 'DPA']
X (96, 423, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 355
X_fs (96, 355)
samples (96,) features (423,) non zero 355
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (70, 15) ['DPA' 'DualGo' 'DualNoGo']
X (70, 423, 84) nans 0.0 y (70,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 379
X_fs (70, 379)
samples (70,) features (423,) non zero 379
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 15) ['DualNoGo' 'DualGo' 'DPA']
X (96, 423, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 373
X_fs (96, 373)
samples (96,) features (423,) non zero 373
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (71, 15) ['DPA' 'DualNoGo' 'DualGo']
X (71, 423, 84) nans 0.0 y (71,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 368
X_fs (71, 368)
samples (71,) features (423,) non zero 368
Loading files from /storage/leon/dual_task/data/JawsM12
X_days (960, 423, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (96, 15) ['DPA' 'DualGo' 'DualNoGo']
X (96, 423, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 368
X_fs (96, 368)
samples (96,) features (423,) non zero 368
(3, 5, 423)
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (59, 16) ['DualGo' 'DualNoGo' 'DPA']
X (59, 693, 84) nans 0.0 y (59,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 625
X_fs (59, 625)
samples (59,) features (693,) non zero 625
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 16) ['DualGo' 'DPA' 'DualNoGo']
X (96, 693, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 603
X_fs (96, 603)
samples (96,) features (693,) non zero 603
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (63, 16) ['DualNoGo' 'DualGo' 'DPA']
X (63, 693, 84) nans 0.0 y (63,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 623
X_fs (63, 623)
samples (63,) features (693,) non zero 623
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 16) ['DualNoGo' 'DPA' 'DualGo']
X (96, 693, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 590
X_fs (96, 590)
samples (96,) features (693,) non zero 590
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (73, 16) ['DualGo' 'DPA' 'DualNoGo']
X (73, 693, 84) nans 0.0 y (73,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 631
X_fs (73, 631)
samples (73,) features (693,) non zero 631
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 16) ['DPA' 'DualGo' 'DualNoGo']
X (96, 693, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 597
X_fs (96, 597)
samples (96,) features (693,) non zero 597
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (89, 16) ['DualGo' 'DualNoGo' 'DPA']
X (89, 693, 84) nans 0.0 y (89,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 630
X_fs (89, 630)
samples (89,) features (693,) non zero 630
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 16) ['DualGo' 'DualNoGo' 'DPA']
X (96, 693, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 581
X_fs (96, 581)
samples (96,) features (693,) non zero 581
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (70, 16) ['DualNoGo' 'DualGo' 'DPA']
X (70, 693, 84) nans 0.0 y (70,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 613
X_fs (70, 613)
samples (70,) features (693,) non zero 613
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (96, 16) ['DualGo' 'DPA' 'DualNoGo']
X (96, 693, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 580
X_fs (96, 580)
samples (96,) features (693,) non zero 580
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 6 LASER 0
y_labels (90, 16) ['DualNoGo' 'DualGo' 'DPA']
X (90, 693, 84) nans 0.0 y (90,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 632
X_fs (90, 632)
samples (90,) features (693,) non zero 632
Loading files from /storage/leon/dual_task/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 6 LASER 0
y_labels (96, 16) ['DPA' 'DualNoGo' 'DualGo']
X (96, 693, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 623
X_fs (96, 623)
samples (96,) features (693,) non zero 623
(3, 6, 693)
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (64, 16) ['DualNoGo' 'DualGo' 'DPA']
X (64, 444, 84) nans 0.0 y (64,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 382
X_fs (64, 382)
samples (64,) features (444,) non zero 382
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 16) ['DPA' 'DualNoGo' 'DualGo']
X (96, 444, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 382
X_fs (96, 382)
samples (96,) features (444,) non zero 382
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (83, 16) ['DPA' 'DualGo' 'DualNoGo']
X (83, 444, 84) nans 0.0 y (83,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 401
X_fs (83, 401)
samples (83,) features (444,) non zero 401
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 16) ['DualNoGo' 'DPA' 'DualGo']
X (96, 444, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 389
X_fs (96, 389)
samples (96,) features (444,) non zero 389
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (88, 16) ['DualGo' 'DualNoGo' 'DPA']
X (88, 444, 84) nans 0.0 y (88,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 392
X_fs (88, 392)
samples (88,) features (444,) non zero 392
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 16) ['DPA' 'DualGo' 'DualNoGo']
X (96, 444, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 383
X_fs (96, 383)
samples (96,) features (444,) non zero 383
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (94, 16) ['DPA' 'DualNoGo' 'DualGo']
X (94, 444, 84) nans 0.0 y (94,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 387
X_fs (94, 387)
samples (94,) features (444,) non zero 387
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 16) ['DPA' 'DualGo' 'DualNoGo']
X (96, 444, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 393
X_fs (96, 393)
samples (96,) features (444,) non zero 393
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (95, 16) ['DPA' 'DualNoGo' 'DualGo']
X (95, 444, 84) nans 0.0 y (95,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 392
X_fs (95, 392)
samples (95,) features (444,) non zero 392
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (96, 16) ['DualGo' 'DPA' 'DualNoGo']
X (96, 444, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 390
X_fs (96, 390)
samples (96,) features (444,) non zero 390
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 6 LASER 0
y_labels (94, 16) ['DPA' 'DualGo' 'DualNoGo']
X (94, 444, 84) nans 0.0 y (94,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 394
X_fs (94, 394)
samples (94,) features (444,) non zero 394
Loading files from /storage/leon/dual_task/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 6 LASER 0
y_labels (96, 16) ['DPA' 'DualGo' 'DualNoGo']
X (96, 444, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 393
X_fs (96, 393)
samples (96,) features (444,) non zero 393
(3, 6, 444)
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (57, 16) ['DualNoGo' 'DPA' 'DualGo']
X (57, 668, 84) nans 0.0 y (57,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 598
X_fs (57, 598)
samples (57,) features (668,) non zero 598
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 16) ['DualNoGo' 'DualGo' 'DPA']
X (96, 668, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 607
X_fs (96, 607)
samples (96,) features (668,) non zero 607
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (92, 16) ['DualGo' 'DPA' 'DualNoGo']
X (92, 668, 84) nans 0.0 y (92,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 605
X_fs (92, 605)
samples (92,) features (668,) non zero 605
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 16) ['DualGo' 'DPA' 'DualNoGo']
X (96, 668, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 589
X_fs (96, 589)
samples (96,) features (668,) non zero 589
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (85, 16) ['DualGo' 'DPA' 'DualNoGo']
X (85, 668, 84) nans 0.0 y (85,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 577
X_fs (85, 577)
samples (85,) features (668,) non zero 577
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 16) ['DPA' 'DualGo' 'DualNoGo']
X (96, 668, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 614
X_fs (96, 614)
samples (96,) features (668,) non zero 614
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (94, 16) ['DualNoGo' 'DualGo' 'DPA']
X (94, 668, 84) nans 0.0 y (94,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 590
X_fs (94, 590)
samples (94,) features (668,) non zero 590
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 16) ['DualGo' 'DPA' 'DualNoGo']
X (96, 668, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 593
X_fs (96, 593)
samples (96,) features (668,) non zero 593
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (86, 16) ['DualNoGo' 'DualGo' 'DPA']
X (86, 668, 84) nans 0.0 y (86,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 600
X_fs (86, 600)
samples (86,) features (668,) non zero 600
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (96, 16) ['DualGo' 'DualNoGo' 'DPA']
X (96, 668, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 596
X_fs (96, 596)
samples (96,) features (668,) non zero 596
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 6 LASER 0
y_labels (84, 16) ['DualGo' 'DPA' 'DualNoGo']
X (84, 668, 84) nans 0.0 y (84,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 581
X_fs (84, 581)
samples (84,) features (668,) non zero 581
Loading files from /storage/leon/dual_task/data/ChRM04
X_days (1152, 668, 84) y_days (1152, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 6 LASER 0
y_labels (96, 16) ['DualGo' 'DPA' 'DualNoGo']
X (96, 668, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 668)
p_val (668,)
significant 599
X_fs (96, 599)
samples (96,) features (668,) non zero 599
(3, 6, 668)
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (64, 15) ['DualGo' 'DPA' 'DualNoGo']
X (64, 232, 84) nans 0.0 y (64,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 188
X_fs (64, 188)
samples (64,) features (232,) non zero 188
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (96, 15) ['DualGo' 'DPA' 'DualNoGo']
X (96, 232, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 213
X_fs (96, 213)
samples (96,) features (232,) non zero 213
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (66, 15) ['DualNoGo' 'DPA' 'DualGo']
X (66, 232, 84) nans 0.0 y (66,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 209
X_fs (66, 209)
samples (66,) features (232,) non zero 209
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (96, 15) ['DPA' 'DualNoGo' 'DualGo']
X (96, 232, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 218
X_fs (96, 218)
samples (96,) features (232,) non zero 218
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (68, 15) ['DualNoGo' 'DualGo' 'DPA']
X (68, 232, 84) nans 0.0 y (68,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 199
X_fs (68, 199)
samples (68,) features (232,) non zero 199
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (96, 15) ['DualNoGo' 'DualGo' 'DPA']
X (96, 232, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 208
X_fs (96, 208)
samples (96,) features (232,) non zero 208
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (66, 15) ['DualNoGo' 'DualGo' 'DPA']
X (66, 232, 84) nans 0.0 y (66,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 214
X_fs (66, 214)
samples (66,) features (232,) non zero 214
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (96, 15) ['DualNoGo' 'DualGo' 'DPA']
X (96, 232, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 206
X_fs (96, 206)
samples (96,) features (232,) non zero 206
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (79, 15) ['DualNoGo' 'DPA' 'DualGo']
X (79, 232, 84) nans 0.0 y (79,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 205
X_fs (79, 205)
samples (79,) features (232,) non zero 205
Loading files from /storage/leon/dual_task/data/ChRM23
X_days (960, 232, 84) y_days (960, 14)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (96, 15) ['DualNoGo' 'DPA' 'DualGo']
X (96, 232, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 232)
p_val (232,)
significant 209
X_fs (96, 209)
samples (96,) features (232,) non zero 209
(3, 5, 232)
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (102, 16) ['DPA' 'DualGo' 'DualNoGo']
X (102, 361, 84) nans 0.0 y (102,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 321
X_fs (102, 321)
samples (102,) features (361,) non zero 321
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (192, 16) ['DualNoGo' 'DualGo' 'DPA']
X (192, 361, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 308
X_fs (192, 308)
samples (192,) features (361,) non zero 308
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (118, 16) ['DPA' 'DualNoGo' 'DualGo']
X (118, 361, 84) nans 0.0 y (118,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 321
X_fs (118, 321)
samples (118,) features (361,) non zero 321
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (192, 16) ['DPA' 'DualNoGo' 'DualGo']
X (192, 361, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 326
X_fs (192, 326)
samples (192,) features (361,) non zero 326
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (152, 16) ['DualNoGo' 'DualGo' 'DPA']
X (152, 361, 84) nans 0.0 y (152,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 329
X_fs (152, 329)
samples (152,) features (361,) non zero 329
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (192, 16) ['DualGo' 'DualNoGo' 'DPA']
X (192, 361, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 317
X_fs (192, 317)
samples (192,) features (361,) non zero 317
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (168, 16) ['DualGo' 'DualNoGo' 'DPA']
X (168, 361, 84) nans 0.0 y (168,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 329
X_fs (168, 329)
samples (168,) features (361,) non zero 329
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (192, 16) ['DPA' 'DualGo' 'DualNoGo']
X (192, 361, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 321
X_fs (192, 321)
samples (192,) features (361,) non zero 321
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (181, 16) ['DPA' 'DualNoGo' 'DualGo']
X (181, 361, 84) nans 0.0 y (181,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 328
X_fs (181, 328)
samples (181,) features (361,) non zero 328
Loading files from /storage/leon/dual_task/data/ACCM03
X_days (960, 361, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (192, 16) ['DualNoGo' 'DPA' 'DualGo']
X (192, 361, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 361)
p_val (361,)
significant 313
X_fs (192, 313)
samples (192,) features (361,) non zero 313
(3, 5, 361)
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 1 LASER 0
y_labels (96, 16) ['DualNoGo' 'DPA' 'DualGo']
X (96, 113, 84) nans 0.0 y (96,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 102
X_fs (96, 102)
samples (96,) features (113,) non zero 102
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 1 LASER 0
y_labels (192, 16) ['DualNoGo' 'DualGo' 'DPA']
X (192, 113, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 102
X_fs (192, 102)
samples (192,) features (113,) non zero 102
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 2 LASER 0
y_labels (113, 16) ['DPA' 'DualGo' 'DualNoGo']
X (113, 113, 84) nans 0.0 y (113,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 100
X_fs (113, 100)
samples (113,) features (113,) non zero 100
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 2 LASER 0
y_labels (192, 16) ['DPA' 'DualGo' 'DualNoGo']
X (192, 113, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 101
X_fs (192, 101)
samples (192,) features (113,) non zero 101
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 3 LASER 0
y_labels (123, 16) ['DPA' 'DualNoGo' 'DualGo']
X (123, 113, 84) nans 0.0 y (123,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 94
X_fs (123, 94)
samples (123,) features (113,) non zero 94
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 3 LASER 0
y_labels (192, 16) ['DPA' 'DualNoGo' 'DualGo']
X (192, 113, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 96
X_fs (192, 96)
samples (192,) features (113,) non zero 96
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 4 LASER 0
y_labels (130, 16) ['DualGo' 'DPA' 'DualNoGo']
X (130, 113, 84) nans 0.0 y (130,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 101
X_fs (130, 101)
samples (130,) features (113,) non zero 101
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 4 LASER 0
y_labels (192, 16) ['DualGo' 'DPA' 'DualNoGo']
X (192, 113, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 98
X_fs (192, 98)
samples (192,) features (113,) non zero 98
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES sample TASK all TRIALS correct DAYS 5 LASER 0
y_labels (153, 16) ['DPA' 'DualNoGo' 'DualGo']
X (153, 113, 84) nans 0.0 y (153,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 99
X_fs (153, 99)
samples (153,) features (113,) non zero 99
Loading files from /storage/leon/dual_task/data/ACCM04
X_days (960, 113, 84) y_days (960, 15)
DATA: FEATURES choice TASK all TRIALS  DAYS 5 LASER 0
y_labels (192, 16) ['DualNoGo' 'DPA' 'DualGo']
X (192, 113, 84) nans 0.0 y (192,) [0. 1.]
boots_coefs (1000, 113)
p_val (113,)
significant 92
X_fs (192, 92)
samples (192,) features (113,) non zero 92
(3, 5, 113)
#+end_example

#+begin_src ipython
print(len(coefs_mice))
#+end_src

#+RESULTS:
: 9

#+begin_src ipython
idx = 3
print(options['mice'][idx], coefs_mice[idx].shape)
#+end_src

#+RESULTS:
: JawsM15 (3, 6, 693)

#+begin_src ipython
angle_SD_mice = []
angle_SC_mice = []
angle_DC_mice = []

for j, mouse in enumerate(options['mice']):
    angle_SD = []
    angle_SC = []
    angle_DC = []

    try:
        coefs = coefs_mice[j]

        for i in range(len(options['days'])):
            try:
                angle_SD.append(angle_AB(-coefs[0][i], -coefs[1][i]))
                angle_SC.append(angle_AB(-coefs[0][i], -coefs[2][i]))
                angle_DC.append(angle_AB(-coefs[2][i], -coefs[1][i]))

            except Exception as e:
                error_message = str(e)
                print(f"An error occurred: {error_message}")
                print(i)
                angle_SD.append(np.nan)
                angle_SC.append(np.nan)
                angle_DC.append(np.nan)

        angle_SD_mice.append(np.array(angle_SD))
        angle_SC_mice.append(np.array(angle_SC))
        angle_DC_mice.append(np.array(angle_DC))

    except:
        pass

    pkl_save(angle_SD, 'angle_%s' % mouse, path=".")
#+end_src

#+RESULTS:
: An error occurred: index 4 is out of bounds for axis 0 with size 4
: 4

#+begin_src ipython
angle_SD_mice = np.array(angle_SD_mice)
angle_SC_mice = np.array(angle_SC_mice)
angle_DC_mice = np.array(angle_DC_mice)
#+end_src

#+RESULTS:

#+begin_src ipython
print(angle_SD_mice.shape, options['days'])
#+end_src

#+RESULTS:
: (9, 5) [1 2 3 4 5]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize= [3*width , width * golden_ratio], sharex=True)

# options['days'] = np.arange(1, 7)

for i in range(angle_SD_mice.shape[0]):
    ax[0].plot(options['days'], angle_SD_mice[i]-90, '-o', alpha=0.2)
    ax[1].plot(options['days'], angle_SC_mice[i]- 90, '-o', alpha=0.2)
    ax[2].plot(options['days'], angle_DC_mice[i]-90, '-o', alpha=0.2)

ax[0].plot(options['days'], np.nanmean(angle_SD_mice-90, 0), '-ko')
ax[0].set_xlabel('Day')
ax[0].set_ylabel('Angle A/B vs Go/noGo (°)')
ax[0].axhline(0, ls='--', color='k')

ax[1].plot(options['days'], np.nanmean(angle_SC_mice-90, 0), '-ko')
ax[1].set_xlabel('Day')
ax[1].set_ylabel('Angle A/B vs Choice (°)')
ax[1].axhline(0, ls='--', color='k')

ax[2].plot(options['days'], np.nanmean(angle_DC_mice-90, 0), '-ko')
ax[2].set_xlabel('Day')
ax[2].set_ylabel('Angle Go/noGo vs Choice(°)')
ax[2].axhline(0, ls='--', color='k')
# ax[0].set_xticks([1,2,3,4,5,6])

plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_32.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize= [3*width , width * golden_ratio], sharey=True)

# options['days'] = np.arange(1, 7)

for i in range(angle_SD_mice.shape[0]):
    ax[0].plot(options['days'], np.abs(angle_SD_mice[i]-90), '-o', alpha=0.2)
    ax[1].plot(options['days'], np.abs(angle_SC_mice[i]- 90), '-o', alpha=0.2)
    ax[2].plot(options['days'], np.abs(angle_DC_mice[i]-90), '-o', alpha=0.2)

ax[0].plot(options['days'], np.nanmean(np.abs(angle_SD_mice-90), 0), '-ko')
ax[0].set_xlabel('Day')
ax[0].set_ylabel('Angle A/B vs Go/noGo (°)')
# ax[0].axhline(90, ls='--', color='k')

ax[1].plot(options['days'], np.nanmean(np.abs(angle_SC_mice-90), 0), '-ko')
ax[1].set_xlabel('Day')
ax[1].set_ylabel('Angle A/B vs Choice (°)')
# ax[1].axhline(90, ls='--', color='k')

ax[2].plot(options['days'], np.nanmean(np.abs(angle_DC_mice-90), 0), '-ko')
ax[2].set_xlabel('Day')
ax[2].set_ylabel('Angle Go/noGo vs Choice(°)')
# ax[2].axhline(90, ls='--', color='k')

plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_33.png]]

#+begin_src ipython
print(options['days'])
#+end_src

#+RESULTS:
: [1 2 3 4 5]

* Reload data

#+begin_src ipython
coefs_mice = []

for mouse in options['mice']:
    options['mouse'] = mouse
    coefs_mice.append(pkl_load('%s_coefs_%.2f_l1_ratio%s' % (options['mouse'], options['l1_ratio'], options['fname']), path="/storage/leon/dual_task/data/%s/" % options['mouse']))

#+end_src

#+RESULTS:

#+begin_src ipython
X_mouse, y_mouse = [], []
new_mice = ['JawsM01', 'JawsM06', 'JawsM12', 'ChRM23']
theta_mouse = []
for idx, mouse in enumerate(options['mice']):
    options['mouse'] = mouse
    options['features'] = 'sample'
    options['verbose'] = 0

    options['trials'] = 'correct'
    options['reload'] = 0
    options['laser'] = 0

    if mouse in new_mice:
        options['reload'] = 0
        options['NEW_DATA'] = 1
    else:
        options['reload'] = 0
        options['NEW_DATA'] = 0

    options = set_options(**options)

    coefs = coefs_mice[idx]
    theta = get_theta(coefs[0], coefs[-1], IF_NORM=0, GM=0)
    theta_mouse.append(theta)
    index = np.argsort(theta, -1)
    print(theta.shape, index.shape)

    X_list = []
    y_list = []
    tasks = ["DPA", "DualGo", "DualNoGo"]

    for i, day in enumerate(options['days']):
        X_dum = []
        y_dum = []
        options['day'] = day
        for task in tasks:
            options['task'] = task
            X_days, y_days = get_X_y_days(**options)
            X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

            X_dum.append(X_data[..., index[i], :])
            y_dum.append(y_data.odor_pair.to_numpy())
            options['reload'] = 0

        X_list.append(X_dum)
        y_list.append(y_dum)

    X_mouse.append(X_list)
    y_mouse.append(y_list)
#+end_src

#+RESULTS:
: (4, 184) (4, 184)
: (6, 201) (6, 201)
: (5, 423) (5, 423)
: (6, 693) (6, 693)
: (6, 444) (6, 444)
: (6, 668) (6, 668)
: (5, 232) (5, 232)
: (5, 361) (5, 361)
: (5, 113) (5, 113)

#+begin_src ipython

#+end_src

#+RESULTS:

* Energy

#+begin_src ipython
from src.attractor.landscape import EnergyLandscape
energy = EnergyLandscape(IF_HMM=0)
#+end_src

#+RESULTS:

#+begin_src ipython
num_bins = 64
window = 0
sigma = 1
bins = np.linspace(0, 2*np.pi, num_bins, endpoint=False)
# bins = np.linspace(-2, 2, num_bins, endpoint=False)

if len(options['days'])>3:
     days = np.arange(1, 7)
else:
     days = options['days']

print(days)
#+end_src

#+RESULTS:
: [1 2 3 4 5 6]

#+begin_src ipython
from scipy.ndimage import gaussian_filter1d
from scipy.stats import gaussian_kde

mouse = 3
task = 0
pair = 0

print(options['mice'][mouse], tasks[task])

X_list = np.array(X_mouse[mouse][-1][task])
y_list = np.array(y_mouse[mouse][-1][task])
print(X_list.shape, y_list.shape)
sigma = 0.05 * X_list.shape[-2]

theta = np.array(theta_mouse[mouse][-1])
index = np.argsort(theta, -1)
pref_dir = theta[index]

kde = gaussian_kde(pref_dir, bw_method=10)
density = kde(pref_dir)
weights = 1.0 / (density+1e-6)
# Optional: normalize weights so mean stays comparable
weights *= len(weights) / weights.sum()

maxw = np.percentile(weights, 95)
weights = np.clip(weights, None, maxw)

idx = y_list==pair

weighted = X_list[idx] * weights[None, :, None]      # shape: (n_trials, n_neurons, n_time)
mean_image = weighted.mean(0)                        # mean over trials -> (n_neurons, n_time)
img = gaussian_filter1d(mean_image, sigma, axis=0)   # smooth across neurons (vertical)

# --- Plotting ---
fig, ax = plt.subplots(figsize=(12, height))
ax.imshow(img, aspect='auto', cmap='jet', vmin=0, vmax=0.2,
          extent=[0, 14, 0, X_list.shape[-2]])

ax.set_xlabel('Time (s)')
ax.set_ylabel('Neuron #')
add_vdashed(ax)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: JawsM15 DPA
: (32, 693, 84) (32,)
[[./figures/landscape/figure_40.png]]
:END:

#+begin_src ipython
plt.hist(pref_dir
          * 180 / np.pi, weights=weights, bins=15)
plt.xlabel('Pref. Loc (°)')
plt.ylabel('Count')
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_41.png]]

#+begin_src ipython
epoch = np.concatenate((options['bins_BL'], options['bins_STIM'], options['bins_ED']))
energy_mouse, ci_mouse = [], []

for idx, mouse in enumerate(options['mice']):
    X_list = X_mouse[idx]

    options['mouse'] = mouse
    options = set_options(**options)

    energy_day = []
    ci_day = []

    for i, day in enumerate(options['days']):
        X = np.vstack(X_list[i])
        X = X[..., options['bins_ED']]
        # X = X[..., epoch]
        _, phi = decode_bump(X, axis=1)

        X = X_list[i][0]
        X = X[..., options['bins_LD']]
        # X = X[..., epoch]
        _, phi1 = decode_bump(X, axis=1)

        phi = np.vstack((phi, phi1))

        # print(X.shape)
        # _, phi = decode_bump(X, axis=1)
        # print(phi.shape)

        landscape = energy.fit(phi, bins, window=window)
        energy_day.append(landscape)

        ci = None
        ci_day.append(ci)

    energy_mouse.append(energy_day)
    ci_mouse.append(ci_day)
#+end_src

#+RESULTS:

#+begin_src ipython
cmap = plt.get_cmap('Blues')
colors = [cmap((i+1)/6) for i in range(7)]
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

def find_circular_minima(energy):
    N = len(energy)
    minima_idx = []
    for i in range(N):
        prev = energy[i-1]
        curr = energy[i]
        next_ = energy[(i+1)%N]
        if curr < prev and curr < next_:
            minima_idx.append(i)
    return np.array(minima_idx)

# minima_indices = find_circular_minima(energy_smooth)
# minima_angles = bin_centers[minima_indices]
#+end_src


#+begin_src ipython
mouse = 4
task = 0
print(options['mice'][mouse], tasks[task])


X_list = np.array(X_mouse[mouse][-1][task])
y_list = np.array(y_mouse[mouse][-1][task])
print(X_list.shape, y_list.shape)
sigma = 0.05 * X_list.shape[-2]

kde = gaussian_kde(pref_dir, bw_method=0.2)
density = kde(pref_dir)
weights = 1. / density
weights /= weights.sum() # optional: normalize

# When computing mean response over neurons
pop_avg = np.average(X_list[idx].mean(0), axis=0, weights=weights)

idx = y_list==0
fig, ax = plt.subplots(figsize=(12, height))
ax.imshow(gaussian_filter1d(X_list[idx].mean(0), sigma, axis=0), aspect='auto', cmap='jet', vmin=0, vmax=.2, extent=[0, 14, 0, X_list.shape[-2]])
ax.set_xlabel('Time (s)')
ax.set_ylabel('Neuron #')
add_vdashed(ax)
plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
epoch = np.concatenate((options['bins_BL'], options['bins_STIM'], options['bins_ED']))
energy_mouse, ci_mouse = [], []

for idx, mouse in enumerate(options['mice']):
    X_list = X_mouse[idx]

    options['mouse'] = mouse
    options = set_options(**options)

    energy_day = []
    ci_day = []

    for i, day in enumerate(options['days']):
        X = np.vstack(X_list[i])
        X = X[..., options['bins_ED']]
        # X = X[..., epoch]
        _, phi = decode_bump(X, axis=1)

        X = X_list[i][0]
        X = X[..., options['bins_LD']]
        # X = X[..., epoch]
        _, phi1 = decode_bump(X, axis=1)

        phi = np.vstack((phi, phi1))

        # print(X.shape)
        # _, phi = decode_bump(X, axis=1)
        # print(phi.shape)

        landscape = energy.fit(phi, bins, window=window)
        energy_day.append(landscape)

        ci = None
        ci_day.append(ci)

    energy_mouse.append(energy_day)
    ci_mouse.append(ci_day)
#+end_src

#+RESULTS:

#+begin_src ipython
cmap = plt.get_cmap('Blues')
colors = [cmap((i+1)/6) for i in range(7)]
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

def find_circular_minima(energy):
    N = len(energy)
    minima_idx = []
    for i in range(N):
        prev = energy[i-1]
        curr = energy[i]
        next_ = energy[(i+1)%N]
        if curr < prev and curr < next_:
            minima_idx.append(i)
    return np.array(minima_idx)

# minima_indices = find_circular_minima(energy_smooth)
# minima_angles = bin_centers[minima_indices]
#+end_src

#+RESULTS:

#+begin_src ipython
from scipy.signal import find_peaks, find_peaks_cwt

minima_mouse = np.zeros((9, len(days), 2), dtype='int') * np.nan
bin_centers = 0.5 * (bins[:-1] + bins[1:])   # Midpoint of each bin
locations = np.rad2deg(bin_centers)  # Convert degrees to radians

for idx, mouse in enumerate(options['mice']):
    energy_day = energy_mouse[idx]

    options['mouse'] = mouse
    options = set_options(**options)

    for i, day in enumerate(options['days']):
        # locations = np.linspace(0, 360, energy_day[i].shape[0])

        # minimas = find_peaks_cwt(-energy_day[i], widths=np.arange(1, 10))
        energy_filtered = gaussian_filter1d(energy_day[i], sigma)  # Adjust sigma as needed
        results = find_multiple_minima_from_values(locations, energy_filtered).T
        minimas = results[0]
        energies = results[1]
        # print(minimas)

        if len(minimas)<2:
            minimas = [minimas[0], minimas[0]]

        minima_mouse[idx][i] = minimas[:2]
#+end_src

#+RESULTS:

#+begin_src ipython
y_loc = []
for idx, mouse in enumerate(options['mice']):
     id = ~np.isnan(minima_mouse[idx].T)
     minima = minima_mouse[idx].T

     # y1 = locations[minima[0][id[0]].astype('int')] * np.pi / 180.0
     # y2 = locations[minima[1][id[1]].astype('int')] * np.pi / 180.0

     y1 = minima[0][id[0]].astype('int') * np.pi / 180.0
     y2 = minima[1][id[1]].astype('int') * np.pi / 180.0

     y_mean = (np.sin(y1)+np.sin(y2)) / 2

     while len(y_mean)<len(days):
          y_mean = np.append(y_mean, np.nan)

     y_loc.append(y_mean)

y_loc = np.array(y_loc)

plt.plot(np.arange(1, len(days)+1), np.nanmean(y_loc, 0), '-o')
plt.plot(np.arange(1, len(days)+1), y_loc.T, '-', alpha=.2)

# plt.xticks(np.arange(1, 7))
plt.axhline(0, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Choice Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_44.png]]

#+begin_src ipython
from scipy.signal import find_peaks
from scipy.ndimage import gaussian_filter1d

fig, ax = plt.subplots(3, 3, figsize= [3*width, 3*width * golden_ratio])
ax_flat = ax.flatten()

minima_mouse = np.zeros((9, 6, 2), dtype='int') * np.nan
bin_centers = 0.5 * (bins[:-1] + bins[1:])   # Midpoint of each bin
locations = np.rad2deg(bin_centers)  # Convert degrees to radians

for idx, mouse in enumerate(options['mice']):
    peaks_list, minimas_list = [], []
    energy_day = energy_mouse[idx]

    options['mouse'] = mouse
    options = set_options(**options)

    ax = ax_flat[idx]

    for i, day in enumerate(options['days']):
        #locations = np.linspace(0, 360, energy_day[i].shape[0])
        energy_filtered = gaussian_filter1d(energy_day[i], sigma)  # Adjust sigma as needed
        ax.plot(locations, energy_filtered * 100 , color=colors[i])
        # ax.plot(energy_day[i] * 100 , color=colors[i])
        ax.set_title(mouse)

        # peaks = find_peaks_cwt(energy_day[i], widths=np.arange(1, 10))[:2]
        # minimas = find_peaks_cwt(-energy_day[i], widths=np.arange(1, 10))[:2]

        # peaks,  _ = find_peaks(energy_day[i], width=8)[:2]
        # minimas, _ = find_peaks(-energy_day[i], width=8)[:2]

        # ax.plot(locations[peaks], energy_day[i][peaks] * 100, '^', color=colors[i])
        # ax.plot(locations[minimas], energy_day[i][minimas] * 100, 'o', color=colors[i])

        minimas = find_multiple_minima_from_values(locations, energy_filtered)
        ax.plot(minimas[:, 0], minimas[:, 1] * 100, 'o', color=colors[i])
        minima_mouse[idx][i] = minimas[:2, 0]

        # if len(peaks)<2:
        #     peaks =[peaks[0], peaks[0]]
        # if len(minimas)<2:
        #     minimas = [minimas[0], minimas[0]]

        # peaks_list.append(peaks[:1])
        # minimas_list.append(minimas[:1])

        # print(peaks, minimas)

        ax.set_xlabel('Pref Loc (°)')
        ax.set_ylabel('Energy')
        # ax.set_ylim([0, 3])
#+end_src

#+RESULTS:
[[./figures/landscape/figure_45.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
