#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session landscape :kernel dual_data :exports results :output-dir ./figures/landscape :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports

#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  from time import perf_counter

  import torch
  import torch.nn as nn
  import torch.optim as optim
  from skorch import NeuralNetClassifier

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.ensemble import BaggingClassifier
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.pipeline import Pipeline
  from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, LeaveOneOut
  from sklearn.decomposition import PCA

  from mne.decoding import SlidingEstimator, cross_val_multiscore, GeneralizingEstimator, get_coef

  from src.attractor.energy import run_energy, plot_energy
  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.decode.bump import decode_bump, circcvl
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs
#+end_src

#+RESULTS:

* Helpers
** Model
#+begin_src ipython
  def get_bagged_coefs(clf, n_estimators):
      coefs_list = []
      bias_list = []
      for i in range(n_estimators):
          model = clf.estimators_[i]
          try:
              coefs = model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
              bias = model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
          except:
              coefs = model.named_steps['net'].coef_[0]
              bias = model.named_steps['net'].intercept_[0]

          # coefs, bias = rescale_coefs(model, coefs, bias)

          coefs_list.append(coefs)
          bias_list.append(bias)

      return np.array(coefs_list).mean(0), np.array(bias_list).mean(0)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/classificationCV.py
    from time import perf_counter
    from sklearn.ensemble import BaggingClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.pipeline import Pipeline
    from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, LeaveOneOut
    from sklearn.decomposition import PCA

    from mne.decoding import SlidingEstimator, cross_val_multiscore

    class ClassificationCV():
        def __init__(self, net, params, **kwargs):

            pipe = []
            self.scaler = kwargs['scaler']
            if self.scaler is not None and self.scaler !=0 :
                pipe.append(("scaler", StandardScaler()))

            self.n_comp = kwargs['n_comp']
            if kwargs['n_comp'] is not None:
                self.n_comp = kwargs['n_comp']
                pipe.append(("pca", PCA(n_components=self.n_comp)))

            pipe.append(("net", net))
            self.model = Pipeline(pipe)

            self.num_features = kwargs['num_features']
            self.scoring =  kwargs['scoring']

            if  kwargs['n_splits']==-1:
                self.cv = LeaveOneOut()
            else:
                self.cv = RepeatedStratifiedKFold(n_splits=kwargs['n_splits'], n_repeats=kwargs['n_repeats'])

            self.params = params
            self.verbose =  kwargs['verbose']
            self.n_jobs =  kwargs['n_jobs']

        def fit(self, X, y):
            start = perf_counter()
            if self.verbose:
                print('Fitting hyperparameters ...')

            try:
                self.model['net'].module__num_features = self.num_features
            except:
                pass

            grid = GridSearchCV(self.model, self.params, refit=True, cv=self.cv, scoring=self.scoring, n_jobs=self.n_jobs)
            grid.fit(X.astype('float32'), y.astype('float32'))
            end = perf_counter()
            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            self.best_model = grid.best_estimator_
            self.best_params = grid.best_params_

            if self.verbose:
                print(self.best_params)

            try:
                self.coefs = self.best_model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
                self.bias = self.best_model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
            except:
                self.coefs = self.best_model.named_steps['net'].coef_[0]
                self.bias = self.best_model.named_steps['net'].intercept_[0]

        def get_bootstrap_coefs(self, X, y, n_boots=10):
            start = perf_counter()
            if self.verbose:
                print('Bootstrapping coefficients ...')

            self.bagging_clf = BaggingClassifier(base_estimator=self.best_model, n_estimators=n_boots)
            self.bagging_clf.fit(X.astype('float32'), y.astype('float32'))
            end = perf_counter()

            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            self.coefs, self.bias = get_bagged_coefs(self.bagging_clf, n_estimators=n_boots)

            return self.coefs, self.bias

        def get_overlap(self, model, X):
            try:
                coefs = model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
                bias = model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
            except:
                coefs = model.named_steps['net'].coef_[0]
                bias = model.named_steps['net'].intercept_[0]

            if self.scaler is not None and self.scaler!=0:
                scaler = model.named_steps['scaler']
                for i in range(X.shape[-1]):
                    X[..., i] = scaler.transform(X[..., i])

            if self.n_comp is not None:
                pca = model.named_steps['pca']
                X_pca = np.zeros((X.shape[0], self.n_comp, X.shape[-1]))

                for i in range(X.shape[-1]):
                    X_pca[..., i] = pca.transform(X[..., i])

                self.overlaps = (np.swapaxes(X_pca, 1, -1) @ coefs + bias) / np.linalg.norm(coefs)
            else:
                self.overlaps = -(np.swapaxes(X, 1, -1) @ coefs + bias) / np.linalg.norm(coefs)

            return self.overlaps

        def get_bootstrap_overlaps(self, X):
            start = perf_counter()
            if self.verbose:
                print('Getting bootstrapped overlaps ...')

            X_copy = np.copy(X)
            overlaps_list = []
            n_boots = len(self.bagging_clf.estimators_)

            for i in range(n_boots):
                model = self.bagging_clf.estimators_[i]
                overlaps = self.get_overlap(model, X_copy)
                overlaps_list.append(overlaps)

            end = perf_counter()
            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            return np.array(overlaps_list).mean(0)

        def get_cv_scores(self, X, y, scoring):
            start = perf_counter()
            if self.verbose:
                print('Computing cv scores ...')

            estimator = SlidingEstimator(clone(self.best_model), n_jobs=1,
                                         scoring=scoring, verbose=False)

            self.scores = cross_val_multiscore(estimator, X.astype('float32'), y.astype('float32'),
                                               cv=self.cv, n_jobs=-1, verbose=False)
            end = perf_counter()
            if self.verbose:
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

            return self.scores
#+end_src

#+RESULTS:


  #+begin_src ipython :tangle ../src/torch/main.py
      from src.common.get_data import get_X_y_days, get_X_y_S1_S2
      from src.preprocess.helpers import avg_epochs

      def get_classification(model, RETURN='overlaps', **options):
              start = perf_counter()

              dum = 0
              if options['features'] == 'distractor':
                      if options['task'] != 'Dual':
                              task = options['task']
                              options['task'] = 'Dual'
                              dum = 1

              X_days, y_days = get_X_y_days(**options)
              X, y = get_X_y_S1_S2(X_days, y_days, **options)
              y[y==-1] = 0
              if options['verbose']:
                  print('X', X.shape, 'y', y.shape)

              X_avg = avg_epochs(X, **options).astype('float32')
              if dum:
                      options['features'] = 'sample'
                      options['task'] = task
                      X, _ = get_X_y_S1_S2(X_days, y_days, **options)

              index = mice.index(options['mouse'])
              model.num_features = N_NEURONS[index]

              if options['class_weight']:
                      pos_weight = torch.tensor(np.sum(y==0) / np.sum(y==1), device=DEVICE).to(torch.float32)
                      print('imbalance', pos_weight)
                      model.criterion__pos_weight = pos_weight

              model.fit(X_avg, y)

              if 'scores' in RETURN:
                  scores = model.get_cv_scores(X, y, options['scoring'])
                  end = perf_counter()
                  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                  return scores
              if 'overlaps' in RETURN:
                  if options['n_boots']>1:
                          coefs, bias = model.get_bootstrap_coefs(X_avg, y, n_boots=options['n_boots'])
                          overlaps = model.get_bootstrap_overlaps(X)
                  else:
                          coefs = model.coefs
                          bias = model.bias
                          overlaps = model.get_overlap(model, X)

                  end = perf_counter()
                  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                  return overlaps
              if 'coefs' in RETURN:
                  if options['n_boots']>1:
                          coefs, bias = model.get_bootstrap_coefs(X_avg, y, n_boots=options['n_boots'])
                  else:
                          coefs = model.coefs
                          bias = model.bias
                  end = perf_counter()
                  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                  return coefs, bias
#+end_src

#+RESULTS:

** Other

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython
def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

** Plots

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u) % (2.0 * np.pi)
#+end_src

#+RESULTS:


#+begin_src ipython
  def get_energy(X, y, task, num_bins, bins, bins0, window, IF_BOOT=0, IF_NORM=0, IF_HMM=0, n_iter=10):
    ci_ = None
    energy_ = run_energy(X, num_bins, bins, bins0, task, window, VERBOSE=0, IF_HMM=IF_HMM, n_iter=n_iter)
    if IF_BOOT:
        _, ci_ = my_boots_ci(X, lambda x: run_energy(x, num_bins, bins, task, window, IF_HMM=IF_HMM, n_iter=n_iter), n_samples=1000)
    if ci_ is not None:
      ci_ = ci_ / 2.0
    return energy_, ci_
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_theta_energy(theta, energy, ci=None, window=.9, ax=None, SMOOTH=0, color='r'):
      if ax is None:
          fig, ax = plt.subplots()

      theta = np.linspace(0, 360, energy.shape[0], endpoint=False)
      # theta = np.linspace(-180, 180, energy.shape[0], endpoint=False)
      energy = energy[1:]
      theta = theta[1:]

      windowSize = int(window * energy.shape[0])
      if SMOOTH:
          # window = np.ones(windowSize) / windowSize
          # energy = np.convolve(energy, window, mode='same')
          # theta = circcvl(theta, windowSize=windowSize)
          energy = circcvl(energy, windowSize=windowSize)

      ax.plot(theta, energy * 100, lw=4, color=color)

      if ci is not None:
          ax.fill_between(
              theta,
              (energy - ci[:, 0]) * 100,
              (energy + ci[:, 1]) * 100,
              alpha=0.1, color=color
          )

      ax.set_ylabel('Energy')
      ax.set_xlabel('Pref. Location (°)')
      ax.set_xticks([0, 90, 180, 270, 360])
#+end_src

#+RESULTS:

#+begin_src ipython
  import numpy as np

  def circcvl(signal, windowSize=10, axis=-1):
      signal_copy = signal.copy()

      if axis != -1 and signal.ndim != 1:
          signal_copy = np.swapaxes(signal_copy, axis, -1)

      # Save the nan positions before replacing them
      nan_mask = np.isnan(signal_copy)
      signal_copy[nan_mask] = np.interp(np.flatnonzero(nan_mask),
                                        np.flatnonzero(~nan_mask),
                                        signal_copy[~nan_mask])

      # Ensure the window size is odd for a centered kernel
      if windowSize % 2 == 0:
          windowSize += 1

      # Create a centered averaging kernel
      kernel = np.ones(windowSize) / windowSize

      # Apply convolution along the last axis or specified axis
      smooth_signal = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='valid'), axis=-1, arr=signal_copy)

      # Substitute the original nan positions back into the result
      smooth_signal[nan_mask] = np.nan

      if axis != -1 and signal.ndim != 1:
          smooth_signal = np.swapaxes(smooth_signal, axis, -1)

      return smooth_signal
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

def circcvl(signal, windowSize=10, axis=-1):
    signal_copy = signal.copy()

    if axis != -1 and signal.ndim != 1:
        signal_copy = np.swapaxes(signal_copy, axis, -1)

    # Save the NaN positions before replacing them
    nan_mask = np.isnan(signal_copy)
    signal_copy[nan_mask] = np.interp(
        np.flatnonzero(nan_mask),
        np.flatnonzero(~nan_mask),
        signal_copy[~nan_mask]
    )

    # Ensure the window size is odd for a centered kernel
    if windowSize % 2 == 0:
        windowSize += 1

    # Create a centered averaging kernel
    kernel = np.ones(windowSize) / windowSize

    # Number of elements to pad on each side
    pad_width = windowSize // 2

    # Pad the signal circularly
    if signal.ndim == 1:
        padded_signal = np.pad(signal_copy, pad_width, mode='wrap')
    else:
        padding = [(0, 0)] * (signal.ndim - 1) + [(pad_width, pad_width)]
        padded_signal = np.pad(signal_copy, padding, mode='wrap')

    # Apply convolution along the last axis or specified axis
    smooth_signal = np.apply_along_axis(
        lambda m: np.convolve(m, kernel, mode='same'),
        axis=-1,
        arr=padded_signal
    )

    # Remove padding
    if signal.ndim == 1:
        smooth_signal = smooth_signal[pad_width:-pad_width]
    else:
        indexer = [slice(None)] * (smooth_signal.ndim - 1) + [slice(pad_width, -pad_width)]
        smooth_signal = smooth_signal[tuple(indexer)]

    # Substitute the original NaN positions back into the result
    smooth_signal[nan_mask] = np.nan

    if axis != -1 and signal.ndim != 1:
        smooth_signal = np.swapaxes(smooth_signal, axis, -1)

    return smooth_signal
#+end_src

#+RESULTS:

#+begin_src ipython
  import numpy as np
  from scipy.optimize import differential_evolution
  from scipy.interpolate import interp1d
  import matplotlib.pyplot as plt

  def get_distance(x, y):
      distance = abs(x - y)
      if distance>180:
          distance -= 360
          distance *= -1
      return distance

  def find_multiple_minima_from_values(x_vals, y_vals, num_minima=2, num_runs=50, tol=0.05, popsize=50, maxiter=10000, min_distance=0.1, ax=None, color='k'):
      # Interpolate the energy landscape
      energy_function = interp1d(x_vals, y_vals, kind='cubic', fill_value="extrapolate")

      # Define the bounds for the differential evolution
      bounds = [(x_vals.min(), x_vals.max())]

      results = []

      for _ in range(num_runs):
          result = differential_evolution(energy_function, bounds, strategy='rand1bin',
                                          maxiter=maxiter, popsize=popsize, tol=tol,
                                          seed=np.random.randint(0, 10000))

          results.append((result.x[0], result.fun))

      # Filter unique minima within a tolerance and minimum distance
      unique_minima = []
      angles = []
      for x_val, energy in results:

          if not any(np.isclose(x_val, um[0], atol=tol) or get_distance(x_val, um[0]) < min_distance for um in unique_minima):
              unique_minima.append([x_val, energy])
              angles.append(x_val)

      # Ensure we only return the requested number of unique minima
      unique_minima = sorted(unique_minima, key=lambda x: x[1])[:num_minima]

      if ax is None:
          fig, ax = plt.subplots()
      # Plot the function
      x = np.linspace(x_vals.min(), x_vals.max(), 400)
      y = [energy_function(xi) for xi in x]  # Without noise for plotting
      # ax.plot(x, y)

      for min_x, _ in unique_minima:
          ax.plot(min_x, np.abs(energy_function(min_x)), 'o', color=color, markeredgecolor='k')  # Mark the minima points

      return angles

  # Example usage
  # x_vals = np.linspace(-2, 2, 50)
  # y_vals = np.sin(np.pi * x_vals) * 2 + np.cos(2 * np.pi * x_vals) * 2 + 0.1 * x_vals * 2 + np.random.normal(0, 0.1, size=x_vals.shape)

  # find_multiple_minima_from_values(x_vals, y_vals, num_minima=4, num_runs=10, tol=0.05, popsize=15, maxiter=100, min_distance=0.1)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return 0.5  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score, average='weighted')
      #+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["model"].coef_.flatten()
        clf = estimator.named_steps["model"]
    except:
        coef = estimator.best_estimator_.named_steps["model"].coef_.flatten()
        clf = estimator.best_estimator_named_steps["model"]

    norm_w = np.linalg.norm(coef)

    if IF_SIGN:
        # dot_product = (2*y_test -1) * np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)
        dot_product = (2*y_test -1) * clf.decision_function(X_test)
    else:
        dot_product = clf.decision_function(X_test)
        # dot_product = -np.dot(X_test, coef) / (np.linalg.norm(coef) + .00001)

    return np.nanmean(dot_product) / coef.shape[0] / norm_w
#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12']
  # mice = ['PP09', 'PP17']

  kwargs = {
      'mouse': mice[1], 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise': True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 1000,
      'n_splits': 5, 'n_repeats': 16,
      'class_weight': 0,
      'multilabel':0,
      'mne_estimator': 'generalizing', # sliding or generalizing
      'n_jobs': 128,
      'bolasso_penalty': 'l2',
      'bolasso_pval': 0.05,
  }

  kwargs['days'] = ['first', 'middle', 'last']
  # kwargs['days'] = ['first', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)
  options['cv'] = LeaveOneOut()

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  safe_f1 = make_scorer(safe_f1_score, needs_proba=True)

  options['hp_scoring'] = lambda estimator, X_test, y_test: np.abs(overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1))
  # options['scoring'] = options['hp_scoring']
  options['scoring'] = overlaps_scorer

#+end_src

#+RESULTS:

* Landscape vs days

#+begin_src ipython
import sys
sys.path.insert(0, '/home/leon/Dclassify')
from src.classificationCV import ClassificationCV
#+end_src

#+RESULTS:

#+begin_src ipython
#  from src.torch.classificationCV import ClassificationCV
from src.torch.classify import get_classification
#+end_src

#+RESULTS:

 #+begin_src ipython
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
Cs = np.logspace(-2, 2, 10)

net = LogisticRegressionCV(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None, tol=0.001, cv=5, Cs=Cs)
# net = LogisticRegressionCV(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratios=[0.95], max_iter=100, tol=.001, Cs=Cs, cv=3)

# net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None, tol=0.001)
# net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)

params = {'model__C': np.logspace(-2, 2, 10)}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['verbose'] = 1
#+end_src

#+RESULTS:

     #+begin_src ipython
options['mice'] = ['JawsM01', 'JawsM06', 'JawsM12', 'JawsM15', 'JawsM18'] #, 'ACCM03', 'ACCM04']
# options['mice'] = ['JawsM06', 'JawsM12', 'JawsM15', 'JawsM18', 'ChRM04', 'ChRM23', 'ACCM03', 'ACCM04']
     #+end_src

#+RESULTS:

#+begin_src ipython
coefs_mice = []

for mouse in options['mice']:
    options['mouse'] = mouse
    options = set_options(**options)

    coefs_sample = []
    coefs_dist = []
    coefs_choice = []

    bias_sample = []
    bias_dist = []
    bias_choice = []

    theta_day = []
    index_day = []

    for day in options['days']:
        options['day'] = day

        options['task'] = 'all'
        options['features'] = 'sample'
        options['epochs'] = ['ED']

        try:
            # coefs, bias = get_classification(model, RETURN='coefs', **options)
            # coefs_sample.append(coefs[:, 0])
            coefs, bias = get_classification(model, RETURN='bolasso', **options)
            coefs_sample.append(coefs)
        except:
            # coefs_sample.append(coefs[:, 0] * np.nan)
            coefs_sample.append(coefs * np.nan)

        options['task'] = 'Dual'
        options['features'] = 'distractor'
        options['epochs'] = ['MD']

        try:
            # coefs, bias = get_classification(model, RETURN='coefs', **options)
            # coefs_dist.append(coefs[:, 0])
            coefs, bias = get_classification(model, RETURN='bolasso', **options)
            coefs_dist.append(coefs)
        except:
            # coefs_dist.append(coefs[:, 0] * np.nan)
            coefs_dist.append(coefs * np.nan)

        options['task'] = 'all'
        options['features'] = 'choice'
        options['epochs'] = ['CHOICE']

        try:
            # coefs, bias = get_classification(model, RETURN='coefs', **options)
            # coefs_choice.append(coefs[:, 0])
            coefs, bias = get_classification(model, RETURN='bolasso', **options)
            coefs_choice.append(coefs)
        except:
            # coefs_choice.append(coefs[:, 0] * np.nan)
            coefs_choice.append(coefs * np.nan)

    coefs_save = np.stack((coefs_sample, coefs_dist, coefs_choice))
    coefs_mice.append(coefs_save)

    print(coefs_save.shape)
    pkl_save(coefs_save, '%s_coefs_%.2f_l1_ratio%s' % (options['mouse'], options['l1_ratio'], options['fname']), path="../data/%s/" % options['mouse'])
    #+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 184, 84) X_S2 (96, 184, 84)
X_B (192, 184, 84) y_B (192,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 184, 84) X_S2 (96, 184, 84)
y_labels (192, 11) ['DualGo' 'DualNoGo' 'DPA']
X (192, 184, 84) y (192,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 172
X_fs (192, 172)
samples (192,) features (184,) non zero 172
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 184, 84) X_S2 (64, 184, 84)
y_labels (128, 11) ['DualGo' 'DualNoGo']
X (128, 184, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 184)
p_val (184,)
significant 178
X_fs (128, 178)
samples (128,) features (184,) non zero 178
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES choice TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (163, 184, 84) X_S2 (29, 184, 84)
y_labels (192, 11) ['DualGo' 'DPA' 'DualNoGo']
X (192, 184, 84) y (192,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 176
X_fs (192, 176)
samples (192,) features (184,) non zero 176
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 184, 84) X_S2 (96, 184, 84)
X_B (192, 184, 84) y_B (192,) [0. 1.] ['DPA' 'DualGo' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 184, 84) X_S2 (96, 184, 84)
y_labels (192, 11) ['DPA' 'DualGo' 'DualNoGo']
X (192, 184, 84) y (192,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 178
X_fs (192, 178)
samples (192,) features (184,) non zero 178
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 184, 84) X_S2 (64, 184, 84)
y_labels (128, 11) ['DualGo' 'DualNoGo']
X (128, 184, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 184)
p_val (184,)
significant 174
X_fs (128, 174)
samples (128,) features (184,) non zero 174
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES choice TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (106, 184, 84) X_S2 (86, 184, 84)
y_labels (192, 11) ['DPA' 'DualGo' 'DualNoGo']
X (192, 184, 84) y (192,) [0. 1.]
boots_coefs (1000, 184)
p_val (184,)
significant 174
X_fs (192, 174)
samples (192,) features (184,) non zero 174
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (0, 184, 84) X_S2 (0, 184, 84)
X_B (0, 184, 84) y_B (0,) [] []
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (0, 184, 84) X_S2 (0, 184, 84)
y_labels (0, 11) []
X (0, 184, 84) y (0,) []
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (0, 184, 84) X_S2 (0, 184, 84)
y_labels (0, 11) []
X (0, 184, 84) y (0,) []
Loading files from /home/leon/dual_task/dual_data/data/JawsM01
X_days (768, 184, 84) y_days (768, 10)
DATA: FEATURES choice TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (0, 184, 84) X_S2 (0, 184, 84)
y_labels (0, 11) []
X (0, 184, 84) y (0,) []
(3, 3, 184)
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 201, 84) X_S2 (96, 201, 84)
X_B (192, 201, 84) y_B (192,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 201, 84) X_S2 (96, 201, 84)
y_labels (192, 12) ['DualNoGo' 'DualGo' 'DPA']
X (192, 201, 84) y (192,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 190
X_fs (192, 190)
samples (192,) features (201,) non zero 190
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 201, 84) X_S2 (64, 201, 84)
y_labels (128, 12) ['DualGo' 'DualNoGo']
X (128, 201, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 201)
p_val (201,)
significant 197
X_fs (128, 197)
samples (128,) features (201,) non zero 197
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES choice TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (139, 201, 84) X_S2 (53, 201, 84)
y_labels (192, 12) ['DPA' 'DualNoGo' 'DualGo']
X (192, 201, 84) y (192,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 196
X_fs (192, 196)
samples (192,) features (201,) non zero 196
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 201, 84) X_S2 (96, 201, 84)
X_B (192, 201, 84) y_B (192,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 201, 84) X_S2 (96, 201, 84)
y_labels (192, 12) ['DualNoGo' 'DualGo' 'DPA']
X (192, 201, 84) y (192,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 190
X_fs (192, 190)
samples (192,) features (201,) non zero 190
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 201, 84) X_S2 (64, 201, 84)
y_labels (128, 12) ['DualGo' 'DualNoGo']
X (128, 201, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 201)
p_val (201,)
significant 195
X_fs (128, 195)
samples (128,) features (201,) non zero 195
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES choice TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (112, 201, 84) X_S2 (80, 201, 84)
y_labels (192, 12) ['DPA' 'DualNoGo' 'DualGo']
X (192, 201, 84) y (192,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 191
X_fs (192, 191)
samples (192,) features (201,) non zero 191
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 201, 84) X_S2 (96, 201, 84)
X_B (192, 201, 84) y_B (192,) [0. 1.] ['DPA' 'DualNoGo' 'DualGo']
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 201, 84) X_S2 (96, 201, 84)
y_labels (192, 12) ['DPA' 'DualNoGo' 'DualGo']
X (192, 201, 84) y (192,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 193
X_fs (192, 193)
samples (192,) features (201,) non zero 193
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 201, 84) X_S2 (64, 201, 84)
y_labels (128, 12) ['DualGo' 'DualNoGo']
X (128, 201, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 201)
p_val (201,)
significant 197
X_fs (128, 197)
samples (128,) features (201,) non zero 197
Loading files from /home/leon/dual_task/dual_data/data/JawsM06
X_days (1152, 201, 84) y_days (1152, 11)
DATA: FEATURES choice TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (84, 201, 84) X_S2 (108, 201, 84)
y_labels (192, 12) ['DPA' 'DualNoGo' 'DualGo']
X (192, 201, 84) y (192,) [0. 1.]
boots_coefs (1000, 201)
p_val (201,)
significant 194
X_fs (192, 194)
samples (192,) features (201,) non zero 194
(3, 3, 201)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 423, 84) X_S2 (96, 423, 84)
X_B (192, 423, 84) y_B (192,) [0. 1.] ['DPA' 'DualGo' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 423, 84) X_S2 (96, 423, 84)
y_labels (192, 11) ['DPA' 'DualGo' 'DualNoGo']
X (192, 423, 84) y (192,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 404
X_fs (192, 404)
samples (192,) features (423,) non zero 404
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 423, 84) X_S2 (64, 423, 84)
y_labels (128, 11) ['DualGo' 'DualNoGo']
X (128, 423, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 423)
p_val (423,)
significant 404
X_fs (128, 404)
samples (128,) features (423,) non zero 404
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES choice TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (93, 423, 84) X_S2 (99, 423, 84)
y_labels (192, 11) ['DPA' 'DualGo' 'DualNoGo']
X (192, 423, 84) y (192,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 403
X_fs (192, 403)
samples (192,) features (423,) non zero 403
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 423, 84) X_S2 (96, 423, 84)
X_B (192, 423, 84) y_B (192,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 423, 84) X_S2 (96, 423, 84)
y_labels (192, 11) ['DualNoGo' 'DualGo' 'DPA']
X (192, 423, 84) y (192,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 409
X_fs (192, 409)
samples (192,) features (423,) non zero 409
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 423, 84) X_S2 (64, 423, 84)
y_labels (128, 11) ['DualGo' 'DualNoGo']
X (128, 423, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 423)
p_val (423,)
significant 407
X_fs (128, 407)
samples (128,) features (423,) non zero 407
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES choice TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (115, 423, 84) X_S2 (77, 423, 84)
y_labels (192, 11) ['DualNoGo' 'DualGo' 'DPA']
X (192, 423, 84) y (192,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 408
X_fs (192, 408)
samples (192,) features (423,) non zero 408
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (48, 423, 84) X_S2 (48, 423, 84)
X_B (96, 423, 84) y_B (96,) [0. 1.] ['DPA' 'DualGo' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (48, 423, 84) X_S2 (48, 423, 84)
y_labels (96, 11) ['DPA' 'DualGo' 'DualNoGo']
X (96, 423, 84) y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 401
X_fs (96, 401)
samples (96,) features (423,) non zero 401
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
y_labels (64, 11) ['DualGo' 'DualNoGo']
X (64, 423, 84) y (64,) [0. 1. 2. 3.]
boots_coefs (1000, 423)
p_val (423,)
significant 413
X_fs (64, 413)
samples (64,) features (423,) non zero 413
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
X_days (960, 423, 84) y_days (960, 10)
DATA: FEATURES choice TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (55, 423, 84) X_S2 (41, 423, 84)
y_labels (96, 11) ['DPA' 'DualGo' 'DualNoGo']
X (96, 423, 84) y (96,) [0. 1.]
boots_coefs (1000, 423)
p_val (423,)
significant 411
X_fs (96, 411)
samples (96,) features (423,) non zero 411
(3, 3, 423)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 693, 84) X_S2 (96, 693, 84)
X_B (192, 693, 84) y_B (192,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 693, 84) X_S2 (96, 693, 84)
y_labels (192, 12) ['DualNoGo' 'DualGo' 'DPA']
X (192, 693, 84) y (192,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 673
X_fs (192, 673)
samples (192,) features (693,) non zero 673
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 693, 84) X_S2 (64, 693, 84)
y_labels (128, 12) ['DualGo' 'DualNoGo']
X (128, 693, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 693)
p_val (693,)
significant 673
X_fs (128, 673)
samples (128,) features (693,) non zero 673
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES choice TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (100, 693, 84) X_S2 (92, 693, 84)
y_labels (192, 12) ['DualGo' 'DPA' 'DualNoGo']
X (192, 693, 84) y (192,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 661
X_fs (192, 661)
samples (192,) features (693,) non zero 661
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 693, 84) X_S2 (96, 693, 84)
X_B (192, 693, 84) y_B (192,) [0. 1.] ['DualGo' 'DPA' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 693, 84) X_S2 (96, 693, 84)
y_labels (192, 12) ['DualGo' 'DPA' 'DualNoGo']
X (192, 693, 84) y (192,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 669
X_fs (192, 669)
samples (192,) features (693,) non zero 669
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 693, 84) X_S2 (64, 693, 84)
y_labels (128, 12) ['DualGo' 'DualNoGo']
X (128, 693, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 693)
p_val (693,)
significant 673
X_fs (128, 673)
samples (128,) features (693,) non zero 673
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES choice TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (94, 693, 84) X_S2 (98, 693, 84)
y_labels (192, 12) ['DPA' 'DualGo' 'DualNoGo']
X (192, 693, 84) y (192,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 650
X_fs (192, 650)
samples (192,) features (693,) non zero 650
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 693, 84) X_S2 (96, 693, 84)
X_B (192, 693, 84) y_B (192,) [0. 1.] ['DualNoGo' 'DPA' 'DualGo']
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 693, 84) X_S2 (96, 693, 84)
y_labels (192, 12) ['DualNoGo' 'DPA' 'DualGo']
X (192, 693, 84) y (192,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 672
X_fs (192, 672)
samples (192,) features (693,) non zero 672
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 693, 84) X_S2 (64, 693, 84)
y_labels (128, 12) ['DualGo' 'DualNoGo']
X (128, 693, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 693)
p_val (693,)
significant 672
X_fs (128, 672)
samples (128,) features (693,) non zero 672
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
X_days (1152, 693, 84) y_days (1152, 11)
DATA: FEATURES choice TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (70, 693, 84) X_S2 (122, 693, 84)
y_labels (192, 12) ['DualGo' 'DPA' 'DualNoGo']
X (192, 693, 84) y (192,) [0. 1.]
boots_coefs (1000, 693)
p_val (693,)
significant 660
X_fs (192, 660)
samples (192,) features (693,) non zero 660
(3, 3, 693)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 444, 84) X_S2 (96, 444, 84)
X_B (192, 444, 84) y_B (192,) [0. 1.] ['DualNoGo' 'DualGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 444, 84) X_S2 (96, 444, 84)
y_labels (192, 10) ['DualNoGo' 'DualGo' 'DPA']
X (192, 444, 84) y (192,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 429
X_fs (192, 429)
samples (192,) features (444,) non zero 429
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 444, 84) X_S2 (64, 444, 84)
y_labels (128, 10) ['DualGo' 'DualNoGo']
X (128, 444, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 444)
p_val (444,)
significant 435
X_fs (128, 435)
samples (128,) features (444,) non zero 435
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES choice TASK all TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (139, 444, 84) X_S2 (53, 444, 84)
y_labels (192, 10) ['DPA' 'DualNoGo' 'DualGo']
X (192, 444, 84) y (192,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 424
X_fs (192, 424)
samples (192,) features (444,) non zero 424
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 444, 84) X_S2 (96, 444, 84)
X_B (192, 444, 84) y_B (192,) [0. 1.] ['DualGo' 'DualNoGo' 'DPA']
DATA: FEATURES sample TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 444, 84) X_S2 (96, 444, 84)
y_labels (192, 10) ['DualGo' 'DualNoGo' 'DPA']
X (192, 444, 84) y (192,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 433
X_fs (192, 433)
samples (192,) features (444,) non zero 433
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 444, 84) X_S2 (64, 444, 84)
y_labels (128, 10) ['DualGo' 'DualNoGo']
X (128, 444, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 444)
p_val (444,)
significant 432
X_fs (128, 432)
samples (128,) features (444,) non zero 432
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES choice TASK all TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (106, 444, 84) X_S2 (86, 444, 84)
y_labels (192, 10) ['DPA' 'DualGo' 'DualNoGo']
X (192, 444, 84) y (192,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 425
X_fs (192, 425)
samples (192,) features (444,) non zero 425
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 444, 84) X_S2 (96, 444, 84)
X_B (192, 444, 84) y_B (192,) [0. 1.] ['DualGo' 'DPA' 'DualNoGo']
DATA: FEATURES sample TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (96, 444, 84) X_S2 (96, 444, 84)
y_labels (192, 10) ['DualGo' 'DPA' 'DualNoGo']
X (192, 444, 84) y (192,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 434
X_fs (192, 434)
samples (192,) features (444,) non zero 434
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (64, 444, 84) X_S2 (64, 444, 84)
y_labels (128, 10) ['DualGo' 'DualNoGo']
X (128, 444, 84) y (128,) [0. 1. 2. 3.]
boots_coefs (1000, 444)
p_val (444,)
significant 438
X_fs (128, 438)
samples (128,) features (444,) non zero 438
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
X_days (1152, 444, 84) y_days (1152, 9)
DATA: FEATURES choice TASK all TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (97, 444, 84) X_S2 (95, 444, 84)
y_labels (192, 10) ['DualGo' 'DPA' 'DualNoGo']
X (192, 444, 84) y (192,) [0. 1.]
boots_coefs (1000, 444)
p_val (444,)
significant 422
X_fs (192, 422)
samples (192,) features (444,) non zero 422
(3, 3, 444)
#+end_example

#+begin_src ipython
print(len(coefs_mice))
#+end_src

#+RESULTS:
: 5

#+begin_src ipython
angle_SD_mice = []
angle_SC_mice = []
angle_DC_mice = []

for j, mouse in enumerate(options['mice']):
    angle_SD = []
    angle_SC = []
    angle_DC = []

    try:
        coefs = coefs_mice[j]

        for i in range(6):
            try:
                angle_SD.append(angle_AB(-coefs[0][i], -coefs[1][i]))
                angle_SC.append(angle_AB(-coefs[0][i], -coefs[2][i]))
                angle_DC.append(angle_AB(-coefs[2][i], -coefs[1][i]))
            except:
                angle_SD.append(np.nan)
                angle_SC.append(np.nan)
                angle_DC.append(np.nan)

        angle_SD_mice.append(np.array(angle_SD))
        angle_SC_mice.append(np.array(angle_SC))
        angle_DC_mice.append(np.array(angle_DC))

    except:
        pass

    pkl_save(angle_SD, 'angle_%s' % mouse, path=".")
#+end_src

#+RESULTS:

#+begin_src ipython
angle_SD_mice = np.array(angle_SD_mice)
angle_SC_mice = np.array(angle_SC_mice)
angle_DC_mice = np.array(angle_DC_mice)
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize= [3*width , width * golden_ratio], sharey=False)

options['days'] = np.arange(1, 7)

for i in range(angle_SD_mice.shape[0]):
    ax[0].plot(options['days'], angle_SD_mice[i]-90, '-o', alpha=0.2)
    ax[1].plot(options['days'], angle_SC_mice[i]- 90, '-o', alpha=0.2)
    ax[2].plot(options['days'], angle_DC_mice[i]-90, '-o', alpha=0.2)

ax[0].plot(options['days'], np.nanmean(angle_SD_mice-90, 0), '-ko')
ax[0].set_xlabel('Day')
ax[0].set_ylabel('Angle A/B vs Go/noGo (°)')
ax[0].axhline(0, ls='--', color='k')

ax[1].plot(options['days'], np.nanmean(angle_SC_mice-90, 0), '-ko')
ax[1].set_xlabel('Day')
ax[1].set_ylabel('Angle A/B vs Choice (°)')
ax[1].axhline(0, ls='--', color='k')

ax[2].plot(options['days'], np.nanmean(angle_DC_mice-90, 0), '-ko')
ax[2].set_xlabel('Day')
ax[2].set_ylabel('Angle Go/noGo vs Choice(°)')
ax[2].axhline(0, ls='--', color='k')

plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_28.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize= [3*width , width * golden_ratio], sharey=True)

options['days'] = np.arange(1, 7)
# options['days'] = ['first', ]

for i in range(angle_SD_mice.shape[0]):
    ax[0].plot(options['days'], np.abs(angle_SD_mice[i]-90), '-o', alpha=0.2)
    ax[1].plot(options['days'], np.abs(angle_SC_mice[i]- 90), '-o', alpha=0.2)
    ax[2].plot(options['days'], np.abs(angle_DC_mice[i]-90), '-o', alpha=0.2)

ax[0].plot(options['days'], np.nanmean(np.abs(angle_SD_mice-90), 0), '-ko')
ax[0].set_xlabel('Day')
ax[0].set_ylabel('Angle A/B vs Go/noGo (°)')
# ax[0].axhline(90, ls='--', color='k')

ax[1].plot(options['days'], np.nanmean(np.abs(angle_SC_mice-90), 0), '-ko')
ax[1].set_xlabel('Day')
ax[1].set_ylabel('Angle A/B vs Choice (°)')
# ax[1].axhline(90, ls='--', color='k')

ax[2].plot(options['days'], np.nanmean(np.abs(angle_DC_mice-90), 0), '-ko')
ax[2].set_xlabel('Day')
ax[2].set_ylabel('Angle Go/noGo vs Choice(°)')
# ax[2].axhline(90, ls='--', color='k')

plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_29.png]]

* Reload data

#+begin_src ipython
idx = 2
options['days'] = ['first', 'middle', 'last']
coefs = coefs_mice[idx]
theta = get_theta(-coefs[0], -coefs[-1], IF_NORM=0, GM=0)
print(theta.shape)
index = np.argsort(theta, -1)
print(index.shape)
#+end_src

#+RESULTS:
: (3, 423)
: (3, 423)

#+begin_src ipython
options['mouse'] = options['mice'][idx]
options['features'] = 'sample'
options['verbose'] = 1

options['trials'] = ''
options['reload'] = 0

X_list = []
y_list = []
tasks = ["DPA", "DualGo", "DualNoGo"]

for i, day in enumerate(options['days']):
    X_dum = []
    y_dum = []
    options['day'] = day
    for task in tasks:
        options['task'] = task
        X_days, y_days = get_X_y_days(**options)
        X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)
        # y_data[y_data==-1] = 0


        X_dum.append(X_data[..., index[i], :])
        y_dum.append(y_data.sample_odor.to_numpy())

    X_list.append(X_dum)
    y_list.append(y_dum)

try:
    X_list = np.array(X_list)
    y_list = np.array(y_list)

    print(X_list.shape, y_list.shape)
except:
    pass
#+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DualGo TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 423, 84) X_S2 (32, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (16, 423, 84) X_S2 (16, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (16, 423, 84) X_S2 (16, 423, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM12
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (16, 423, 84) X_S2 (16, 423, 84)
#+end_example


#+begin_src ipython
# X_list = np.array(X_list)
# print(X_list.shape, y_list.shape)
# print(np.array(X_list[0]).mean(0).shape)
#+end_src

#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt

def add_vdashed(ax=None, y0=693, mouse=""):
    # Define time intervals
    t_STIM = [2, 3]
    t_DIST = [4.5, 5.5]
    t_CUE = [6.5, 7]
    t_TEST = [9, 10]

    # Add vertical dashed lines and text labels for each interval
    if ax is not None:
        # Draw vertical lines
        for t in [t_STIM, t_DIST, t_CUE, t_TEST]:
            ax.axvline(x=t[0], linestyle='--', color='k', lw=2)
            ax.axvline(x=t[1], linestyle='--', color='k', lw=2)

        # Add text labels at the middle of each interval
        ax.text((t_STIM[0] + t_STIM[1]) / 2, y0, 'A/B', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_DIST[0] + t_DIST[1]) / 2, y0, 'GnG', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_CUE[0] + t_CUE[1]) / 2, y0, 'CUE', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
        ax.text((t_TEST[0] + t_TEST[1]) / 2, y0, 'TEST', color='black',
                horizontalalignment='center', verticalalignment='center', fontsize=16)
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_bump(X, y, trial, windowSize=10, width=7, s=0):
    golden_ratio = (5**.5 - 1) / 2

    fig, ax = plt.subplots(1, 3, figsize= [3*width, width * golden_ratio], sharex=True)
    sample = [0, 1]

    for i in range(3):
        if i==0:
            rng = np.random.default_rng()
            X_sample = X[y == sample[s]]
            rng.shuffle(X_sample, axis=1)
        else:
            X_sample = X[y == sample[s]]

        if windowSize != 0:
            X_scaled = circcvl(X_sample, windowSize, axis=1)
        else:
            X_scaled = X_sample

        if trial == "all":
            X_ = np.mean(X_scaled, 0)
        else:
            if i==2:
                X_ = np.mean(X_scaled, 0)
            else:
                X_ = X_scaled[trial]

        if i>0:
            im = ax[i].imshow(
                # X_,
                np.roll(X_, int(X_.shape[0]/2)+windowSize//2, axis=0),
                # interpolation="lanczos",
                # origin="lower",
                cmap="jet",
                extent=[0, 14, 0, 360],
                # vmin=-1,
                # vmax=2,
                aspect="auto",  #
            )
        else:
            im = ax[i].imshow(
                # X_,
                np.roll(X_, int(X_.shape[0]/2)+windowSize//2, axis=0),
                # interpolation="lanczos",
                origin="lower",
                cmap="jet",
                extent=[0, 14, 0, X_.shape[0]],
                # vmin=-1.5,
                # vmax=2,
                aspect="auto",
            )

        # if i==0:
        #     ax[i].set_title('Unordered')
        # else:
        #     ax[i].set_title('Ordered')

        ax[i].set_xlabel("Time (s)")
        if i == 0:
            ax[i].set_ylabel("Neuron #")
        else:
            ax[i].set_ylabel("Pref. Location (°)")
            ax[i].set_yticks([0, 90, 180, 270, 360])

        ax[i].set_xlim([0, 12])
        if i==0:
            add_vdashed(ax[i], y0=X_.shape[0]+10)
        else:
            add_vdashed(ax[i], y0=370)

    # cbar = plt.colorbar(im, ax=ax[2])
    # cbar.set_label("Norm. Fluo")
    # cbar.set_ticks([-0.5, 0.0, 0.5, 1.0, 1.5])
 #+end_src

#+RESULTS:

* Bumps

#+begin_src ipython
from src.preprocess.helpers import preprocess_X
day = -1
task = 0
X_norm = X_list[day][ task]
# X_norm = preprocess_X(X_list[day][task], scaler="robust", avg_noise=0, unit_var=1)
idx = np.random.randint(X_norm.shape[0]//2)
print(idx)

plot_bump(X_norm, y_list[day][ task], trial=idx, windowSize=int(0.1 * X_norm.shape[1]), s=1)
plt.savefig('./cosyne/dpa_bump.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 21
[[./figures/landscape/figure_35.png]]
:END:

#+begin_src ipython
from src.preprocess.helpers import preprocess_X
day = 1
task = 1
X_norm = X_list[day][ task]
# X_norm = preprocess_X(X_list[day][task], scaler="robust", avg_noise=0, unit_var=1)
idx = np.random.randint(X_norm.shape[0]//2)
print(idx)
plot_bump(X_norm, y_list[day][ task], trial=idx, windowSize=int(0.1 * X_norm.shape[1]))
plt.savefig('./cosyne/dualgo_bump.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 3
[[./figures/landscape/figure_36.png]]
:END:

#+begin_src ipython
from src.preprocess.helpers import preprocess_X
day = 1
task = -1
X_norm = X_list[day][ task]
# X_norm = preprocess_X(X_list[day][task], scaler="robust", avg_noise=0, unit_var=1)
idx = np.random.randint(X_norm.shape[0]//2)
print(idx)
plot_bump(X_norm, y_list[day][ task], trial=idx, windowSize=64)
plt.savefig('./cosyne/dualnogo_bump.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 22
[[./figures/landscape/figure_37.png]]
:END:

* Energy

#+begin_src ipython
from src.attractor.landscape import EnergyLandscape
energy = EnergyLandscape()
#+end_src

#+RESULTS:

#+begin_src ipython
num_bins = 96
bins = np.linspace(0, 2*np.pi, num_bins, endpoint=False)
#+end_src

#+RESULTS:

#+begin_src ipython
  energy_day = []
  ci_day = []

  for i, day in enumerate(options['days']):
      # X = np.vstack(X_list[i, ..., options['bins_ED']])
      print('X', X_list.shape)

      X = X_list[i, 0, :, options['bins_DELAY']]
      print('X', X.shape)

      _, phi = decode_bump(X, axis=-1)

      print('phi', phi.shape, phi.min() * 180 / np.pi, phi.max() * 180 / np.pi)

      landscape = energy.fit(phi, bins, window=10)
      energy_day.append(landscape)

      ci = None
      ci_day.append(ci)
#+end_src

#+RESULTS:
: X (3, 3, 64, 444, 84)
: X (36, 64, 84)
: phi (36, 64) 0.0 359.9398412457152
: X (3, 3, 64, 444, 84)
: X (36, 64, 84)
: phi (36, 64) 0.611908029910187 359.8651881568341
: X (3, 3, 64, 444, 84)
: X (36, 64, 84)
: phi (36, 64) 0.5353325172432484 359.7536377076096

#+begin_src ipython
  cmap = plt.get_cmap('Blues')
  colors = [cmap((i+1)/len(options['days'])) for i in range(len(options['days']))]
#+end_src

#+RESULTS:

#+begin_src ipython
for i, day in enumerate(options['days']):
      plt.plot(np.linspace(0, 360, landscape.shape[0]), circcvl(energy_day[i], windowSize=10) * 100, color=colors[i])

plt.xlabel('Pref Loc (°)')
plt.ylabel('Energy')

plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_42.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Energy

#+begin_src ipython
    opts = set_options(T_WINDOW=0.0)
    bins0 = None
    bins = None
    # bins = np.concatenate( (opts['bins_BL'], opts['bins_ED'], opts['bins_MD'], opts['bins_LD']))
    # bins = np.concatenate( (opts['bins_BL'], opts['bins_ED']))
    # bins0 = opts['bins_ED']
    # bins = np.concatenate( (opts['bins_BL'], opts['bins_STIM'], opts['bins_ED']))
    # bins = np.concatenate( (opts['bins_BL'], opts['bins_ED'], opts['bins_MD'], opts['bins_LD']))
    # bins = opts['bins_PRE_DIST']
    bins = opts['bins_DELAY']

    # bins = np.concatenate( (opts['bins_BL'], opts['bins_ED']))
#+end_src

#+RESULTS:

#+begin_src ipython
  task = 0
  kwargs['task'] = task

  num_bins = 96
  print('num_bins', num_bins)

  window = 0.1
  print('window', window)

  IF_HMM = 0
  n_iter = 100
  IF_BOOT=0
  IF_NORM=0
#+end_src

#+RESULTS:
: num_bins 96
: window 0.1

#+begin_src ipython
  energy_day = []
  ci_day = []

  for i, day in enumerate(options['days']):
      energy, ci = get_energy(X_list[i], y_list[i], task, num_bins, bins, bins0, window, IF_BOOT, IF_NORM, IF_HMM, n_iter)
      energy_day.append(energy)
      ci_day.append(ci)
#+end_src

#+RESULTS:

#+begin_src ipython
  from scipy.signal import find_peaks
  import numpy as np

  def find_minima(energy, ax, color, window=0.1, prominence=1, distance=90, height=0.5):
      energy = energy[1:]
      windowSize = int(window * energy.shape[0])

      # Smooth the energy data
      # window = np.ones(windowSize) / windowSize
      # energy_smoothed = np.convolve(energy, window, mode='same')
      energy_smoothed = circcvl(energy, windowSize=windowSize)

      # Invert the energy to find minima as peaks
      inv_energy = np.max(energy_smoothed) - energy_smoothed
      # inv_energy = np.mean(energy_smoothed) - energy_smoothed

      # Find peaks with higher prominence for global minima identification
      peaks, properties = find_peaks(inv_energy, prominence=prominence, distance=distance, height=height)

      theta = np.linspace(0, 360, energy.shape[0], endpoint=False)
      minima_angles = theta[peaks]
      minima_energy = energy[peaks]

      # Filter out closely spaced minima based on the threshold
      filtered_minima_angles = []
      filtered_minima_energy = []

      for i in range(len(minima_angles)):
          if minima_energy[i]>0:
              filtered_minima_angles.append(minima_angles[i])
              filtered_minima_energy.append(0)

      print(filtered_minima_angles)
      # print(minima_energy)

      # Plot results
      ax.plot(filtered_minima_angles[:2], filtered_minima_energy[:2], 'o', color=color, ms=10)

      # if len(filtered_minima_angles) >= 2:
      #     angular_distances = np.abs(filtered_minima_angles[0] % 180 - filtered_minima_angles[1] % 180)
      #     print(f"The distance between the two main minima is {angular_distances} degrees.")
      # else:
      #     print("Less than two main minima found.")

      return filtered_minima_angles[:2], filtered_minima_energy[:2]
#+end_src

#+RESULTS:

#+begin_src ipython
from matplotlib.patches import Circle

def plot_fix_points(phi, ax, color='k', title=''):

    x = np.cos(phi)
    y = np.sin(phi)

    ax.plot(x, y, 'o', ms=15, color=color, markeredgecolor='k')
    circle = Circle((0., 0.), 1, fill=False, edgecolor='k')
    ax.add_patch(circle)

    ax.set_aspect('equal')
    ax.set_title(title)
    ax.axis('off')
#+end_src

#+RESULTS:

#+begin_src ipython
  days = options['days']
  cmap = plt.get_cmap('Blues')
  colors = [cmap((i+1)/len(options['days'])) for i in range(len(options['days']))]
  window = .1

  min_angles, min_energies = [], []
  theta = np.linspace(0, 360, energy_day[0].shape[0], endpoint=False)
  windowSize = int(window * energy_day[0].shape[0])

  fig, ax = plt.subplots(1, 2, figsize= [2*width, height])
  for i, day in enumerate(options['days']):
      plot_theta_energy(0, energy_day[i], ci_day[i],
                        window=window, ax=ax[0], SMOOTH=1, color=colors[i])

      minima = find_multiple_minima_from_values(theta, circcvl(energy_day[i]*100, windowSize), num_minima=2,
                                                num_runs=360, tol=.1, ax=ax[0], min_distance=40, popsize=1, color=colors[i])
      # print(minima)
      plot_fix_points(np.array(minima[:2]) * np.pi / 180.0, ax[1], color=colors[i])
      min_angles.append(minima[:2])
      # maxima = find_multiple_minima_from_values(theta, -circcvl(energy_day[i][1:]*100, windowSize), num_minima=10, num_runs=1000,
      #                                           tol=.01, ax=ax[0],
      #                                           min_distance=0, popsize=1, color='w')
      # # print(maxima)
      # plot_fix_points(np.array(maxima[:2]) * np.pi / 180.0, ax[1], color='w')

  fig.savefig('./cosyne/%s_landscape_days.svg' % options['mouse'], dpi=300)
  # fig.savefig('./cosyne/%s_landscape_days.svg' % options['mouse'], dpi=300)
#+end_src

#+RESULTS:
[[./figures/landscape/figure_49.png]]

 #+begin_src ipython
print(min_angles)
a = np.array(min_angles[:])
pkl_save(a, 'minima_%s' % options['mouse'], path=".")
#+end_src

#+RESULTS:
: [[27.814288319019422, 121.47710789250513], [354.37476510895465, 163.77766964907946], [206.38321738390303, 38.692533620273146]]

#+begin_src ipython
plt.plot((np.sin(a[:,0]*np.pi/180)+np.sin(a[:,1]*np.pi/180))/2, '-o')
plt.xlabel('Day')
plt.ylabel('Y-location')
fig.savefig('./cosyne/%s_land_y.svg' % options['mouse'], dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_51.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

#+begin_src ipython
yloc = []
for mouse in options['mice']:
    a = pkl_load('minima_%s' % mouse, path=".")
    if a.shape[0]==5:
        a = np.vstack((a, [np.nan, np.nan]))
    yloc.append(a)
yloc = np.array(yloc[:])
yloc_mean = np.nanmean(np.array(yloc[:]), 0)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
Cell In[246], line 3
      1 yloc = []
      2 for mouse in options['mice']:
----> 3     a = pkl_load('minima_%s' % mouse, path=".")
      4     if a.shape[0]==5:
      5         a = np.vstack((a, [np.nan, np.nan]))

Cell In[11], line 8, in pkl_load(name, path)
      7 def pkl_load(name, path="."):
----> 8     return pkl.load(open(path + "/" + name + '.pkl', "rb"))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284, in _modified_open(file, *args, **kwargs)
    277 if file in {0, 1, 2}:
    278     raise ValueError(
    279         f"IPython won't let you open fd={file} by default "
    280         "as it is likely to crash IPython. If you know what you are doing, "
    281         "you can use builtins' open."
    282     )
--> 284 return io_open(file, *args, **kwargs)

FileNotFoundError: [Errno 2] No such file or directory: './minima_JawsM01.pkl'
#+end_example
:END:

#+begin_src ipython
print(yloc.shape)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AttributeError                            Traceback (most recent call last)
: Cell In[247], line 1
: ----> 1 print(yloc.shape)
:
: AttributeError: 'list' object has no attribute 'shape'
:END:

#+begin_src ipython
for i in range(yloc.shape[0]):
    plt.plot(np.arange(1, 7), (np.sin(yloc[i,:,0]*np.pi/180)+np.sin(yloc[i,:,1]*np.pi/180))/2, '-o', alpha=0.1)
plt.plot(np.arange(1, 7), (np.sin(yloc_mean[:,0]*np.pi/180)+np.sin(yloc_mean[:,1]*np.pi/180))/2, '-ko')
plt.axhline(0, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('GnG-projection')
plt.xticks([1,2,3,4,5,6])
plt.savefig('./cosyne/landscape_yloc.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AttributeError                            Traceback (most recent call last)
: Cell In[248], line 1
: ----> 1 for i in range(yloc.shape[0]):
:       2     plt.plot(np.arange(1, 7), (np.sin(yloc[i,:,0]*np.pi/180)+np.sin(yloc[i,:,1]*np.pi/180))/2, '-o', alpha=0.1)
:       3 plt.plot(np.arange(1, 7), (np.sin(yloc_mean[:,0]*np.pi/180)+np.sin(yloc_mean[:,1]*np.pi/180))/2, '-ko')
:
: AttributeError: 'list' object has no attribute 'shape'
:END:

#+begin_src ipython
ang_list = []
for mouse in options['mice']:
    angle = pkl_load('angle_%s' % mouse, path=".")
    if len(angle) ==5:
        angle = np.hstack( (angle, np.nan))

    ang_list.append(angle)
ang_list = np.array(ang_list)
#+end_src

#+RESULTS:

#+begin_src ipython
print(ang_list)
#+end_src
#+RESULTS:
: [[89. 81. nan nan nan nan]
:  [90. 89. 87. nan nan nan]
:  [90. 89. 90. nan nan nan]
:  [95. 89. 89. nan nan nan]
:  [90. 91. 89. nan nan nan]]

#+begin_src ipython
for i in range(yloc.shape[0]):
    plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)
plt.plot(np.arange(1, 7), np.nanmean(ang_list, 0), '-ko')
plt.axhline(90, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Angle A/B-GnG (°)')
plt.xticks([1,2,3,4,5,6])
plt.savefig('./cosyne/landscape_angle.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AttributeError                            Traceback (most recent call last)
: Cell In[251], line 1
: ----> 1 for i in range(yloc.shape[0]):
:       2     plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)
:       3 plt.plot(np.arange(1, 7), np.nanmean(ang_list, 0), '-ko')
:
: AttributeError: 'list' object has no attribute 'shape'
:END:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Sample data
# yloc, ang_list = ... (Ensure these are defined appropriately)

confidence_level = 0.95

mean_angles = np.nanmean(ang_list, axis=0)
n = ang_list.shape[0]

# Standard error of the mean
sem = stats.sem(ang_list, axis=0, nan_policy='omit')

# Compute confidence intervals
confidence_intervals = stats.t.interval(confidence_level, n-1, loc=mean_angles, scale=sem)

# Plotting
for i in range(yloc.shape[0]):
    plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)

plt.plot(np.arange(1, 7), mean_angles, '-ko', label='Mean')

# Plot confidence intervals
plt.fill_between(np.arange(1, 7), confidence_intervals[0], confidence_intervals[1], color='gray', alpha=0.2, label='Confidence Interval')

plt.axhline(90, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Angle A/B-GnG (°)')
plt.xticks([1, 2, 3, 4, 5, 6])

plt.savefig('./cosyne/landscape_angle.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AttributeError                            Traceback (most recent call last)
: Cell In[252], line 20
:      17 confidence_intervals = stats.t.interval(confidence_level, n-1, loc=mean_angles, scale=sem)
:      19 # Plotting
: ---> 20 for i in range(yloc.shape[0]):
:      21     plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)
:      23 plt.plot(np.arange(1, 7), mean_angles, '-ko', label='Mean')
:
: AttributeError: 'list' object has no attribute 'shape'
:END:

   #+begin_src ipython
   import numpy as np
   import matplotlib.pyplot as plt
   from scipy import stats

   # Function to perform bootstrap resampling
   def bootstrap_conf_int(data, num_samples=1000, confidence_level=0.95):
       bootstrap_samples = np.random.choice(data, (num_samples, len(data)), replace=True)
       bootstrap_means = np.nanmean(bootstrap_samples, axis=1)
       lower_bound = np.nanpercentile(bootstrap_means, (1 - confidence_level) / 2 * 100)
       upper_bound = np.nanpercentile(bootstrap_means, (1 + confidence_level) / 2 * 100)
       return lower_bound, upper_bound

   # Sample data
   mean_angles = np.nanmean(ang_list, axis=0)
   lower_bounds, upper_bounds = [], []

   for i in range(mean_angles.size):
       lb, ub = bootstrap_conf_int(ang_list[:, i])
       lower_bounds.append(lb)
       upper_bounds.append(ub)

   # Plotting
   for i in range(yloc.shape[0]):
       plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)

   plt.plot(np.arange(1, 7), mean_angles, '-ko', label='Mean')

   # Plot bootstrap confidence intervals
   plt.fill_between(np.arange(1, 7), lower_bounds, upper_bounds, color='gray', alpha=0.1, label='Bootstrap CI')

   plt.axhline(90, ls='--', color='k')
   plt.xlabel('Day')
   plt.ylabel('Angle A/B-GnG (°)')
   plt.xticks([1, 2, 3, 4, 5, 6])

   plt.savefig('./cosyne/landscape_angle.svg', dpi=300)
   plt.show()
   #+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: AttributeError                            Traceback (most recent call last)
: Cell In[253], line 23
:      20     upper_bounds.append(ub)
:      22 # Plotting
: ---> 23 for i in range(yloc.shape[0]):
:      24     plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)
:      26 plt.plot(np.arange(1, 7), mean_angles, '-ko', label='Mean')
:
: AttributeError: 'list' object has no attribute 'shape'
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Sample data
# yloc, ang_list = ... # Ensure these are already defined

# Function to calculate the mean of the sample
def mean_func(data, axis):
    return np.nanmean(data, axis=axis)

# Bootstrapping using scipy.stats.bootstrap
confidence_level = 0.95
lower_bounds, upper_bounds = [], []

# Calculate the bootstrap confidence intervals for each day
for i in range(ang_list.shape[1]):
    res = stats.bootstrap((ang_list[:, i],), mean_func, vectorized=True, n_resamples=1000, confidence_level=confidence_level, method='percentile')
    lower_bounds.append(res.confidence_interval.low)
    upper_bounds.append(res.confidence_interval.high)

mean_angles = np.nanmean(ang_list, axis=0)

# Plotting
for i in range(yloc.shape[0]):
    plt.plot(np.arange(1, 7), ang_list[i], '-o', alpha=0.1)

plt.plot(np.arange(1, 7), mean_angles, '-ko', label='Mean')

# Plot bootstrap confidence intervals
plt.fill_between(np.arange(1, 7), lower_bounds, upper_bounds, color='gray', alpha=0.2, label='Bootstrap CI')

plt.axhline(90, ls='--', color='k')
plt.xlabel('Day')
plt.ylabel('Angle A/B-GnG (°)')
plt.xticks([1, 2, 3, 4, 5, 6])

plt.savefig('./cosyne/landscape_angle.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: [0;31m---------------------------------------------------------------------------[0m
: [0;31mAttributeError[0m                            Traceback (most recent call last)
: Cell [0;32mIn[254], line 25[0m
: [1;32m     22[0m mean_angles [38;5;241m=[39m np[38;5;241m.[39mnanmean(ang_list, axis[38;5;241m=[39m[38;5;241m0[39m)
: [1;32m     24[0m [38;5;66;03m# Plotting[39;00m
: [0;32m---> 25[0m [38;5;28;01mfor[39;00m i [38;5;129;01min[39;00m [38;5;28mrange[39m([41myloc[49m[38;5;241;41m.[39;49m[41mshape[49m[[38;5;241m0[39m]):
: [1;32m     26[0m     plt[38;5;241m.[39mplot(np[38;5;241m.[39marange([38;5;241m1[39m, [38;5;241m7[39m), ang_list[i], [38;5;124m'[39m[38;5;124m-o[39m[38;5;124m'[39m, alpha[38;5;241m=[39m[38;5;241m0.1[39m)
: [1;32m     28[0m plt[38;5;241m.[39mplot(np[38;5;241m.[39marange([38;5;241m1[39m, [38;5;241m7[39m), mean_angles, [38;5;124m'[39m[38;5;124m-ko[39m[38;5;124m'[39m, label[38;5;241m=[39m[38;5;124m'[39m[38;5;124mMean[39m[38;5;124m'[39m)
:
: [0;31mAttributeError[0m: 'list' object has no attribute 'shape'
:END:
